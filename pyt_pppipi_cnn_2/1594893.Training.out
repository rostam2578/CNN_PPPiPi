0: gpu031.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-6a8b37c1-dc08-9ec1-db57-64a21f01a4ec)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        69:2F:B4:1D:24:AA:21:BC:48:5B:A0:14:1E:6E:F5:F4:C8:D8:A0:D4
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Wed Aug 31 15:35:21 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   40C    P0    44W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b2dd99658e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m37.964s
user	0m2.961s
sys	0m2.086s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 







 Loading data ... 



training set shape (20000, 43, 288) 
sum 5279207

target set shape (20000, 6796) 
sum 4575851
Net(
  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=667776, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=6796, bias=True)
)

number of the free parameters: 171805196
parameters of the network conv1.weight 
 torch.Size([256, 1, 3, 3]) 
 True 
 tensor([[[[-0.0409, -0.3082, -0.2109],
          [-0.3072, -0.2454,  0.0673],
          [ 0.2932, -0.1293,  0.1658]]],


        [[[ 0.1011, -0.1918,  0.0271],
          [ 0.1713,  0.3208,  0.0346],
          [-0.3014,  0.0895,  0.2629]]],


        [[[-0.0422,  0.1202,  0.2165],
          [ 0.1142,  0.1862,  0.2644],
          [-0.0165, -0.3197, -0.3199]]],


        ...,


        [[[-0.1969,  0.1698,  0.3235],
          [-0.2294,  0.3260, -0.0259],
          [ 0.0255, -0.0572,  0.0672]]],


        [[[ 0.0224,  0.3318,  0.1409],
          [ 0.2592,  0.2413, -0.0020],
          [ 0.1931,  0.1969, -0.1325]]],


        [[[ 0.1216,  0.0269, -0.2082],
          [ 0.2597,  0.0930,  0.1914],
          [ 0.0775,  0.0985, -0.0221]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[-0.0409, -0.3082, -0.2109],
          [-0.3072, -0.2454,  0.0673],
          [ 0.2932, -0.1293,  0.1658]]],


        [[[ 0.1011, -0.1918,  0.0271],
          [ 0.1713,  0.3208,  0.0346],
          [-0.3014,  0.0895,  0.2629]]],


        [[[-0.0422,  0.1202,  0.2165],
          [ 0.1142,  0.1862,  0.2644],
          [-0.0165, -0.3197, -0.3199]]],


        ...,


        [[[-0.1969,  0.1698,  0.3235],
          [-0.2294,  0.3260, -0.0259],
          [ 0.0255, -0.0572,  0.0672]]],


        [[[ 0.0224,  0.3318,  0.1409],
          [ 0.2592,  0.2413, -0.0020],
          [ 0.1931,  0.1969, -0.1325]]],


        [[[ 0.1216,  0.0269, -0.2082],
          [ 0.2597,  0.0930,  0.1914],
          [ 0.0775,  0.0985, -0.0221]]]], device='cuda:0', requires_grad=True)
parameters of the network conv1.bias 
 torch.Size([256]) 
 True 
 tensor([ 2.2542e-01,  1.7748e-01,  2.3261e-02,  3.1090e-01,  2.3466e-01,
         1.3388e-01, -2.7490e-01, -2.6748e-01,  1.4134e-03,  1.5057e-01,
        -8.6245e-02, -2.6525e-01,  1.1538e-01,  5.0001e-02, -1.2438e-01,
         1.8601e-01, -1.7948e-01,  2.1573e-01, -2.4648e-01, -1.9266e-01,
         2.2896e-01,  1.9355e-01, -2.9198e-01,  1.3913e-01,  2.6255e-01,
         2.3156e-01, -1.7553e-01,  6.2780e-02, -5.8069e-02,  2.3251e-01,
        -8.9037e-02, -1.7244e-01, -1.2636e-01,  2.9649e-03, -2.7310e-01,
         1.9693e-01,  7.7334e-02,  5.2527e-03, -1.9220e-01, -4.5235e-02,
         1.5544e-01, -2.8004e-01,  4.3943e-02, -2.5929e-01,  3.0796e-01,
         2.0548e-02,  2.6259e-01,  3.2438e-01, -1.2852e-01,  9.0584e-02,
        -2.7177e-01, -1.7813e-01,  1.3870e-01, -1.6958e-01,  1.0858e-01,
         4.8864e-02, -2.4826e-01, -1.4004e-01, -2.1277e-01, -4.9884e-02,
        -8.3426e-02, -2.0654e-01,  1.2918e-01,  5.6649e-02, -2.6845e-01,
        -7.1091e-02, -2.5343e-01,  8.0517e-02, -2.0710e-01, -2.0949e-02,
         2.4253e-02, -1.2381e-01, -1.5254e-01, -2.5804e-02, -7.1214e-02,
        -2.3652e-01, -1.5332e-01,  1.7581e-01,  7.2996e-02,  2.0846e-01,
         1.9197e-01,  2.2977e-02,  1.8834e-01, -1.5853e-01, -2.8334e-01,
         1.2055e-01, -2.7946e-01,  1.3091e-01,  1.8368e-01,  2.5232e-01,
         3.1802e-01,  2.2305e-01,  2.3376e-01,  7.2847e-02,  1.2029e-02,
         3.1770e-01, -1.5782e-01, -2.7427e-01,  9.8614e-02, -1.7891e-01,
        -1.2319e-02, -3.2840e-01,  7.5003e-02,  2.1940e-01, -1.9390e-01,
         1.8856e-02,  8.1723e-02,  1.9782e-01,  1.9476e-01,  1.0180e-01,
        -3.3022e-01,  1.2055e-01, -1.9441e-01,  2.7371e-01, -3.2351e-01,
        -1.2358e-01, -1.2934e-01, -7.2951e-02,  1.4434e-02, -2.5932e-01,
         2.8013e-01, -1.3560e-02,  2.7679e-02, -4.6931e-02, -2.6278e-01,
         2.7357e-01,  3.9402e-02,  2.7980e-01,  1.1123e-01, -3.1931e-01,
        -2.6045e-01,  2.2631e-01, -1.0454e-02,  4.9794e-02,  2.5452e-01,
         7.9919e-02,  1.3490e-01,  3.2478e-01,  6.2082e-02,  3.7336e-02,
        -1.3755e-01, -3.0342e-01, -3.1680e-01,  2.3947e-03,  1.8163e-01,
         2.1120e-01,  5.4269e-02,  2.1272e-01, -3.4202e-02, -8.4988e-02,
        -1.1970e-01, -5.3938e-02,  2.6556e-01,  2.9950e-01, -7.7594e-02,
        -2.1659e-01,  2.2464e-01,  1.1501e-02,  4.0371e-02, -3.0528e-01,
        -3.3078e-01, -2.2485e-01, -9.1970e-02, -2.6574e-01, -1.3463e-01,
         2.4626e-02,  1.5394e-01,  1.0984e-01, -1.0719e-01, -4.2206e-02,
         1.6927e-01,  1.1908e-01,  1.7778e-01,  2.5589e-01,  2.5388e-01,
         5.5536e-02,  1.4015e-01,  6.4052e-02,  2.2347e-02, -2.5611e-01,
        -1.2699e-03,  1.9465e-02, -1.4431e-01,  2.0742e-01,  9.8707e-02,
        -1.8669e-01,  3.9591e-03, -2.2427e-01,  2.8341e-01, -3.3238e-02,
        -2.4027e-01, -3.2669e-01, -3.2186e-01, -1.4754e-01,  1.3309e-03,
         5.4968e-02,  9.2520e-02,  3.0864e-01,  1.5310e-01, -1.8248e-02,
        -3.6560e-02, -3.2094e-01, -5.1758e-02, -1.4030e-01,  2.4768e-01,
        -1.8827e-02,  4.6364e-03,  1.1258e-01, -1.1419e-01,  2.4500e-01,
        -2.1063e-01,  3.0034e-01, -2.9567e-03, -5.9640e-02, -7.2551e-02,
         1.5555e-01, -1.1086e-01, -1.4473e-01,  1.3764e-01,  7.5192e-02,
         4.2590e-02,  1.2495e-01,  1.7135e-01,  2.2874e-03, -1.6173e-01,
        -2.7035e-02,  8.1187e-02, -1.2443e-01,  1.9427e-01,  1.1182e-01,
        -2.5706e-01, -1.9651e-01, -2.5378e-01, -2.7540e-02, -3.0560e-01,
         4.8095e-02,  1.2075e-01, -2.4958e-01, -1.1672e-01,  3.0577e-04,
         2.2317e-01, -2.3482e-01, -1.1495e-01, -5.2952e-02, -2.7739e-01,
         4.2423e-02, -2.9880e-01,  1.8476e-01, -1.1107e-01,  1.6032e-01,
         1.0563e-01, -1.3547e-01, -2.4445e-01,  2.4353e-01, -1.6200e-01,
        -2.3387e-01], device='cuda:0') 
 Parameter containing:
tensor([ 2.2542e-01,  1.7748e-01,  2.3261e-02,  3.1090e-01,  2.3466e-01,
         1.3388e-01, -2.7490e-01, -2.6748e-01,  1.4134e-03,  1.5057e-01,
        -8.6245e-02, -2.6525e-01,  1.1538e-01,  5.0001e-02, -1.2438e-01,
         1.8601e-01, -1.7948e-01,  2.1573e-01, -2.4648e-01, -1.9266e-01,
         2.2896e-01,  1.9355e-01, -2.9198e-01,  1.3913e-01,  2.6255e-01,
         2.3156e-01, -1.7553e-01,  6.2780e-02, -5.8069e-02,  2.3251e-01,
        -8.9037e-02, -1.7244e-01, -1.2636e-01,  2.9649e-03, -2.7310e-01,
         1.9693e-01,  7.7334e-02,  5.2527e-03, -1.9220e-01, -4.5235e-02,
         1.5544e-01, -2.8004e-01,  4.3943e-02, -2.5929e-01,  3.0796e-01,
         2.0548e-02,  2.6259e-01,  3.2438e-01, -1.2852e-01,  9.0584e-02,
        -2.7177e-01, -1.7813e-01,  1.3870e-01, -1.6958e-01,  1.0858e-01,
         4.8864e-02, -2.4826e-01, -1.4004e-01, -2.1277e-01, -4.9884e-02,
        -8.3426e-02, -2.0654e-01,  1.2918e-01,  5.6649e-02, -2.6845e-01,
        -7.1091e-02, -2.5343e-01,  8.0517e-02, -2.0710e-01, -2.0949e-02,
         2.4253e-02, -1.2381e-01, -1.5254e-01, -2.5804e-02, -7.1214e-02,
        -2.3652e-01, -1.5332e-01,  1.7581e-01,  7.2996e-02,  2.0846e-01,
         1.9197e-01,  2.2977e-02,  1.8834e-01, -1.5853e-01, -2.8334e-01,
         1.2055e-01, -2.7946e-01,  1.3091e-01,  1.8368e-01,  2.5232e-01,
         3.1802e-01,  2.2305e-01,  2.3376e-01,  7.2847e-02,  1.2029e-02,
         3.1770e-01, -1.5782e-01, -2.7427e-01,  9.8614e-02, -1.7891e-01,
        -1.2319e-02, -3.2840e-01,  7.5003e-02,  2.1940e-01, -1.9390e-01,
         1.8856e-02,  8.1723e-02,  1.9782e-01,  1.9476e-01,  1.0180e-01,
        -3.3022e-01,  1.2055e-01, -1.9441e-01,  2.7371e-01, -3.2351e-01,
        -1.2358e-01, -1.2934e-01, -7.2951e-02,  1.4434e-02, -2.5932e-01,
         2.8013e-01, -1.3560e-02,  2.7679e-02, -4.6931e-02, -2.6278e-01,
         2.7357e-01,  3.9402e-02,  2.7980e-01,  1.1123e-01, -3.1931e-01,
        -2.6045e-01,  2.2631e-01, -1.0454e-02,  4.9794e-02,  2.5452e-01,
         7.9919e-02,  1.3490e-01,  3.2478e-01,  6.2082e-02,  3.7336e-02,
        -1.3755e-01, -3.0342e-01, -3.1680e-01,  2.3947e-03,  1.8163e-01,
         2.1120e-01,  5.4269e-02,  2.1272e-01, -3.4202e-02, -8.4988e-02,
        -1.1970e-01, -5.3938e-02,  2.6556e-01,  2.9950e-01, -7.7594e-02,
        -2.1659e-01,  2.2464e-01,  1.1501e-02,  4.0371e-02, -3.0528e-01,
        -3.3078e-01, -2.2485e-01, -9.1970e-02, -2.6574e-01, -1.3463e-01,
         2.4626e-02,  1.5394e-01,  1.0984e-01, -1.0719e-01, -4.2206e-02,
         1.6927e-01,  1.1908e-01,  1.7778e-01,  2.5589e-01,  2.5388e-01,
         5.5536e-02,  1.4015e-01,  6.4052e-02,  2.2347e-02, -2.5611e-01,
        -1.2699e-03,  1.9465e-02, -1.4431e-01,  2.0742e-01,  9.8707e-02,
        -1.8669e-01,  3.9591e-03, -2.2427e-01,  2.8341e-01, -3.3238e-02,
        -2.4027e-01, -3.2669e-01, -3.2186e-01, -1.4754e-01,  1.3309e-03,
         5.4968e-02,  9.2520e-02,  3.0864e-01,  1.5310e-01, -1.8248e-02,
        -3.6560e-02, -3.2094e-01, -5.1758e-02, -1.4030e-01,  2.4768e-01,
        -1.8827e-02,  4.6364e-03,  1.1258e-01, -1.1419e-01,  2.4500e-01,
        -2.1063e-01,  3.0034e-01, -2.9567e-03, -5.9640e-02, -7.2551e-02,
         1.5555e-01, -1.1086e-01, -1.4473e-01,  1.3764e-01,  7.5192e-02,
         4.2590e-02,  1.2495e-01,  1.7135e-01,  2.2874e-03, -1.6173e-01,
        -2.7035e-02,  8.1187e-02, -1.2443e-01,  1.9427e-01,  1.1182e-01,
        -2.5706e-01, -1.9651e-01, -2.5378e-01, -2.7540e-02, -3.0560e-01,
         4.8095e-02,  1.2075e-01, -2.4958e-01, -1.1672e-01,  3.0577e-04,
         2.2317e-01, -2.3482e-01, -1.1495e-01, -5.2952e-02, -2.7739e-01,
         4.2423e-02, -2.9880e-01,  1.8476e-01, -1.1107e-01,  1.6032e-01,
         1.0563e-01, -1.3547e-01, -2.4445e-01,  2.4353e-01, -1.6200e-01,
        -2.3387e-01], device='cuda:0', requires_grad=True)
parameters of the network conv2.weight 
 torch.Size([128, 256, 3, 3]) 
 True 
 tensor([[[[ 1.6188e-03, -1.5726e-03, -1.4744e-02],
          [-3.2339e-04, -2.0337e-02, -2.3174e-03],
          [ 1.9752e-02,  9.4876e-03, -8.0680e-03]],

         [[ 9.1026e-03, -1.4061e-02, -3.0521e-03],
          [ 1.3605e-02,  1.0808e-02,  1.4680e-02],
          [ 1.1409e-02,  1.5506e-03,  1.5183e-02]],

         [[-3.9360e-03, -3.6660e-03,  4.8315e-04],
          [ 1.7056e-02,  4.9052e-03,  5.8022e-03],
          [-1.2567e-02,  4.5479e-03,  1.4286e-02]],

         ...,

         [[ 1.8257e-02, -4.1608e-03,  1.7332e-02],
          [-1.4423e-02,  7.0036e-03, -1.1752e-02],
          [-4.5203e-03, -1.1150e-03,  1.8516e-02]],

         [[-1.7013e-02, -5.5944e-03, -1.3263e-02],
          [-1.7972e-02,  1.4380e-02,  9.3353e-03],
          [ 9.7420e-03,  1.5347e-02,  4.1629e-03]],

         [[-1.3873e-02,  2.3653e-03, -1.5926e-02],
          [-8.9209e-03,  1.3861e-02, -8.3966e-03],
          [-9.6114e-03, -1.4976e-02,  1.9430e-02]]],


        [[[ 1.0431e-02, -1.8536e-02,  3.6786e-03],
          [-9.3259e-03, -4.8685e-03, -4.4686e-03],
          [ 9.9120e-03,  7.7058e-04, -1.4102e-02]],

         [[ 1.1161e-02,  1.3878e-02, -1.9506e-02],
          [ 1.9376e-02, -1.3464e-02,  1.2885e-02],
          [-8.1867e-03,  3.4777e-03,  1.5633e-02]],

         [[-8.8553e-04,  1.6956e-02,  1.7479e-02],
          [ 1.4173e-02,  9.0305e-03,  9.6289e-03],
          [-1.5346e-02,  7.6984e-03,  9.7603e-03]],

         ...,

         [[ 1.3078e-02, -9.0386e-03,  1.7282e-02],
          [ 1.8312e-02,  1.5902e-02, -1.7877e-02],
          [ 2.0732e-02,  5.3694e-04, -1.9911e-02]],

         [[ 1.7714e-02,  9.1841e-03, -1.3080e-03],
          [-1.7078e-02,  2.4292e-03,  2.7979e-03],
          [ 1.8381e-02,  1.5937e-02, -1.4076e-02]],

         [[-1.2429e-02, -1.8524e-02, -3.5657e-03],
          [ 8.5626e-03,  1.0883e-02, -1.5966e-02],
          [ 1.6121e-02, -4.0653e-03, -1.2767e-02]]],


        [[[-2.0757e-02,  1.3487e-02,  1.1994e-02],
          [-5.5823e-03,  5.3143e-05,  2.4316e-03],
          [ 6.1682e-03, -1.0490e-02,  1.9744e-02]],

         [[ 1.4398e-02,  1.8687e-02, -2.0468e-02],
          [ 1.3918e-02,  5.5943e-03, -9.9418e-04],
          [ 7.2682e-03, -1.5645e-02,  1.4963e-02]],

         [[ 8.0979e-03, -2.0644e-02, -1.9238e-02],
          [-1.1692e-02, -5.4833e-03,  1.6075e-02],
          [ 1.7163e-02, -1.2692e-02,  1.1399e-02]],

         ...,

         [[-9.9897e-03, -1.1529e-02, -1.5877e-02],
          [ 3.2124e-03,  7.1867e-03, -3.6218e-03],
          [-5.0613e-03,  8.2018e-03,  2.5021e-03]],

         [[-1.7951e-02, -7.1079e-03, -2.0719e-02],
          [ 6.5039e-03,  3.8756e-03, -1.9313e-02],
          [-1.4121e-02, -1.4525e-03,  1.7532e-02]],

         [[-1.3040e-02, -1.7676e-02,  9.8318e-03],
          [ 1.1497e-02,  2.0258e-02, -2.0655e-02],
          [ 4.5539e-03, -4.8338e-03,  1.9269e-02]]],


        ...,


        [[[ 1.1395e-02, -1.1216e-02, -1.0999e-02],
          [-9.6541e-03, -4.7683e-03,  1.3675e-02],
          [ 1.9193e-02, -1.8958e-02,  9.8688e-03]],

         [[ 1.4922e-02, -1.6412e-02, -1.6646e-02],
          [-3.3418e-03,  1.7214e-02,  1.2542e-02],
          [-2.0567e-02,  7.5062e-03,  1.2927e-02]],

         [[ 3.0905e-03, -1.0903e-04,  4.4774e-03],
          [ 1.5768e-02,  3.9797e-03, -1.8900e-02],
          [ 1.4671e-02, -5.6660e-03, -1.4550e-02]],

         ...,

         [[-1.0139e-02, -1.8617e-02, -8.6239e-03],
          [ 1.4483e-02, -1.5176e-02, -4.2803e-03],
          [ 1.4593e-02, -2.1055e-03, -1.8029e-02]],

         [[ 4.8076e-03,  1.9594e-02, -2.6995e-03],
          [ 5.7331e-03,  3.6000e-03,  1.1691e-02],
          [-3.2996e-03, -7.7230e-03,  1.9604e-02]],

         [[ 1.4269e-03,  1.1323e-02,  1.2626e-02],
          [-7.0050e-03,  2.3432e-04,  8.6081e-03],
          [-1.2762e-02, -1.4132e-02,  1.2677e-03]]],


        [[[ 1.6194e-02, -1.7634e-02,  1.2762e-02],
          [-2.2638e-03,  1.0247e-02, -7.2364e-03],
          [-5.7017e-04,  1.4898e-02, -3.7035e-03]],

         [[-1.0670e-02,  1.6617e-02, -1.6849e-02],
          [-4.7079e-03,  1.6690e-02, -4.0025e-03],
          [ 1.4537e-02,  1.8017e-02,  1.3504e-02]],

         [[-1.5079e-02,  8.6930e-03, -7.6810e-03],
          [-1.8313e-02,  1.2881e-02,  6.4295e-03],
          [ 4.0532e-03,  2.0698e-02, -1.7097e-02]],

         ...,

         [[-1.2287e-03,  2.0595e-02,  1.7386e-02],
          [ 1.9125e-03, -1.5656e-02,  6.2358e-03],
          [ 5.8951e-03, -1.5081e-02,  1.6625e-02]],

         [[-1.9769e-02, -1.1746e-02, -1.2168e-03],
          [ 1.3043e-02,  1.5916e-02, -3.3693e-03],
          [ 1.3123e-02, -1.2071e-02, -5.3984e-03]],

         [[-1.7381e-02,  1.7318e-02,  9.6601e-03],
          [-2.3793e-03,  8.3735e-03,  1.6388e-02],
          [-4.7767e-03, -5.0455e-03,  1.6524e-02]]],


        [[[-1.7592e-02, -3.2817e-04, -1.5809e-02],
          [-9.7470e-03,  9.9257e-03, -1.9466e-02],
          [-1.4915e-02, -9.8718e-04,  1.3872e-02]],

         [[ 1.5578e-02, -1.3965e-02,  1.0752e-02],
          [-4.7126e-03,  1.5298e-02,  9.0604e-03],
          [-2.7974e-03, -9.4266e-03, -2.0026e-02]],

         [[-1.4807e-02, -1.6235e-02, -1.7307e-03],
          [-1.9745e-02,  1.8929e-02, -1.9453e-03],
          [-8.9778e-03,  3.1476e-03,  1.6151e-02]],

         ...,

         [[-7.8857e-03,  2.0827e-02,  4.5902e-03],
          [ 1.4239e-02,  3.0472e-03, -1.0979e-02],
          [ 1.9726e-02, -1.7844e-02,  1.3557e-02]],

         [[-9.3171e-03,  7.5211e-04,  1.5612e-02],
          [-1.2874e-02, -8.9696e-03,  8.0320e-03],
          [-3.9888e-03,  1.2405e-02, -3.7741e-03]],

         [[ 1.2635e-02, -4.8564e-03,  5.1510e-03],
          [-8.5257e-03, -4.1647e-03, -8.2563e-03],
          [ 2.0355e-03,  7.4000e-03,  1.5827e-02]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 1.6188e-03, -1.5726e-03, -1.4744e-02],
          [-3.2339e-04, -2.0337e-02, -2.3174e-03],
          [ 1.9752e-02,  9.4876e-03, -8.0680e-03]],

         [[ 9.1026e-03, -1.4061e-02, -3.0521e-03],
          [ 1.3605e-02,  1.0808e-02,  1.4680e-02],
          [ 1.1409e-02,  1.5506e-03,  1.5183e-02]],

         [[-3.9360e-03, -3.6660e-03,  4.8315e-04],
          [ 1.7056e-02,  4.9052e-03,  5.8022e-03],
          [-1.2567e-02,  4.5479e-03,  1.4286e-02]],

         ...,

         [[ 1.8257e-02, -4.1608e-03,  1.7332e-02],
          [-1.4423e-02,  7.0036e-03, -1.1752e-02],
          [-4.5203e-03, -1.1150e-03,  1.8516e-02]],

         [[-1.7013e-02, -5.5944e-03, -1.3263e-02],
          [-1.7972e-02,  1.4380e-02,  9.3353e-03],
          [ 9.7420e-03,  1.5347e-02,  4.1629e-03]],

         [[-1.3873e-02,  2.3653e-03, -1.5926e-02],
          [-8.9209e-03,  1.3861e-02, -8.3966e-03],
          [-9.6114e-03, -1.4976e-02,  1.9430e-02]]],


        [[[ 1.0431e-02, -1.8536e-02,  3.6786e-03],
          [-9.3259e-03, -4.8685e-03, -4.4686e-03],
          [ 9.9120e-03,  7.7058e-04, -1.4102e-02]],

         [[ 1.1161e-02,  1.3878e-02, -1.9506e-02],
          [ 1.9376e-02, -1.3464e-02,  1.2885e-02],
          [-8.1867e-03,  3.4777e-03,  1.5633e-02]],

         [[-8.8553e-04,  1.6956e-02,  1.7479e-02],
          [ 1.4173e-02,  9.0305e-03,  9.6289e-03],
          [-1.5346e-02,  7.6984e-03,  9.7603e-03]],

         ...,

         [[ 1.3078e-02, -9.0386e-03,  1.7282e-02],
          [ 1.8312e-02,  1.5902e-02, -1.7877e-02],
          [ 2.0732e-02,  5.3694e-04, -1.9911e-02]],

         [[ 1.7714e-02,  9.1841e-03, -1.3080e-03],
          [-1.7078e-02,  2.4292e-03,  2.7979e-03],
          [ 1.8381e-02,  1.5937e-02, -1.4076e-02]],

         [[-1.2429e-02, -1.8524e-02, -3.5657e-03],
          [ 8.5626e-03,  1.0883e-02, -1.5966e-02],
          [ 1.6121e-02, -4.0653e-03, -1.2767e-02]]],


        [[[-2.0757e-02,  1.3487e-02,  1.1994e-02],
          [-5.5823e-03,  5.3143e-05,  2.4316e-03],
          [ 6.1682e-03, -1.0490e-02,  1.9744e-02]],

         [[ 1.4398e-02,  1.8687e-02, -2.0468e-02],
          [ 1.3918e-02,  5.5943e-03, -9.9418e-04],
          [ 7.2682e-03, -1.5645e-02,  1.4963e-02]],

         [[ 8.0979e-03, -2.0644e-02, -1.9238e-02],
          [-1.1692e-02, -5.4833e-03,  1.6075e-02],
          [ 1.7163e-02, -1.2692e-02,  1.1399e-02]],

         ...,

         [[-9.9897e-03, -1.1529e-02, -1.5877e-02],
          [ 3.2124e-03,  7.1867e-03, -3.6218e-03],
          [-5.0613e-03,  8.2018e-03,  2.5021e-03]],

         [[-1.7951e-02, -7.1079e-03, -2.0719e-02],
          [ 6.5039e-03,  3.8756e-03, -1.9313e-02],
          [-1.4121e-02, -1.4525e-03,  1.7532e-02]],

         [[-1.3040e-02, -1.7676e-02,  9.8318e-03],
          [ 1.1497e-02,  2.0258e-02, -2.0655e-02],
          [ 4.5539e-03, -4.8338e-03,  1.9269e-02]]],


        ...,


        [[[ 1.1395e-02, -1.1216e-02, -1.0999e-02],
          [-9.6541e-03, -4.7683e-03,  1.3675e-02],
          [ 1.9193e-02, -1.8958e-02,  9.8688e-03]],

         [[ 1.4922e-02, -1.6412e-02, -1.6646e-02],
          [-3.3418e-03,  1.7214e-02,  1.2542e-02],
          [-2.0567e-02,  7.5062e-03,  1.2927e-02]],

         [[ 3.0905e-03, -1.0903e-04,  4.4774e-03],
          [ 1.5768e-02,  3.9797e-03, -1.8900e-02],
          [ 1.4671e-02, -5.6660e-03, -1.4550e-02]],

         ...,

         [[-1.0139e-02, -1.8617e-02, -8.6239e-03],
          [ 1.4483e-02, -1.5176e-02, -4.2803e-03],
          [ 1.4593e-02, -2.1055e-03, -1.8029e-02]],

         [[ 4.8076e-03,  1.9594e-02, -2.6995e-03],
          [ 5.7331e-03,  3.6000e-03,  1.1691e-02],
          [-3.2996e-03, -7.7230e-03,  1.9604e-02]],

         [[ 1.4269e-03,  1.1323e-02,  1.2626e-02],
          [-7.0050e-03,  2.3432e-04,  8.6081e-03],
          [-1.2762e-02, -1.4132e-02,  1.2677e-03]]],


        [[[ 1.6194e-02, -1.7634e-02,  1.2762e-02],
          [-2.2638e-03,  1.0247e-02, -7.2364e-03],
          [-5.7017e-04,  1.4898e-02, -3.7035e-03]],

         [[-1.0670e-02,  1.6617e-02, -1.6849e-02],
          [-4.7079e-03,  1.6690e-02, -4.0025e-03],
          [ 1.4537e-02,  1.8017e-02,  1.3504e-02]],

         [[-1.5079e-02,  8.6930e-03, -7.6810e-03],
          [-1.8313e-02,  1.2881e-02,  6.4295e-03],
          [ 4.0532e-03,  2.0698e-02, -1.7097e-02]],

         ...,

         [[-1.2287e-03,  2.0595e-02,  1.7386e-02],
          [ 1.9125e-03, -1.5656e-02,  6.2358e-03],
          [ 5.8951e-03, -1.5081e-02,  1.6625e-02]],

         [[-1.9769e-02, -1.1746e-02, -1.2168e-03],
          [ 1.3043e-02,  1.5916e-02, -3.3693e-03],
          [ 1.3123e-02, -1.2071e-02, -5.3984e-03]],

         [[-1.7381e-02,  1.7318e-02,  9.6601e-03],
          [-2.3793e-03,  8.3735e-03,  1.6388e-02],
          [-4.7767e-03, -5.0455e-03,  1.6524e-02]]],


        [[[-1.7592e-02, -3.2817e-04, -1.5809e-02],
          [-9.7470e-03,  9.9257e-03, -1.9466e-02],
          [-1.4915e-02, -9.8718e-04,  1.3872e-02]],

         [[ 1.5578e-02, -1.3965e-02,  1.0752e-02],
          [-4.7126e-03,  1.5298e-02,  9.0604e-03],
          [-2.7974e-03, -9.4266e-03, -2.0026e-02]],

         [[-1.4807e-02, -1.6235e-02, -1.7307e-03],
          [-1.9745e-02,  1.8929e-02, -1.9453e-03],
          [-8.9778e-03,  3.1476e-03,  1.6151e-02]],

         ...,

         [[-7.8857e-03,  2.0827e-02,  4.5902e-03],
          [ 1.4239e-02,  3.0472e-03, -1.0979e-02],
          [ 1.9726e-02, -1.7844e-02,  1.3557e-02]],

         [[-9.3171e-03,  7.5211e-04,  1.5612e-02],
          [-1.2874e-02, -8.9696e-03,  8.0320e-03],
          [-3.9888e-03,  1.2405e-02, -3.7741e-03]],

         [[ 1.2635e-02, -4.8564e-03,  5.1510e-03],
          [-8.5257e-03, -4.1647e-03, -8.2563e-03],
          [ 2.0355e-03,  7.4000e-03,  1.5827e-02]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv2.bias 
 torch.Size([128]) 
 True 
 tensor([ 1.3150e-02, -9.9331e-05,  3.4531e-03,  2.8926e-03,  7.3496e-03,
         2.0088e-04, -5.6907e-03, -1.8756e-02,  9.1130e-03,  3.5487e-03,
        -1.1031e-02,  8.9427e-03, -5.4477e-03, -1.0586e-02, -6.6001e-03,
        -7.8747e-03, -1.2201e-02, -1.2385e-02, -1.6034e-02,  1.2743e-02,
        -2.5568e-03,  1.0159e-02, -9.0835e-03, -1.9293e-03,  4.9636e-03,
        -1.1368e-02, -1.3471e-02,  1.0191e-02, -1.9691e-02,  1.5322e-02,
        -7.5769e-03,  2.0421e-02, -1.1287e-02, -1.5444e-02,  1.8913e-02,
         1.5794e-02,  8.9187e-03, -1.4780e-02,  3.7258e-03, -2.0365e-02,
        -2.0862e-05,  1.3633e-02,  8.3362e-03,  1.8781e-02,  7.9879e-03,
         1.3184e-02,  8.3395e-03,  7.0855e-03,  1.6819e-02,  7.1972e-03,
         5.7330e-03, -1.4360e-03,  1.6672e-02, -1.4321e-02,  1.2800e-03,
         1.8439e-03, -6.6837e-03, -6.2048e-03,  1.0217e-02, -1.2377e-02,
        -9.6748e-03, -3.3080e-03,  1.2878e-02, -1.6817e-02, -2.8713e-03,
        -3.5511e-04,  7.7333e-03,  5.6467e-03,  1.3199e-02, -2.6336e-03,
         1.8104e-02, -4.2465e-03,  1.6199e-02, -9.7527e-03, -1.2797e-02,
         9.7054e-03,  5.4595e-03,  5.9857e-03,  8.0734e-03,  4.0640e-03,
         1.7981e-02, -1.9970e-02, -1.9059e-02, -1.1314e-02, -1.6392e-02,
        -1.9683e-02,  3.2473e-03,  1.6809e-02,  1.2146e-02, -3.5072e-03,
        -6.3199e-03, -1.7865e-03, -1.8601e-02, -1.8684e-02, -2.0641e-02,
        -6.3961e-04,  4.2182e-03, -1.9002e-02, -4.2488e-04, -1.8966e-02,
        -9.2023e-03,  2.0224e-02, -1.6634e-02,  1.7477e-03, -1.9505e-02,
         1.7302e-02, -1.2747e-02, -1.4466e-02, -4.0112e-03,  1.8172e-02,
         6.4018e-03, -8.5591e-03,  7.9742e-03,  1.5168e-02, -1.9582e-02,
         1.4539e-02, -5.0509e-03,  2.7457e-03, -5.7317e-03, -2.0523e-03,
        -1.1310e-02, -1.4584e-02,  1.4167e-02,  1.9611e-02, -1.7206e-02,
         1.8866e-02,  9.8993e-03, -7.9423e-03], device='cuda:0') 
 Parameter containing:
tensor([ 1.3150e-02, -9.9331e-05,  3.4531e-03,  2.8926e-03,  7.3496e-03,
         2.0088e-04, -5.6907e-03, -1.8756e-02,  9.1130e-03,  3.5487e-03,
        -1.1031e-02,  8.9427e-03, -5.4477e-03, -1.0586e-02, -6.6001e-03,
        -7.8747e-03, -1.2201e-02, -1.2385e-02, -1.6034e-02,  1.2743e-02,
        -2.5568e-03,  1.0159e-02, -9.0835e-03, -1.9293e-03,  4.9636e-03,
        -1.1368e-02, -1.3471e-02,  1.0191e-02, -1.9691e-02,  1.5322e-02,
        -7.5769e-03,  2.0421e-02, -1.1287e-02, -1.5444e-02,  1.8913e-02,
         1.5794e-02,  8.9187e-03, -1.4780e-02,  3.7258e-03, -2.0365e-02,
        -2.0862e-05,  1.3633e-02,  8.3362e-03,  1.8781e-02,  7.9879e-03,
         1.3184e-02,  8.3395e-03,  7.0855e-03,  1.6819e-02,  7.1972e-03,
         5.7330e-03, -1.4360e-03,  1.6672e-02, -1.4321e-02,  1.2800e-03,
         1.8439e-03, -6.6837e-03, -6.2048e-03,  1.0217e-02, -1.2377e-02,
        -9.6748e-03, -3.3080e-03,  1.2878e-02, -1.6817e-02, -2.8713e-03,
        -3.5511e-04,  7.7333e-03,  5.6467e-03,  1.3199e-02, -2.6336e-03,
         1.8104e-02, -4.2465e-03,  1.6199e-02, -9.7527e-03, -1.2797e-02,
         9.7054e-03,  5.4595e-03,  5.9857e-03,  8.0734e-03,  4.0640e-03,
         1.7981e-02, -1.9970e-02, -1.9059e-02, -1.1314e-02, -1.6392e-02,
        -1.9683e-02,  3.2473e-03,  1.6809e-02,  1.2146e-02, -3.5072e-03,
        -6.3199e-03, -1.7865e-03, -1.8601e-02, -1.8684e-02, -2.0641e-02,
        -6.3961e-04,  4.2182e-03, -1.9002e-02, -4.2488e-04, -1.8966e-02,
        -9.2023e-03,  2.0224e-02, -1.6634e-02,  1.7477e-03, -1.9505e-02,
         1.7302e-02, -1.2747e-02, -1.4466e-02, -4.0112e-03,  1.8172e-02,
         6.4018e-03, -8.5591e-03,  7.9742e-03,  1.5168e-02, -1.9582e-02,
         1.4539e-02, -5.0509e-03,  2.7457e-03, -5.7317e-03, -2.0523e-03,
        -1.1310e-02, -1.4584e-02,  1.4167e-02,  1.9611e-02, -1.7206e-02,
         1.8866e-02,  9.8993e-03, -7.9423e-03], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.weight 
 torch.Size([64, 128, 3, 3]) 
 True 
 tensor([[[[ 0.0129, -0.0071, -0.0043],
          [-0.0201,  0.0043,  0.0192],
          [-0.0075,  0.0057,  0.0261]],

         [[ 0.0179,  0.0083,  0.0131],
          [-0.0145,  0.0043,  0.0192],
          [-0.0050,  0.0272, -0.0027]],

         [[ 0.0093, -0.0265, -0.0268],
          [-0.0224, -0.0268,  0.0135],
          [-0.0239, -0.0212, -0.0059]],

         ...,

         [[-0.0106, -0.0290, -0.0112],
          [-0.0162,  0.0021,  0.0117],
          [-0.0022,  0.0193,  0.0065]],

         [[ 0.0036, -0.0053, -0.0094],
          [-0.0146,  0.0131,  0.0100],
          [-0.0262,  0.0071,  0.0045]],

         [[-0.0108, -0.0067, -0.0250],
          [-0.0096, -0.0182,  0.0193],
          [ 0.0149,  0.0074,  0.0070]]],


        [[[-0.0052, -0.0090, -0.0195],
          [ 0.0207,  0.0200, -0.0189],
          [ 0.0291,  0.0048, -0.0294]],

         [[-0.0041,  0.0204, -0.0117],
          [-0.0283, -0.0116, -0.0241],
          [-0.0129, -0.0204,  0.0025]],

         [[-0.0249,  0.0078, -0.0114],
          [ 0.0271, -0.0212,  0.0208],
          [-0.0117,  0.0007, -0.0286]],

         ...,

         [[ 0.0272,  0.0161, -0.0125],
          [ 0.0111,  0.0109,  0.0275],
          [-0.0141, -0.0076,  0.0110]],

         [[-0.0088,  0.0007,  0.0213],
          [-0.0271,  0.0236, -0.0159],
          [ 0.0093, -0.0103,  0.0164]],

         [[-0.0035, -0.0043, -0.0064],
          [ 0.0068,  0.0037,  0.0202],
          [ 0.0129, -0.0269, -0.0290]]],


        [[[ 0.0123, -0.0105, -0.0137],
          [ 0.0158,  0.0031,  0.0162],
          [-0.0003, -0.0099,  0.0202]],

         [[-0.0020,  0.0044,  0.0263],
          [-0.0154,  0.0104,  0.0186],
          [ 0.0133,  0.0087, -0.0274]],

         [[-0.0286, -0.0232,  0.0199],
          [ 0.0105,  0.0161,  0.0223],
          [ 0.0294, -0.0244, -0.0217]],

         ...,

         [[ 0.0190,  0.0045,  0.0139],
          [-0.0148, -0.0214, -0.0193],
          [ 0.0058,  0.0229,  0.0254]],

         [[ 0.0025, -0.0139,  0.0283],
          [ 0.0130,  0.0114, -0.0109],
          [-0.0278,  0.0053,  0.0199]],

         [[ 0.0242,  0.0116,  0.0032],
          [ 0.0012, -0.0194,  0.0125],
          [-0.0149, -0.0163,  0.0158]]],


        ...,


        [[[-0.0050,  0.0108, -0.0096],
          [-0.0117, -0.0014, -0.0074],
          [ 0.0111,  0.0252,  0.0074]],

         [[ 0.0116, -0.0146,  0.0216],
          [ 0.0062, -0.0243, -0.0234],
          [-0.0126, -0.0243,  0.0213]],

         [[-0.0227,  0.0224, -0.0009],
          [ 0.0130, -0.0229, -0.0116],
          [-0.0284,  0.0152, -0.0225]],

         ...,

         [[ 0.0221, -0.0026, -0.0100],
          [-0.0153,  0.0269, -0.0229],
          [ 0.0289, -0.0175,  0.0207]],

         [[-0.0042,  0.0251, -0.0157],
          [-0.0290,  0.0143, -0.0124],
          [ 0.0116, -0.0105, -0.0091]],

         [[-0.0289,  0.0289, -0.0211],
          [ 0.0173, -0.0056, -0.0188],
          [-0.0140,  0.0096,  0.0023]]],


        [[[ 0.0199, -0.0098, -0.0143],
          [-0.0171, -0.0259, -0.0071],
          [-0.0246, -0.0010, -0.0063]],

         [[ 0.0100, -0.0280, -0.0228],
          [-0.0174,  0.0252, -0.0164],
          [ 0.0053,  0.0272, -0.0203]],

         [[ 0.0270,  0.0261,  0.0053],
          [-0.0078, -0.0122,  0.0209],
          [-0.0211,  0.0175, -0.0172]],

         ...,

         [[-0.0274,  0.0240,  0.0117],
          [-0.0261,  0.0043, -0.0071],
          [ 0.0136,  0.0045, -0.0238]],

         [[-0.0160, -0.0013, -0.0234],
          [-0.0219,  0.0033, -0.0238],
          [-0.0063, -0.0292, -0.0097]],

         [[ 0.0070,  0.0079,  0.0103],
          [-0.0294,  0.0177, -0.0153],
          [ 0.0137, -0.0197,  0.0047]]],


        [[[-0.0119, -0.0259, -0.0284],
          [ 0.0145, -0.0068,  0.0092],
          [ 0.0236, -0.0166, -0.0233]],

         [[-0.0100,  0.0101, -0.0058],
          [ 0.0283, -0.0235,  0.0186],
          [ 0.0190, -0.0172,  0.0063]],

         [[ 0.0198, -0.0002,  0.0254],
          [ 0.0140,  0.0192, -0.0236],
          [-0.0180,  0.0216,  0.0045]],

         ...,

         [[ 0.0221, -0.0249,  0.0214],
          [-0.0219, -0.0261, -0.0004],
          [ 0.0064,  0.0210, -0.0157]],

         [[ 0.0071, -0.0095,  0.0047],
          [ 0.0278, -0.0018,  0.0087],
          [ 0.0111,  0.0155,  0.0178]],

         [[ 0.0099,  0.0259, -0.0024],
          [ 0.0038,  0.0168, -0.0283],
          [ 0.0042, -0.0084, -0.0060]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 0.0129, -0.0071, -0.0043],
          [-0.0201,  0.0043,  0.0192],
          [-0.0075,  0.0057,  0.0261]],

         [[ 0.0179,  0.0083,  0.0131],
          [-0.0145,  0.0043,  0.0192],
          [-0.0050,  0.0272, -0.0027]],

         [[ 0.0093, -0.0265, -0.0268],
          [-0.0224, -0.0268,  0.0135],
          [-0.0239, -0.0212, -0.0059]],

         ...,

         [[-0.0106, -0.0290, -0.0112],
          [-0.0162,  0.0021,  0.0117],
          [-0.0022,  0.0193,  0.0065]],

         [[ 0.0036, -0.0053, -0.0094],
          [-0.0146,  0.0131,  0.0100],
          [-0.0262,  0.0071,  0.0045]],

         [[-0.0108, -0.0067, -0.0250],
          [-0.0096, -0.0182,  0.0193],
          [ 0.0149,  0.0074,  0.0070]]],


        [[[-0.0052, -0.0090, -0.0195],
          [ 0.0207,  0.0200, -0.0189],
          [ 0.0291,  0.0048, -0.0294]],

         [[-0.0041,  0.0204, -0.0117],
          [-0.0283, -0.0116, -0.0241],
          [-0.0129, -0.0204,  0.0025]],

         [[-0.0249,  0.0078, -0.0114],
          [ 0.0271, -0.0212,  0.0208],
          [-0.0117,  0.0007, -0.0286]],

         ...,

         [[ 0.0272,  0.0161, -0.0125],
          [ 0.0111,  0.0109,  0.0275],
          [-0.0141, -0.0076,  0.0110]],

         [[-0.0088,  0.0007,  0.0213],
          [-0.0271,  0.0236, -0.0159],
          [ 0.0093, -0.0103,  0.0164]],

         [[-0.0035, -0.0043, -0.0064],
          [ 0.0068,  0.0037,  0.0202],
          [ 0.0129, -0.0269, -0.0290]]],


        [[[ 0.0123, -0.0105, -0.0137],
          [ 0.0158,  0.0031,  0.0162],
          [-0.0003, -0.0099,  0.0202]],

         [[-0.0020,  0.0044,  0.0263],
          [-0.0154,  0.0104,  0.0186],
          [ 0.0133,  0.0087, -0.0274]],

         [[-0.0286, -0.0232,  0.0199],
          [ 0.0105,  0.0161,  0.0223],
          [ 0.0294, -0.0244, -0.0217]],

         ...,

         [[ 0.0190,  0.0045,  0.0139],
          [-0.0148, -0.0214, -0.0193],
          [ 0.0058,  0.0229,  0.0254]],

         [[ 0.0025, -0.0139,  0.0283],
          [ 0.0130,  0.0114, -0.0109],
          [-0.0278,  0.0053,  0.0199]],

         [[ 0.0242,  0.0116,  0.0032],
          [ 0.0012, -0.0194,  0.0125],
          [-0.0149, -0.0163,  0.0158]]],


        ...,


        [[[-0.0050,  0.0108, -0.0096],
          [-0.0117, -0.0014, -0.0074],
          [ 0.0111,  0.0252,  0.0074]],

         [[ 0.0116, -0.0146,  0.0216],
          [ 0.0062, -0.0243, -0.0234],
          [-0.0126, -0.0243,  0.0213]],

         [[-0.0227,  0.0224, -0.0009],
          [ 0.0130, -0.0229, -0.0116],
          [-0.0284,  0.0152, -0.0225]],

         ...,

         [[ 0.0221, -0.0026, -0.0100],
          [-0.0153,  0.0269, -0.0229],
          [ 0.0289, -0.0175,  0.0207]],

         [[-0.0042,  0.0251, -0.0157],
          [-0.0290,  0.0143, -0.0124],
          [ 0.0116, -0.0105, -0.0091]],

         [[-0.0289,  0.0289, -0.0211],
          [ 0.0173, -0.0056, -0.0188],
          [-0.0140,  0.0096,  0.0023]]],


        [[[ 0.0199, -0.0098, -0.0143],
          [-0.0171, -0.0259, -0.0071],
          [-0.0246, -0.0010, -0.0063]],

         [[ 0.0100, -0.0280, -0.0228],
          [-0.0174,  0.0252, -0.0164],
          [ 0.0053,  0.0272, -0.0203]],

         [[ 0.0270,  0.0261,  0.0053],
          [-0.0078, -0.0122,  0.0209],
          [-0.0211,  0.0175, -0.0172]],

         ...,

         [[-0.0274,  0.0240,  0.0117],
          [-0.0261,  0.0043, -0.0071],
          [ 0.0136,  0.0045, -0.0238]],

         [[-0.0160, -0.0013, -0.0234],
          [-0.0219,  0.0033, -0.0238],
          [-0.0063, -0.0292, -0.0097]],

         [[ 0.0070,  0.0079,  0.0103],
          [-0.0294,  0.0177, -0.0153],
          [ 0.0137, -0.0197,  0.0047]]],


        [[[-0.0119, -0.0259, -0.0284],
          [ 0.0145, -0.0068,  0.0092],
          [ 0.0236, -0.0166, -0.0233]],

         [[-0.0100,  0.0101, -0.0058],
          [ 0.0283, -0.0235,  0.0186],
          [ 0.0190, -0.0172,  0.0063]],

         [[ 0.0198, -0.0002,  0.0254],
          [ 0.0140,  0.0192, -0.0236],
          [-0.0180,  0.0216,  0.0045]],

         ...,

         [[ 0.0221, -0.0249,  0.0214],
          [-0.0219, -0.0261, -0.0004],
          [ 0.0064,  0.0210, -0.0157]],

         [[ 0.0071, -0.0095,  0.0047],
          [ 0.0278, -0.0018,  0.0087],
          [ 0.0111,  0.0155,  0.0178]],

         [[ 0.0099,  0.0259, -0.0024],
          [ 0.0038,  0.0168, -0.0283],
          [ 0.0042, -0.0084, -0.0060]]]], device='cuda:0', requires_grad=True)
parameters of the network conv3.bias 
 torch.Size([64]) 
 True 
 tensor([-0.0261, -0.0224, -0.0088, -0.0216,  0.0286,  0.0042, -0.0255, -0.0214,
        -0.0133,  0.0163,  0.0198,  0.0236,  0.0112, -0.0282, -0.0271, -0.0064,
        -0.0029,  0.0209,  0.0010, -0.0275,  0.0257,  0.0066, -0.0047,  0.0208,
         0.0146,  0.0198,  0.0274,  0.0288,  0.0271,  0.0110,  0.0149, -0.0215,
        -0.0259, -0.0033,  0.0255,  0.0055, -0.0047, -0.0229, -0.0177,  0.0100,
        -0.0212,  0.0030, -0.0121, -0.0138,  0.0072, -0.0257,  0.0115, -0.0008,
         0.0237, -0.0257, -0.0116, -0.0262, -0.0021, -0.0240, -0.0255,  0.0286,
        -0.0158, -0.0157,  0.0288,  0.0233, -0.0135, -0.0029, -0.0175, -0.0148],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0261, -0.0224, -0.0088, -0.0216,  0.0286,  0.0042, -0.0255, -0.0214,
        -0.0133,  0.0163,  0.0198,  0.0236,  0.0112, -0.0282, -0.0271, -0.0064,
        -0.0029,  0.0209,  0.0010, -0.0275,  0.0257,  0.0066, -0.0047,  0.0208,
         0.0146,  0.0198,  0.0274,  0.0288,  0.0271,  0.0110,  0.0149, -0.0215,
        -0.0259, -0.0033,  0.0255,  0.0055, -0.0047, -0.0229, -0.0177,  0.0100,
        -0.0212,  0.0030, -0.0121, -0.0138,  0.0072, -0.0257,  0.0115, -0.0008,
         0.0237, -0.0257, -0.0116, -0.0262, -0.0021, -0.0240, -0.0255,  0.0286,
        -0.0158, -0.0157,  0.0288,  0.0233, -0.0135, -0.0029, -0.0175, -0.0148],
       device='cuda:0', requires_grad=True)
parameters of the network fc1.weight 
 torch.Size([256, 667776]) 
 True 
 tensor([[ 1.1270e-03, -9.2165e-04,  1.2118e-04,  ...,  7.7948e-04,
         -8.4428e-04, -7.9912e-04],
        [ 1.9684e-04,  1.5760e-04,  4.4830e-04,  ...,  1.9324e-04,
         -7.6240e-05,  7.9734e-04],
        [ 6.8742e-04, -1.0704e-03,  1.1192e-03,  ...,  8.7934e-04,
         -1.5307e-04, -4.1193e-04],
        ...,
        [-1.9775e-04, -5.1997e-04,  8.2149e-04,  ...,  1.1439e-03,
         -1.2073e-03,  7.7411e-04],
        [-2.0999e-04, -1.1409e-03, -3.0785e-04,  ...,  9.9066e-04,
         -2.0021e-04, -6.6900e-06],
        [-9.2083e-04, -2.2516e-04, -1.2028e-03,  ...,  2.9899e-04,
          4.9929e-04,  4.5104e-04]], device='cuda:0') 
 Parameter containing:
tensor([[ 1.1270e-03, -9.2165e-04,  1.2118e-04,  ...,  7.7948e-04,
         -8.4428e-04, -7.9912e-04],
        [ 1.9684e-04,  1.5760e-04,  4.4830e-04,  ...,  1.9324e-04,
         -7.6240e-05,  7.9734e-04],
        [ 6.8742e-04, -1.0704e-03,  1.1192e-03,  ...,  8.7934e-04,
         -1.5307e-04, -4.1193e-04],
        ...,
        [-1.9775e-04, -5.1997e-04,  8.2149e-04,  ...,  1.1439e-03,
         -1.2073e-03,  7.7411e-04],
        [-2.0999e-04, -1.1409e-03, -3.0785e-04,  ...,  9.9066e-04,
         -2.0021e-04, -6.6900e-06],
        [-9.2083e-04, -2.2516e-04, -1.2028e-03,  ...,  2.9899e-04,
          4.9929e-04,  4.5104e-04]], device='cuda:0', requires_grad=True)
parameters of the network fc1.bias 
 torch.Size([256]) 
 True 
 tensor([-5.4111e-04, -6.6931e-04,  4.2109e-04, -4.2981e-04,  2.6888e-04,
         1.1571e-03, -1.0991e-03, -4.5080e-04,  3.8666e-04, -9.1460e-04,
         9.6893e-04,  1.1291e-03, -7.3510e-05, -7.7437e-04,  1.1434e-04,
         1.2805e-04, -9.7149e-04,  1.0722e-04,  5.6940e-04, -6.1511e-04,
         2.0517e-05, -6.3192e-04, -3.5059e-04,  4.4777e-04,  2.2647e-04,
        -1.0678e-03,  1.6537e-04, -9.2147e-04,  9.7867e-04,  1.0578e-03,
        -2.0367e-04, -1.0180e-03,  1.5826e-05, -7.5308e-04,  8.9081e-04,
        -1.6023e-04, -1.1746e-03, -1.0203e-03,  1.0398e-03,  9.9430e-04,
        -9.4398e-04,  8.0283e-04,  5.3372e-04, -4.7192e-04,  9.1556e-04,
        -8.1881e-04, -3.2899e-04, -8.7693e-04, -4.8942e-04,  8.3541e-04,
        -1.0745e-03,  1.4139e-05,  7.7134e-04, -4.9992e-04,  1.0924e-03,
         9.5352e-04,  9.5945e-04, -9.9436e-04, -9.0120e-04, -5.6164e-05,
         9.8452e-05, -9.0279e-04,  1.4684e-04, -2.0549e-04,  5.0138e-04,
        -1.0604e-03,  8.3729e-04,  6.0713e-04, -1.1139e-03, -5.4124e-04,
         1.0619e-03, -2.0097e-04, -6.5548e-04, -1.6563e-04, -1.9983e-04,
         3.3142e-04,  2.9413e-04,  6.6364e-04,  5.2079e-06, -3.6126e-04,
        -6.1388e-04, -4.9184e-04, -9.9426e-04, -1.0227e-03, -1.9615e-04,
        -1.2179e-03,  8.2304e-04,  2.6876e-04,  2.8097e-04, -4.1352e-04,
        -2.0356e-04,  3.7917e-04, -5.2825e-04, -1.1920e-03, -8.5679e-04,
        -1.1685e-03,  1.0150e-03,  3.7063e-04, -5.4761e-04,  9.3355e-04,
         2.6735e-04,  1.7244e-04, -9.9686e-04,  6.2094e-04,  1.9287e-04,
        -1.2136e-03,  7.0723e-04, -2.7928e-05,  2.1722e-04, -4.0679e-04,
         1.2010e-03,  6.6366e-04, -1.0047e-03,  7.1315e-04, -7.2802e-04,
         3.4255e-04, -1.1017e-03,  9.7149e-05,  1.2050e-03, -1.0777e-03,
        -6.4623e-04,  2.5760e-04,  1.0172e-03,  5.3414e-04, -2.8920e-04,
        -3.9463e-04, -6.8989e-05,  1.0386e-03,  9.3418e-04, -9.0410e-04,
         2.4574e-04, -8.4005e-04,  2.8919e-04,  1.1870e-03, -6.5706e-04,
         6.2449e-04, -1.0711e-04, -2.3564e-04,  1.0843e-03,  4.5157e-05,
        -5.8875e-04, -1.0424e-03,  3.7888e-04,  1.1836e-03,  1.0210e-03,
         3.3248e-04, -2.4319e-04,  4.1963e-04,  1.2091e-03,  9.7025e-04,
         7.7979e-04,  1.4060e-04, -5.5149e-04,  3.1632e-04,  1.9584e-04,
         8.2737e-04,  1.1889e-03, -4.4406e-04,  2.9565e-04, -1.1739e-03,
         1.8757e-04,  7.6513e-04, -1.1143e-03,  4.9077e-04,  8.2729e-04,
         4.6734e-04,  3.1024e-04, -1.1334e-04, -1.2130e-03,  1.0047e-03,
         4.7108e-04,  9.9165e-04,  7.4713e-04, -5.2256e-04,  3.3824e-04,
        -6.5813e-04, -5.7817e-04,  8.6009e-04,  9.3205e-04,  5.2609e-04,
        -7.0885e-04,  3.5254e-04, -3.7213e-05,  2.2665e-04,  1.1425e-03,
         1.1604e-03, -1.1375e-03, -5.6722e-04,  4.9502e-04, -7.0647e-04,
         9.7185e-04,  3.0661e-04, -7.9089e-04, -7.9889e-04, -4.1612e-04,
        -2.9805e-04, -3.6654e-04,  5.9937e-04, -8.6463e-04, -2.9704e-04,
        -9.2267e-04,  3.9103e-04,  1.6696e-04,  8.0422e-04, -1.1523e-03,
         2.0468e-04, -3.9130e-05, -1.0260e-03,  3.3029e-04,  4.4975e-04,
         7.6442e-04, -6.8657e-04, -1.1503e-03, -5.0343e-04, -7.0945e-04,
        -3.3452e-04, -1.2188e-03, -8.4303e-04,  7.4055e-04, -4.8737e-04,
         4.5875e-04,  6.7080e-04,  6.1483e-05,  7.2528e-04, -2.0592e-04,
         6.7825e-04, -1.6491e-04, -9.8878e-04,  5.7375e-04,  7.7825e-04,
        -4.9613e-04,  6.7846e-04,  1.5731e-04, -6.9042e-04,  6.5447e-04,
        -1.0302e-03, -5.3145e-04,  1.0409e-03, -9.3309e-05,  1.1215e-03,
        -1.7065e-04,  5.3715e-04,  2.3446e-04,  2.1571e-04, -1.0847e-03,
         9.5772e-05,  4.6462e-04,  1.1341e-03,  3.6574e-04, -8.4747e-04,
        -9.8738e-05,  1.0861e-03, -2.2829e-04,  9.0824e-04,  7.4592e-04,
         1.1314e-04], device='cuda:0') 
 Parameter containing:
tensor([-5.4111e-04, -6.6931e-04,  4.2109e-04, -4.2981e-04,  2.6888e-04,
         1.1571e-03, -1.0991e-03, -4.5080e-04,  3.8666e-04, -9.1460e-04,
         9.6893e-04,  1.1291e-03, -7.3510e-05, -7.7437e-04,  1.1434e-04,
         1.2805e-04, -9.7149e-04,  1.0722e-04,  5.6940e-04, -6.1511e-04,
         2.0517e-05, -6.3192e-04, -3.5059e-04,  4.4777e-04,  2.2647e-04,
        -1.0678e-03,  1.6537e-04, -9.2147e-04,  9.7867e-04,  1.0578e-03,
        -2.0367e-04, -1.0180e-03,  1.5826e-05, -7.5308e-04,  8.9081e-04,
        -1.6023e-04, -1.1746e-03, -1.0203e-03,  1.0398e-03,  9.9430e-04,
        -9.4398e-04,  8.0283e-04,  5.3372e-04, -4.7192e-04,  9.1556e-04,
        -8.1881e-04, -3.2899e-04, -8.7693e-04, -4.8942e-04,  8.3541e-04,
        -1.0745e-03,  1.4139e-05,  7.7134e-04, -4.9992e-04,  1.0924e-03,
         9.5352e-04,  9.5945e-04, -9.9436e-04, -9.0120e-04, -5.6164e-05,
         9.8452e-05, -9.0279e-04,  1.4684e-04, -2.0549e-04,  5.0138e-04,
        -1.0604e-03,  8.3729e-04,  6.0713e-04, -1.1139e-03, -5.4124e-04,
         1.0619e-03, -2.0097e-04, -6.5548e-04, -1.6563e-04, -1.9983e-04,
         3.3142e-04,  2.9413e-04,  6.6364e-04,  5.2079e-06, -3.6126e-04,
        -6.1388e-04, -4.9184e-04, -9.9426e-04, -1.0227e-03, -1.9615e-04,
        -1.2179e-03,  8.2304e-04,  2.6876e-04,  2.8097e-04, -4.1352e-04,
        -2.0356e-04,  3.7917e-04, -5.2825e-04, -1.1920e-03, -8.5679e-04,
        -1.1685e-03,  1.0150e-03,  3.7063e-04, -5.4761e-04,  9.3355e-04,
         2.6735e-04,  1.7244e-04, -9.9686e-04,  6.2094e-04,  1.9287e-04,
        -1.2136e-03,  7.0723e-04, -2.7928e-05,  2.1722e-04, -4.0679e-04,
         1.2010e-03,  6.6366e-04, -1.0047e-03,  7.1315e-04, -7.2802e-04,
         3.4255e-04, -1.1017e-03,  9.7149e-05,  1.2050e-03, -1.0777e-03,
        -6.4623e-04,  2.5760e-04,  1.0172e-03,  5.3414e-04, -2.8920e-04,
        -3.9463e-04, -6.8989e-05,  1.0386e-03,  9.3418e-04, -9.0410e-04,
         2.4574e-04, -8.4005e-04,  2.8919e-04,  1.1870e-03, -6.5706e-04,
         6.2449e-04, -1.0711e-04, -2.3564e-04,  1.0843e-03,  4.5157e-05,
        -5.8875e-04, -1.0424e-03,  3.7888e-04,  1.1836e-03,  1.0210e-03,
         3.3248e-04, -2.4319e-04,  4.1963e-04,  1.2091e-03,  9.7025e-04,
         7.7979e-04,  1.4060e-04, -5.5149e-04,  3.1632e-04,  1.9584e-04,
         8.2737e-04,  1.1889e-03, -4.4406e-04,  2.9565e-04, -1.1739e-03,
         1.8757e-04,  7.6513e-04, -1.1143e-03,  4.9077e-04,  8.2729e-04,
         4.6734e-04,  3.1024e-04, -1.1334e-04, -1.2130e-03,  1.0047e-03,
         4.7108e-04,  9.9165e-04,  7.4713e-04, -5.2256e-04,  3.3824e-04,
        -6.5813e-04, -5.7817e-04,  8.6009e-04,  9.3205e-04,  5.2609e-04,
        -7.0885e-04,  3.5254e-04, -3.7213e-05,  2.2665e-04,  1.1425e-03,
         1.1604e-03, -1.1375e-03, -5.6722e-04,  4.9502e-04, -7.0647e-04,
         9.7185e-04,  3.0661e-04, -7.9089e-04, -7.9889e-04, -4.1612e-04,
        -2.9805e-04, -3.6654e-04,  5.9937e-04, -8.6463e-04, -2.9704e-04,
        -9.2267e-04,  3.9103e-04,  1.6696e-04,  8.0422e-04, -1.1523e-03,
         2.0468e-04, -3.9130e-05, -1.0260e-03,  3.3029e-04,  4.4975e-04,
         7.6442e-04, -6.8657e-04, -1.1503e-03, -5.0343e-04, -7.0945e-04,
        -3.3452e-04, -1.2188e-03, -8.4303e-04,  7.4055e-04, -4.8737e-04,
         4.5875e-04,  6.7080e-04,  6.1483e-05,  7.2528e-04, -2.0592e-04,
         6.7825e-04, -1.6491e-04, -9.8878e-04,  5.7375e-04,  7.7825e-04,
        -4.9613e-04,  6.7846e-04,  1.5731e-04, -6.9042e-04,  6.5447e-04,
        -1.0302e-03, -5.3145e-04,  1.0409e-03, -9.3309e-05,  1.1215e-03,
        -1.7065e-04,  5.3715e-04,  2.3446e-04,  2.1571e-04, -1.0847e-03,
         9.5772e-05,  4.6462e-04,  1.1341e-03,  3.6574e-04, -8.4747e-04,
        -9.8738e-05,  1.0861e-03, -2.2829e-04,  9.0824e-04,  7.4592e-04,
         1.1314e-04], device='cuda:0', requires_grad=True)
parameters of the network fc2.weight 
 torch.Size([128, 256]) 
 True 
 tensor([[-3.9634e-02,  1.0286e-02,  1.8465e-03,  ..., -3.3826e-02,
          3.5192e-02, -5.3101e-02],
        [ 5.9243e-02, -2.4571e-02,  3.1042e-02,  ...,  1.6644e-02,
          1.4967e-02,  5.8076e-02],
        [-4.9515e-02, -3.0099e-02,  4.9599e-02,  ..., -1.9949e-02,
         -1.5172e-02, -6.8617e-03],
        ...,
        [-2.2158e-02,  2.4102e-02,  4.5571e-03,  ..., -2.1295e-02,
          3.6046e-03, -1.3420e-02],
        [ 5.5661e-02, -4.2334e-02, -3.9073e-02,  ..., -3.2645e-02,
          2.7090e-05,  8.8009e-03],
        [-2.5518e-02,  1.5762e-02,  2.7072e-02,  ...,  9.8805e-03,
         -1.3590e-02,  4.1811e-02]], device='cuda:0') 
 Parameter containing:
tensor([[-3.9634e-02,  1.0286e-02,  1.8465e-03,  ..., -3.3826e-02,
          3.5192e-02, -5.3101e-02],
        [ 5.9243e-02, -2.4571e-02,  3.1042e-02,  ...,  1.6644e-02,
          1.4967e-02,  5.8076e-02],
        [-4.9515e-02, -3.0099e-02,  4.9599e-02,  ..., -1.9949e-02,
         -1.5172e-02, -6.8617e-03],
        ...,
        [-2.2158e-02,  2.4102e-02,  4.5571e-03,  ..., -2.1295e-02,
          3.6046e-03, -1.3420e-02],
        [ 5.5661e-02, -4.2334e-02, -3.9073e-02,  ..., -3.2645e-02,
          2.7090e-05,  8.8009e-03],
        [-2.5518e-02,  1.5762e-02,  2.7072e-02,  ...,  9.8805e-03,
         -1.3590e-02,  4.1811e-02]], device='cuda:0', requires_grad=True)
parameters of the network fc2.bias 
 torch.Size([128]) 
 True 
 tensor([-0.0192,  0.0441, -0.0334, -0.0345,  0.0425, -0.0572,  0.0290,  0.0099,
        -0.0400,  0.0302, -0.0359,  0.0620,  0.0404,  0.0586,  0.0610,  0.0177,
        -0.0234, -0.0036,  0.0398,  0.0001,  0.0581, -0.0613, -0.0575, -0.0608,
         0.0023, -0.0162, -0.0474, -0.0436,  0.0436,  0.0549,  0.0577,  0.0622,
         0.0573, -0.0609, -0.0031, -0.0083,  0.0240,  0.0515, -0.0064,  0.0496,
         0.0119, -0.0261, -0.0069,  0.0592,  0.0390,  0.0352,  0.0327, -0.0586,
        -0.0223, -0.0194, -0.0125,  0.0118,  0.0496,  0.0545, -0.0617,  0.0575,
        -0.0293,  0.0389, -0.0136, -0.0251,  0.0269, -0.0196, -0.0370, -0.0029,
         0.0169, -0.0517, -0.0207,  0.0196, -0.0204,  0.0453, -0.0386,  0.0096,
         0.0583, -0.0022, -0.0453,  0.0102,  0.0016, -0.0261, -0.0433,  0.0066,
         0.0581, -0.0051,  0.0188, -0.0411,  0.0008,  0.0296,  0.0061,  0.0412,
        -0.0467,  0.0202,  0.0616,  0.0226, -0.0006, -0.0570,  0.0198,  0.0162,
        -0.0176, -0.0060,  0.0612,  0.0544, -0.0437, -0.0146,  0.0562, -0.0513,
         0.0388, -0.0174,  0.0424, -0.0254, -0.0140, -0.0028,  0.0233,  0.0239,
         0.0514,  0.0385, -0.0017, -0.0445, -0.0306, -0.0468,  0.0004, -0.0070,
        -0.0055,  0.0386, -0.0342, -0.0033,  0.0512, -0.0611,  0.0462,  0.0347],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0192,  0.0441, -0.0334, -0.0345,  0.0425, -0.0572,  0.0290,  0.0099,
        -0.0400,  0.0302, -0.0359,  0.0620,  0.0404,  0.0586,  0.0610,  0.0177,
        -0.0234, -0.0036,  0.0398,  0.0001,  0.0581, -0.0613, -0.0575, -0.0608,
         0.0023, -0.0162, -0.0474, -0.0436,  0.0436,  0.0549,  0.0577,  0.0622,
         0.0573, -0.0609, -0.0031, -0.0083,  0.0240,  0.0515, -0.0064,  0.0496,
         0.0119, -0.0261, -0.0069,  0.0592,  0.0390,  0.0352,  0.0327, -0.0586,
        -0.0223, -0.0194, -0.0125,  0.0118,  0.0496,  0.0545, -0.0617,  0.0575,
        -0.0293,  0.0389, -0.0136, -0.0251,  0.0269, -0.0196, -0.0370, -0.0029,
         0.0169, -0.0517, -0.0207,  0.0196, -0.0204,  0.0453, -0.0386,  0.0096,
         0.0583, -0.0022, -0.0453,  0.0102,  0.0016, -0.0261, -0.0433,  0.0066,
         0.0581, -0.0051,  0.0188, -0.0411,  0.0008,  0.0296,  0.0061,  0.0412,
        -0.0467,  0.0202,  0.0616,  0.0226, -0.0006, -0.0570,  0.0198,  0.0162,
        -0.0176, -0.0060,  0.0612,  0.0544, -0.0437, -0.0146,  0.0562, -0.0513,
         0.0388, -0.0174,  0.0424, -0.0254, -0.0140, -0.0028,  0.0233,  0.0239,
         0.0514,  0.0385, -0.0017, -0.0445, -0.0306, -0.0468,  0.0004, -0.0070,
        -0.0055,  0.0386, -0.0342, -0.0033,  0.0512, -0.0611,  0.0462,  0.0347],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.weight 
 torch.Size([64, 128]) 
 True 
 tensor([[-0.0004,  0.0029, -0.0098,  ..., -0.0139, -0.0376,  0.0619],
        [-0.0436,  0.0303,  0.0234,  ...,  0.0597,  0.0718, -0.0407],
        [ 0.0591,  0.0207, -0.0265,  ..., -0.0842, -0.0579,  0.0760],
        ...,
        [ 0.0202,  0.0653,  0.0866,  ...,  0.0638,  0.0013, -0.0683],
        [ 0.0349,  0.0672,  0.0412,  ..., -0.0218, -0.0441,  0.0423],
        [-0.0461,  0.0703, -0.0435,  ...,  0.0446,  0.0269,  0.0229]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0004,  0.0029, -0.0098,  ..., -0.0139, -0.0376,  0.0619],
        [-0.0436,  0.0303,  0.0234,  ...,  0.0597,  0.0718, -0.0407],
        [ 0.0591,  0.0207, -0.0265,  ..., -0.0842, -0.0579,  0.0760],
        ...,
        [ 0.0202,  0.0653,  0.0866,  ...,  0.0638,  0.0013, -0.0683],
        [ 0.0349,  0.0672,  0.0412,  ..., -0.0218, -0.0441,  0.0423],
        [-0.0461,  0.0703, -0.0435,  ...,  0.0446,  0.0269,  0.0229]],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.bias 
 torch.Size([64]) 
 True 
 tensor([-0.0260, -0.0514, -0.0768,  0.0244,  0.0286,  0.0638,  0.0091, -0.0742,
         0.0866,  0.0133,  0.0332, -0.0244, -0.0701, -0.0301,  0.0137,  0.0348,
        -0.0339, -0.0726, -0.0006, -0.0302, -0.0714, -0.0304, -0.0403, -0.0212,
        -0.0274, -0.0220, -0.0124,  0.0356,  0.0021, -0.0781, -0.0831, -0.0217,
         0.0665,  0.0214, -0.0304, -0.0316,  0.0195,  0.0200,  0.0760, -0.0334,
         0.0596,  0.0498, -0.0619, -0.0046, -0.0045,  0.0140, -0.0243,  0.0413,
         0.0534,  0.0010,  0.0247,  0.0030,  0.0494,  0.0151,  0.0278,  0.0625,
        -0.0109, -0.0113, -0.0866, -0.0810, -0.0773, -0.0863, -0.0227, -0.0336],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0260, -0.0514, -0.0768,  0.0244,  0.0286,  0.0638,  0.0091, -0.0742,
         0.0866,  0.0133,  0.0332, -0.0244, -0.0701, -0.0301,  0.0137,  0.0348,
        -0.0339, -0.0726, -0.0006, -0.0302, -0.0714, -0.0304, -0.0403, -0.0212,
        -0.0274, -0.0220, -0.0124,  0.0356,  0.0021, -0.0781, -0.0831, -0.0217,
         0.0665,  0.0214, -0.0304, -0.0316,  0.0195,  0.0200,  0.0760, -0.0334,
         0.0596,  0.0498, -0.0619, -0.0046, -0.0045,  0.0140, -0.0243,  0.0413,
         0.0534,  0.0010,  0.0247,  0.0030,  0.0494,  0.0151,  0.0278,  0.0625,
        -0.0109, -0.0113, -0.0866, -0.0810, -0.0773, -0.0863, -0.0227, -0.0336],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.weight 
 torch.Size([6796, 64]) 
 True 
 tensor([[-0.0143,  0.0609, -0.0949,  ...,  0.0631, -0.0759,  0.0753],
        [ 0.0797, -0.0188, -0.0581,  ...,  0.1074, -0.0153, -0.1196],
        [-0.0666,  0.0551, -0.0699,  ...,  0.0017, -0.0103,  0.0034],
        ...,
        [-0.0957, -0.0798,  0.0552,  ...,  0.0380,  0.1080, -0.0244],
        [ 0.0111,  0.0709, -0.0418,  ...,  0.0098, -0.0583, -0.0121],
        [-0.0372,  0.0065, -0.1141,  ...,  0.0461,  0.1029, -0.1026]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0143,  0.0609, -0.0949,  ...,  0.0631, -0.0759,  0.0753],
        [ 0.0797, -0.0188, -0.0581,  ...,  0.1074, -0.0153, -0.1196],
        [-0.0666,  0.0551, -0.0699,  ...,  0.0017, -0.0103,  0.0034],
        ...,
        [-0.0957, -0.0798,  0.0552,  ...,  0.0380,  0.1080, -0.0244],
        [ 0.0111,  0.0709, -0.0418,  ...,  0.0098, -0.0583, -0.0121],
        [-0.0372,  0.0065, -0.1141,  ...,  0.0461,  0.1029, -0.1026]],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.bias 
 torch.Size([6796]) 
 True 
 tensor([ 0.1038, -0.0950,  0.0255,  ..., -0.0673,  0.1009, -0.0580],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.1038, -0.0950,  0.0255,  ..., -0.0673,  0.1009, -0.0580],
       device='cuda:0', requires_grad=True)

Passing event 1007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([[0.0965, 0.0000, 0.0129,  ..., 0.0000, 0.1069, 0.0000],
        [0.0965, 0.0000, 0.0130,  ..., 0.0000, 0.1072, 0.0000],
        [0.0962, 0.0000, 0.0132,  ..., 0.0000, 0.1074, 0.0000],
        ...,
        [0.0962, 0.0000, 0.0131,  ..., 0.0000, 0.1073, 0.0000],
        [0.0967, 0.0000, 0.0131,  ..., 0.0000, 0.1071, 0.0000],
        [0.0962, 0.0000, 0.0133,  ..., 0.0000, 0.1070, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
result1.shape: torch.Size([20, 6796])

Passing two random events from the network before training 
result1: tensor([[0.0965, 0.0000, 0.0129,  ..., 0.0000, 0.1069, 0.0000],
        [0.0965, 0.0000, 0.0130,  ..., 0.0000, 0.1072, 0.0000],
        [0.0962, 0.0000, 0.0132,  ..., 0.0000, 0.1074, 0.0000],
        ...,
        [0.0962, 0.0000, 0.0131,  ..., 0.0000, 0.1073, 0.0000],
        [0.0967, 0.0000, 0.0131,  ..., 0.0000, 0.1071, 0.0000],
        [0.0962, 0.0000, 0.0133,  ..., 0.0000, 0.1070, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
result1.shape: torch.Size([20, 6796]) 
input: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]



load_model False 
TraEvN 10008 
BatchSize 30 
EpochNum 10 
epoch_save 5 
LrVal 0.001 
weight_decay 0.0001 
startmesh 305 
endmesh 306 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[[[-0.0409, -0.3082, -0.2109],
          [-0.3072, -0.2454,  0.0673],
          [ 0.2932, -0.1293,  0.1658]]],


        [[[ 0.1011, -0.1918,  0.0271],
          [ 0.1713,  0.3208,  0.0346],
          [-0.3014,  0.0895,  0.2629]]],


        [[[-0.0422,  0.1202,  0.2165],
          [ 0.1142,  0.1862,  0.2644],
          [-0.0165, -0.3197, -0.3199]]],


        ...,


        [[[-0.1969,  0.1698,  0.3235],
          [-0.2294,  0.3260, -0.0259],
          [ 0.0255, -0.0572,  0.0672]]],


        [[[ 0.0224,  0.3318,  0.1409],
          [ 0.2592,  0.2413, -0.0020],
          [ 0.1931,  0.1969, -0.1325]]],


        [[[ 0.1216,  0.0269, -0.2082],
          [ 0.2597,  0.0930,  0.1914],
          [ 0.0775,  0.0985, -0.0221]]]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 2.2542e-01,  1.7748e-01,  2.3261e-02,  3.1090e-01,  2.3466e-01,
         1.3388e-01, -2.7490e-01, -2.6748e-01,  1.4134e-03,  1.5057e-01,
        -8.6245e-02, -2.6525e-01,  1.1538e-01,  5.0001e-02, -1.2438e-01,
         1.8601e-01, -1.7948e-01,  2.1573e-01, -2.4648e-01, -1.9266e-01,
         2.2896e-01,  1.9355e-01, -2.9198e-01,  1.3913e-01,  2.6255e-01,
         2.3156e-01, -1.7553e-01,  6.2780e-02, -5.8069e-02,  2.3251e-01,
        -8.9037e-02, -1.7244e-01, -1.2636e-01,  2.9649e-03, -2.7310e-01,
         1.9693e-01,  7.7334e-02,  5.2527e-03, -1.9220e-01, -4.5235e-02,
         1.5544e-01, -2.8004e-01,  4.3943e-02, -2.5929e-01,  3.0796e-01,
         2.0548e-02,  2.6259e-01,  3.2438e-01, -1.2852e-01,  9.0584e-02,
        -2.7177e-01, -1.7813e-01,  1.3870e-01, -1.6958e-01,  1.0858e-01,
         4.8864e-02, -2.4826e-01, -1.4004e-01, -2.1277e-01, -4.9884e-02,
        -8.3426e-02, -2.0654e-01,  1.2918e-01,  5.6649e-02, -2.6845e-01,
        -7.1091e-02, -2.5343e-01,  8.0517e-02, -2.0710e-01, -2.0949e-02,
         2.4253e-02, -1.2381e-01, -1.5254e-01, -2.5804e-02, -7.1214e-02,
        -2.3652e-01, -1.5332e-01,  1.7581e-01,  7.2996e-02,  2.0846e-01,
         1.9197e-01,  2.2977e-02,  1.8834e-01, -1.5853e-01, -2.8334e-01,
         1.2055e-01, -2.7946e-01,  1.3091e-01,  1.8368e-01,  2.5232e-01,
         3.1802e-01,  2.2305e-01,  2.3376e-01,  7.2847e-02,  1.2029e-02,
         3.1770e-01, -1.5782e-01, -2.7427e-01,  9.8614e-02, -1.7891e-01,
        -1.2319e-02, -3.2840e-01,  7.5003e-02,  2.1940e-01, -1.9390e-01,
         1.8856e-02,  8.1723e-02,  1.9782e-01,  1.9476e-01,  1.0180e-01,
        -3.3022e-01,  1.2055e-01, -1.9441e-01,  2.7371e-01, -3.2351e-01,
        -1.2358e-01, -1.2934e-01, -7.2951e-02,  1.4434e-02, -2.5932e-01,
         2.8013e-01, -1.3560e-02,  2.7679e-02, -4.6931e-02, -2.6278e-01,
         2.7357e-01,  3.9402e-02,  2.7980e-01,  1.1123e-01, -3.1931e-01,
        -2.6045e-01,  2.2631e-01, -1.0454e-02,  4.9794e-02,  2.5452e-01,
         7.9919e-02,  1.3490e-01,  3.2478e-01,  6.2082e-02,  3.7336e-02,
        -1.3755e-01, -3.0342e-01, -3.1680e-01,  2.3947e-03,  1.8163e-01,
         2.1120e-01,  5.4269e-02,  2.1272e-01, -3.4202e-02, -8.4988e-02,
        -1.1970e-01, -5.3938e-02,  2.6556e-01,  2.9950e-01, -7.7594e-02,
        -2.1659e-01,  2.2464e-01,  1.1501e-02,  4.0371e-02, -3.0528e-01,
        -3.3078e-01, -2.2485e-01, -9.1970e-02, -2.6574e-01, -1.3463e-01,
         2.4626e-02,  1.5394e-01,  1.0984e-01, -1.0719e-01, -4.2206e-02,
         1.6927e-01,  1.1908e-01,  1.7778e-01,  2.5589e-01,  2.5388e-01,
         5.5536e-02,  1.4015e-01,  6.4052e-02,  2.2347e-02, -2.5611e-01,
        -1.2699e-03,  1.9465e-02, -1.4431e-01,  2.0742e-01,  9.8707e-02,
        -1.8669e-01,  3.9591e-03, -2.2427e-01,  2.8341e-01, -3.3238e-02,
        -2.4027e-01, -3.2669e-01, -3.2186e-01, -1.4754e-01,  1.3309e-03,
         5.4968e-02,  9.2520e-02,  3.0864e-01,  1.5310e-01, -1.8248e-02,
        -3.6560e-02, -3.2094e-01, -5.1758e-02, -1.4030e-01,  2.4768e-01,
        -1.8827e-02,  4.6364e-03,  1.1258e-01, -1.1419e-01,  2.4500e-01,
        -2.1063e-01,  3.0034e-01, -2.9567e-03, -5.9640e-02, -7.2551e-02,
         1.5555e-01, -1.1086e-01, -1.4473e-01,  1.3764e-01,  7.5192e-02,
         4.2590e-02,  1.2495e-01,  1.7135e-01,  2.2874e-03, -1.6173e-01,
        -2.7035e-02,  8.1187e-02, -1.2443e-01,  1.9427e-01,  1.1182e-01,
        -2.5706e-01, -1.9651e-01, -2.5378e-01, -2.7540e-02, -3.0560e-01,
         4.8095e-02,  1.2075e-01, -2.4958e-01, -1.1672e-01,  3.0577e-04,
         2.2317e-01, -2.3482e-01, -1.1495e-01, -5.2952e-02, -2.7739e-01,
         4.2423e-02, -2.9880e-01,  1.8476e-01, -1.1107e-01,  1.6032e-01,
         1.0563e-01, -1.3547e-01, -2.4445e-01,  2.4353e-01, -1.6200e-01,
        -2.3387e-01], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[ 1.6188e-03, -1.5726e-03, -1.4744e-02],
          [-3.2339e-04, -2.0337e-02, -2.3174e-03],
          [ 1.9752e-02,  9.4876e-03, -8.0680e-03]],

         [[ 9.1026e-03, -1.4061e-02, -3.0521e-03],
          [ 1.3605e-02,  1.0808e-02,  1.4680e-02],
          [ 1.1409e-02,  1.5506e-03,  1.5183e-02]],

         [[-3.9360e-03, -3.6660e-03,  4.8315e-04],
          [ 1.7056e-02,  4.9052e-03,  5.8022e-03],
          [-1.2567e-02,  4.5479e-03,  1.4286e-02]],

         ...,

         [[ 1.8257e-02, -4.1608e-03,  1.7332e-02],
          [-1.4423e-02,  7.0036e-03, -1.1752e-02],
          [-4.5203e-03, -1.1150e-03,  1.8516e-02]],

         [[-1.7013e-02, -5.5944e-03, -1.3263e-02],
          [-1.7972e-02,  1.4380e-02,  9.3353e-03],
          [ 9.7420e-03,  1.5347e-02,  4.1629e-03]],

         [[-1.3873e-02,  2.3653e-03, -1.5926e-02],
          [-8.9209e-03,  1.3861e-02, -8.3966e-03],
          [-9.6114e-03, -1.4976e-02,  1.9430e-02]]],


        [[[ 1.0431e-02, -1.8536e-02,  3.6786e-03],
          [-9.3259e-03, -4.8685e-03, -4.4686e-03],
          [ 9.9120e-03,  7.7058e-04, -1.4102e-02]],

         [[ 1.1161e-02,  1.3878e-02, -1.9506e-02],
          [ 1.9376e-02, -1.3464e-02,  1.2885e-02],
          [-8.1867e-03,  3.4777e-03,  1.5633e-02]],

         [[-8.8553e-04,  1.6956e-02,  1.7479e-02],
          [ 1.4173e-02,  9.0305e-03,  9.6289e-03],
          [-1.5346e-02,  7.6984e-03,  9.7603e-03]],

         ...,

         [[ 1.3078e-02, -9.0386e-03,  1.7282e-02],
          [ 1.8312e-02,  1.5902e-02, -1.7877e-02],
          [ 2.0732e-02,  5.3694e-04, -1.9911e-02]],

         [[ 1.7714e-02,  9.1841e-03, -1.3080e-03],
          [-1.7078e-02,  2.4292e-03,  2.7979e-03],
          [ 1.8381e-02,  1.5937e-02, -1.4076e-02]],

         [[-1.2429e-02, -1.8524e-02, -3.5657e-03],
          [ 8.5626e-03,  1.0883e-02, -1.5966e-02],
          [ 1.6121e-02, -4.0653e-03, -1.2767e-02]]],


        [[[-2.0757e-02,  1.3487e-02,  1.1994e-02],
          [-5.5823e-03,  5.3143e-05,  2.4316e-03],
          [ 6.1682e-03, -1.0490e-02,  1.9744e-02]],

         [[ 1.4398e-02,  1.8687e-02, -2.0468e-02],
          [ 1.3918e-02,  5.5943e-03, -9.9418e-04],
          [ 7.2682e-03, -1.5645e-02,  1.4963e-02]],

         [[ 8.0979e-03, -2.0644e-02, -1.9238e-02],
          [-1.1692e-02, -5.4833e-03,  1.6075e-02],
          [ 1.7163e-02, -1.2692e-02,  1.1399e-02]],

         ...,

         [[-9.9897e-03, -1.1529e-02, -1.5877e-02],
          [ 3.2124e-03,  7.1867e-03, -3.6218e-03],
          [-5.0613e-03,  8.2018e-03,  2.5021e-03]],

         [[-1.7951e-02, -7.1079e-03, -2.0719e-02],
          [ 6.5039e-03,  3.8756e-03, -1.9313e-02],
          [-1.4121e-02, -1.4525e-03,  1.7532e-02]],

         [[-1.3040e-02, -1.7676e-02,  9.8318e-03],
          [ 1.1497e-02,  2.0258e-02, -2.0655e-02],
          [ 4.5539e-03, -4.8338e-03,  1.9269e-02]]],


        ...,


        [[[ 1.1395e-02, -1.1216e-02, -1.0999e-02],
          [-9.6541e-03, -4.7683e-03,  1.3675e-02],
          [ 1.9193e-02, -1.8958e-02,  9.8688e-03]],

         [[ 1.4922e-02, -1.6412e-02, -1.6646e-02],
          [-3.3418e-03,  1.7214e-02,  1.2542e-02],
          [-2.0567e-02,  7.5062e-03,  1.2927e-02]],

         [[ 3.0905e-03, -1.0903e-04,  4.4774e-03],
          [ 1.5768e-02,  3.9797e-03, -1.8900e-02],
          [ 1.4671e-02, -5.6660e-03, -1.4550e-02]],

         ...,

         [[-1.0139e-02, -1.8617e-02, -8.6239e-03],
          [ 1.4483e-02, -1.5176e-02, -4.2803e-03],
          [ 1.4593e-02, -2.1055e-03, -1.8029e-02]],

         [[ 4.8076e-03,  1.9594e-02, -2.6995e-03],
          [ 5.7331e-03,  3.6000e-03,  1.1691e-02],
          [-3.2996e-03, -7.7230e-03,  1.9604e-02]],

         [[ 1.4269e-03,  1.1323e-02,  1.2626e-02],
          [-7.0050e-03,  2.3432e-04,  8.6081e-03],
          [-1.2762e-02, -1.4132e-02,  1.2677e-03]]],


        [[[ 1.6194e-02, -1.7634e-02,  1.2762e-02],
          [-2.2638e-03,  1.0247e-02, -7.2364e-03],
          [-5.7017e-04,  1.4898e-02, -3.7035e-03]],

         [[-1.0670e-02,  1.6617e-02, -1.6849e-02],
          [-4.7079e-03,  1.6690e-02, -4.0025e-03],
          [ 1.4537e-02,  1.8017e-02,  1.3504e-02]],

         [[-1.5079e-02,  8.6930e-03, -7.6810e-03],
          [-1.8313e-02,  1.2881e-02,  6.4295e-03],
          [ 4.0532e-03,  2.0698e-02, -1.7097e-02]],

         ...,

         [[-1.2287e-03,  2.0595e-02,  1.7386e-02],
          [ 1.9125e-03, -1.5656e-02,  6.2358e-03],
          [ 5.8951e-03, -1.5081e-02,  1.6625e-02]],

         [[-1.9769e-02, -1.1746e-02, -1.2168e-03],
          [ 1.3043e-02,  1.5916e-02, -3.3693e-03],
          [ 1.3123e-02, -1.2071e-02, -5.3984e-03]],

         [[-1.7381e-02,  1.7318e-02,  9.6601e-03],
          [-2.3793e-03,  8.3735e-03,  1.6388e-02],
          [-4.7767e-03, -5.0455e-03,  1.6524e-02]]],


        [[[-1.7592e-02, -3.2817e-04, -1.5809e-02],
          [-9.7470e-03,  9.9257e-03, -1.9466e-02],
          [-1.4915e-02, -9.8718e-04,  1.3872e-02]],

         [[ 1.5578e-02, -1.3965e-02,  1.0752e-02],
          [-4.7126e-03,  1.5298e-02,  9.0604e-03],
          [-2.7974e-03, -9.4266e-03, -2.0026e-02]],

         [[-1.4807e-02, -1.6235e-02, -1.7307e-03],
          [-1.9745e-02,  1.8929e-02, -1.9453e-03],
          [-8.9778e-03,  3.1476e-03,  1.6151e-02]],

         ...,

         [[-7.8857e-03,  2.0827e-02,  4.5902e-03],
          [ 1.4239e-02,  3.0472e-03, -1.0979e-02],
          [ 1.9726e-02, -1.7844e-02,  1.3557e-02]],

         [[-9.3171e-03,  7.5211e-04,  1.5612e-02],
          [-1.2874e-02, -8.9696e-03,  8.0320e-03],
          [-3.9888e-03,  1.2405e-02, -3.7741e-03]],

         [[ 1.2635e-02, -4.8564e-03,  5.1510e-03],
          [-8.5257e-03, -4.1647e-03, -8.2563e-03],
          [ 2.0355e-03,  7.4000e-03,  1.5827e-02]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([ 1.3150e-02, -9.9331e-05,  3.4531e-03,  2.8926e-03,  7.3496e-03,
         2.0088e-04, -5.6907e-03, -1.8756e-02,  9.1130e-03,  3.5487e-03,
        -1.1031e-02,  8.9427e-03, -5.4477e-03, -1.0586e-02, -6.6001e-03,
        -7.8747e-03, -1.2201e-02, -1.2385e-02, -1.6034e-02,  1.2743e-02,
        -2.5568e-03,  1.0159e-02, -9.0835e-03, -1.9293e-03,  4.9636e-03,
        -1.1368e-02, -1.3471e-02,  1.0191e-02, -1.9691e-02,  1.5322e-02,
        -7.5769e-03,  2.0421e-02, -1.1287e-02, -1.5444e-02,  1.8913e-02,
         1.5794e-02,  8.9187e-03, -1.4780e-02,  3.7258e-03, -2.0365e-02,
        -2.0862e-05,  1.3633e-02,  8.3362e-03,  1.8781e-02,  7.9879e-03,
         1.3184e-02,  8.3395e-03,  7.0855e-03,  1.6819e-02,  7.1972e-03,
         5.7330e-03, -1.4360e-03,  1.6672e-02, -1.4321e-02,  1.2800e-03,
         1.8439e-03, -6.6837e-03, -6.2048e-03,  1.0217e-02, -1.2377e-02,
        -9.6748e-03, -3.3080e-03,  1.2878e-02, -1.6817e-02, -2.8713e-03,
        -3.5511e-04,  7.7333e-03,  5.6467e-03,  1.3199e-02, -2.6336e-03,
         1.8104e-02, -4.2465e-03,  1.6199e-02, -9.7527e-03, -1.2797e-02,
         9.7054e-03,  5.4595e-03,  5.9857e-03,  8.0734e-03,  4.0640e-03,
         1.7981e-02, -1.9970e-02, -1.9059e-02, -1.1314e-02, -1.6392e-02,
        -1.9683e-02,  3.2473e-03,  1.6809e-02,  1.2146e-02, -3.5072e-03,
        -6.3199e-03, -1.7865e-03, -1.8601e-02, -1.8684e-02, -2.0641e-02,
        -6.3961e-04,  4.2182e-03, -1.9002e-02, -4.2488e-04, -1.8966e-02,
        -9.2023e-03,  2.0224e-02, -1.6634e-02,  1.7477e-03, -1.9505e-02,
         1.7302e-02, -1.2747e-02, -1.4466e-02, -4.0112e-03,  1.8172e-02,
         6.4018e-03, -8.5591e-03,  7.9742e-03,  1.5168e-02, -1.9582e-02,
         1.4539e-02, -5.0509e-03,  2.7457e-03, -5.7317e-03, -2.0523e-03,
        -1.1310e-02, -1.4584e-02,  1.4167e-02,  1.9611e-02, -1.7206e-02,
         1.8866e-02,  9.8993e-03, -7.9423e-03], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[[[ 0.0129, -0.0071, -0.0043],
          [-0.0201,  0.0043,  0.0192],
          [-0.0075,  0.0057,  0.0261]],

         [[ 0.0179,  0.0083,  0.0131],
          [-0.0145,  0.0043,  0.0192],
          [-0.0050,  0.0272, -0.0027]],

         [[ 0.0093, -0.0265, -0.0268],
          [-0.0224, -0.0268,  0.0135],
          [-0.0239, -0.0212, -0.0059]],

         ...,

         [[-0.0106, -0.0290, -0.0112],
          [-0.0162,  0.0021,  0.0117],
          [-0.0022,  0.0193,  0.0065]],

         [[ 0.0036, -0.0053, -0.0094],
          [-0.0146,  0.0131,  0.0100],
          [-0.0262,  0.0071,  0.0045]],

         [[-0.0108, -0.0067, -0.0250],
          [-0.0096, -0.0182,  0.0193],
          [ 0.0149,  0.0074,  0.0070]]],


        [[[-0.0052, -0.0090, -0.0195],
          [ 0.0207,  0.0200, -0.0189],
          [ 0.0291,  0.0048, -0.0294]],

         [[-0.0041,  0.0204, -0.0117],
          [-0.0283, -0.0116, -0.0241],
          [-0.0129, -0.0204,  0.0025]],

         [[-0.0249,  0.0078, -0.0114],
          [ 0.0271, -0.0212,  0.0208],
          [-0.0117,  0.0007, -0.0286]],

         ...,

         [[ 0.0272,  0.0161, -0.0125],
          [ 0.0111,  0.0109,  0.0275],
          [-0.0141, -0.0076,  0.0110]],

         [[-0.0088,  0.0007,  0.0213],
          [-0.0271,  0.0236, -0.0159],
          [ 0.0093, -0.0103,  0.0164]],

         [[-0.0035, -0.0043, -0.0064],
          [ 0.0068,  0.0037,  0.0202],
          [ 0.0129, -0.0269, -0.0290]]],


        [[[ 0.0123, -0.0105, -0.0137],
          [ 0.0158,  0.0031,  0.0162],
          [-0.0003, -0.0099,  0.0202]],

         [[-0.0020,  0.0044,  0.0263],
          [-0.0154,  0.0104,  0.0186],
          [ 0.0133,  0.0087, -0.0274]],

         [[-0.0286, -0.0232,  0.0199],
          [ 0.0105,  0.0161,  0.0223],
          [ 0.0294, -0.0244, -0.0217]],

         ...,

         [[ 0.0190,  0.0045,  0.0139],
          [-0.0148, -0.0214, -0.0193],
          [ 0.0058,  0.0229,  0.0254]],

         [[ 0.0025, -0.0139,  0.0283],
          [ 0.0130,  0.0114, -0.0109],
          [-0.0278,  0.0053,  0.0199]],

         [[ 0.0242,  0.0116,  0.0032],
          [ 0.0012, -0.0194,  0.0125],
          [-0.0149, -0.0163,  0.0158]]],


        ...,


        [[[-0.0050,  0.0108, -0.0096],
          [-0.0117, -0.0014, -0.0074],
          [ 0.0111,  0.0252,  0.0074]],

         [[ 0.0116, -0.0146,  0.0216],
          [ 0.0062, -0.0243, -0.0234],
          [-0.0126, -0.0243,  0.0213]],

         [[-0.0227,  0.0224, -0.0009],
          [ 0.0130, -0.0229, -0.0116],
          [-0.0284,  0.0152, -0.0225]],

         ...,

         [[ 0.0221, -0.0026, -0.0100],
          [-0.0153,  0.0269, -0.0229],
          [ 0.0289, -0.0175,  0.0207]],

         [[-0.0042,  0.0251, -0.0157],
          [-0.0290,  0.0143, -0.0124],
          [ 0.0116, -0.0105, -0.0091]],

         [[-0.0289,  0.0289, -0.0211],
          [ 0.0173, -0.0056, -0.0188],
          [-0.0140,  0.0096,  0.0023]]],


        [[[ 0.0199, -0.0098, -0.0143],
          [-0.0171, -0.0259, -0.0071],
          [-0.0246, -0.0010, -0.0063]],

         [[ 0.0100, -0.0280, -0.0228],
          [-0.0174,  0.0252, -0.0164],
          [ 0.0053,  0.0272, -0.0203]],

         [[ 0.0270,  0.0261,  0.0053],
          [-0.0078, -0.0122,  0.0209],
          [-0.0211,  0.0175, -0.0172]],

         ...,

         [[-0.0274,  0.0240,  0.0117],
          [-0.0261,  0.0043, -0.0071],
          [ 0.0136,  0.0045, -0.0238]],

         [[-0.0160, -0.0013, -0.0234],
          [-0.0219,  0.0033, -0.0238],
          [-0.0063, -0.0292, -0.0097]],

         [[ 0.0070,  0.0079,  0.0103],
          [-0.0294,  0.0177, -0.0153],
          [ 0.0137, -0.0197,  0.0047]]],


        [[[-0.0119, -0.0259, -0.0284],
          [ 0.0145, -0.0068,  0.0092],
          [ 0.0236, -0.0166, -0.0233]],

         [[-0.0100,  0.0101, -0.0058],
          [ 0.0283, -0.0235,  0.0186],
          [ 0.0190, -0.0172,  0.0063]],

         [[ 0.0198, -0.0002,  0.0254],
          [ 0.0140,  0.0192, -0.0236],
          [-0.0180,  0.0216,  0.0045]],

         ...,

         [[ 0.0221, -0.0249,  0.0214],
          [-0.0219, -0.0261, -0.0004],
          [ 0.0064,  0.0210, -0.0157]],

         [[ 0.0071, -0.0095,  0.0047],
          [ 0.0278, -0.0018,  0.0087],
          [ 0.0111,  0.0155,  0.0178]],

         [[ 0.0099,  0.0259, -0.0024],
          [ 0.0038,  0.0168, -0.0283],
          [ 0.0042, -0.0084, -0.0060]]]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0261, -0.0224, -0.0088, -0.0216,  0.0286,  0.0042, -0.0255, -0.0214,
        -0.0133,  0.0163,  0.0198,  0.0236,  0.0112, -0.0282, -0.0271, -0.0064,
        -0.0029,  0.0209,  0.0010, -0.0275,  0.0257,  0.0066, -0.0047,  0.0208,
         0.0146,  0.0198,  0.0274,  0.0288,  0.0271,  0.0110,  0.0149, -0.0215,
        -0.0259, -0.0033,  0.0255,  0.0055, -0.0047, -0.0229, -0.0177,  0.0100,
        -0.0212,  0.0030, -0.0121, -0.0138,  0.0072, -0.0257,  0.0115, -0.0008,
         0.0237, -0.0257, -0.0116, -0.0262, -0.0021, -0.0240, -0.0255,  0.0286,
        -0.0158, -0.0157,  0.0288,  0.0233, -0.0135, -0.0029, -0.0175, -0.0148],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 1.1270e-03, -9.2165e-04,  1.2118e-04,  ...,  7.7948e-04,
         -8.4428e-04, -7.9912e-04],
        [ 1.9684e-04,  1.5760e-04,  4.4830e-04,  ...,  1.9324e-04,
         -7.6240e-05,  7.9734e-04],
        [ 6.8742e-04, -1.0704e-03,  1.1192e-03,  ...,  8.7934e-04,
         -1.5307e-04, -4.1193e-04],
        ...,
        [-1.9775e-04, -5.1997e-04,  8.2149e-04,  ...,  1.1439e-03,
         -1.2073e-03,  7.7411e-04],
        [-2.0999e-04, -1.1409e-03, -3.0785e-04,  ...,  9.9066e-04,
         -2.0021e-04, -6.6900e-06],
        [-9.2083e-04, -2.2516e-04, -1.2028e-03,  ...,  2.9899e-04,
          4.9929e-04,  4.5104e-04]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-5.4111e-04, -6.6931e-04,  4.2109e-04, -4.2981e-04,  2.6888e-04,
         1.1571e-03, -1.0991e-03, -4.5080e-04,  3.8666e-04, -9.1460e-04,
         9.6893e-04,  1.1291e-03, -7.3510e-05, -7.7437e-04,  1.1434e-04,
         1.2805e-04, -9.7149e-04,  1.0722e-04,  5.6940e-04, -6.1511e-04,
         2.0517e-05, -6.3192e-04, -3.5059e-04,  4.4777e-04,  2.2647e-04,
        -1.0678e-03,  1.6537e-04, -9.2147e-04,  9.7867e-04,  1.0578e-03,
        -2.0367e-04, -1.0180e-03,  1.5826e-05, -7.5308e-04,  8.9081e-04,
        -1.6023e-04, -1.1746e-03, -1.0203e-03,  1.0398e-03,  9.9430e-04,
        -9.4398e-04,  8.0283e-04,  5.3372e-04, -4.7192e-04,  9.1556e-04,
        -8.1881e-04, -3.2899e-04, -8.7693e-04, -4.8942e-04,  8.3541e-04,
        -1.0745e-03,  1.4139e-05,  7.7134e-04, -4.9992e-04,  1.0924e-03,
         9.5352e-04,  9.5945e-04, -9.9436e-04, -9.0120e-04, -5.6164e-05,
         9.8452e-05, -9.0279e-04,  1.4684e-04, -2.0549e-04,  5.0138e-04,
        -1.0604e-03,  8.3729e-04,  6.0713e-04, -1.1139e-03, -5.4124e-04,
         1.0619e-03, -2.0097e-04, -6.5548e-04, -1.6563e-04, -1.9983e-04,
         3.3142e-04,  2.9413e-04,  6.6364e-04,  5.2079e-06, -3.6126e-04,
        -6.1388e-04, -4.9184e-04, -9.9426e-04, -1.0227e-03, -1.9615e-04,
        -1.2179e-03,  8.2304e-04,  2.6876e-04,  2.8097e-04, -4.1352e-04,
        -2.0356e-04,  3.7917e-04, -5.2825e-04, -1.1920e-03, -8.5679e-04,
        -1.1685e-03,  1.0150e-03,  3.7063e-04, -5.4761e-04,  9.3355e-04,
         2.6735e-04,  1.7244e-04, -9.9686e-04,  6.2094e-04,  1.9287e-04,
        -1.2136e-03,  7.0723e-04, -2.7928e-05,  2.1722e-04, -4.0679e-04,
         1.2010e-03,  6.6366e-04, -1.0047e-03,  7.1315e-04, -7.2802e-04,
         3.4255e-04, -1.1017e-03,  9.7149e-05,  1.2050e-03, -1.0777e-03,
        -6.4623e-04,  2.5760e-04,  1.0172e-03,  5.3414e-04, -2.8920e-04,
        -3.9463e-04, -6.8989e-05,  1.0386e-03,  9.3418e-04, -9.0410e-04,
         2.4574e-04, -8.4005e-04,  2.8919e-04,  1.1870e-03, -6.5706e-04,
         6.2449e-04, -1.0711e-04, -2.3564e-04,  1.0843e-03,  4.5157e-05,
        -5.8875e-04, -1.0424e-03,  3.7888e-04,  1.1836e-03,  1.0210e-03,
         3.3248e-04, -2.4319e-04,  4.1963e-04,  1.2091e-03,  9.7025e-04,
         7.7979e-04,  1.4060e-04, -5.5149e-04,  3.1632e-04,  1.9584e-04,
         8.2737e-04,  1.1889e-03, -4.4406e-04,  2.9565e-04, -1.1739e-03,
         1.8757e-04,  7.6513e-04, -1.1143e-03,  4.9077e-04,  8.2729e-04,
         4.6734e-04,  3.1024e-04, -1.1334e-04, -1.2130e-03,  1.0047e-03,
         4.7108e-04,  9.9165e-04,  7.4713e-04, -5.2256e-04,  3.3824e-04,
        -6.5813e-04, -5.7817e-04,  8.6009e-04,  9.3205e-04,  5.2609e-04,
        -7.0885e-04,  3.5254e-04, -3.7213e-05,  2.2665e-04,  1.1425e-03,
         1.1604e-03, -1.1375e-03, -5.6722e-04,  4.9502e-04, -7.0647e-04,
         9.7185e-04,  3.0661e-04, -7.9089e-04, -7.9889e-04, -4.1612e-04,
        -2.9805e-04, -3.6654e-04,  5.9937e-04, -8.6463e-04, -2.9704e-04,
        -9.2267e-04,  3.9103e-04,  1.6696e-04,  8.0422e-04, -1.1523e-03,
         2.0468e-04, -3.9130e-05, -1.0260e-03,  3.3029e-04,  4.4975e-04,
         7.6442e-04, -6.8657e-04, -1.1503e-03, -5.0343e-04, -7.0945e-04,
        -3.3452e-04, -1.2188e-03, -8.4303e-04,  7.4055e-04, -4.8737e-04,
         4.5875e-04,  6.7080e-04,  6.1483e-05,  7.2528e-04, -2.0592e-04,
         6.7825e-04, -1.6491e-04, -9.8878e-04,  5.7375e-04,  7.7825e-04,
        -4.9613e-04,  6.7846e-04,  1.5731e-04, -6.9042e-04,  6.5447e-04,
        -1.0302e-03, -5.3145e-04,  1.0409e-03, -9.3309e-05,  1.1215e-03,
        -1.7065e-04,  5.3715e-04,  2.3446e-04,  2.1571e-04, -1.0847e-03,
         9.5772e-05,  4.6462e-04,  1.1341e-03,  3.6574e-04, -8.4747e-04,
        -9.8738e-05,  1.0861e-03, -2.2829e-04,  9.0824e-04,  7.4592e-04,
         1.1314e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-3.9634e-02,  1.0286e-02,  1.8465e-03,  ..., -3.3826e-02,
          3.5192e-02, -5.3101e-02],
        [ 5.9243e-02, -2.4571e-02,  3.1042e-02,  ...,  1.6644e-02,
          1.4967e-02,  5.8076e-02],
        [-4.9515e-02, -3.0099e-02,  4.9599e-02,  ..., -1.9949e-02,
         -1.5172e-02, -6.8617e-03],
        ...,
        [-2.2158e-02,  2.4102e-02,  4.5571e-03,  ..., -2.1295e-02,
          3.6046e-03, -1.3420e-02],
        [ 5.5661e-02, -4.2334e-02, -3.9073e-02,  ..., -3.2645e-02,
          2.7090e-05,  8.8009e-03],
        [-2.5518e-02,  1.5762e-02,  2.7072e-02,  ...,  9.8805e-03,
         -1.3590e-02,  4.1811e-02]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0192,  0.0441, -0.0334, -0.0345,  0.0425, -0.0572,  0.0290,  0.0099,
        -0.0400,  0.0302, -0.0359,  0.0620,  0.0404,  0.0586,  0.0610,  0.0177,
        -0.0234, -0.0036,  0.0398,  0.0001,  0.0581, -0.0613, -0.0575, -0.0608,
         0.0023, -0.0162, -0.0474, -0.0436,  0.0436,  0.0549,  0.0577,  0.0622,
         0.0573, -0.0609, -0.0031, -0.0083,  0.0240,  0.0515, -0.0064,  0.0496,
         0.0119, -0.0261, -0.0069,  0.0592,  0.0390,  0.0352,  0.0327, -0.0586,
        -0.0223, -0.0194, -0.0125,  0.0118,  0.0496,  0.0545, -0.0617,  0.0575,
        -0.0293,  0.0389, -0.0136, -0.0251,  0.0269, -0.0196, -0.0370, -0.0029,
         0.0169, -0.0517, -0.0207,  0.0196, -0.0204,  0.0453, -0.0386,  0.0096,
         0.0583, -0.0022, -0.0453,  0.0102,  0.0016, -0.0261, -0.0433,  0.0066,
         0.0581, -0.0051,  0.0188, -0.0411,  0.0008,  0.0296,  0.0061,  0.0412,
        -0.0467,  0.0202,  0.0616,  0.0226, -0.0006, -0.0570,  0.0198,  0.0162,
        -0.0176, -0.0060,  0.0612,  0.0544, -0.0437, -0.0146,  0.0562, -0.0513,
         0.0388, -0.0174,  0.0424, -0.0254, -0.0140, -0.0028,  0.0233,  0.0239,
         0.0514,  0.0385, -0.0017, -0.0445, -0.0306, -0.0468,  0.0004, -0.0070,
        -0.0055,  0.0386, -0.0342, -0.0033,  0.0512, -0.0611,  0.0462,  0.0347],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0004,  0.0029, -0.0098,  ..., -0.0139, -0.0376,  0.0619],
        [-0.0436,  0.0303,  0.0234,  ...,  0.0597,  0.0718, -0.0407],
        [ 0.0591,  0.0207, -0.0265,  ..., -0.0842, -0.0579,  0.0760],
        ...,
        [ 0.0202,  0.0653,  0.0866,  ...,  0.0638,  0.0013, -0.0683],
        [ 0.0349,  0.0672,  0.0412,  ..., -0.0218, -0.0441,  0.0423],
        [-0.0461,  0.0703, -0.0435,  ...,  0.0446,  0.0269,  0.0229]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0260, -0.0514, -0.0768,  0.0244,  0.0286,  0.0638,  0.0091, -0.0742,
         0.0866,  0.0133,  0.0332, -0.0244, -0.0701, -0.0301,  0.0137,  0.0348,
        -0.0339, -0.0726, -0.0006, -0.0302, -0.0714, -0.0304, -0.0403, -0.0212,
        -0.0274, -0.0220, -0.0124,  0.0356,  0.0021, -0.0781, -0.0831, -0.0217,
         0.0665,  0.0214, -0.0304, -0.0316,  0.0195,  0.0200,  0.0760, -0.0334,
         0.0596,  0.0498, -0.0619, -0.0046, -0.0045,  0.0140, -0.0243,  0.0413,
         0.0534,  0.0010,  0.0247,  0.0030,  0.0494,  0.0151,  0.0278,  0.0625,
        -0.0109, -0.0113, -0.0866, -0.0810, -0.0773, -0.0863, -0.0227, -0.0336],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0143,  0.0609, -0.0949,  ...,  0.0631, -0.0759,  0.0753],
        [ 0.0797, -0.0188, -0.0581,  ...,  0.1074, -0.0153, -0.1196],
        [-0.0666,  0.0551, -0.0699,  ...,  0.0017, -0.0103,  0.0034],
        ...,
        [-0.0957, -0.0798,  0.0552,  ...,  0.0380,  0.1080, -0.0244],
        [ 0.0111,  0.0709, -0.0418,  ...,  0.0098, -0.0583, -0.0121],
        [-0.0372,  0.0065, -0.1141,  ...,  0.0461,  0.1029, -0.1026]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.1038, -0.0950,  0.0255,  ..., -0.0673,  0.1009, -0.0580],
       device='cuda:0', requires_grad=True)], 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}]
epoch: 0 batch 0.0 event: 0 loss: tensor(184.3792, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 10.0 event: 300 loss: tensor(1841.9899, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 30.0 event: 900 loss: tensor(3849.6348, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 40.0 event: 1200 loss: tensor(2013.0344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 50.0 event: 1500 loss: tensor(2039.3190, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 60.0 event: 1800 loss: tensor(1803.6185, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 70.0 event: 2100 loss: tensor(2026.8021, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 80.0 event: 2400 loss: tensor(1751.9159, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 90.0 event: 2700 loss: tensor(1841.7255, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 100.0 event: 3000 loss: tensor(1761.8329, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 110.0 event: 3300 loss: tensor(2054.8401, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 120.0 event: 3600 loss: tensor(1539.7828, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 130.0 event: 3900 loss: tensor(1793.1650, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 140.0 event: 4200 loss: tensor(1978.6288, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 160.0 event: 4800 loss: tensor(3565.3787, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 170.0 event: 5100 loss: tensor(2002.1766, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 180.0 event: 5400 loss: tensor(1848.8951, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 190.0 event: 5700 loss: tensor(1815.1064, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 200.0 event: 6000 loss: tensor(2140.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 210.0 event: 6300 loss: tensor(1746.6252, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 220.0 event: 6600 loss: tensor(1870.7395, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 230.0 event: 6900 loss: tensor(2041.0596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 240.0 event: 7200 loss: tensor(2100.2590, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 250.0 event: 7500 loss: tensor(2079.4341, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 260.0 event: 7800 loss: tensor(2019.0784, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 270.0 event: 8100 loss: tensor(1780.1090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 280.0 event: 8400 loss: tensor(1828.6552, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 290.0 event: 8700 loss: tensor(1734.9945, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 300.0 event: 9000 loss: tensor(2055.5752, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 310.0 event: 9300 loss: tensor(1988.4628, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 320.0 event: 9600 loss: tensor(1749.8945, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 330.0 event: 9900 loss: tensor(1863.0648, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:00:22.161867
evaluation loss: 2027.5537109375
epoch: 0 mean loss: 1901.740478515625
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 1 batch 0.0 event: 0 loss: tensor(183.5517, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 10.0 event: 300 loss: tensor(1815.2744, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 30.0 event: 900 loss: tensor(3833.4556, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 40.0 event: 1200 loss: tensor(2005.4504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 50.0 event: 1500 loss: tensor(2033.0684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 60.0 event: 1800 loss: tensor(1798.6116, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 70.0 event: 2100 loss: tensor(2022.7842, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 80.0 event: 2400 loss: tensor(1749.1522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 90.0 event: 2700 loss: tensor(1839.6611, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 100.0 event: 3000 loss: tensor(1759.7952, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 110.0 event: 3300 loss: tensor(2052.7234, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 120.0 event: 3600 loss: tensor(1537.7227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 130.0 event: 3900 loss: tensor(1790.8180, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 140.0 event: 4200 loss: tensor(1974.8567, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 160.0 event: 4800 loss: tensor(3555.7361, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 170.0 event: 5100 loss: tensor(1995.0404, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 180.0 event: 5400 loss: tensor(1841.0588, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 190.0 event: 5700 loss: tensor(1807.7926, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 200.0 event: 6000 loss: tensor(2130.2930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 210.0 event: 6300 loss: tensor(1735.5253, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 220.0 event: 6600 loss: tensor(1858.5192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 230.0 event: 6900 loss: tensor(2029.2112, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 240.0 event: 7200 loss: tensor(2086.5918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 250.0 event: 7500 loss: tensor(2062.5637, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 260.0 event: 7800 loss: tensor(2002.5426, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 270.0 event: 8100 loss: tensor(1765.2762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 280.0 event: 8400 loss: tensor(1813.9135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 290.0 event: 8700 loss: tensor(1719.1981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 300.0 event: 9000 loss: tensor(2036.1136, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 310.0 event: 9300 loss: tensor(1969.5487, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 320.0 event: 9600 loss: tensor(1732.0813, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 330.0 event: 9900 loss: tensor(1846.8065, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:00:59.228654
evaluation loss: 2018.824462890625
epoch: 1 mean loss: 1891.767333984375
epoch: 2 batch 0.0 event: 0 loss: tensor(181.2424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 10.0 event: 300 loss: tensor(1797.4723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 30.0 event: 900 loss: tensor(3791.8599, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 40.0 event: 1200 loss: tensor(1982.7499, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 50.0 event: 1500 loss: tensor(2010.0592, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 60.0 event: 1800 loss: tensor(1777.4159, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 70.0 event: 2100 loss: tensor(2001.7139, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 80.0 event: 2400 loss: tensor(1727.3746, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 90.0 event: 2700 loss: tensor(1817.5908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 100.0 event: 3000 loss: tensor(1736.8381, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 110.0 event: 3300 loss: tensor(2026.4686, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 120.0 event: 3600 loss: tensor(1516.9993, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 130.0 event: 3900 loss: tensor(1765.7227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 140.0 event: 4200 loss: tensor(1947.9668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 160.0 event: 4800 loss: tensor(3512.0605, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 170.0 event: 5100 loss: tensor(1971.8928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 180.0 event: 5400 loss: tensor(1821.2059, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 190.0 event: 5700 loss: tensor(1785.8173, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 200.0 event: 6000 loss: tensor(2108.1833, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 210.0 event: 6300 loss: tensor(1716.0264, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 220.0 event: 6600 loss: tensor(1839.8682, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 230.0 event: 6900 loss: tensor(2010.2086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 240.0 event: 7200 loss: tensor(2066.0718, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 250.0 event: 7500 loss: tensor(2042.6702, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 260.0 event: 7800 loss: tensor(1984.7435, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 270.0 event: 8100 loss: tensor(1747.6223, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 280.0 event: 8400 loss: tensor(1797.2611, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 290.0 event: 8700 loss: tensor(1701.3978, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 300.0 event: 9000 loss: tensor(2017.7686, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 310.0 event: 9300 loss: tensor(1950.4398, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 320.0 event: 9600 loss: tensor(1716.3834, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 330.0 event: 9900 loss: tensor(1831.0615, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:32.250853
evaluation loss: 1997.0262451171875
epoch: 2 mean loss: 1871.106689453125
epoch: 3 batch 0.0 event: 0 loss: tensor(179.2056, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 10.0 event: 300 loss: tensor(1779.7496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 30.0 event: 900 loss: tensor(3758.5840, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 40.0 event: 1200 loss: tensor(1962.7360, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 50.0 event: 1500 loss: tensor(1992.6692, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 60.0 event: 1800 loss: tensor(1762.8746, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 70.0 event: 2100 loss: tensor(1986.1272, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 80.0 event: 2400 loss: tensor(1712.2582, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 90.0 event: 2700 loss: tensor(1803.0696, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 100.0 event: 3000 loss: tensor(1723.2426, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 110.0 event: 3300 loss: tensor(2011.3916, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 120.0 event: 3600 loss: tensor(1505.2933, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 130.0 event: 3900 loss: tensor(1753.7601, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 140.0 event: 4200 loss: tensor(1935.1240, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 160.0 event: 4800 loss: tensor(3488.6353, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 170.0 event: 5100 loss: tensor(1958.4980, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 180.0 event: 5400 loss: tensor(1808.9198, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 190.0 event: 5700 loss: tensor(1773.0156, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 200.0 event: 6000 loss: tensor(2096.1882, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 210.0 event: 6300 loss: tensor(1704.1307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 220.0 event: 6600 loss: tensor(1829.4032, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 230.0 event: 6900 loss: tensor(1999.4385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 240.0 event: 7200 loss: tensor(2054.5413, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 250.0 event: 7500 loss: tensor(2030.9922, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 260.0 event: 7800 loss: tensor(1974.2250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 270.0 event: 8100 loss: tensor(1738.2145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 280.0 event: 8400 loss: tensor(1788.4912, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 290.0 event: 8700 loss: tensor(1692.4398, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 300.0 event: 9000 loss: tensor(2007.4274, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 310.0 event: 9300 loss: tensor(1939.1356, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 320.0 event: 9600 loss: tensor(1707.3264, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 330.0 event: 9900 loss: tensor(1821.4467, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:05.256320
evaluation loss: 1984.5521240234375
epoch: 3 mean loss: 1858.3072509765625
epoch: 4 batch 0.0 event: 0 loss: tensor(178.2649, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 10.0 event: 300 loss: tensor(1785.2871, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 30.0 event: 900 loss: tensor(3755.8887, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 40.0 event: 1200 loss: tensor(1956.1403, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 50.0 event: 1500 loss: tensor(1982.5989, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 60.0 event: 1800 loss: tensor(1754.4250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 70.0 event: 2100 loss: tensor(1975.8187, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 80.0 event: 2400 loss: tensor(1702.2152, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 90.0 event: 2700 loss: tensor(1793.8350, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 100.0 event: 3000 loss: tensor(1713.6705, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 110.0 event: 3300 loss: tensor(2001.0582, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 120.0 event: 3600 loss: tensor(1496.8362, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 130.0 event: 3900 loss: tensor(1744.4071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 140.0 event: 4200 loss: tensor(1923.0287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 160.0 event: 4800 loss: tensor(3466.1111, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 170.0 event: 5100 loss: tensor(1943.3389, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 180.0 event: 5400 loss: tensor(1798.6731, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 190.0 event: 5700 loss: tensor(1761.5194, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 200.0 event: 6000 loss: tensor(2084.2393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 210.0 event: 6300 loss: tensor(1693.2875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 220.0 event: 6600 loss: tensor(1818.5371, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 230.0 event: 6900 loss: tensor(1985.9834, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 240.0 event: 7200 loss: tensor(2042.5863, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 250.0 event: 7500 loss: tensor(2019.4541, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 260.0 event: 7800 loss: tensor(1961.4437, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 270.0 event: 8100 loss: tensor(1725.6178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 280.0 event: 8400 loss: tensor(1777.3846, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 290.0 event: 8700 loss: tensor(1681.3030, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 300.0 event: 9000 loss: tensor(1995.2539, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 310.0 event: 9300 loss: tensor(1926.9940, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 320.0 event: 9600 loss: tensor(1696.2213, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 330.0 event: 9900 loss: tensor(1810.3760, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:38.256001
evaluation loss: 1976.1214599609375
epoch: 4 mean loss: 1848.390869140625
epoch: 5 batch 0.0 event: 0 loss: tensor(177.0304, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 10.0 event: 300 loss: tensor(1759.0811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 30.0 event: 900 loss: tensor(3718.6443, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 40.0 event: 1200 loss: tensor(1939.9280, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 50.0 event: 1500 loss: tensor(1969.3525, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 60.0 event: 1800 loss: tensor(1743.3508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 70.0 event: 2100 loss: tensor(1964.4193, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 80.0 event: 2400 loss: tensor(1691.9661, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 90.0 event: 2700 loss: tensor(1783.1893, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 100.0 event: 3000 loss: tensor(1703.4260, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 110.0 event: 3300 loss: tensor(1990.1826, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 120.0 event: 3600 loss: tensor(1488.1959, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 130.0 event: 3900 loss: tensor(1734.5520, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 140.0 event: 4200 loss: tensor(1913.1305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 160.0 event: 4800 loss: tensor(3449.5193, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 170.0 event: 5100 loss: tensor(1935.0979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 180.0 event: 5400 loss: tensor(1791.2535, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 190.0 event: 5700 loss: tensor(1754.3217, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 200.0 event: 6000 loss: tensor(2075.4175, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 210.0 event: 6300 loss: tensor(1685.5428, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 220.0 event: 6600 loss: tensor(1810.7330, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 230.0 event: 6900 loss: tensor(1976.7733, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 240.0 event: 7200 loss: tensor(2033.2050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 250.0 event: 7500 loss: tensor(2010.6389, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 260.0 event: 7800 loss: tensor(1952.9598, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 270.0 event: 8100 loss: tensor(1717.9095, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 280.0 event: 8400 loss: tensor(1769.8275, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 290.0 event: 8700 loss: tensor(1673.3563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 300.0 event: 9000 loss: tensor(1985.7639, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 310.0 event: 9300 loss: tensor(1918.3925, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 320.0 event: 9600 loss: tensor(1689.8846, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 330.0 event: 9900 loss: tensor(1804.4198, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:11.280305
evaluation loss: 1965.541259765625
epoch: 5 mean loss: 1838.1175537109375
=> saveing checkpoint at epoch 5
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 6 batch 0.0 event: 0 loss: tensor(176.1472, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 10.0 event: 300 loss: tensor(1752.1602, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 30.0 event: 900 loss: tensor(3705.5579, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 40.0 event: 1200 loss: tensor(1933.7308, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 50.0 event: 1500 loss: tensor(1961.4836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 60.0 event: 1800 loss: tensor(1737.5565, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 70.0 event: 2100 loss: tensor(1957.2551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 80.0 event: 2400 loss: tensor(1686.1840, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 90.0 event: 2700 loss: tensor(1777.5312, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 100.0 event: 3000 loss: tensor(1697.2841, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 110.0 event: 3300 loss: tensor(1983.0443, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 120.0 event: 3600 loss: tensor(1482.5575, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 130.0 event: 3900 loss: tensor(1728.1581, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 140.0 event: 4200 loss: tensor(1906.3254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 160.0 event: 4800 loss: tensor(3436.4880, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 170.0 event: 5100 loss: tensor(1929.9012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 180.0 event: 5400 loss: tensor(1785.2640, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 190.0 event: 5700 loss: tensor(1747.8203, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 200.0 event: 6000 loss: tensor(2068.6636, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 210.0 event: 6300 loss: tensor(1679.5234, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 220.0 event: 6600 loss: tensor(1805.8055, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 230.0 event: 6900 loss: tensor(1970.2285, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 240.0 event: 7200 loss: tensor(2026.7727, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 250.0 event: 7500 loss: tensor(2003.6569, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 260.0 event: 7800 loss: tensor(1945.9520, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 270.0 event: 8100 loss: tensor(1711.4969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 280.0 event: 8400 loss: tensor(1763.2952, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 290.0 event: 8700 loss: tensor(1667.6770, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 300.0 event: 9000 loss: tensor(1979.3984, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 310.0 event: 9300 loss: tensor(1913.1493, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 320.0 event: 9600 loss: tensor(1683.4277, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 330.0 event: 9900 loss: tensor(1798.2539, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:48.898873
evaluation loss: 1960.204345703125
epoch: 6 mean loss: 1831.7607421875
epoch: 7 batch 0.0 event: 0 loss: tensor(175.5880, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 10.0 event: 300 loss: tensor(1746.7836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 30.0 event: 900 loss: tensor(3693.7668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 40.0 event: 1200 loss: tensor(1927.4486, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 50.0 event: 1500 loss: tensor(1955.5020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 60.0 event: 1800 loss: tensor(1732.4111, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 70.0 event: 2100 loss: tensor(1951.5029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 80.0 event: 2400 loss: tensor(1681.3037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 90.0 event: 2700 loss: tensor(1772.1116, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 100.0 event: 3000 loss: tensor(1691.7979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 110.0 event: 3300 loss: tensor(1976.7327, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 120.0 event: 3600 loss: tensor(1478.2264, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 130.0 event: 3900 loss: tensor(1723.7877, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 140.0 event: 4200 loss: tensor(1900.8889, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 160.0 event: 4800 loss: tensor(3425.6106, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 170.0 event: 5100 loss: tensor(1925.7008, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 180.0 event: 5400 loss: tensor(1781.1458, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 190.0 event: 5700 loss: tensor(1743.8625, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 200.0 event: 6000 loss: tensor(2065.1230, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 210.0 event: 6300 loss: tensor(1674.9336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 220.0 event: 6600 loss: tensor(1801.5881, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 230.0 event: 6900 loss: tensor(1965.1213, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 240.0 event: 7200 loss: tensor(2022.1898, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 250.0 event: 7500 loss: tensor(1999.5106, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 260.0 event: 7800 loss: tensor(1940.3271, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 270.0 event: 8100 loss: tensor(1707.1942, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 280.0 event: 8400 loss: tensor(1758.4254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 290.0 event: 8700 loss: tensor(1663.8055, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 300.0 event: 9000 loss: tensor(1975.8525, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 310.0 event: 9300 loss: tensor(1908.8505, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 320.0 event: 9600 loss: tensor(1679.2167, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 330.0 event: 9900 loss: tensor(1793.7203, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:21.947543
evaluation loss: 1956.8177490234375
epoch: 7 mean loss: 1826.853271484375
epoch: 8 batch 0.0 event: 0 loss: tensor(174.9777, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 10.0 event: 300 loss: tensor(1742.9027, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 30.0 event: 900 loss: tensor(3683.4805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 40.0 event: 1200 loss: tensor(1922.6393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 50.0 event: 1500 loss: tensor(1951.4125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 60.0 event: 1800 loss: tensor(1728.3033, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 70.0 event: 2100 loss: tensor(1946.8828, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 80.0 event: 2400 loss: tensor(1677.9290, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 90.0 event: 2700 loss: tensor(1768.9678, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 100.0 event: 3000 loss: tensor(1688.4830, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 110.0 event: 3300 loss: tensor(1973.5648, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 120.0 event: 3600 loss: tensor(1476.0184, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 130.0 event: 3900 loss: tensor(1720.2268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 140.0 event: 4200 loss: tensor(1897.0409, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 160.0 event: 4800 loss: tensor(3417.4583, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 170.0 event: 5100 loss: tensor(1919.8990, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 180.0 event: 5400 loss: tensor(1777.1107, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 190.0 event: 5700 loss: tensor(1740.0455, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 200.0 event: 6000 loss: tensor(2061.3911, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 210.0 event: 6300 loss: tensor(1671.7158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 220.0 event: 6600 loss: tensor(1797.2106, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 230.0 event: 6900 loss: tensor(1960.2145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 240.0 event: 7200 loss: tensor(2018.4850, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 250.0 event: 7500 loss: tensor(1995.8229, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 260.0 event: 7800 loss: tensor(1936.9055, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 270.0 event: 8100 loss: tensor(1704.0331, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 280.0 event: 8400 loss: tensor(1754.8059, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 290.0 event: 8700 loss: tensor(1659.6057, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 300.0 event: 9000 loss: tensor(1972.5754, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 310.0 event: 9300 loss: tensor(1906.4098, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 320.0 event: 9600 loss: tensor(1677.8688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 330.0 event: 9900 loss: tensor(1789.8977, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:55.005469
evaluation loss: 1954.4794921875
epoch: 8 mean loss: 1823.041748046875
epoch: 9 batch 0.0 event: 0 loss: tensor(174.4502, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 10.0 event: 300 loss: tensor(1738.3295, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 30.0 event: 900 loss: tensor(3677.0969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 40.0 event: 1200 loss: tensor(1918.6910, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 50.0 event: 1500 loss: tensor(1947.0840, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 60.0 event: 1800 loss: tensor(1724.9469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 70.0 event: 2100 loss: tensor(1943.5551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 80.0 event: 2400 loss: tensor(1675.2012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 90.0 event: 2700 loss: tensor(1766.1526, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 100.0 event: 3000 loss: tensor(1685.9510, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 110.0 event: 3300 loss: tensor(1969.1852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 120.0 event: 3600 loss: tensor(1472.1725, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 130.0 event: 3900 loss: tensor(1716.8522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 140.0 event: 4200 loss: tensor(1894.0604, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 160.0 event: 4800 loss: tensor(3413.2244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 170.0 event: 5100 loss: tensor(1916.6340, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 180.0 event: 5400 loss: tensor(1773.4540, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 190.0 event: 5700 loss: tensor(1737.0299, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 200.0 event: 6000 loss: tensor(2056.6304, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 210.0 event: 6300 loss: tensor(1667.9521, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 220.0 event: 6600 loss: tensor(1794.3903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 230.0 event: 6900 loss: tensor(1956.8293, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 240.0 event: 7200 loss: tensor(2015.6224, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 250.0 event: 7500 loss: tensor(1993.5862, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 260.0 event: 7800 loss: tensor(1935.7689, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 270.0 event: 8100 loss: tensor(1703.2295, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 280.0 event: 8400 loss: tensor(1754.0084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 290.0 event: 8700 loss: tensor(1656.7689, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 300.0 event: 9000 loss: tensor(1969.5487, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 310.0 event: 9300 loss: tensor(1903.2493, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 320.0 event: 9600 loss: tensor(1674.8463, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 330.0 event: 9900 loss: tensor(1786.5028, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:06:34.366781
evaluation loss: 1953.196533203125
epoch: 9 mean loss: 1819.962158203125
=> saveing checkpoint at epoch 9
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2

outi tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.3911, 0.4757, 0.4057,  ..., 0.0000, 0.0000, 0.0000],
        [2.5538, 1.4147, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
 torch.Size([30, 6796]) 
 tensor(45687.7383, device='cuda:0', grad_fn=<SumBackward0>) 
 tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0') 
 tensor(203880, device='cuda:0')



training loss:
 [1901.74047852 1891.76733398 1871.10668945 1858.30725098 1848.39086914
 1838.11755371 1831.76074219 1826.85327148 1823.04174805 1819.9621582 ] 

\evaluation loss:
 [2027.55371094 2018.82446289 1997.02624512 1984.55212402 1976.12145996
 1965.54125977 1960.2043457  1956.81774902 1954.47949219 1953.1965332 ]



eval_efficiency:
 [0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625 0.50023625
 0.50023625 0.50023625 0.50023625 0.50023625] 


eval_purity:
 [0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881 0.8802881
 0.8802881 0.8802881]

Passing event 10003 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0000, 0.1237, 0.0000,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10003 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network before training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0.0000, 0.4770, 2.2800,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network after training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([1.0152, 2.4506, 2.0459,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

real	7m43.244s
user	7m45.071s
sys	4m17.744s
