0: gpu025.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-505643ce-4699-2c41-2564-301ff49acdf3)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        D3:30:74:BE:C5:18:67:19:1B:75:41:E9:26:B1:89:41:A6:DD:3B:01
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Wed Aug 31 16:08:57 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:16:00.0 Off |                    0 |
| N/A   33C    P0    41W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b66ba1738e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	7m24.354s
user	0m3.290s
sys	0m2.349s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 







 Loading data ... 



training set shape (20000, 43, 288) 
sum 5279207

target set shape (20000, 6796) 
sum 4575851
Net(
  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=667776, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=6796, bias=True)
)

number of the free parameters: 171805196
parameters of the network conv1.weight 
 torch.Size([256, 1, 3, 3]) 
 True 
 tensor([[[[ 0.1300,  0.2539,  0.1056],
          [ 0.1892, -0.0420,  0.1968],
          [ 0.2824, -0.0671, -0.1754]]],


        [[[ 0.0094,  0.0541,  0.2346],
          [ 0.2336,  0.1892,  0.0927],
          [-0.1275,  0.1335,  0.0333]]],


        [[[ 0.0435,  0.1754,  0.2775],
          [-0.2997,  0.2156, -0.0604],
          [ 0.1585,  0.3243, -0.1331]]],


        ...,


        [[[ 0.0385,  0.1465, -0.0947],
          [ 0.1467, -0.0706,  0.1657],
          [-0.0525,  0.1295,  0.1878]]],


        [[[-0.3288,  0.2571,  0.0005],
          [-0.1199, -0.1798, -0.1083],
          [ 0.0187,  0.0122,  0.1195]]],


        [[[-0.1841, -0.0651, -0.2594],
          [ 0.3250,  0.1360,  0.2915],
          [ 0.2140,  0.1932,  0.0829]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 0.1300,  0.2539,  0.1056],
          [ 0.1892, -0.0420,  0.1968],
          [ 0.2824, -0.0671, -0.1754]]],


        [[[ 0.0094,  0.0541,  0.2346],
          [ 0.2336,  0.1892,  0.0927],
          [-0.1275,  0.1335,  0.0333]]],


        [[[ 0.0435,  0.1754,  0.2775],
          [-0.2997,  0.2156, -0.0604],
          [ 0.1585,  0.3243, -0.1331]]],


        ...,


        [[[ 0.0385,  0.1465, -0.0947],
          [ 0.1467, -0.0706,  0.1657],
          [-0.0525,  0.1295,  0.1878]]],


        [[[-0.3288,  0.2571,  0.0005],
          [-0.1199, -0.1798, -0.1083],
          [ 0.0187,  0.0122,  0.1195]]],


        [[[-0.1841, -0.0651, -0.2594],
          [ 0.3250,  0.1360,  0.2915],
          [ 0.2140,  0.1932,  0.0829]]]], device='cuda:0', requires_grad=True)
parameters of the network conv1.bias 
 torch.Size([256]) 
 True 
 tensor([ 0.0717,  0.0976,  0.1402, -0.2131, -0.3200,  0.1525,  0.2002,  0.2346,
         0.3042, -0.1043,  0.2848, -0.1249,  0.1533, -0.1258,  0.3199,  0.1638,
         0.0282, -0.2640,  0.3259, -0.1254, -0.0841, -0.1140, -0.3277,  0.2824,
         0.1486, -0.0298,  0.0353, -0.0473, -0.2431, -0.1643, -0.1421, -0.0978,
         0.1590, -0.1316, -0.0613, -0.0651, -0.2729, -0.1357, -0.2346,  0.2909,
         0.2024, -0.2953, -0.1618, -0.2933, -0.0780, -0.1958,  0.3311, -0.2190,
         0.0562,  0.1671, -0.1628, -0.1848, -0.0408,  0.0905, -0.2052, -0.2035,
         0.0890, -0.0205,  0.2112, -0.0151,  0.2384,  0.2886,  0.0363, -0.0028,
        -0.1088, -0.2712,  0.3137,  0.0749,  0.3041, -0.1400, -0.2110, -0.3080,
         0.0077, -0.2037,  0.2160,  0.0112,  0.0226,  0.3288,  0.0552, -0.0703,
        -0.1464, -0.0693,  0.1277, -0.0381,  0.0906, -0.3288,  0.2454, -0.3277,
        -0.0752, -0.0437, -0.2816, -0.1686,  0.1702,  0.1915, -0.2791, -0.0663,
        -0.1606, -0.2019, -0.3239,  0.1428,  0.2036, -0.2336, -0.0408,  0.2928,
        -0.2291,  0.1331,  0.0817, -0.0289,  0.0447, -0.2374,  0.2204,  0.0827,
        -0.1522, -0.0716,  0.0564, -0.3011, -0.1840,  0.2277, -0.1885,  0.2033,
        -0.1361,  0.1750, -0.3220,  0.1179,  0.0159,  0.0218, -0.3097, -0.0115,
        -0.2075, -0.1478,  0.2420,  0.3244, -0.3226,  0.0293, -0.2929,  0.1407,
         0.0254, -0.1307,  0.2734,  0.0228, -0.3197, -0.3256,  0.3125,  0.2081,
         0.3251, -0.2617,  0.0402, -0.2913, -0.1398, -0.0901,  0.1991, -0.0884,
         0.0128, -0.3058,  0.1297, -0.0864,  0.1650, -0.1733, -0.1868, -0.0878,
         0.1328,  0.3267,  0.2455,  0.1573,  0.0770,  0.2580, -0.1503,  0.2824,
        -0.2538,  0.1500, -0.3118,  0.1447,  0.1806,  0.1647,  0.2323,  0.0333,
         0.2845,  0.2215,  0.3062, -0.2022,  0.1376,  0.2014,  0.2894,  0.1821,
        -0.0858, -0.1240, -0.0304,  0.0051, -0.1852,  0.0460,  0.2984, -0.0831,
        -0.2950,  0.2049,  0.1611, -0.1986,  0.2872,  0.0301, -0.2702,  0.3040,
        -0.1014,  0.1052, -0.1305, -0.1417, -0.2794, -0.0141, -0.0654, -0.2609,
         0.1948,  0.2711,  0.0657,  0.1970, -0.0769, -0.2962, -0.1813,  0.1547,
        -0.0242,  0.2589, -0.0521,  0.1937, -0.1913, -0.1909,  0.1196,  0.0251,
         0.3252,  0.3252,  0.2202, -0.2364,  0.1066,  0.2821, -0.2067,  0.1922,
         0.2671,  0.2711,  0.1052, -0.2341, -0.1061,  0.3211,  0.2165,  0.3155,
         0.1978,  0.0344,  0.0644, -0.1326,  0.2921,  0.1021,  0.2946,  0.1797,
        -0.1362, -0.3090, -0.0945, -0.3287, -0.1823, -0.1550, -0.0238,  0.0931],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0717,  0.0976,  0.1402, -0.2131, -0.3200,  0.1525,  0.2002,  0.2346,
         0.3042, -0.1043,  0.2848, -0.1249,  0.1533, -0.1258,  0.3199,  0.1638,
         0.0282, -0.2640,  0.3259, -0.1254, -0.0841, -0.1140, -0.3277,  0.2824,
         0.1486, -0.0298,  0.0353, -0.0473, -0.2431, -0.1643, -0.1421, -0.0978,
         0.1590, -0.1316, -0.0613, -0.0651, -0.2729, -0.1357, -0.2346,  0.2909,
         0.2024, -0.2953, -0.1618, -0.2933, -0.0780, -0.1958,  0.3311, -0.2190,
         0.0562,  0.1671, -0.1628, -0.1848, -0.0408,  0.0905, -0.2052, -0.2035,
         0.0890, -0.0205,  0.2112, -0.0151,  0.2384,  0.2886,  0.0363, -0.0028,
        -0.1088, -0.2712,  0.3137,  0.0749,  0.3041, -0.1400, -0.2110, -0.3080,
         0.0077, -0.2037,  0.2160,  0.0112,  0.0226,  0.3288,  0.0552, -0.0703,
        -0.1464, -0.0693,  0.1277, -0.0381,  0.0906, -0.3288,  0.2454, -0.3277,
        -0.0752, -0.0437, -0.2816, -0.1686,  0.1702,  0.1915, -0.2791, -0.0663,
        -0.1606, -0.2019, -0.3239,  0.1428,  0.2036, -0.2336, -0.0408,  0.2928,
        -0.2291,  0.1331,  0.0817, -0.0289,  0.0447, -0.2374,  0.2204,  0.0827,
        -0.1522, -0.0716,  0.0564, -0.3011, -0.1840,  0.2277, -0.1885,  0.2033,
        -0.1361,  0.1750, -0.3220,  0.1179,  0.0159,  0.0218, -0.3097, -0.0115,
        -0.2075, -0.1478,  0.2420,  0.3244, -0.3226,  0.0293, -0.2929,  0.1407,
         0.0254, -0.1307,  0.2734,  0.0228, -0.3197, -0.3256,  0.3125,  0.2081,
         0.3251, -0.2617,  0.0402, -0.2913, -0.1398, -0.0901,  0.1991, -0.0884,
         0.0128, -0.3058,  0.1297, -0.0864,  0.1650, -0.1733, -0.1868, -0.0878,
         0.1328,  0.3267,  0.2455,  0.1573,  0.0770,  0.2580, -0.1503,  0.2824,
        -0.2538,  0.1500, -0.3118,  0.1447,  0.1806,  0.1647,  0.2323,  0.0333,
         0.2845,  0.2215,  0.3062, -0.2022,  0.1376,  0.2014,  0.2894,  0.1821,
        -0.0858, -0.1240, -0.0304,  0.0051, -0.1852,  0.0460,  0.2984, -0.0831,
        -0.2950,  0.2049,  0.1611, -0.1986,  0.2872,  0.0301, -0.2702,  0.3040,
        -0.1014,  0.1052, -0.1305, -0.1417, -0.2794, -0.0141, -0.0654, -0.2609,
         0.1948,  0.2711,  0.0657,  0.1970, -0.0769, -0.2962, -0.1813,  0.1547,
        -0.0242,  0.2589, -0.0521,  0.1937, -0.1913, -0.1909,  0.1196,  0.0251,
         0.3252,  0.3252,  0.2202, -0.2364,  0.1066,  0.2821, -0.2067,  0.1922,
         0.2671,  0.2711,  0.1052, -0.2341, -0.1061,  0.3211,  0.2165,  0.3155,
         0.1978,  0.0344,  0.0644, -0.1326,  0.2921,  0.1021,  0.2946,  0.1797,
        -0.1362, -0.3090, -0.0945, -0.3287, -0.1823, -0.1550, -0.0238,  0.0931],
       device='cuda:0', requires_grad=True)
parameters of the network conv2.weight 
 torch.Size([128, 256, 3, 3]) 
 True 
 tensor([[[[ 2.0447e-02, -9.3437e-03,  8.8529e-03],
          [ 2.0620e-02,  1.9259e-02,  3.9326e-03],
          [-1.2888e-02, -3.4387e-03, -1.6442e-03]],

         [[-1.4767e-02,  1.3802e-02,  1.2310e-02],
          [-4.7198e-03, -1.2830e-02, -2.2843e-03],
          [ 1.2030e-02,  1.1148e-02, -2.4368e-05]],

         [[ 2.1460e-03, -4.0320e-03, -1.6274e-02],
          [ 1.0864e-02, -2.6898e-04, -7.0875e-03],
          [-2.9975e-03,  1.4012e-02,  2.0387e-02]],

         ...,

         [[-1.0014e-02, -8.3496e-03, -1.1552e-02],
          [-1.1068e-02,  4.7658e-03,  2.4705e-03],
          [ 1.5536e-02, -4.7830e-03, -1.7747e-02]],

         [[ 4.3879e-04,  1.0050e-02, -8.2543e-03],
          [ 5.8850e-03, -1.8745e-02,  6.7846e-03],
          [-6.4102e-03, -1.2311e-02, -9.3415e-03]],

         [[-1.5644e-02, -1.1583e-02,  1.5437e-02],
          [ 1.2591e-02,  1.0741e-03,  4.2108e-03],
          [ 1.2093e-02, -1.5815e-02,  4.1976e-03]]],


        [[[ 1.2813e-02, -1.8134e-02, -2.0148e-02],
          [-3.5025e-03,  1.7234e-02,  6.9500e-03],
          [ 3.7090e-03, -9.0251e-03,  1.6279e-03]],

         [[-1.3246e-02,  1.5425e-02, -6.0059e-03],
          [ 1.6149e-02,  1.2130e-02, -9.5626e-03],
          [-3.8709e-03, -1.2996e-02,  2.0202e-02]],

         [[ 1.0146e-03, -1.7203e-02, -5.0416e-03],
          [-1.7982e-02,  5.6497e-03, -1.9458e-02],
          [-3.2752e-03, -1.0402e-03, -5.1682e-03]],

         ...,

         [[ 5.4206e-03, -1.5928e-02, -2.8425e-03],
          [ 5.4481e-03,  1.8880e-02,  9.8208e-03],
          [ 5.4804e-03, -2.0432e-02, -1.9328e-02]],

         [[ 4.0839e-03,  8.9251e-03,  5.1630e-03],
          [-2.0147e-02,  1.4772e-02,  1.6589e-02],
          [ 1.9612e-02,  7.5683e-03,  1.5521e-02]],

         [[ 1.3782e-03, -2.0406e-02,  1.3426e-03],
          [ 1.4948e-02, -1.7439e-02, -8.5251e-03],
          [ 2.8500e-03, -1.3989e-03, -6.4163e-03]]],


        [[[ 1.0667e-02,  1.4200e-02, -1.8923e-03],
          [ 9.8867e-03, -1.8323e-03,  7.7043e-03],
          [-1.2822e-02, -6.6032e-03,  1.4090e-02]],

         [[-1.3749e-02,  1.7811e-02,  3.5116e-03],
          [-8.8563e-03, -1.0811e-02,  2.6015e-03],
          [ 7.2704e-03, -5.0494e-03, -6.4722e-03]],

         [[ 1.1935e-02, -1.5227e-02,  1.3791e-02],
          [-1.3386e-04,  1.1787e-02,  9.8076e-03],
          [-1.3650e-02,  2.0697e-02,  1.6044e-02]],

         ...,

         [[-1.3711e-02,  1.3767e-02,  9.0743e-03],
          [-8.8176e-03,  1.9471e-02, -1.9482e-02],
          [ 8.9476e-03, -1.6076e-03, -1.5214e-02]],

         [[ 2.0524e-02, -9.2568e-03,  1.7459e-02],
          [-1.5957e-02, -1.6791e-02,  2.9327e-03],
          [ 2.0116e-02, -1.4576e-02, -2.1693e-03]],

         [[ 1.9259e-02, -5.7427e-04,  1.8249e-02],
          [-1.6455e-02,  7.4292e-03, -1.1131e-02],
          [ 9.9502e-03, -1.3666e-02,  1.2028e-02]]],


        ...,


        [[[ 1.3111e-02, -1.6359e-02,  7.6491e-03],
          [ 1.7238e-02, -4.6205e-03, -1.9534e-02],
          [ 4.8428e-03, -8.0649e-03,  7.5007e-03]],

         [[-5.5545e-03, -1.4070e-02,  7.6360e-03],
          [-7.1890e-03, -1.3454e-02,  1.5221e-02],
          [ 1.5661e-02, -1.1219e-02,  2.0326e-03]],

         [[-8.7364e-04, -6.6158e-03, -6.7891e-03],
          [ 1.0186e-02, -5.7430e-03,  1.4738e-02],
          [-1.4937e-02,  4.6856e-03,  9.5520e-03]],

         ...,

         [[ 1.7098e-03,  1.8662e-02,  5.7258e-03],
          [-1.5104e-03,  1.2135e-02, -1.8963e-02],
          [-3.9503e-03, -1.5716e-02, -2.0686e-02]],

         [[ 9.5501e-03, -1.4716e-02, -1.0513e-02],
          [ 2.0298e-03,  8.0212e-04, -1.4191e-02],
          [-8.2414e-03,  1.3982e-02,  1.5367e-03]],

         [[ 1.3319e-02, -2.3483e-03, -5.5896e-04],
          [-1.1663e-02, -1.1070e-02,  2.0491e-02],
          [-1.9567e-02,  6.0372e-04,  1.6960e-02]]],


        [[[ 6.8376e-03,  6.0216e-03,  3.8658e-03],
          [ 1.4345e-02, -2.3362e-03, -4.2923e-03],
          [-9.5583e-03,  9.4881e-03, -8.4301e-03]],

         [[ 1.5823e-02,  1.4267e-02,  1.1154e-02],
          [-3.2707e-03,  9.8281e-03,  1.4957e-02],
          [-8.9514e-03, -9.6174e-03,  2.9666e-03]],

         [[-2.0634e-02, -7.9396e-03, -3.1997e-03],
          [-1.0070e-02,  6.3587e-03,  1.0682e-02],
          [ 8.8438e-03,  8.2258e-03,  3.1466e-03]],

         ...,

         [[ 6.7910e-03,  2.0245e-02, -1.0399e-03],
          [ 1.1159e-02,  1.4481e-02, -1.3736e-02],
          [ 1.6879e-02,  1.4616e-02, -1.7492e-02]],

         [[-1.7065e-02, -1.1266e-02,  1.2695e-02],
          [ 1.6721e-02,  6.4699e-03,  1.0509e-02],
          [-2.6251e-03,  1.2305e-02, -5.6250e-03]],

         [[-7.4362e-03, -1.1634e-03,  3.6173e-03],
          [-9.2019e-04, -1.9429e-02, -1.6367e-02],
          [ 8.4950e-03,  1.3639e-02,  3.7095e-03]]],


        [[[-6.9384e-04, -1.2066e-02,  1.5816e-02],
          [-8.6057e-04,  7.3563e-04, -9.0572e-03],
          [ 1.2749e-02, -1.7127e-02, -1.1272e-02]],

         [[-1.0462e-02, -1.0676e-02,  4.1877e-04],
          [-2.8075e-03,  1.0806e-02, -6.2650e-03],
          [-1.4746e-02, -4.8298e-03,  9.5182e-03]],

         [[-1.9037e-02, -1.8732e-02,  1.4403e-02],
          [-1.5722e-02, -8.6430e-03,  1.7808e-02],
          [ 1.4840e-02, -1.9682e-02,  1.8378e-02]],

         ...,

         [[ 4.9827e-03,  3.6439e-03, -6.8156e-03],
          [-1.5004e-02,  1.1079e-03, -1.7139e-02],
          [ 1.2727e-03, -1.6452e-03, -2.0467e-02]],

         [[ 1.9787e-02,  1.7874e-02, -1.1859e-03],
          [ 3.7367e-03,  9.0426e-03, -1.7025e-02],
          [ 8.9751e-03,  1.8014e-02,  3.4048e-03]],

         [[ 2.0165e-02, -1.0525e-02, -7.7729e-03],
          [-1.8393e-02, -1.1939e-02,  8.7746e-03],
          [-2.5868e-03, -1.3243e-02, -4.3490e-03]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 2.0447e-02, -9.3437e-03,  8.8529e-03],
          [ 2.0620e-02,  1.9259e-02,  3.9326e-03],
          [-1.2888e-02, -3.4387e-03, -1.6442e-03]],

         [[-1.4767e-02,  1.3802e-02,  1.2310e-02],
          [-4.7198e-03, -1.2830e-02, -2.2843e-03],
          [ 1.2030e-02,  1.1148e-02, -2.4368e-05]],

         [[ 2.1460e-03, -4.0320e-03, -1.6274e-02],
          [ 1.0864e-02, -2.6898e-04, -7.0875e-03],
          [-2.9975e-03,  1.4012e-02,  2.0387e-02]],

         ...,

         [[-1.0014e-02, -8.3496e-03, -1.1552e-02],
          [-1.1068e-02,  4.7658e-03,  2.4705e-03],
          [ 1.5536e-02, -4.7830e-03, -1.7747e-02]],

         [[ 4.3879e-04,  1.0050e-02, -8.2543e-03],
          [ 5.8850e-03, -1.8745e-02,  6.7846e-03],
          [-6.4102e-03, -1.2311e-02, -9.3415e-03]],

         [[-1.5644e-02, -1.1583e-02,  1.5437e-02],
          [ 1.2591e-02,  1.0741e-03,  4.2108e-03],
          [ 1.2093e-02, -1.5815e-02,  4.1976e-03]]],


        [[[ 1.2813e-02, -1.8134e-02, -2.0148e-02],
          [-3.5025e-03,  1.7234e-02,  6.9500e-03],
          [ 3.7090e-03, -9.0251e-03,  1.6279e-03]],

         [[-1.3246e-02,  1.5425e-02, -6.0059e-03],
          [ 1.6149e-02,  1.2130e-02, -9.5626e-03],
          [-3.8709e-03, -1.2996e-02,  2.0202e-02]],

         [[ 1.0146e-03, -1.7203e-02, -5.0416e-03],
          [-1.7982e-02,  5.6497e-03, -1.9458e-02],
          [-3.2752e-03, -1.0402e-03, -5.1682e-03]],

         ...,

         [[ 5.4206e-03, -1.5928e-02, -2.8425e-03],
          [ 5.4481e-03,  1.8880e-02,  9.8208e-03],
          [ 5.4804e-03, -2.0432e-02, -1.9328e-02]],

         [[ 4.0839e-03,  8.9251e-03,  5.1630e-03],
          [-2.0147e-02,  1.4772e-02,  1.6589e-02],
          [ 1.9612e-02,  7.5683e-03,  1.5521e-02]],

         [[ 1.3782e-03, -2.0406e-02,  1.3426e-03],
          [ 1.4948e-02, -1.7439e-02, -8.5251e-03],
          [ 2.8500e-03, -1.3989e-03, -6.4163e-03]]],


        [[[ 1.0667e-02,  1.4200e-02, -1.8923e-03],
          [ 9.8867e-03, -1.8323e-03,  7.7043e-03],
          [-1.2822e-02, -6.6032e-03,  1.4090e-02]],

         [[-1.3749e-02,  1.7811e-02,  3.5116e-03],
          [-8.8563e-03, -1.0811e-02,  2.6015e-03],
          [ 7.2704e-03, -5.0494e-03, -6.4722e-03]],

         [[ 1.1935e-02, -1.5227e-02,  1.3791e-02],
          [-1.3386e-04,  1.1787e-02,  9.8076e-03],
          [-1.3650e-02,  2.0697e-02,  1.6044e-02]],

         ...,

         [[-1.3711e-02,  1.3767e-02,  9.0743e-03],
          [-8.8176e-03,  1.9471e-02, -1.9482e-02],
          [ 8.9476e-03, -1.6076e-03, -1.5214e-02]],

         [[ 2.0524e-02, -9.2568e-03,  1.7459e-02],
          [-1.5957e-02, -1.6791e-02,  2.9327e-03],
          [ 2.0116e-02, -1.4576e-02, -2.1693e-03]],

         [[ 1.9259e-02, -5.7427e-04,  1.8249e-02],
          [-1.6455e-02,  7.4292e-03, -1.1131e-02],
          [ 9.9502e-03, -1.3666e-02,  1.2028e-02]]],


        ...,


        [[[ 1.3111e-02, -1.6359e-02,  7.6491e-03],
          [ 1.7238e-02, -4.6205e-03, -1.9534e-02],
          [ 4.8428e-03, -8.0649e-03,  7.5007e-03]],

         [[-5.5545e-03, -1.4070e-02,  7.6360e-03],
          [-7.1890e-03, -1.3454e-02,  1.5221e-02],
          [ 1.5661e-02, -1.1219e-02,  2.0326e-03]],

         [[-8.7364e-04, -6.6158e-03, -6.7891e-03],
          [ 1.0186e-02, -5.7430e-03,  1.4738e-02],
          [-1.4937e-02,  4.6856e-03,  9.5520e-03]],

         ...,

         [[ 1.7098e-03,  1.8662e-02,  5.7258e-03],
          [-1.5104e-03,  1.2135e-02, -1.8963e-02],
          [-3.9503e-03, -1.5716e-02, -2.0686e-02]],

         [[ 9.5501e-03, -1.4716e-02, -1.0513e-02],
          [ 2.0298e-03,  8.0212e-04, -1.4191e-02],
          [-8.2414e-03,  1.3982e-02,  1.5367e-03]],

         [[ 1.3319e-02, -2.3483e-03, -5.5896e-04],
          [-1.1663e-02, -1.1070e-02,  2.0491e-02],
          [-1.9567e-02,  6.0372e-04,  1.6960e-02]]],


        [[[ 6.8376e-03,  6.0216e-03,  3.8658e-03],
          [ 1.4345e-02, -2.3362e-03, -4.2923e-03],
          [-9.5583e-03,  9.4881e-03, -8.4301e-03]],

         [[ 1.5823e-02,  1.4267e-02,  1.1154e-02],
          [-3.2707e-03,  9.8281e-03,  1.4957e-02],
          [-8.9514e-03, -9.6174e-03,  2.9666e-03]],

         [[-2.0634e-02, -7.9396e-03, -3.1997e-03],
          [-1.0070e-02,  6.3587e-03,  1.0682e-02],
          [ 8.8438e-03,  8.2258e-03,  3.1466e-03]],

         ...,

         [[ 6.7910e-03,  2.0245e-02, -1.0399e-03],
          [ 1.1159e-02,  1.4481e-02, -1.3736e-02],
          [ 1.6879e-02,  1.4616e-02, -1.7492e-02]],

         [[-1.7065e-02, -1.1266e-02,  1.2695e-02],
          [ 1.6721e-02,  6.4699e-03,  1.0509e-02],
          [-2.6251e-03,  1.2305e-02, -5.6250e-03]],

         [[-7.4362e-03, -1.1634e-03,  3.6173e-03],
          [-9.2019e-04, -1.9429e-02, -1.6367e-02],
          [ 8.4950e-03,  1.3639e-02,  3.7095e-03]]],


        [[[-6.9384e-04, -1.2066e-02,  1.5816e-02],
          [-8.6057e-04,  7.3563e-04, -9.0572e-03],
          [ 1.2749e-02, -1.7127e-02, -1.1272e-02]],

         [[-1.0462e-02, -1.0676e-02,  4.1877e-04],
          [-2.8075e-03,  1.0806e-02, -6.2650e-03],
          [-1.4746e-02, -4.8298e-03,  9.5182e-03]],

         [[-1.9037e-02, -1.8732e-02,  1.4403e-02],
          [-1.5722e-02, -8.6430e-03,  1.7808e-02],
          [ 1.4840e-02, -1.9682e-02,  1.8378e-02]],

         ...,

         [[ 4.9827e-03,  3.6439e-03, -6.8156e-03],
          [-1.5004e-02,  1.1079e-03, -1.7139e-02],
          [ 1.2727e-03, -1.6452e-03, -2.0467e-02]],

         [[ 1.9787e-02,  1.7874e-02, -1.1859e-03],
          [ 3.7367e-03,  9.0426e-03, -1.7025e-02],
          [ 8.9751e-03,  1.8014e-02,  3.4048e-03]],

         [[ 2.0165e-02, -1.0525e-02, -7.7729e-03],
          [-1.8393e-02, -1.1939e-02,  8.7746e-03],
          [-2.5868e-03, -1.3243e-02, -4.3490e-03]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv2.bias 
 torch.Size([128]) 
 True 
 tensor([-0.0041, -0.0024,  0.0148, -0.0105, -0.0092,  0.0083, -0.0101, -0.0163,
         0.0083, -0.0076,  0.0056,  0.0065, -0.0150,  0.0020, -0.0157, -0.0100,
         0.0135,  0.0201,  0.0203, -0.0181, -0.0006,  0.0140,  0.0049, -0.0198,
         0.0065,  0.0036, -0.0029, -0.0162,  0.0165, -0.0033,  0.0062,  0.0199,
        -0.0067,  0.0047,  0.0139,  0.0135, -0.0130, -0.0082,  0.0183,  0.0062,
         0.0005,  0.0154, -0.0060, -0.0041, -0.0058,  0.0151,  0.0178, -0.0181,
         0.0002,  0.0204, -0.0126,  0.0016,  0.0105,  0.0121,  0.0024,  0.0090,
        -0.0058, -0.0060, -0.0065,  0.0028, -0.0083, -0.0183, -0.0099, -0.0205,
         0.0090,  0.0016, -0.0037, -0.0182, -0.0116, -0.0156,  0.0077,  0.0203,
         0.0151,  0.0029,  0.0104,  0.0153,  0.0075,  0.0201, -0.0003,  0.0011,
         0.0138,  0.0015, -0.0008,  0.0122, -0.0127, -0.0164,  0.0186, -0.0179,
        -0.0164, -0.0043, -0.0137,  0.0073,  0.0018, -0.0180,  0.0200,  0.0071,
         0.0038,  0.0172, -0.0063, -0.0028, -0.0046,  0.0197, -0.0177,  0.0089,
        -0.0067, -0.0024,  0.0056,  0.0035, -0.0076,  0.0175,  0.0165,  0.0028,
        -0.0061,  0.0020,  0.0085, -0.0028, -0.0009,  0.0100,  0.0137,  0.0013,
         0.0140,  0.0049,  0.0013,  0.0121, -0.0201,  0.0145, -0.0116,  0.0206],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0041, -0.0024,  0.0148, -0.0105, -0.0092,  0.0083, -0.0101, -0.0163,
         0.0083, -0.0076,  0.0056,  0.0065, -0.0150,  0.0020, -0.0157, -0.0100,
         0.0135,  0.0201,  0.0203, -0.0181, -0.0006,  0.0140,  0.0049, -0.0198,
         0.0065,  0.0036, -0.0029, -0.0162,  0.0165, -0.0033,  0.0062,  0.0199,
        -0.0067,  0.0047,  0.0139,  0.0135, -0.0130, -0.0082,  0.0183,  0.0062,
         0.0005,  0.0154, -0.0060, -0.0041, -0.0058,  0.0151,  0.0178, -0.0181,
         0.0002,  0.0204, -0.0126,  0.0016,  0.0105,  0.0121,  0.0024,  0.0090,
        -0.0058, -0.0060, -0.0065,  0.0028, -0.0083, -0.0183, -0.0099, -0.0205,
         0.0090,  0.0016, -0.0037, -0.0182, -0.0116, -0.0156,  0.0077,  0.0203,
         0.0151,  0.0029,  0.0104,  0.0153,  0.0075,  0.0201, -0.0003,  0.0011,
         0.0138,  0.0015, -0.0008,  0.0122, -0.0127, -0.0164,  0.0186, -0.0179,
        -0.0164, -0.0043, -0.0137,  0.0073,  0.0018, -0.0180,  0.0200,  0.0071,
         0.0038,  0.0172, -0.0063, -0.0028, -0.0046,  0.0197, -0.0177,  0.0089,
        -0.0067, -0.0024,  0.0056,  0.0035, -0.0076,  0.0175,  0.0165,  0.0028,
        -0.0061,  0.0020,  0.0085, -0.0028, -0.0009,  0.0100,  0.0137,  0.0013,
         0.0140,  0.0049,  0.0013,  0.0121, -0.0201,  0.0145, -0.0116,  0.0206],
       device='cuda:0', requires_grad=True)
parameters of the network conv3.weight 
 torch.Size([64, 128, 3, 3]) 
 True 
 tensor([[[[ 4.5453e-04,  1.7613e-02, -1.6277e-02],
          [-2.5726e-02, -2.7158e-02,  3.1118e-04],
          [-2.3752e-02,  2.7251e-02, -1.6105e-02]],

         [[-1.0049e-02,  2.2214e-03,  2.0591e-02],
          [ 1.5435e-02,  1.9698e-02, -3.0639e-03],
          [-7.2844e-03, -2.6063e-02,  2.0222e-02]],

         [[-1.6951e-03,  1.8575e-02,  2.4050e-02],
          [-1.2537e-04, -8.1040e-03, -2.6869e-02],
          [ 2.9186e-02, -3.0140e-03,  1.8923e-02]],

         ...,

         [[ 1.2487e-02, -1.7601e-02,  2.0946e-02],
          [ 2.8998e-02,  6.1971e-03,  1.6475e-02],
          [-1.1077e-02, -4.8220e-04,  1.9964e-02]],

         [[-2.2098e-02, -2.8035e-02,  1.0709e-02],
          [-1.5979e-02, -1.9414e-02, -1.9423e-02],
          [-1.7653e-02, -1.8851e-03,  3.8634e-03]],

         [[-4.4923e-03,  2.5526e-02,  1.3284e-02],
          [ 1.0511e-02,  1.7487e-02,  8.8904e-03],
          [ 1.5362e-03, -2.4182e-02, -6.9412e-03]]],


        [[[ 9.6233e-03,  2.4508e-02, -2.6640e-02],
          [ 2.5769e-02, -5.5382e-03, -2.2970e-02],
          [ 1.6539e-02,  1.9953e-02, -1.6291e-02]],

         [[-2.1677e-02,  2.5894e-02, -1.6854e-02],
          [ 3.0450e-03, -4.9128e-03, -1.8359e-02],
          [ 9.9343e-03, -1.9257e-03, -5.5576e-03]],

         [[ 2.9305e-02, -2.6840e-02, -2.2768e-02],
          [-2.9512e-03, -1.5998e-02, -2.2032e-02],
          [ 2.5766e-02,  1.9467e-02, -2.5637e-02]],

         ...,

         [[-2.1225e-02, -1.3118e-02,  2.4343e-02],
          [ 1.3054e-02, -9.6362e-03, -1.6712e-02],
          [-1.0173e-02, -2.2359e-02, -9.1608e-03]],

         [[ 6.3400e-03,  1.1983e-02,  1.0121e-02],
          [-2.0474e-02,  9.9567e-03, -2.2530e-02],
          [-2.5936e-03,  1.7296e-02,  1.1902e-02]],

         [[-2.4731e-02,  1.7771e-02, -2.6263e-02],
          [-1.4270e-02, -1.5318e-02,  7.8495e-05],
          [ 1.1980e-02,  1.0349e-02, -4.9597e-03]]],


        [[[ 1.6304e-02, -2.0353e-02, -2.6330e-02],
          [-1.5042e-02, -9.1050e-04, -2.3683e-02],
          [ 2.3221e-02, -5.2590e-03,  1.3113e-02]],

         [[-6.9088e-03,  2.9862e-03,  2.8520e-02],
          [ 2.6549e-02,  6.0907e-03, -3.8819e-03],
          [-1.8952e-02,  2.6829e-02, -4.6253e-04]],

         [[ 7.3984e-03, -1.0994e-02, -1.8597e-02],
          [-2.4134e-02, -2.9313e-02, -2.3126e-02],
          [-2.1257e-02, -1.1951e-02, -8.9019e-03]],

         ...,

         [[ 5.8203e-03,  2.5423e-02,  2.6630e-03],
          [-3.5102e-03, -1.4794e-02, -2.5638e-02],
          [ 7.3247e-03, -2.1108e-02,  2.6935e-02]],

         [[ 1.1943e-02,  1.4597e-03,  4.6249e-03],
          [ 2.0468e-02, -2.0938e-02, -1.1465e-02],
          [-4.6450e-04, -2.7526e-02, -1.3870e-02]],

         [[ 5.8873e-03,  2.4714e-02,  1.2052e-02],
          [ 4.9111e-03,  2.3572e-02, -1.1896e-02],
          [-2.3025e-02,  3.5371e-04, -2.2785e-02]]],


        ...,


        [[[-1.4623e-02, -8.1976e-03, -2.1781e-02],
          [ 2.5254e-02, -2.7979e-02, -5.1181e-03],
          [-1.7846e-02, -3.5718e-03,  2.0012e-03]],

         [[-1.3848e-02, -2.7253e-02, -7.2586e-03],
          [-2.5464e-02, -1.8872e-02,  1.9234e-02],
          [ 2.9717e-03,  1.0056e-02, -7.9463e-03]],

         [[ 2.2979e-02, -8.4272e-03, -6.3833e-03],
          [-4.6145e-03,  2.4230e-02,  4.6450e-03],
          [-2.3066e-03,  1.8039e-02, -1.8463e-02]],

         ...,

         [[ 2.0421e-02,  2.7978e-02, -1.9638e-02],
          [-1.9885e-02,  3.7466e-03,  8.9481e-03],
          [-1.6542e-02,  2.9013e-02, -2.5936e-02]],

         [[-2.5137e-02,  1.8378e-02,  2.1615e-02],
          [-9.4335e-03, -2.1929e-04,  1.2497e-02],
          [-1.8433e-02,  2.9312e-02,  1.1675e-02]],

         [[ 2.7967e-02, -1.7403e-02,  1.2443e-02],
          [-1.5951e-02, -2.6353e-02,  1.6394e-02],
          [ 4.6239e-03, -1.6787e-02,  5.8716e-03]]],


        [[[ 2.7195e-02, -2.3606e-02, -1.7474e-02],
          [ 6.0857e-03,  9.7624e-04, -2.1702e-02],
          [-1.1213e-02, -1.1254e-02,  3.6211e-03]],

         [[-1.5871e-02,  8.9605e-03, -1.4065e-02],
          [ 2.5574e-02, -2.4907e-02, -1.9239e-02],
          [ 3.1885e-03, -1.4814e-02,  5.4749e-03]],

         [[-5.6072e-03, -2.2862e-03, -1.9888e-02],
          [-7.0637e-03,  1.9481e-02,  1.0668e-02],
          [ 3.6958e-03,  6.0989e-03,  2.8462e-03]],

         ...,

         [[-8.8511e-03,  1.2049e-02, -1.2445e-03],
          [ 3.0146e-03, -8.2803e-03,  9.2608e-03],
          [-2.2091e-02,  2.4171e-03,  2.1149e-02]],

         [[ 6.7642e-03,  3.9584e-03,  2.0016e-02],
          [ 2.9217e-02, -2.1378e-02,  2.0139e-02],
          [-1.6892e-02, -1.9462e-02,  2.6589e-02]],

         [[-2.3251e-02, -2.6676e-03, -1.2397e-02],
          [ 2.5255e-02, -1.4074e-02,  2.0210e-02],
          [-2.6688e-02, -2.8823e-02, -9.0829e-03]]],


        [[[-1.4338e-02, -2.2364e-02,  2.8312e-02],
          [-5.4261e-03, -2.8646e-02,  2.6163e-02],
          [ 1.3008e-03,  2.1978e-02, -2.6093e-02]],

         [[ 2.5520e-02,  2.5839e-02,  2.1462e-02],
          [-1.9375e-02,  1.7019e-02,  1.6511e-02],
          [-7.0787e-03, -5.4380e-03,  1.7863e-02]],

         [[ 2.1437e-02,  5.9638e-03, -2.6196e-02],
          [-7.3662e-03, -1.3003e-02, -2.6536e-02],
          [-6.3870e-03,  2.3304e-02,  1.5882e-04]],

         ...,

         [[-1.3634e-02, -4.7680e-03, -2.7980e-03],
          [ 7.8626e-03, -2.0583e-03,  2.4470e-02],
          [-2.5111e-02,  2.6314e-02,  7.4372e-03]],

         [[ 7.0212e-03,  1.1080e-02, -7.5485e-03],
          [-2.2314e-02,  9.5471e-03, -1.8688e-02],
          [ 2.7392e-02,  2.5947e-02, -1.6770e-02]],

         [[ 1.4953e-02, -8.5152e-03, -2.6065e-03],
          [ 1.4956e-03,  7.4092e-03, -9.7669e-03],
          [ 2.4357e-02,  8.9176e-03, -2.8527e-02]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 4.5453e-04,  1.7613e-02, -1.6277e-02],
          [-2.5726e-02, -2.7158e-02,  3.1118e-04],
          [-2.3752e-02,  2.7251e-02, -1.6105e-02]],

         [[-1.0049e-02,  2.2214e-03,  2.0591e-02],
          [ 1.5435e-02,  1.9698e-02, -3.0639e-03],
          [-7.2844e-03, -2.6063e-02,  2.0222e-02]],

         [[-1.6951e-03,  1.8575e-02,  2.4050e-02],
          [-1.2537e-04, -8.1040e-03, -2.6869e-02],
          [ 2.9186e-02, -3.0140e-03,  1.8923e-02]],

         ...,

         [[ 1.2487e-02, -1.7601e-02,  2.0946e-02],
          [ 2.8998e-02,  6.1971e-03,  1.6475e-02],
          [-1.1077e-02, -4.8220e-04,  1.9964e-02]],

         [[-2.2098e-02, -2.8035e-02,  1.0709e-02],
          [-1.5979e-02, -1.9414e-02, -1.9423e-02],
          [-1.7653e-02, -1.8851e-03,  3.8634e-03]],

         [[-4.4923e-03,  2.5526e-02,  1.3284e-02],
          [ 1.0511e-02,  1.7487e-02,  8.8904e-03],
          [ 1.5362e-03, -2.4182e-02, -6.9412e-03]]],


        [[[ 9.6233e-03,  2.4508e-02, -2.6640e-02],
          [ 2.5769e-02, -5.5382e-03, -2.2970e-02],
          [ 1.6539e-02,  1.9953e-02, -1.6291e-02]],

         [[-2.1677e-02,  2.5894e-02, -1.6854e-02],
          [ 3.0450e-03, -4.9128e-03, -1.8359e-02],
          [ 9.9343e-03, -1.9257e-03, -5.5576e-03]],

         [[ 2.9305e-02, -2.6840e-02, -2.2768e-02],
          [-2.9512e-03, -1.5998e-02, -2.2032e-02],
          [ 2.5766e-02,  1.9467e-02, -2.5637e-02]],

         ...,

         [[-2.1225e-02, -1.3118e-02,  2.4343e-02],
          [ 1.3054e-02, -9.6362e-03, -1.6712e-02],
          [-1.0173e-02, -2.2359e-02, -9.1608e-03]],

         [[ 6.3400e-03,  1.1983e-02,  1.0121e-02],
          [-2.0474e-02,  9.9567e-03, -2.2530e-02],
          [-2.5936e-03,  1.7296e-02,  1.1902e-02]],

         [[-2.4731e-02,  1.7771e-02, -2.6263e-02],
          [-1.4270e-02, -1.5318e-02,  7.8495e-05],
          [ 1.1980e-02,  1.0349e-02, -4.9597e-03]]],


        [[[ 1.6304e-02, -2.0353e-02, -2.6330e-02],
          [-1.5042e-02, -9.1050e-04, -2.3683e-02],
          [ 2.3221e-02, -5.2590e-03,  1.3113e-02]],

         [[-6.9088e-03,  2.9862e-03,  2.8520e-02],
          [ 2.6549e-02,  6.0907e-03, -3.8819e-03],
          [-1.8952e-02,  2.6829e-02, -4.6253e-04]],

         [[ 7.3984e-03, -1.0994e-02, -1.8597e-02],
          [-2.4134e-02, -2.9313e-02, -2.3126e-02],
          [-2.1257e-02, -1.1951e-02, -8.9019e-03]],

         ...,

         [[ 5.8203e-03,  2.5423e-02,  2.6630e-03],
          [-3.5102e-03, -1.4794e-02, -2.5638e-02],
          [ 7.3247e-03, -2.1108e-02,  2.6935e-02]],

         [[ 1.1943e-02,  1.4597e-03,  4.6249e-03],
          [ 2.0468e-02, -2.0938e-02, -1.1465e-02],
          [-4.6450e-04, -2.7526e-02, -1.3870e-02]],

         [[ 5.8873e-03,  2.4714e-02,  1.2052e-02],
          [ 4.9111e-03,  2.3572e-02, -1.1896e-02],
          [-2.3025e-02,  3.5371e-04, -2.2785e-02]]],


        ...,


        [[[-1.4623e-02, -8.1976e-03, -2.1781e-02],
          [ 2.5254e-02, -2.7979e-02, -5.1181e-03],
          [-1.7846e-02, -3.5718e-03,  2.0012e-03]],

         [[-1.3848e-02, -2.7253e-02, -7.2586e-03],
          [-2.5464e-02, -1.8872e-02,  1.9234e-02],
          [ 2.9717e-03,  1.0056e-02, -7.9463e-03]],

         [[ 2.2979e-02, -8.4272e-03, -6.3833e-03],
          [-4.6145e-03,  2.4230e-02,  4.6450e-03],
          [-2.3066e-03,  1.8039e-02, -1.8463e-02]],

         ...,

         [[ 2.0421e-02,  2.7978e-02, -1.9638e-02],
          [-1.9885e-02,  3.7466e-03,  8.9481e-03],
          [-1.6542e-02,  2.9013e-02, -2.5936e-02]],

         [[-2.5137e-02,  1.8378e-02,  2.1615e-02],
          [-9.4335e-03, -2.1929e-04,  1.2497e-02],
          [-1.8433e-02,  2.9312e-02,  1.1675e-02]],

         [[ 2.7967e-02, -1.7403e-02,  1.2443e-02],
          [-1.5951e-02, -2.6353e-02,  1.6394e-02],
          [ 4.6239e-03, -1.6787e-02,  5.8716e-03]]],


        [[[ 2.7195e-02, -2.3606e-02, -1.7474e-02],
          [ 6.0857e-03,  9.7624e-04, -2.1702e-02],
          [-1.1213e-02, -1.1254e-02,  3.6211e-03]],

         [[-1.5871e-02,  8.9605e-03, -1.4065e-02],
          [ 2.5574e-02, -2.4907e-02, -1.9239e-02],
          [ 3.1885e-03, -1.4814e-02,  5.4749e-03]],

         [[-5.6072e-03, -2.2862e-03, -1.9888e-02],
          [-7.0637e-03,  1.9481e-02,  1.0668e-02],
          [ 3.6958e-03,  6.0989e-03,  2.8462e-03]],

         ...,

         [[-8.8511e-03,  1.2049e-02, -1.2445e-03],
          [ 3.0146e-03, -8.2803e-03,  9.2608e-03],
          [-2.2091e-02,  2.4171e-03,  2.1149e-02]],

         [[ 6.7642e-03,  3.9584e-03,  2.0016e-02],
          [ 2.9217e-02, -2.1378e-02,  2.0139e-02],
          [-1.6892e-02, -1.9462e-02,  2.6589e-02]],

         [[-2.3251e-02, -2.6676e-03, -1.2397e-02],
          [ 2.5255e-02, -1.4074e-02,  2.0210e-02],
          [-2.6688e-02, -2.8823e-02, -9.0829e-03]]],


        [[[-1.4338e-02, -2.2364e-02,  2.8312e-02],
          [-5.4261e-03, -2.8646e-02,  2.6163e-02],
          [ 1.3008e-03,  2.1978e-02, -2.6093e-02]],

         [[ 2.5520e-02,  2.5839e-02,  2.1462e-02],
          [-1.9375e-02,  1.7019e-02,  1.6511e-02],
          [-7.0787e-03, -5.4380e-03,  1.7863e-02]],

         [[ 2.1437e-02,  5.9638e-03, -2.6196e-02],
          [-7.3662e-03, -1.3003e-02, -2.6536e-02],
          [-6.3870e-03,  2.3304e-02,  1.5882e-04]],

         ...,

         [[-1.3634e-02, -4.7680e-03, -2.7980e-03],
          [ 7.8626e-03, -2.0583e-03,  2.4470e-02],
          [-2.5111e-02,  2.6314e-02,  7.4372e-03]],

         [[ 7.0212e-03,  1.1080e-02, -7.5485e-03],
          [-2.2314e-02,  9.5471e-03, -1.8688e-02],
          [ 2.7392e-02,  2.5947e-02, -1.6770e-02]],

         [[ 1.4953e-02, -8.5152e-03, -2.6065e-03],
          [ 1.4956e-03,  7.4092e-03, -9.7669e-03],
          [ 2.4357e-02,  8.9176e-03, -2.8527e-02]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.bias 
 torch.Size([64]) 
 True 
 tensor([ 2.2572e-02,  2.1522e-02, -1.7836e-02,  2.2004e-02, -1.0202e-02,
        -2.4384e-02,  2.7090e-02,  6.7530e-03,  4.1721e-03, -4.3134e-03,
         4.6785e-03, -8.3531e-03, -3.0911e-03, -1.6113e-03, -9.5161e-03,
         9.3167e-04,  2.5658e-02,  5.3037e-03, -2.3168e-02,  5.4595e-03,
        -1.5486e-02, -1.6531e-02,  2.8434e-03,  2.1881e-02,  2.7749e-02,
        -1.6874e-02, -2.2405e-02, -8.1785e-03, -2.4144e-03,  2.7952e-02,
         2.3632e-03, -9.3861e-03, -1.4524e-02, -2.0935e-02, -7.0429e-03,
         2.3154e-02, -2.3081e-02,  2.9005e-02,  2.5500e-02, -4.3471e-03,
         7.4124e-03, -1.9293e-02,  1.5354e-02, -2.0228e-02,  2.5451e-04,
         2.8710e-02, -2.1192e-02,  2.4866e-02,  2.8978e-02,  2.9766e-05,
         1.6365e-02,  2.5627e-02,  2.0647e-02, -2.9130e-02, -1.1039e-04,
        -2.5963e-03, -1.8926e-02, -1.9984e-02, -8.7402e-03, -1.8288e-02,
        -9.2722e-03, -2.2074e-03, -2.2616e-02,  9.1711e-04], device='cuda:0') 
 Parameter containing:
tensor([ 2.2572e-02,  2.1522e-02, -1.7836e-02,  2.2004e-02, -1.0202e-02,
        -2.4384e-02,  2.7090e-02,  6.7530e-03,  4.1721e-03, -4.3134e-03,
         4.6785e-03, -8.3531e-03, -3.0911e-03, -1.6113e-03, -9.5161e-03,
         9.3167e-04,  2.5658e-02,  5.3037e-03, -2.3168e-02,  5.4595e-03,
        -1.5486e-02, -1.6531e-02,  2.8434e-03,  2.1881e-02,  2.7749e-02,
        -1.6874e-02, -2.2405e-02, -8.1785e-03, -2.4144e-03,  2.7952e-02,
         2.3632e-03, -9.3861e-03, -1.4524e-02, -2.0935e-02, -7.0429e-03,
         2.3154e-02, -2.3081e-02,  2.9005e-02,  2.5500e-02, -4.3471e-03,
         7.4124e-03, -1.9293e-02,  1.5354e-02, -2.0228e-02,  2.5451e-04,
         2.8710e-02, -2.1192e-02,  2.4866e-02,  2.8978e-02,  2.9766e-05,
         1.6365e-02,  2.5627e-02,  2.0647e-02, -2.9130e-02, -1.1039e-04,
        -2.5963e-03, -1.8926e-02, -1.9984e-02, -8.7402e-03, -1.8288e-02,
        -9.2722e-03, -2.2074e-03, -2.2616e-02,  9.1711e-04], device='cuda:0',
       requires_grad=True)
parameters of the network fc1.weight 
 torch.Size([256, 667776]) 
 True 
 tensor([[-5.6193e-04, -2.9911e-04, -1.9869e-04,  ..., -4.0883e-04,
         -5.2278e-04, -1.6720e-04],
        [ 6.8487e-04,  6.5279e-04,  9.7259e-04,  ...,  6.0488e-05,
          2.5620e-04,  1.6315e-04],
        [-7.5571e-04,  4.5742e-04, -2.3668e-04,  ...,  1.7443e-04,
         -5.2644e-04, -5.6855e-04],
        ...,
        [ 9.3006e-04,  1.0654e-03,  1.0930e-03,  ..., -6.7807e-04,
          7.1885e-04,  4.8323e-04],
        [ 1.1064e-03,  1.9981e-04,  7.4310e-04,  ..., -5.3168e-04,
         -6.4797e-04,  7.0141e-04],
        [-1.4987e-04, -2.6135e-04,  7.2443e-04,  ..., -1.2055e-03,
          4.9755e-04,  1.0897e-03]], device='cuda:0') 
 Parameter containing:
tensor([[-5.6193e-04, -2.9911e-04, -1.9869e-04,  ..., -4.0883e-04,
         -5.2278e-04, -1.6720e-04],
        [ 6.8487e-04,  6.5279e-04,  9.7259e-04,  ...,  6.0488e-05,
          2.5620e-04,  1.6315e-04],
        [-7.5571e-04,  4.5742e-04, -2.3668e-04,  ...,  1.7443e-04,
         -5.2644e-04, -5.6855e-04],
        ...,
        [ 9.3006e-04,  1.0654e-03,  1.0930e-03,  ..., -6.7807e-04,
          7.1885e-04,  4.8323e-04],
        [ 1.1064e-03,  1.9981e-04,  7.4310e-04,  ..., -5.3168e-04,
         -6.4797e-04,  7.0141e-04],
        [-1.4987e-04, -2.6135e-04,  7.2443e-04,  ..., -1.2055e-03,
          4.9755e-04,  1.0897e-03]], device='cuda:0', requires_grad=True)
parameters of the network fc1.bias 
 torch.Size([256]) 
 True 
 tensor([-3.6889e-04,  8.7075e-05, -5.3887e-04,  5.9023e-04, -3.3991e-05,
        -4.0267e-06,  4.9707e-04,  7.4583e-04,  2.5451e-04,  7.5231e-05,
         1.1472e-03,  1.4671e-04,  1.4507e-04,  2.3221e-04,  1.0239e-03,
         7.9568e-04,  1.0427e-03,  1.2142e-03,  6.1917e-04,  1.1824e-03,
        -5.5091e-04,  1.1160e-03, -1.4652e-04, -7.6510e-04, -1.1754e-03,
        -4.2866e-04, -6.1710e-04,  1.5152e-04,  8.1475e-04, -9.9473e-04,
         7.5479e-04,  1.0053e-03, -1.6341e-04,  9.3995e-04,  9.4917e-04,
        -8.5470e-04,  1.1766e-03,  5.0278e-04, -7.6669e-04, -1.4580e-04,
        -4.1758e-04,  1.1908e-03,  1.0825e-03, -5.0496e-04, -6.4142e-04,
         1.5047e-04, -5.0663e-04, -3.1008e-04,  8.9781e-04,  4.7372e-04,
         3.7085e-04, -3.6228e-04, -5.9595e-04,  1.2045e-03, -1.0256e-03,
         5.0139e-04,  6.8939e-04,  7.8710e-04,  6.7949e-04, -7.1928e-04,
         4.9789e-04,  7.4322e-04,  6.4862e-04,  1.0753e-03, -3.1140e-04,
        -4.1793e-04, -4.8685e-04,  7.2775e-04, -1.1260e-03, -1.1767e-03,
        -6.4484e-04,  8.8348e-05,  6.6037e-04, -8.0674e-04, -6.9116e-04,
        -5.7324e-04,  3.7570e-05,  3.6912e-04,  2.3825e-04,  6.5085e-04,
        -9.9387e-04,  2.9390e-04,  6.1422e-04,  6.8742e-04,  5.3596e-04,
         1.8732e-04,  1.2329e-04, -4.7621e-04,  3.9896e-05,  8.0111e-04,
        -1.1151e-03, -2.5948e-04,  1.0411e-03,  5.8914e-04, -7.7865e-04,
        -6.6077e-04,  8.0592e-04, -3.4601e-04,  1.4363e-04,  4.4772e-04,
         1.2475e-04, -1.1548e-03,  9.8792e-05,  6.9132e-04, -1.0863e-03,
         7.6476e-04,  4.1934e-04, -6.6826e-04, -7.1412e-05, -6.1948e-04,
         5.4796e-04, -1.1277e-03, -3.9449e-04,  4.3479e-04, -7.4834e-04,
        -2.4480e-04,  7.8082e-04, -9.4871e-04,  9.1722e-04,  3.6279e-05,
         1.1001e-04,  5.0288e-04,  7.9963e-04, -8.3988e-05,  2.2692e-04,
        -3.6269e-04,  3.0619e-04, -1.0824e-04,  7.2829e-04, -4.2133e-04,
        -1.5568e-04, -1.1273e-03,  7.5628e-04,  1.1570e-03, -9.8784e-04,
         7.1314e-04,  6.2580e-04,  3.3747e-04, -5.9272e-04, -2.1170e-04,
         5.7593e-04,  4.1452e-04, -5.0709e-04, -7.5633e-04,  2.9078e-04,
        -7.7124e-04,  3.0443e-05, -6.8596e-04,  8.4821e-05, -8.5782e-04,
        -8.7830e-04,  1.2074e-03,  8.7839e-04, -1.0963e-03,  7.3341e-04,
        -1.1969e-03, -1.0550e-03, -1.1923e-03,  7.3129e-04,  4.9031e-04,
        -7.6607e-04, -9.3847e-04,  7.8988e-04, -5.1617e-04, -3.7990e-04,
        -7.7887e-04,  7.5601e-04,  1.1637e-03,  7.0836e-04, -8.2909e-04,
        -6.9858e-04,  9.2774e-04, -7.4494e-05,  1.6675e-04, -1.8970e-04,
         1.1868e-03, -4.2996e-04, -1.6480e-04,  7.6290e-04, -1.1131e-03,
        -2.6570e-04,  2.3566e-05, -8.0087e-04,  5.4504e-04, -9.3830e-04,
        -4.6520e-04,  9.4621e-04, -1.1630e-03, -1.1750e-03,  1.4952e-04,
        -4.0661e-04, -1.0904e-03,  4.4488e-04, -5.2157e-04,  7.8725e-04,
        -4.1464e-04,  8.0967e-05,  9.5373e-04,  3.8342e-04,  1.1872e-03,
         3.8597e-04, -8.5274e-04, -7.1437e-04, -6.1950e-04, -6.7697e-04,
         1.0445e-03, -8.0943e-04, -2.7729e-04,  9.3810e-04,  8.3738e-04,
        -5.5063e-05, -1.1903e-03,  7.4568e-04,  8.3865e-04, -7.9981e-04,
        -7.5952e-04, -3.9418e-04,  4.2412e-04, -9.6561e-05, -1.0803e-03,
         1.1329e-03, -4.0704e-04,  7.2610e-04,  3.5704e-04, -2.6588e-04,
        -7.7041e-04, -5.7710e-04, -1.1751e-03,  1.0037e-03, -5.9507e-04,
         9.8642e-04, -1.0579e-05,  4.4674e-04,  2.7233e-04, -6.5157e-04,
         9.2810e-04, -8.1797e-04,  6.4107e-04, -1.1721e-03,  9.5958e-04,
         1.0403e-03, -8.8988e-04, -1.2066e-03,  1.1490e-03, -9.6422e-04,
        -2.2468e-04, -1.1890e-04,  7.1596e-04,  6.3427e-04,  2.0841e-04,
         9.6882e-04,  7.0363e-04,  7.9316e-04,  1.6995e-04,  1.1255e-03,
         7.6311e-04], device='cuda:0') 
 Parameter containing:
tensor([-3.6889e-04,  8.7075e-05, -5.3887e-04,  5.9023e-04, -3.3991e-05,
        -4.0267e-06,  4.9707e-04,  7.4583e-04,  2.5451e-04,  7.5231e-05,
         1.1472e-03,  1.4671e-04,  1.4507e-04,  2.3221e-04,  1.0239e-03,
         7.9568e-04,  1.0427e-03,  1.2142e-03,  6.1917e-04,  1.1824e-03,
        -5.5091e-04,  1.1160e-03, -1.4652e-04, -7.6510e-04, -1.1754e-03,
        -4.2866e-04, -6.1710e-04,  1.5152e-04,  8.1475e-04, -9.9473e-04,
         7.5479e-04,  1.0053e-03, -1.6341e-04,  9.3995e-04,  9.4917e-04,
        -8.5470e-04,  1.1766e-03,  5.0278e-04, -7.6669e-04, -1.4580e-04,
        -4.1758e-04,  1.1908e-03,  1.0825e-03, -5.0496e-04, -6.4142e-04,
         1.5047e-04, -5.0663e-04, -3.1008e-04,  8.9781e-04,  4.7372e-04,
         3.7085e-04, -3.6228e-04, -5.9595e-04,  1.2045e-03, -1.0256e-03,
         5.0139e-04,  6.8939e-04,  7.8710e-04,  6.7949e-04, -7.1928e-04,
         4.9789e-04,  7.4322e-04,  6.4862e-04,  1.0753e-03, -3.1140e-04,
        -4.1793e-04, -4.8685e-04,  7.2775e-04, -1.1260e-03, -1.1767e-03,
        -6.4484e-04,  8.8348e-05,  6.6037e-04, -8.0674e-04, -6.9116e-04,
        -5.7324e-04,  3.7570e-05,  3.6912e-04,  2.3825e-04,  6.5085e-04,
        -9.9387e-04,  2.9390e-04,  6.1422e-04,  6.8742e-04,  5.3596e-04,
         1.8732e-04,  1.2329e-04, -4.7621e-04,  3.9896e-05,  8.0111e-04,
        -1.1151e-03, -2.5948e-04,  1.0411e-03,  5.8914e-04, -7.7865e-04,
        -6.6077e-04,  8.0592e-04, -3.4601e-04,  1.4363e-04,  4.4772e-04,
         1.2475e-04, -1.1548e-03,  9.8792e-05,  6.9132e-04, -1.0863e-03,
         7.6476e-04,  4.1934e-04, -6.6826e-04, -7.1412e-05, -6.1948e-04,
         5.4796e-04, -1.1277e-03, -3.9449e-04,  4.3479e-04, -7.4834e-04,
        -2.4480e-04,  7.8082e-04, -9.4871e-04,  9.1722e-04,  3.6279e-05,
         1.1001e-04,  5.0288e-04,  7.9963e-04, -8.3988e-05,  2.2692e-04,
        -3.6269e-04,  3.0619e-04, -1.0824e-04,  7.2829e-04, -4.2133e-04,
        -1.5568e-04, -1.1273e-03,  7.5628e-04,  1.1570e-03, -9.8784e-04,
         7.1314e-04,  6.2580e-04,  3.3747e-04, -5.9272e-04, -2.1170e-04,
         5.7593e-04,  4.1452e-04, -5.0709e-04, -7.5633e-04,  2.9078e-04,
        -7.7124e-04,  3.0443e-05, -6.8596e-04,  8.4821e-05, -8.5782e-04,
        -8.7830e-04,  1.2074e-03,  8.7839e-04, -1.0963e-03,  7.3341e-04,
        -1.1969e-03, -1.0550e-03, -1.1923e-03,  7.3129e-04,  4.9031e-04,
        -7.6607e-04, -9.3847e-04,  7.8988e-04, -5.1617e-04, -3.7990e-04,
        -7.7887e-04,  7.5601e-04,  1.1637e-03,  7.0836e-04, -8.2909e-04,
        -6.9858e-04,  9.2774e-04, -7.4494e-05,  1.6675e-04, -1.8970e-04,
         1.1868e-03, -4.2996e-04, -1.6480e-04,  7.6290e-04, -1.1131e-03,
        -2.6570e-04,  2.3566e-05, -8.0087e-04,  5.4504e-04, -9.3830e-04,
        -4.6520e-04,  9.4621e-04, -1.1630e-03, -1.1750e-03,  1.4952e-04,
        -4.0661e-04, -1.0904e-03,  4.4488e-04, -5.2157e-04,  7.8725e-04,
        -4.1464e-04,  8.0967e-05,  9.5373e-04,  3.8342e-04,  1.1872e-03,
         3.8597e-04, -8.5274e-04, -7.1437e-04, -6.1950e-04, -6.7697e-04,
         1.0445e-03, -8.0943e-04, -2.7729e-04,  9.3810e-04,  8.3738e-04,
        -5.5063e-05, -1.1903e-03,  7.4568e-04,  8.3865e-04, -7.9981e-04,
        -7.5952e-04, -3.9418e-04,  4.2412e-04, -9.6561e-05, -1.0803e-03,
         1.1329e-03, -4.0704e-04,  7.2610e-04,  3.5704e-04, -2.6588e-04,
        -7.7041e-04, -5.7710e-04, -1.1751e-03,  1.0037e-03, -5.9507e-04,
         9.8642e-04, -1.0579e-05,  4.4674e-04,  2.7233e-04, -6.5157e-04,
         9.2810e-04, -8.1797e-04,  6.4107e-04, -1.1721e-03,  9.5958e-04,
         1.0403e-03, -8.8988e-04, -1.2066e-03,  1.1490e-03, -9.6422e-04,
        -2.2468e-04, -1.1890e-04,  7.1596e-04,  6.3427e-04,  2.0841e-04,
         9.6882e-04,  7.0363e-04,  7.9316e-04,  1.6995e-04,  1.1255e-03,
         7.6311e-04], device='cuda:0', requires_grad=True)
parameters of the network fc2.weight 
 torch.Size([128, 256]) 
 True 
 tensor([[-0.0202, -0.0547, -0.0603,  ...,  0.0315, -0.0050,  0.0177],
        [ 0.0026,  0.0177,  0.0545,  ..., -0.0136,  0.0408, -0.0331],
        [ 0.0461, -0.0270,  0.0483,  ...,  0.0249, -0.0439, -0.0207],
        ...,
        [ 0.0603, -0.0402, -0.0313,  ..., -0.0317,  0.0538, -0.0492],
        [-0.0254,  0.0180,  0.0157,  ..., -0.0496, -0.0215,  0.0003],
        [ 0.0045,  0.0449, -0.0094,  ...,  0.0024, -0.0110, -0.0022]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0202, -0.0547, -0.0603,  ...,  0.0315, -0.0050,  0.0177],
        [ 0.0026,  0.0177,  0.0545,  ..., -0.0136,  0.0408, -0.0331],
        [ 0.0461, -0.0270,  0.0483,  ...,  0.0249, -0.0439, -0.0207],
        ...,
        [ 0.0603, -0.0402, -0.0313,  ..., -0.0317,  0.0538, -0.0492],
        [-0.0254,  0.0180,  0.0157,  ..., -0.0496, -0.0215,  0.0003],
        [ 0.0045,  0.0449, -0.0094,  ...,  0.0024, -0.0110, -0.0022]],
       device='cuda:0', requires_grad=True)
parameters of the network fc2.bias 
 torch.Size([128]) 
 True 
 tensor([ 2.8398e-02, -4.9114e-02, -1.3021e-02, -5.6115e-02,  4.4016e-02,
         4.2332e-02,  3.6064e-02,  2.0302e-02, -5.9616e-02,  3.8734e-02,
        -3.0407e-02, -1.5732e-02, -4.4952e-02,  1.8800e-02,  5.1309e-02,
        -2.9003e-02, -1.0275e-02,  5.6236e-02,  3.3259e-02, -2.8250e-02,
         2.1211e-02,  4.0767e-02,  5.9505e-02,  2.6608e-02, -8.9710e-03,
         3.5946e-02, -3.4879e-02, -2.7768e-02, -4.4092e-02, -5.1937e-02,
        -3.6403e-02,  3.8056e-02,  4.9460e-02, -2.2155e-02,  3.4454e-03,
         4.6637e-02,  2.1283e-02, -1.2471e-03, -1.1128e-02,  6.0548e-02,
        -1.1393e-02, -4.3168e-02, -5.0510e-02,  3.3883e-02, -3.2276e-02,
        -3.6804e-02, -3.7722e-02, -3.5208e-02,  9.8269e-03,  2.6617e-02,
         4.4101e-02,  1.9127e-02,  4.4970e-02, -1.8316e-02,  3.5733e-02,
         2.0213e-05, -1.5108e-02, -3.6099e-02, -1.8384e-02,  9.3722e-03,
         1.2078e-02, -2.4117e-02, -4.0641e-02,  2.4572e-02, -5.7725e-02,
        -2.2154e-02, -2.6671e-02, -2.4321e-02,  2.2470e-02, -6.0520e-02,
        -2.0444e-03,  2.5156e-02,  1.3770e-02, -4.7174e-02,  4.2390e-02,
        -5.7952e-02,  5.1718e-02,  5.1687e-02, -1.6804e-02,  6.1818e-02,
         6.2614e-03, -4.2673e-02, -4.8110e-02, -7.9451e-03, -6.1090e-02,
        -2.7795e-02, -9.0981e-03, -3.6718e-02, -5.7335e-02,  1.1377e-02,
         4.6817e-02, -4.9716e-02, -4.4412e-02,  2.0058e-02,  2.7179e-02,
         4.3421e-02, -9.1303e-03, -1.5495e-02, -3.4566e-02, -3.6779e-02,
        -3.3066e-02, -3.8067e-02, -6.0046e-02,  1.4398e-02,  4.9199e-02,
         2.3150e-02, -4.7481e-02,  3.5076e-02,  9.9307e-03,  1.7637e-02,
         4.6183e-02, -2.0726e-02, -2.5038e-02, -1.5368e-02,  4.1401e-02,
         5.3977e-02,  2.0318e-02, -3.8781e-02,  3.7142e-02, -2.7159e-02,
        -5.1915e-02,  6.0299e-02, -1.5281e-02,  3.3026e-02,  5.9777e-02,
         4.4288e-02, -1.5248e-02, -5.8015e-02], device='cuda:0') 
 Parameter containing:
tensor([ 2.8398e-02, -4.9114e-02, -1.3021e-02, -5.6115e-02,  4.4016e-02,
         4.2332e-02,  3.6064e-02,  2.0302e-02, -5.9616e-02,  3.8734e-02,
        -3.0407e-02, -1.5732e-02, -4.4952e-02,  1.8800e-02,  5.1309e-02,
        -2.9003e-02, -1.0275e-02,  5.6236e-02,  3.3259e-02, -2.8250e-02,
         2.1211e-02,  4.0767e-02,  5.9505e-02,  2.6608e-02, -8.9710e-03,
         3.5946e-02, -3.4879e-02, -2.7768e-02, -4.4092e-02, -5.1937e-02,
        -3.6403e-02,  3.8056e-02,  4.9460e-02, -2.2155e-02,  3.4454e-03,
         4.6637e-02,  2.1283e-02, -1.2471e-03, -1.1128e-02,  6.0548e-02,
        -1.1393e-02, -4.3168e-02, -5.0510e-02,  3.3883e-02, -3.2276e-02,
        -3.6804e-02, -3.7722e-02, -3.5208e-02,  9.8269e-03,  2.6617e-02,
         4.4101e-02,  1.9127e-02,  4.4970e-02, -1.8316e-02,  3.5733e-02,
         2.0213e-05, -1.5108e-02, -3.6099e-02, -1.8384e-02,  9.3722e-03,
         1.2078e-02, -2.4117e-02, -4.0641e-02,  2.4572e-02, -5.7725e-02,
        -2.2154e-02, -2.6671e-02, -2.4321e-02,  2.2470e-02, -6.0520e-02,
        -2.0444e-03,  2.5156e-02,  1.3770e-02, -4.7174e-02,  4.2390e-02,
        -5.7952e-02,  5.1718e-02,  5.1687e-02, -1.6804e-02,  6.1818e-02,
         6.2614e-03, -4.2673e-02, -4.8110e-02, -7.9451e-03, -6.1090e-02,
        -2.7795e-02, -9.0981e-03, -3.6718e-02, -5.7335e-02,  1.1377e-02,
         4.6817e-02, -4.9716e-02, -4.4412e-02,  2.0058e-02,  2.7179e-02,
         4.3421e-02, -9.1303e-03, -1.5495e-02, -3.4566e-02, -3.6779e-02,
        -3.3066e-02, -3.8067e-02, -6.0046e-02,  1.4398e-02,  4.9199e-02,
         2.3150e-02, -4.7481e-02,  3.5076e-02,  9.9307e-03,  1.7637e-02,
         4.6183e-02, -2.0726e-02, -2.5038e-02, -1.5368e-02,  4.1401e-02,
         5.3977e-02,  2.0318e-02, -3.8781e-02,  3.7142e-02, -2.7159e-02,
        -5.1915e-02,  6.0299e-02, -1.5281e-02,  3.3026e-02,  5.9777e-02,
         4.4288e-02, -1.5248e-02, -5.8015e-02], device='cuda:0',
       requires_grad=True)
parameters of the network fc3.weight 
 torch.Size([64, 128]) 
 True 
 tensor([[ 0.0862, -0.0658, -0.0599,  ..., -0.0212, -0.0092,  0.0807],
        [-0.0851, -0.0042, -0.0483,  ...,  0.0314,  0.0783,  0.0329],
        [-0.0586, -0.0157,  0.0577,  ...,  0.0728, -0.0834,  0.0765],
        ...,
        [-0.0177,  0.0540,  0.0082,  ...,  0.0161,  0.0039,  0.0132],
        [-0.0840, -0.0056, -0.0422,  ..., -0.0623,  0.0125, -0.0184],
        [ 0.0877,  0.0380,  0.0132,  ..., -0.0193,  0.0514,  0.0129]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0862, -0.0658, -0.0599,  ..., -0.0212, -0.0092,  0.0807],
        [-0.0851, -0.0042, -0.0483,  ...,  0.0314,  0.0783,  0.0329],
        [-0.0586, -0.0157,  0.0577,  ...,  0.0728, -0.0834,  0.0765],
        ...,
        [-0.0177,  0.0540,  0.0082,  ...,  0.0161,  0.0039,  0.0132],
        [-0.0840, -0.0056, -0.0422,  ..., -0.0623,  0.0125, -0.0184],
        [ 0.0877,  0.0380,  0.0132,  ..., -0.0193,  0.0514,  0.0129]],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.bias 
 torch.Size([64]) 
 True 
 tensor([-0.0223, -0.0181,  0.0179,  0.0781,  0.0830,  0.0171,  0.0287, -0.0552,
        -0.0423, -0.0679, -0.0129,  0.0509, -0.0803,  0.0873,  0.0454, -0.0348,
        -0.0806, -0.0524, -0.0136, -0.0709,  0.0466,  0.0010,  0.0559,  0.0263,
        -0.0548,  0.0741, -0.0234,  0.0555, -0.0377,  0.0313, -0.0390, -0.0363,
         0.0066, -0.0117,  0.0084,  0.0773, -0.0032,  0.0536, -0.0503,  0.0661,
         0.0060,  0.0283, -0.0570, -0.0569, -0.0646,  0.0387, -0.0323,  0.0538,
        -0.0469,  0.0386, -0.0410, -0.0516,  0.0195, -0.0550,  0.0555,  0.0687,
         0.0283, -0.0806,  0.0711,  0.0249,  0.0531, -0.0695, -0.0125, -0.0837],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0223, -0.0181,  0.0179,  0.0781,  0.0830,  0.0171,  0.0287, -0.0552,
        -0.0423, -0.0679, -0.0129,  0.0509, -0.0803,  0.0873,  0.0454, -0.0348,
        -0.0806, -0.0524, -0.0136, -0.0709,  0.0466,  0.0010,  0.0559,  0.0263,
        -0.0548,  0.0741, -0.0234,  0.0555, -0.0377,  0.0313, -0.0390, -0.0363,
         0.0066, -0.0117,  0.0084,  0.0773, -0.0032,  0.0536, -0.0503,  0.0661,
         0.0060,  0.0283, -0.0570, -0.0569, -0.0646,  0.0387, -0.0323,  0.0538,
        -0.0469,  0.0386, -0.0410, -0.0516,  0.0195, -0.0550,  0.0555,  0.0687,
         0.0283, -0.0806,  0.0711,  0.0249,  0.0531, -0.0695, -0.0125, -0.0837],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.weight 
 torch.Size([6796, 64]) 
 True 
 tensor([[-0.0681,  0.0312, -0.0483,  ..., -0.0185, -0.0144, -0.0620],
        [ 0.0664, -0.0471, -0.0929,  ..., -0.0349,  0.0437,  0.0677],
        [ 0.0006, -0.0598, -0.0163,  ..., -0.0045, -0.0551,  0.0665],
        ...,
        [-0.1011, -0.0116,  0.0402,  ..., -0.0860, -0.0274,  0.0084],
        [ 0.0726, -0.0941, -0.1207,  ..., -0.0075, -0.0798,  0.0253],
        [-0.0852,  0.0172,  0.0447,  ..., -0.0537,  0.1067, -0.0528]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0681,  0.0312, -0.0483,  ..., -0.0185, -0.0144, -0.0620],
        [ 0.0664, -0.0471, -0.0929,  ..., -0.0349,  0.0437,  0.0677],
        [ 0.0006, -0.0598, -0.0163,  ..., -0.0045, -0.0551,  0.0665],
        ...,
        [-0.1011, -0.0116,  0.0402,  ..., -0.0860, -0.0274,  0.0084],
        [ 0.0726, -0.0941, -0.1207,  ..., -0.0075, -0.0798,  0.0253],
        [-0.0852,  0.0172,  0.0447,  ..., -0.0537,  0.1067, -0.0528]],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.bias 
 torch.Size([6796]) 
 True 
 tensor([ 0.0321, -0.0612, -0.0106,  ..., -0.1093,  0.0523,  0.0817],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0321, -0.0612, -0.0106,  ..., -0.1093,  0.0523,  0.0817],
       device='cuda:0', requires_grad=True)

Passing event 1007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([[0.0116, 0.0000, 0.0000,  ..., 0.0000, 0.0421, 0.0746],
        [0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0422, 0.0747],
        [0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0420, 0.0747],
        ...,
        [0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0422, 0.0748],
        [0.0116, 0.0000, 0.0000,  ..., 0.0000, 0.0420, 0.0747],
        [0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0418, 0.0748]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
result1.shape: torch.Size([20, 6796])

Passing two random events from the network before training 
result1: tensor([[0.0116, 0.0000, 0.0000,  ..., 0.0000, 0.0421, 0.0746],
        [0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0422, 0.0747],
        [0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0420, 0.0747],
        ...,
        [0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0422, 0.0748],
        [0.0116, 0.0000, 0.0000,  ..., 0.0000, 0.0420, 0.0747],
        [0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0418, 0.0748]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
result1.shape: torch.Size([20, 6796]) 
input: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2/checkpoint_dir/1000810305saved_checkpoint.tar



load_model True 
TraEvN 10008 
BatchSize 30 
EpochNum 10 
epoch_save 5 
LrVal 0.001 
weight_decay 0.0001 
startmesh 305 
endmesh 306 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[[[-1.8390e-01, -5.3248e-01, -3.2598e-01],
          [-3.8884e-01, -3.5522e-01,  1.7992e-02],
          [ 2.6634e-01, -1.7373e-01,  1.0874e-01]]],


        [[[ 7.2498e-02, -3.1936e-01, -1.0330e-01],
          [ 1.3077e-01,  3.2151e-01, -1.1510e-01],
          [-4.3356e-01,  9.7462e-02,  2.0845e-01]]],


        [[[-2.3455e-01,  9.3531e-02,  1.9911e-01],
          [ 7.5014e-02,  2.0264e-01,  2.7617e-01],
          [-2.7996e-01, -4.7170e-01, -4.1869e-01]]],


        ...,


        [[[-3.8034e-01,  9.4928e-03,  1.7688e-01],
          [-3.2652e-01,  2.2446e-01, -1.2028e-01],
          [ 5.1475e-04, -1.2854e-01, -2.2283e-02]]],


        [[[ 2.1061e-01,  4.4343e-01,  3.2662e-01],
          [ 3.5830e-01,  2.7259e-01,  1.1835e-01],
          [ 3.4297e-01,  2.5422e-01,  1.1730e-03]]],


        [[[-1.1968e-01, -7.4712e-02, -8.2861e-02],
          [ 3.3411e-01,  2.2027e-01,  3.3083e-01],
          [-7.3508e-02,  4.8510e-02,  8.3631e-02]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([ 1.6663e-01,  1.1575e-01, -3.6538e-04,  2.1406e-01,  1.7719e-01,
         8.6263e-02, -5.7473e-02, -2.2371e-01, -4.5451e-03,  8.7080e-02,
        -1.1948e-02, -2.5115e-01,  1.7205e-02,  3.6514e-04,  7.9497e-03,
         1.2077e-01, -2.7898e-02,  1.3054e-01, -1.3738e-01, -5.7750e-02,
         1.4579e-01,  1.1038e-01, -2.3511e-08,  8.0796e-02,  1.8752e-01,
         1.4164e-01, -1.5258e-01,  3.5198e-03, -1.4855e-03,  1.7733e-01,
         1.6177e-03, -1.0657e-01, -1.4316e-01,  1.0461e-02, -8.7814e-02,
         1.2827e-01,  2.1958e-02, -2.9416e-03, -1.3724e-01, -4.6174e-02,
         1.0186e-01, -3.1756e-02,  1.0792e-03, -2.2194e-02,  2.0584e-01,
        -7.3894e-03,  1.7069e-01,  2.5149e-01, -1.3582e-03,  3.3643e-02,
        -3.0098e-01,  9.3851e-03,  9.6649e-02, -7.0426e-03,  6.0939e-02,
        -1.4778e-03, -3.6487e-02, -1.4971e-01, -1.6804e-01, -1.2154e-02,
        -5.6773e-02, -8.3493e-02,  2.4753e-02,  3.1392e-02, -2.2396e-01,
        -7.7865e-03, -1.7169e-01,  3.3625e-02, -1.0689e-01, -5.9531e-03,
        -1.0467e-03, -1.1268e-01, -1.1568e-01, -3.5261e-03, -6.8598e-05,
        -2.0498e-01, -1.3137e-02,  9.9152e-02,  3.1353e-02,  1.4254e-01,
         1.1712e-01,  1.5726e-02,  1.1618e-01, -2.2590e-02, -2.8705e-02,
         4.1510e-02, -2.5441e-01,  8.5306e-02,  1.1153e-01,  1.7201e-01,
         2.2170e-01,  1.4446e-01,  1.3512e-01,  3.4653e-02, -1.6648e-02,
         2.6132e-01,  3.3272e-03,  1.5819e-02,  6.6497e-02, -1.1686e-01,
        -1.3406e-02, -9.7771e-02,  1.7417e-02,  1.4951e-01, -2.6435e-02,
        -1.5765e-03,  4.5470e-02,  8.2024e-02,  1.0540e-01,  7.3317e-02,
        -2.3614e-01,  6.3312e-02, -1.0047e-01,  1.9609e-01, -1.7217e-04,
        -7.1981e-02, -6.8850e-03,  4.3656e-03, -1.1922e-02, -1.1961e-04,
         1.8831e-01, -4.4336e-03, -1.4561e-02, -6.3951e-03, -1.2765e-01,
         1.9485e-01,  5.0002e-03,  2.1684e-01,  4.9685e-02, -2.8481e-01,
        -3.7616e-02,  1.3014e-01,  6.7915e-04,  1.1917e-02,  1.8236e-01,
         4.8056e-02,  7.0344e-02,  2.4348e-01,  2.3372e-02,  6.5170e-03,
        -3.8576e-02, -1.8795e-01, -3.9129e-18, -2.1384e-03,  1.0972e-01,
         1.3642e-01,  1.0956e-02,  1.5162e-01, -7.5658e-03,  6.2744e-03,
        -2.0757e-02,  3.2447e-04,  2.0739e-01,  1.9415e-01,  2.1428e-03,
        -9.1508e-02,  1.5401e-01, -3.0816e-03,  2.2099e-03, -1.9417e-01,
        -2.1352e-01, -1.1928e-01,  1.2310e-03, -2.1344e-01, -2.3454e-02,
        -1.3200e-02,  7.9882e-02,  1.9910e-02, -6.5461e-02, -1.0203e-02,
         9.7287e-02,  6.9997e-02,  1.0354e-01,  1.7210e-01,  1.4105e-01,
        -5.0459e-03,  7.2366e-02,  3.1903e-02, -2.3461e-02, -1.4303e-01,
         1.5646e-02, -1.7247e-02,  2.6362e-03,  1.4482e-01,  2.6589e-02,
        -1.0333e-01, -9.9767e-03, -1.8703e-01,  2.2170e-01,  2.3452e-03,
        -1.0632e-01, -2.2678e-01, -7.2492e-07, -1.0176e-01, -7.9980e-03,
         2.2370e-02,  3.2888e-02,  2.4981e-01,  9.5151e-02, -4.4137e-03,
        -2.7429e-02, -1.0119e-14, -1.0239e-01,  2.6048e-03,  1.8242e-01,
        -1.6667e-03,  1.4894e-02,  3.5666e-02, -2.5989e-03,  1.3988e-01,
        -1.1255e-01,  2.1726e-01, -6.7861e-03, -1.7730e-02,  5.7349e-03,
         1.0325e-01, -4.1740e-03, -8.6558e-02,  7.6006e-02, -4.5146e-03,
        -1.8245e-02,  4.9178e-02,  1.2436e-01, -2.5742e-03, -1.1371e-01,
        -6.9124e-03,  3.8450e-02, -9.3726e-02,  1.0498e-01,  5.9332e-02,
        -1.0582e-01, -6.4493e-02, -3.4276e-06, -1.2529e-03, -5.7399e-02,
        -2.5813e-03,  8.0279e-02, -1.6882e-01,  6.3167e-03, -1.0021e-02,
         1.3194e-01, -1.4456e-01, -8.0628e-02, -5.3506e-03, -1.0157e-01,
        -3.1483e-04, -1.6582e-07,  1.2055e-01,  2.7836e-03,  5.8585e-02,
         4.9397e-02, -6.5385e-02, -1.1998e-01,  1.5620e-01, -3.3822e-03,
        -1.7909e-01], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[-2.0989e-02, -2.0456e-02, -2.0489e-02],
          [-2.0744e-02, -2.0499e-02, -2.1705e-02],
          [-2.0221e-02, -1.9716e-02, -1.9968e-02]],

         [[-2.0590e-02, -2.0370e-02, -1.9634e-02],
          [-2.1494e-02, -2.1318e-02, -2.1612e-02],
          [-2.0938e-02, -2.0934e-02, -2.0593e-02]],

         [[-9.0885e-03, -8.5730e-03, -1.0723e-02],
          [-1.6479e-02, -1.5938e-02, -1.5822e-02],
          [-1.4155e-02, -1.2628e-02, -9.0507e-03]],

         ...,

         [[-2.1444e-02, -2.1094e-02, -2.0487e-02],
          [-2.1432e-02, -2.0725e-02, -2.0597e-02],
          [-2.1358e-02, -2.0858e-02, -2.0315e-02]],

         [[-8.5837e-03, -1.3866e-02, -1.3083e-02],
          [-4.9629e-03, -8.1548e-03, -3.4117e-03],
          [-1.1031e-02, -1.4353e-02, -8.7936e-03]],

         [[ 2.1758e-02,  2.0412e-02,  2.0108e-02],
          [-5.7831e-04, -5.3542e-03, -1.7454e-03],
          [ 6.2534e-03,  3.0107e-03,  2.6047e-03]]],


        [[[ 9.9155e-03, -2.2256e-02,  1.1005e-03],
          [-6.6430e-03, -3.7441e-03, -3.7039e-03],
          [ 1.1539e-02,  2.0675e-03, -1.6087e-02]],

         [[ 9.5958e-03,  1.2983e-02, -2.1573e-02],
          [ 1.9150e-02, -1.2759e-02,  1.1004e-02],
          [-9.8169e-03,  3.8941e-03,  1.7066e-02]],

         [[ 3.3921e-02,  4.3062e-02,  4.1235e-02],
          [ 2.3640e-02,  1.8459e-02,  3.4370e-02],
          [-4.7271e-03,  1.3831e-02,  1.7938e-02]],

         ...,

         [[ 1.4824e-02, -7.3832e-03,  1.6970e-02],
          [ 2.0085e-02,  1.7419e-02, -1.8760e-02],
          [ 2.1808e-02,  1.1259e-03, -2.0106e-02]],

         [[-5.4804e-02, -1.6317e-02, -3.6807e-02],
          [-1.0482e-01, -4.4787e-02, -5.1932e-02],
          [-8.5379e-03,  1.9247e-02, -3.1116e-02]],

         [[-2.2352e-01, -2.2523e-01, -2.2440e-01],
          [-2.1815e-01, -1.4248e-01, -1.2627e-01],
          [-1.7314e-01, -2.3845e-01, -1.6835e-01]]],


        [[[-2.9288e-02,  1.4346e-03,  1.7808e-03],
          [-1.4852e-02, -1.1543e-02, -7.1873e-03],
          [-4.3243e-03, -2.0676e-02,  8.0977e-03]],

         [[ 4.7846e-03,  7.1616e-03, -2.8171e-02],
          [ 5.1928e-03, -3.0452e-03, -1.1673e-02],
          [-9.1059e-04, -2.2574e-02,  4.0109e-03]],

         [[-1.2608e-03, -2.0062e-02, -1.8805e-02],
          [-1.3200e-02, -1.0129e-02,  4.3894e-03],
          [ 7.0645e-03, -1.2425e-02,  4.4187e-03]],

         ...,

         [[-1.8797e-02, -2.0188e-02, -2.4451e-02],
          [-5.9534e-03, -2.2409e-03, -1.2541e-02],
          [-1.3653e-02, -7.1845e-04, -8.6138e-03]],

         [[-7.2433e-03, -2.9381e-03, -7.7165e-03],
          [ 3.5143e-03,  3.6581e-03, -7.3428e-03],
          [-1.2956e-03,  2.2744e-03,  9.0004e-03]],

         [[-1.2496e-04, -1.3228e-04, -7.3391e-05],
          [-6.8180e-07, -9.0403e-07, -9.8140e-07],
          [-1.1102e-04, -1.8176e-04, -1.1779e-04]]],


        ...,


        [[[ 3.7261e-03, -1.7012e-02, -1.6884e-02],
          [-1.5560e-02, -1.0652e-02,  6.6514e-03],
          [ 1.2329e-02, -2.5595e-02,  2.0997e-03]],

         [[ 6.0250e-03, -2.3427e-02, -2.4395e-02],
          [-1.1814e-02,  1.0543e-02,  4.9824e-03],
          [-2.9171e-02, -3.7223e-04,  5.7605e-03]],

         [[-2.2395e-03, -5.2769e-03,  7.5322e-05],
          [ 4.6055e-03, -1.4760e-03, -2.1971e-02],
          [ 3.2900e-03, -9.1504e-03, -1.5217e-02]],

         ...,

         [[-1.7192e-02, -2.7148e-02, -1.5191e-02],
          [ 6.3101e-03, -2.2491e-02, -1.1219e-02],
          [ 6.1976e-03, -9.1635e-03, -2.5056e-02]],

         [[ 8.0246e-02, -6.0911e-03, -4.3833e-02],
          [ 4.3112e-02, -4.0655e-02, -4.4412e-02],
          [ 1.8500e-02, -5.3780e-02, -4.7629e-02]],

         [[-4.3422e-02, -1.3075e-02, -7.4116e-03],
          [ 2.7405e-04,  4.5508e-08, -4.1676e-08],
          [-8.5533e-03, -4.8815e-03, -2.7074e-03]]],


        [[[ 9.6311e-03, -2.2045e-02,  8.2057e-03],
          [-6.7482e-03,  5.7035e-03, -1.1698e-02],
          [-7.0535e-03,  1.0332e-02, -8.1818e-03]],

         [[-1.5102e-02,  1.2029e-02, -2.1244e-02],
          [-9.1734e-03,  1.2102e-02, -8.4707e-03],
          [ 9.9618e-03,  1.1436e-02,  8.9325e-03]],

         [[-1.8890e-02,  2.0908e-03, -1.1761e-02],
          [-2.2051e-02,  8.0683e-03,  1.8424e-03],
          [-2.3746e-03,  1.3671e-02, -2.2769e-02]],

         ...,

         [[-5.7226e-03,  1.6009e-02,  1.2814e-02],
          [-2.5950e-03, -2.0089e-02,  1.7121e-03],
          [ 1.3708e-03, -1.9516e-02,  1.2057e-02]],

         [[-1.5107e-02, -1.1292e-02, -3.7676e-03],
          [ 5.3713e-03,  5.8805e-03, -6.2773e-03],
          [ 5.3637e-03, -1.0203e-02, -7.5741e-03]],

         [[-4.4472e-05,  1.3044e-05,  3.3084e-06],
          [-2.4432e-05,  6.8914e-06,  3.5126e-05],
          [-1.2439e-07, -3.1280e-07,  4.5395e-06]]],


        [[[-5.9872e-02, -6.2737e-02, -7.7095e-02],
          [-7.2596e-02, -5.2254e-02, -5.9650e-02],
          [ 5.0876e-03,  6.1071e-03,  4.8326e-03]],

         [[-2.1714e-02,  3.4849e-03, -2.9975e-02],
          [-1.2210e-01, -1.0256e-01, -6.6533e-02],
          [-8.4432e-02, -9.1370e-02, -8.3388e-02]],

         [[ 1.0448e-01,  7.2457e-02,  2.2061e-02],
          [ 5.9802e-02, -2.2351e-02, -2.8509e-02],
          [-5.1825e-02, -6.5423e-02, -7.0700e-02]],

         ...,

         [[-3.5510e-02, -6.6190e-02, -9.8583e-02],
          [-2.3003e-02, -6.9486e-02, -9.7728e-02],
          [-5.5396e-02, -6.0218e-02, -8.0036e-02]],

         [[-2.5567e-02,  4.8722e-03, -7.0988e-03],
          [ 4.2204e-03,  1.0980e-02, -8.4079e-03],
          [-7.1284e-02, -6.1379e-02, -6.7968e-02]],

         [[ 1.5216e-01,  1.5558e-01,  1.0959e-01],
          [-2.9458e-02, -3.4794e-02, -2.5077e-02],
          [ 5.7049e-03, -9.0499e-03, -1.0247e-02]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([-2.0984e-02,  1.0731e-03, -6.3316e-03, -1.4589e-03, -1.7971e-03,
        -4.4317e-03, -2.4253e-08, -1.3079e-24,  1.5284e-02, -4.7680e-15,
        -1.5581e-02,  4.3246e-03, -1.9381e-08, -1.2399e-02, -1.1168e-02,
        -1.0997e-19, -1.0020e-02, -1.3994e-02, -2.0582e-02,  4.9509e-03,
        -4.2946e-06,  3.5990e-03, -2.7173e-02, -6.4840e-03,  2.3061e-04,
        -6.9795e-03, -6.0568e-06, -7.7558e-03, -2.4243e-02,  9.7650e-03,
        -1.4132e-02,  1.5849e-02, -1.5817e-02, -1.9988e-02,  1.4380e-02,
         1.1167e-02,  9.4279e-03, -1.9334e-02, -8.7786e-04, -2.1671e-02,
        -4.4741e-03,  8.9425e-03,  3.6858e-03, -1.8199e-02, -1.2111e-02,
         8.5479e-03, -9.2813e-09, -4.0874e-03,  6.9952e-03, -4.4274e-06,
        -1.8952e-09, -5.6525e-03, -3.7112e-06, -1.5978e-02, -2.7601e-03,
        -2.9914e-03, -3.6749e-03, -9.1029e-15, -2.2184e-02, -1.6933e-02,
        -1.4203e-02, -7.3105e-03, -3.2559e-02, -2.0426e-02, -7.2255e-03,
        -4.9507e-03,  3.0742e-03, -1.0804e-09,  6.5777e-03, -8.4939e-03,
         1.3530e-02, -1.4758e-03,  1.1581e-02, -1.9169e-08, -6.9634e-03,
        -1.8710e-02,  8.3127e-04,  2.1766e-02, -1.7115e-06, -2.3403e-03,
         1.3333e-02, -2.4587e-02, -3.3440e-06, -1.1929e-02, -2.1018e-02,
        -3.3559e-12, -1.2754e-03,  1.2138e-02, -1.9080e-02, -7.1795e-13,
        -1.0907e-02, -5.5872e-11, -2.3154e-02, -1.2638e-03, -6.3758e-02,
        -5.2548e-03, -1.6179e-09, -2.1829e-10, -7.8274e-04, -2.3337e-02,
        -7.6592e-03, -4.1832e-03, -3.0627e-02, -5.1363e-07, -5.8491e-03,
         1.2739e-02, -5.8260e-14, -5.7201e-02, -8.6516e-03, -7.1633e-04,
         1.9057e-03, -1.3347e-02,  3.2802e-03, -2.7356e-02, -1.2201e-06,
        -1.1782e-02, -9.7302e-03, -1.8254e-03, -1.0248e-02, -7.4085e-03,
        -4.1373e-03, -4.6242e-08,  7.5753e-03, -4.4129e-03, -2.1760e-02,
         1.0414e-02,  5.3763e-03, -8.3517e-02], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[[[ 5.7638e-41, -1.1768e-40, -8.8248e-41],
          [ 2.4079e-40, -1.4498e-40, -1.2602e-41],
          [ 2.2118e-40, -3.1414e-41,  1.9728e-40]],

         [[ 4.1669e-03,  7.1760e-04,  3.4468e-03],
          [-1.1567e-02, -8.8674e-04,  7.5927e-03],
          [-5.8870e-03,  1.1293e-02, -4.8596e-03]],

         [[ 5.3708e-07, -1.5049e-05, -3.1106e-07],
          [-4.2723e-07, -1.8593e-06,  2.1003e-07],
          [-1.5614e-07, -1.0214e-07, -5.7826e-09]],

         ...,

         [[-1.1288e-02, -2.7762e-02, -1.8659e-02],
          [-1.7372e-02, -7.7090e-03, -5.4272e-03],
          [-9.0997e-03,  4.7527e-03, -1.0189e-02]],

         [[-7.0900e-04, -7.4739e-03, -1.2173e-02],
          [-1.4561e-02,  6.5120e-03,  2.6115e-03],
          [-2.3451e-02,  1.9145e-03, -5.7158e-05]],

         [[-1.3837e-40,  2.8458e-40, -2.4099e-40],
          [-2.9231e-40, -1.5858e-40, -1.2943e-40],
          [ 2.6258e-40, -1.7305e-40,  2.1062e-40]]],


        [[[-3.8237e-41, -2.8124e-40, -6.7991e-41],
          [-1.1113e-40, -1.6309e-40, -6.3518e-41],
          [-1.6083e-40, -7.0021e-41,  8.5744e-41]],

         [[-2.1559e-02, -2.8124e-03, -2.6923e-02],
          [-4.4949e-02, -3.0275e-02, -4.3022e-02],
          [-3.0279e-02, -3.7922e-02, -2.3200e-02]],

         [[-2.2375e-02, -5.7669e-04, -1.1353e-02],
          [ 1.5157e-02, -1.9412e-02,  9.9941e-03],
          [-1.1599e-02, -4.8562e-03, -2.5271e-02]],

         ...,

         [[ 1.6314e-02,  6.5899e-03, -1.3631e-02],
          [ 9.5390e-04,  4.4413e-04,  1.5091e-02],
          [-1.4654e-02, -9.6605e-03,  1.7543e-03]],

         [[ 2.3688e-40,  2.8541e-40, -9.2070e-41],
          [-1.5137e-40,  2.0630e-40,  1.2724e-42],
          [-2.9490e-40,  1.4256e-40, -2.5756e-42]],

         [[-4.1859e-02, -3.8538e-02, -4.0889e-02],
          [-1.9938e-03,  5.5686e-03,  3.1290e-03],
          [-2.2785e-02, -2.4260e-02, -2.4854e-02]]],


        [[[-5.2298e-41, -1.2341e-40, -1.4137e-40],
          [ 9.3223e-41,  9.5370e-41, -1.3503e-40],
          [-1.5192e-40,  8.6120e-41, -1.2356e-40]],

         [[-2.0322e-02, -1.4531e-02,  6.0397e-03],
          [-2.8135e-02, -3.2691e-03,  3.5420e-03],
          [-5.2084e-03, -1.2400e-02, -4.6244e-02]],

         [[-3.1778e-02, -2.6662e-02,  1.2157e-02],
          [ 3.2206e-03,  8.5464e-03,  1.4379e-02],
          [ 2.1050e-02, -2.7834e-02, -2.5217e-02]],

         ...,

         [[ 2.6524e-03, -1.0896e-02, -3.4347e-03],
          [-2.1162e-02, -2.8659e-02, -2.7320e-02],
          [-1.3042e-02,  4.0195e-03,  4.0411e-03]],

         [[-3.1162e-03, -1.6870e-02,  1.8373e-02],
          [ 5.6681e-03,  4.3463e-03, -1.4310e-02],
          [-2.8474e-02, -8.3440e-04,  9.7563e-03]],

         [[ 6.7495e-03,  7.7558e-03,  8.8644e-03],
          [ 8.1997e-03,  9.8025e-03,  1.1065e-02],
          [ 1.2649e-02,  1.3741e-02,  1.5147e-02]]],


        ...,


        [[[ 1.5550e-02,  1.4171e-02,  7.7677e-03],
          [ 1.6844e-02,  1.6412e-02,  1.5940e-02],
          [ 1.6223e-02,  1.6487e-02,  1.6731e-02]],

         [[-3.4784e-02, -3.7286e-02,  1.5538e-02],
          [-3.2265e-02, -6.2895e-02, -5.6126e-02],
          [-4.8567e-02, -6.1592e-02, -1.6262e-02]],

         [[-1.3174e-02,  1.5154e-03, -1.0090e-03],
          [ 6.0255e-03, -1.8909e-02, -8.6037e-03],
          [-2.5084e-02,  6.0324e-03, -1.9125e-02]],

         ...,

         [[ 1.7564e-02, -9.1052e-03, -1.4522e-02],
          [-2.1871e-02,  2.2346e-02, -2.7462e-02],
          [ 2.2314e-02, -2.4053e-02,  1.4175e-02]],

         [[-1.0754e-02,  2.0486e-02, -2.0219e-02],
          [-3.5540e-02,  7.7295e-03, -1.8948e-02],
          [ 5.0642e-03, -1.5008e-02, -1.3661e-02]],

         [[-7.3139e-02, -8.7017e-02, -6.3149e-02],
          [ 4.7443e-03, -3.9806e-03, -3.0352e-02],
          [-2.4912e-02, -5.9767e-02, -5.5736e-02]]],


        [[[-1.1665e-40,  1.4999e-40,  1.4424e-40],
          [ 9.1293e-41, -8.6355e-41,  3.3103e-41],
          [ 4.1149e-41, -1.3606e-40,  1.3992e-40]],

         [[ 1.4382e-40,  1.6416e-40, -7.4912e-41],
          [ 1.8289e-40,  9.2207e-41,  1.7801e-40],
          [-2.0902e-40,  7.3247e-41,  5.1035e-41]],

         [[ 1.5218e-40,  1.0635e-40, -1.8897e-40],
          [-2.2214e-40,  1.9558e-40,  1.1782e-40],
          [-8.5070e-41,  1.7372e-40, -1.3326e-40]],

         ...,

         [[ 1.5476e-40,  9.8483e-42, -2.9467e-41],
          [-2.2653e-40,  1.5176e-40, -3.7382e-41],
          [ 9.6171e-41, -9.2857e-41,  2.2290e-41]],

         [[-4.9106e-41,  4.9477e-41,  1.6157e-40],
          [ 1.0276e-40, -3.0724e-40, -3.8962e-41],
          [ 4.6962e-41, -1.1846e-40,  7.9790e-42]],

         [[-1.4651e-40, -1.1328e-40, -6.1597e-41],
          [ 1.2618e-40, -7.7252e-41,  1.4608e-40],
          [ 3.4709e-41, -1.5928e-40, -9.7142e-41]]],


        [[[-9.2542e-42, -1.0694e-40, -1.4382e-40],
          [ 2.2918e-40, -1.6311e-40,  2.5028e-40],
          [-5.1540e-42, -1.6712e-40,  2.3634e-40]],

         [[ 1.6349e-41, -7.2010e-41, -8.3573e-41],
          [ 5.4672e-41,  1.9636e-41,  2.8250e-41],
          [ 7.9909e-41, -1.3722e-41,  4.3622e-42]],

         [[ 4.0303e-41,  1.2800e-40, -9.2654e-42],
          [-6.4168e-41,  9.3170e-41, -9.4939e-41],
          [ 8.3136e-41,  5.4276e-41,  1.3821e-41]],

         ...,

         [[ 1.4167e-41,  7.1081e-41,  2.2572e-41],
          [ 4.9506e-41,  2.0469e-41, -2.9262e-41],
          [-6.3173e-41, -8.1336e-41,  2.5951e-41]],

         [[ 6.7907e-41, -1.6506e-41,  6.1154e-41],
          [ 5.3112e-41,  4.4452e-41, -3.1898e-41],
          [ 4.5612e-41, -6.9909e-41, -3.5859e-42]],

         [[-1.1264e-41,  1.7635e-40,  2.8396e-40],
          [ 1.5908e-40,  1.6938e-40,  5.6153e-41],
          [-7.6201e-41, -2.9263e-40, -7.8930e-41]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([-3.1255e-02, -4.6339e-02, -1.9566e-02, -1.8339e-09,  2.3924e-02,
        -5.1155e-04, -4.4883e-02, -4.2237e-02, -2.5318e-02, -1.4503e-02,
         1.5091e-02,  1.8340e-02, -6.5962e-03, -1.2483e-02, -3.3293e-02,
        -1.0953e-02, -2.8940e-02, -9.8735e-03, -1.3288e-02, -5.5252e-11,
         1.2760e-02, -1.9858e-02, -1.1414e-02, -5.6226e-03, -2.3347e-02,
         1.4923e-02,  2.2642e-02,  1.8654e-02,  2.5654e-03,  2.3931e-03,
        -1.8909e-02, -2.7879e-02,  3.0722e-02, -3.0419e-02,  2.0334e-02,
         8.2758e-02, -2.8616e-02, -5.8809e-02, -2.3441e-02,  5.3262e-03,
        -6.3028e-26, -1.8567e-02, -2.5759e-08, -2.5764e-02, -1.8213e-02,
        -1.7226e-02, -4.2058e-13, -6.0307e-03,  1.9158e-02, -6.7384e-03,
        -2.9966e-02, -2.5583e-02, -1.5887e-02, -2.8700e-02, -3.3159e-02,
        -2.9077e-03, -2.0361e-02, -3.7397e-02,  2.4226e-02,  1.8528e-02,
        -2.0623e-12, -1.4555e-02, -6.1454e-13, -5.0570e-16], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[-1.1215e-29, -1.0831e-29, -1.0124e-29,  ..., -7.4661e-41,
         -3.2856e-40, -2.7889e-40],
        [ 1.3670e-09,  1.3702e-09,  1.3928e-09,  ..., -4.3085e-40,
         -5.7205e-40,  4.8216e-40],
        [-2.3105e-07, -2.2984e-07, -2.1557e-07,  ...,  1.9632e-40,
          4.4241e-40,  4.7106e-40],
        ...,
        [ 3.7487e-40,  1.1238e-40,  5.6507e-40,  ..., -2.2962e-40,
          9.2462e-41,  5.8545e-40],
        [-5.5592e-40,  4.2616e-40, -2.6070e-40,  ...,  1.4473e-40,
          1.5139e-40, -2.2340e-40],
        [-4.1584e-40,  5.7043e-41, -3.2390e-40,  ...,  5.5690e-40,
          3.3978e-40, -3.0165e-40]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 7.7013e-03, -1.3213e-04, -6.8935e-03, -2.2963e-03, -3.4860e-03,
        -4.6770e-04, -5.2179e-03, -4.4401e-03,  5.9983e-02, -1.5308e-02,
        -2.4078e-03, -1.4967e-02, -4.3865e-03, -5.4579e-03, -3.9671e-03,
        -1.5806e-04, -3.1070e-04,  3.7751e-04, -5.5770e-03, -2.8600e-20,
        -9.2656e-03,  3.8897e-03, -7.1784e-04, -2.8514e-07, -1.5965e-02,
        -1.4326e-05, -5.8086e-03, -5.6446e-03, -6.5668e-03, -7.8896e-03,
        -1.4225e-02,  2.2548e-03, -4.9438e-07, -1.1213e-02, -4.0056e-05,
        -4.9488e-03, -5.4681e-03, -1.7207e-03, -1.9765e-03, -1.1473e-02,
        -3.9758e-03, -2.3625e-02, -7.9739e-03,  1.1120e-02, -1.4153e-02,
         8.6619e-04, -9.5773e-03, -4.6158e-03,  1.0930e-04, -7.5831e-03,
        -5.4189e-03, -4.2584e-05, -4.2744e-06, -4.9393e-04, -1.5555e-03,
        -1.2072e-10, -5.2937e-03, -2.6104e-03,  8.9246e-04, -4.8120e-03,
        -2.5842e-05, -1.8570e-03, -1.0383e-03, -5.8958e-03, -4.2189e-03,
        -5.7969e-04, -5.0676e-03, -3.7910e-03, -8.4960e-03, -1.3447e-05,
        -3.3635e-03, -3.9970e-03, -4.5681e-04, -1.3931e-07, -4.2634e-03,
         2.5845e-03, -1.4866e-04, -1.1040e-03, -6.5375e-04, -6.4668e-04,
        -7.7701e-03, -2.9768e-03,  2.5792e-03, -6.4933e-03, -4.7015e-03,
        -5.9526e-04, -9.2297e-03, -1.6999e-04, -5.4080e-03, -2.1775e-03,
        -1.3801e-03, -3.4745e-03, -4.9267e-03, -2.1521e-03, -4.9019e-03,
        -6.7997e-03, -2.7288e-03, -5.8254e-03, -5.5048e-05, -2.0895e-03,
        -4.0725e-03, -3.9449e-03, -5.4936e-03, -7.5588e-03, -2.0977e-05,
         1.1303e-03, -1.0021e-03, -2.4663e-04,  1.8017e-03, -6.0452e-19,
        -1.8413e-03, -7.3593e-03,  5.3187e-04, -2.6531e-03, -1.3795e-05,
        -4.3427e-04,  2.5454e-03,  1.1715e-03, -4.8202e-03, -2.6459e-02,
         6.1227e-04, -4.2703e-03, -1.6348e-03, -4.5118e-03, -2.2788e-04,
        -4.0289e-03,  1.6098e-03, -2.5464e-03,  6.6200e-02,  2.6850e-03,
        -1.6321e-02, -3.6125e-03, -4.1243e-03, -2.0703e-03, -1.1894e-03,
        -5.7519e-03,  2.1221e-02, -2.8118e-03, -3.5067e-04, -6.2677e-03,
        -2.8473e-03, -6.6143e-03, -4.3942e-03, -2.2544e-03, -5.2320e-03,
        -5.1042e-03, -1.1105e-03, -5.4418e-04, -5.9305e-06, -1.7719e-03,
        -2.5427e-11, -2.7730e-03, -1.5021e-03, -1.8877e-04, -5.4455e-03,
        -1.1340e-13, -4.9072e-04, -3.5791e-05, -9.6153e-05,  4.9530e-04,
        -3.9230e-03, -1.9256e-03, -5.4727e-03, -1.1361e-06, -3.1908e-02,
        -4.4004e-03, -6.2020e-06, -2.2322e-02, -5.5416e-03, -3.0648e-03,
         1.3716e-03,  2.2149e-04, -2.4254e-02, -6.5440e-04, -3.3817e-11,
         6.9234e-03, -2.2758e-03, -3.6279e-03, -8.0673e-04, -2.5629e-03,
        -3.2550e-03, -1.8958e-03, -7.4664e-03, -4.2350e-03, -3.2408e-05,
         2.0057e-03, -1.7351e-03,  3.6223e-02, -3.8943e-07, -5.3081e-03,
        -3.1936e-03, -8.0322e-05, -8.7357e-03,  3.0310e-03, -8.3077e-04,
        -4.7938e-03,  5.4857e-02, -1.5053e-02, -1.7385e-02, -2.3661e-04,
        -2.4668e-02, -2.2962e-04, -2.1710e-04, -3.5102e-04, -4.8271e-03,
        -1.0727e-05, -4.9080e-03,  2.8123e-02, -5.8579e-03, -4.0342e-03,
        -4.8270e-03, -5.9285e-03,  7.5854e-02, -3.2437e-03, -4.2920e-03,
        -2.2665e-03, -7.6806e-05, -3.5910e-03, -2.1493e-03, -5.9835e-03,
        -3.5970e-03, -1.4826e-03,  1.0210e-03,  3.5568e-03, -4.1954e-27,
        -2.0924e-02, -4.8643e-03, -1.0930e-02, -4.0617e-04, -1.2929e-03,
         3.4942e-03,  2.9451e-02, -2.1474e-05,  2.1338e-03, -1.1998e-04,
        -5.4216e-03, -4.5606e-21, -4.4291e-03, -3.6439e-07, -2.5146e-04,
        -4.8098e-03, -3.6537e-03, -1.4480e-04, -1.3771e-03, -1.1589e-02,
         3.4244e-05, -3.3110e-03,  5.0311e-03,  2.7138e-02,  5.0485e-02,
        -1.5394e-03, -9.0589e-05, -4.4667e-03, -3.5502e-04,  1.4485e-03,
        -2.6116e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-4.4151e-02,  1.5925e-03, -4.6637e-03,  ..., -7.0439e-41,
         -1.5523e-40,  1.6448e-41],
        [ 8.1198e-41,  2.0128e-41, -1.9785e-40,  ...,  1.9675e-40,
         -2.2892e-40, -8.1565e-41],
        [-5.3999e-02, -3.5249e-03,  4.2828e-02,  ..., -1.3098e-40,
          1.9980e-40, -3.1198e-40],
        ...,
        [-1.1876e-40,  2.1381e-40, -3.9258e-40,  ..., -2.7802e-42,
         -4.3375e-40, -3.6271e-41],
        [ 1.2302e-02,  1.2977e-40,  1.6317e-40,  ...,  3.3669e-41,
         -7.1919e-03,  1.5223e-15],
        [-3.0063e-02,  5.2543e-03,  2.0499e-02,  ...,  7.5376e-42,
         -2.0772e-40, -2.2510e-36]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-2.4189e-02, -2.2341e-03, -4.3876e-02, -8.0511e-02,  7.2682e-02,
        -7.9196e-02,  5.7025e-02,  2.2093e-03, -5.2444e-03,  1.4967e-02,
        -3.7503e-02,  1.1277e-01,  9.2469e-02, -9.0915e-03, -3.7760e-02,
        -1.9138e-02,  6.2889e-41,  4.1752e-03,  3.9815e-02, -1.2138e-02,
         3.5589e-02, -7.7976e-03,  6.4550e-02,  7.9002e-02, -1.2019e-01,
        -3.2250e-02, -2.7708e-02, -1.0833e-02,  9.3172e-03,  5.3275e-02,
         2.7902e-02,  4.8005e-02,  3.4871e-02,  2.1191e-03, -1.5073e-02,
        -1.2997e-02,  1.5636e-02,  1.7514e-02, -1.3390e-02,  4.9361e-02,
         5.7327e-02, -5.0852e-02,  6.3090e-03,  1.0751e-01,  1.1802e-01,
         3.0867e-02,  4.7898e-02, -5.6913e-02, -2.7848e-02, -5.6176e-02,
         5.3624e-02,  5.8995e-03,  2.3040e-02,  4.1786e-02, -6.4911e-02,
         3.7573e-02, -2.0760e-02,  2.2354e-02,  6.8414e-02, -1.7484e-02,
         3.3815e-02,  9.1899e-03, -3.6911e-02, -6.6583e-02,  3.0814e-04,
        -8.4955e-02, -2.6524e-02,  2.5643e-02, -4.3465e-02,  7.3733e-02,
        -3.1597e-03, -3.7491e-02,  7.1405e-02, -8.5879e-03, -1.0228e-01,
        -3.4560e-03, -2.1958e-02,  5.6801e-02, -1.7983e-01, -7.9839e-02,
         2.3978e-02, -1.1206e-02, -1.5486e-02, -4.7178e-02, -3.7775e-02,
         8.5430e-03,  5.5287e-02,  2.0060e-02, -2.6002e-02, -2.3280e-02,
         3.7134e-02,  6.1338e-02,  1.2056e-02, -4.5155e-02,  2.4515e-02,
         9.7477e-03, -2.2775e-02, -2.7367e-02,  1.2226e-02,  1.8225e-02,
        -5.4581e-02, -6.0544e-03,  4.7561e-02, -5.4603e-02,  3.9894e-02,
        -3.2176e-02,  2.0608e-02, -3.7034e-02,  3.9622e-02, -1.7646e-02,
         4.3167e-02,  6.0775e-02,  2.2471e-02,  1.9793e-02, -1.1358e-02,
        -5.1181e-02, -2.4009e-02, -1.6992e-02, -1.5837e-02, -1.7588e-02,
        -3.3119e-03,  2.3123e-02, -5.9438e-02, -2.4445e-02,  1.2615e-03,
        -2.8166e-14,  2.7176e-03, -4.8594e-02], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[-4.8885e-03, -5.7476e-20, -1.5539e-02,  ..., -2.0450e-40,
         -2.8498e-02, -6.3592e-02],
        [-4.7964e-02,  1.3325e-40,  1.6590e-02,  ..., -8.0074e-41,
         -4.4483e-41, -1.0563e-01],
        [ 5.2483e-02,  1.8787e-40, -3.0961e-02,  ...,  3.1788e-41,
          4.0837e-41,  1.1237e-01],
        ...,
        [-5.8339e-41,  6.6476e-41, -6.3884e-41,  ...,  3.2090e-43,
         -2.2953e-40, -3.2541e-41],
        [ 1.3172e-02,  6.4516e-42,  7.1772e-02,  ..., -2.6269e-16,
          2.2449e-02, -7.7215e-02],
        [-5.0335e-02, -1.2613e-41, -4.7102e-02,  ..., -4.6389e-41,
          1.1275e-40,  1.6105e-02]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 3.3333e-02,  1.5475e-02, -6.0386e-02,  1.0657e-02,  1.1072e-02,
         7.8528e-03,  6.5053e-02, -9.2528e-02,  6.5203e-02,  1.9077e-02,
         9.0309e-03, -3.8310e-02, -3.6562e-02, -1.3402e-02,  2.7696e-03,
         4.5236e-02, -1.4063e-02, -7.1127e-03, -5.2901e-03, -6.1489e-02,
        -1.5279e-02, -6.2709e-02, -5.2670e-04, -1.5252e-02, -4.8495e-02,
        -5.2017e-02, -2.3400e-02,  5.5550e-02,  1.8826e-02, -9.3007e-03,
        -9.4613e-02, -3.6706e-02,  2.5280e-02,  7.4084e-03, -4.7227e-03,
        -4.9469e-02, -1.4801e-02,  1.0276e-02,  4.8375e-02, -8.4709e-02,
         4.6864e-02,  1.8867e-03, -5.2437e-03, -2.5335e-02,  7.6172e-02,
         5.2153e-02, -3.3166e-02,  9.5284e-02,  2.8317e-02, -7.6799e-02,
         5.5918e-02, -5.0918e-04,  1.2954e-01,  1.5335e-02,  3.9920e-02,
         4.6823e-02, -7.6599e-02, -2.0735e-02, -7.8126e-02, -8.0358e-02,
         2.4170e-41, -2.9058e-02, -7.3096e-02, -5.2271e-02], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[-2.7508e-02, -1.1848e-01, -6.4336e-02,  ...,  2.9560e-03,
         -4.2332e-03,  7.0695e-02],
        [ 2.8163e-03, -6.0144e-02, -2.1819e-02,  ...,  3.4002e-02,
          4.9786e-02, -7.6599e-02],
        [ 4.9812e-02, -1.4211e-01, -3.2292e-01,  ..., -3.4222e-04,
          2.1987e-03,  2.5204e-02],
        ...,
        [ 9.6634e-03,  2.9706e-02, -6.9028e-02,  ...,  1.2475e-40,
          3.8240e-02,  2.3126e-36],
        [-3.1172e-02,  1.3640e-41, -1.9154e-07,  ...,  1.9687e-40,
         -2.1402e-02,  1.7871e-41],
        [-5.6094e-02,  2.2182e-03, -9.8902e-02,  ..., -1.4570e-40,
          8.4534e-03, -6.8139e-02]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0982, -0.0442,  0.0300,  ..., -0.0760,  0.0647, -0.0840],
       device='cuda:0', requires_grad=True)], 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}]
epoch: 0 batch 0.0 event: 0 loss: tensor(173.9999, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 10.0 event: 300 loss: tensor(1913.9990, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 30.0 event: 900 loss: tensor(3666.9062, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 40.0 event: 1200 loss: tensor(1912.4885, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 50.0 event: 1500 loss: tensor(1940.4612, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 60.0 event: 1800 loss: tensor(1898.4329, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 70.0 event: 2100 loss: tensor(1936.1791, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 80.0 event: 2400 loss: tensor(1857.2621, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 100.0 event: 3000 loss: tensor(3480.5840, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 110.0 event: 3300 loss: tensor(1960.5238, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 120.0 event: 3600 loss: tensor(1643.8705, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 130.0 event: 3900 loss: tensor(1708.5194, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 140.0 event: 4200 loss: tensor(1699.6600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 150.0 event: 4500 loss: tensor(1928.2949, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 160.0 event: 4800 loss: tensor(1875.4039, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 170.0 event: 5100 loss: tensor(1907.5283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 180.0 event: 5400 loss: tensor(1972.1995, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 190.0 event: 5700 loss: tensor(1931.6562, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 200.0 event: 6000 loss: tensor(2048.3491, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 210.0 event: 6300 loss: tensor(1681.3418, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 220.0 event: 6600 loss: tensor(1791.4192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 230.0 event: 6900 loss: tensor(1744.0953, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 240.0 event: 7200 loss: tensor(1621.1709, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 250.0 event: 7500 loss: tensor(1783.5647, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 260.0 event: 7800 loss: tensor(1727.2008, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 270.0 event: 8100 loss: tensor(1711.4579, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 280.0 event: 8400 loss: tensor(1936.0719, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 310.0 event: 9300 loss: tensor(5159.7876, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 320.0 event: 9600 loss: tensor(1668.9170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 330.0 event: 9900 loss: tensor(1748.1078, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:33.817541
evaluation loss: 1821.918212890625
epoch: 0 mean loss: 1820.4150390625
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 1 batch 0.0 event: 0 loss: tensor(172.8850, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 10.0 event: 300 loss: tensor(1902.9023, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 30.0 event: 900 loss: tensor(3652.3040, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 40.0 event: 1200 loss: tensor(1906.1293, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 50.0 event: 1500 loss: tensor(1935.1537, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 60.0 event: 1800 loss: tensor(1893.5697, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 70.0 event: 2100 loss: tensor(1931.7141, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 80.0 event: 2400 loss: tensor(1853.1750, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 100.0 event: 3000 loss: tensor(3471.8423, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 110.0 event: 3300 loss: tensor(1957.6426, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 120.0 event: 3600 loss: tensor(1640.7542, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 130.0 event: 3900 loss: tensor(1705.0624, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 140.0 event: 4200 loss: tensor(1696.3004, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 150.0 event: 4500 loss: tensor(1924.5653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 160.0 event: 4800 loss: tensor(1873.7233, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 170.0 event: 5100 loss: tensor(1905.4930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 180.0 event: 5400 loss: tensor(1970.1708, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 190.0 event: 5700 loss: tensor(1929.4661, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 200.0 event: 6000 loss: tensor(2045.7209, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 210.0 event: 6300 loss: tensor(1677.8066, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 220.0 event: 6600 loss: tensor(1787.6725, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 230.0 event: 6900 loss: tensor(1741.5690, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 240.0 event: 7200 loss: tensor(1618.9100, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 250.0 event: 7500 loss: tensor(1781.3096, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 260.0 event: 7800 loss: tensor(1725.2997, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 270.0 event: 8100 loss: tensor(1708.5321, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 280.0 event: 8400 loss: tensor(1932.0979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 310.0 event: 9300 loss: tensor(5149.7573, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 320.0 event: 9600 loss: tensor(1664.6366, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 330.0 event: 9900 loss: tensor(1743.3942, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:19.438246
evaluation loss: 1822.3883056640625
epoch: 1 mean loss: 1816.4573974609375
epoch: 2 batch 0.0 event: 0 loss: tensor(172.6055, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 10.0 event: 300 loss: tensor(1899.6283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 30.0 event: 900 loss: tensor(3647.6438, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 40.0 event: 1200 loss: tensor(1904.0873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 50.0 event: 1500 loss: tensor(1933.3466, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 60.0 event: 1800 loss: tensor(1890.5004, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 70.0 event: 2100 loss: tensor(1929.9424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 80.0 event: 2400 loss: tensor(1850.2523, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 100.0 event: 3000 loss: tensor(3467.8152, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 110.0 event: 3300 loss: tensor(1955.5336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 120.0 event: 3600 loss: tensor(1638.1205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 130.0 event: 3900 loss: tensor(1704.0071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 140.0 event: 4200 loss: tensor(1694.4309, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 150.0 event: 4500 loss: tensor(1922.1790, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 160.0 event: 4800 loss: tensor(1870.0995, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 170.0 event: 5100 loss: tensor(1903.9469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 180.0 event: 5400 loss: tensor(1967.5618, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 190.0 event: 5700 loss: tensor(1928.3391, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 200.0 event: 6000 loss: tensor(2044.0150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 210.0 event: 6300 loss: tensor(1675.8600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 220.0 event: 6600 loss: tensor(1785.8906, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 230.0 event: 6900 loss: tensor(1738.6976, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 240.0 event: 7200 loss: tensor(1615.3759, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 250.0 event: 7500 loss: tensor(1778.3522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 260.0 event: 7800 loss: tensor(1723.2379, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 270.0 event: 8100 loss: tensor(1705.4924, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 280.0 event: 8400 loss: tensor(1928.1957, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 310.0 event: 9300 loss: tensor(5139.0283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 320.0 event: 9600 loss: tensor(1662.9854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 330.0 event: 9900 loss: tensor(1741.3619, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:52.684496
evaluation loss: 1822.2808837890625
epoch: 2 mean loss: 1813.9923095703125
epoch: 3 batch 0.0 event: 0 loss: tensor(172.5196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 10.0 event: 300 loss: tensor(1897.5731, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 30.0 event: 900 loss: tensor(3642.8462, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 40.0 event: 1200 loss: tensor(1903.6927, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 50.0 event: 1500 loss: tensor(1931.9504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 60.0 event: 1800 loss: tensor(1888.8057, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 70.0 event: 2100 loss: tensor(1928.6039, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 80.0 event: 2400 loss: tensor(1848.6415, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 100.0 event: 3000 loss: tensor(3464.1348, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 110.0 event: 3300 loss: tensor(1953.1823, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 120.0 event: 3600 loss: tensor(1634.7626, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 130.0 event: 3900 loss: tensor(1700.4969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 140.0 event: 4200 loss: tensor(1693.3821, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 150.0 event: 4500 loss: tensor(1921.0883, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 160.0 event: 4800 loss: tensor(1868.5775, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 170.0 event: 5100 loss: tensor(1901.8778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 180.0 event: 5400 loss: tensor(1965.5286, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 190.0 event: 5700 loss: tensor(1926.0631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 200.0 event: 6000 loss: tensor(2040.4086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 210.0 event: 6300 loss: tensor(1673.3967, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 220.0 event: 6600 loss: tensor(1784.1536, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 230.0 event: 6900 loss: tensor(1737.8832, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 240.0 event: 7200 loss: tensor(1614.0518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 250.0 event: 7500 loss: tensor(1775.8411, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 260.0 event: 7800 loss: tensor(1719.4984, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 270.0 event: 8100 loss: tensor(1702.6562, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 280.0 event: 8400 loss: tensor(1926.0469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 310.0 event: 9300 loss: tensor(5134.2310, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 320.0 event: 9600 loss: tensor(1661.5654, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 330.0 event: 9900 loss: tensor(1740.0048, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:26.069943
evaluation loss: 1822.2269287109375
epoch: 3 mean loss: 1812.0323486328125
epoch: 4 batch 0.0 event: 0 loss: tensor(172.5549, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 10.0 event: 300 loss: tensor(1895.7465, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 30.0 event: 900 loss: tensor(3640.7583, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 40.0 event: 1200 loss: tensor(1897.9088, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 50.0 event: 1500 loss: tensor(1927.6377, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 60.0 event: 1800 loss: tensor(1885.6044, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 70.0 event: 2100 loss: tensor(1925.5856, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 80.0 event: 2400 loss: tensor(1847.4221, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 100.0 event: 3000 loss: tensor(3459.7505, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 110.0 event: 3300 loss: tensor(1952.3438, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 120.0 event: 3600 loss: tensor(1633.4938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 130.0 event: 3900 loss: tensor(1699.5809, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 140.0 event: 4200 loss: tensor(1691.5651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 150.0 event: 4500 loss: tensor(1915.9413, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 160.0 event: 4800 loss: tensor(1864.1874, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 170.0 event: 5100 loss: tensor(1898.6133, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 180.0 event: 5400 loss: tensor(1960.7844, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 190.0 event: 5700 loss: tensor(1922.7933, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 200.0 event: 6000 loss: tensor(2038.9821, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 210.0 event: 6300 loss: tensor(1672.4901, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 220.0 event: 6600 loss: tensor(1783.0819, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 230.0 event: 6900 loss: tensor(1737.0389, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 240.0 event: 7200 loss: tensor(1614.3694, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 250.0 event: 7500 loss: tensor(1776.2861, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 260.0 event: 7800 loss: tensor(1719.9277, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 270.0 event: 8100 loss: tensor(1702.6146, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 280.0 event: 8400 loss: tensor(1924.3031, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 310.0 event: 9300 loss: tensor(5128.2852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 320.0 event: 9600 loss: tensor(1659.6688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 330.0 event: 9900 loss: tensor(1740.4141, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:59.907592
evaluation loss: 1822.8863525390625
epoch: 4 mean loss: 1810.1322021484375
epoch: 5 batch 0.0 event: 0 loss: tensor(172.9213, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 10.0 event: 300 loss: tensor(1894.5643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 30.0 event: 900 loss: tensor(3632.1387, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 40.0 event: 1200 loss: tensor(1897.8291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 50.0 event: 1500 loss: tensor(1925.6064, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 60.0 event: 1800 loss: tensor(1883.5240, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 70.0 event: 2100 loss: tensor(1923.5575, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 80.0 event: 2400 loss: tensor(1844.3158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 100.0 event: 3000 loss: tensor(3458.4343, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 110.0 event: 3300 loss: tensor(1951.3890, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 120.0 event: 3600 loss: tensor(1633.0759, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 130.0 event: 3900 loss: tensor(1697.1631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 140.0 event: 4200 loss: tensor(1687.8131, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 150.0 event: 4500 loss: tensor(1915.9066, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 160.0 event: 4800 loss: tensor(1863.2354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 170.0 event: 5100 loss: tensor(1895.7301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 180.0 event: 5400 loss: tensor(1958.1204, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 190.0 event: 5700 loss: tensor(1918.7128, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 200.0 event: 6000 loss: tensor(2036.0074, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 210.0 event: 6300 loss: tensor(1669.8671, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 220.0 event: 6600 loss: tensor(1781.4182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 230.0 event: 6900 loss: tensor(1735.0129, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 240.0 event: 7200 loss: tensor(1612.4940, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 250.0 event: 7500 loss: tensor(1771.0468, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 260.0 event: 7800 loss: tensor(1713.7949, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 270.0 event: 8100 loss: tensor(1697.6631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 280.0 event: 8400 loss: tensor(1920.3414, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 310.0 event: 9300 loss: tensor(5121.2563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 320.0 event: 9600 loss: tensor(1657.4742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 330.0 event: 9900 loss: tensor(1738.5797, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:33.581873
evaluation loss: 1821.9920654296875
epoch: 5 mean loss: 1807.66259765625
=> saveing checkpoint at epoch 5
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 6 batch 0.0 event: 0 loss: tensor(172.5222, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 10.0 event: 300 loss: tensor(1894.1283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 30.0 event: 900 loss: tensor(3627.3118, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 40.0 event: 1200 loss: tensor(1893.6903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 50.0 event: 1500 loss: tensor(1923.5707, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 60.0 event: 1800 loss: tensor(1881.0846, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 70.0 event: 2100 loss: tensor(1921.6071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 80.0 event: 2400 loss: tensor(1842.4590, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 100.0 event: 3000 loss: tensor(3454.2683, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 110.0 event: 3300 loss: tensor(1949.8206, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 120.0 event: 3600 loss: tensor(1631.9125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 130.0 event: 3900 loss: tensor(1696.8231, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 140.0 event: 4200 loss: tensor(1685.5692, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 150.0 event: 4500 loss: tensor(1912.4342, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 160.0 event: 4800 loss: tensor(1859.7172, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 170.0 event: 5100 loss: tensor(1893.5361, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 180.0 event: 5400 loss: tensor(1956.8870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 190.0 event: 5700 loss: tensor(1915.5809, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 200.0 event: 6000 loss: tensor(2034.2432, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 210.0 event: 6300 loss: tensor(1669.2001, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 220.0 event: 6600 loss: tensor(1779.3854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 230.0 event: 6900 loss: tensor(1732.9036, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 240.0 event: 7200 loss: tensor(1609.6295, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 250.0 event: 7500 loss: tensor(1768.5848, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 260.0 event: 7800 loss: tensor(1711.9215, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 270.0 event: 8100 loss: tensor(1694.8812, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 280.0 event: 8400 loss: tensor(1918.0774, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 310.0 event: 9300 loss: tensor(5114.7085, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 320.0 event: 9600 loss: tensor(1654.9938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 330.0 event: 9900 loss: tensor(1736.2653, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:19.133049
evaluation loss: 1821.7679443359375
epoch: 6 mean loss: 1805.531982421875
epoch: 7 batch 0.0 event: 0 loss: tensor(172.1879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 10.0 event: 300 loss: tensor(1896.6656, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 30.0 event: 900 loss: tensor(3625.3340, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 40.0 event: 1200 loss: tensor(1892.4182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 50.0 event: 1500 loss: tensor(1922.7676, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 60.0 event: 1800 loss: tensor(1880.0721, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 70.0 event: 2100 loss: tensor(1919.5432, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 80.0 event: 2400 loss: tensor(1841.3988, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 100.0 event: 3000 loss: tensor(3451.8184, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 110.0 event: 3300 loss: tensor(1947.5038, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 120.0 event: 3600 loss: tensor(1630.0184, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 130.0 event: 3900 loss: tensor(1695.2416, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 140.0 event: 4200 loss: tensor(1685.4413, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 150.0 event: 4500 loss: tensor(1910.8701, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 160.0 event: 4800 loss: tensor(1858.5883, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 170.0 event: 5100 loss: tensor(1893.3674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 180.0 event: 5400 loss: tensor(1956.7694, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 190.0 event: 5700 loss: tensor(1915.2803, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 200.0 event: 6000 loss: tensor(2033.2225, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 210.0 event: 6300 loss: tensor(1670.3427, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 220.0 event: 6600 loss: tensor(1779.4657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 230.0 event: 6900 loss: tensor(1730.5800, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 240.0 event: 7200 loss: tensor(1607.6301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 250.0 event: 7500 loss: tensor(1766.6473, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 260.0 event: 7800 loss: tensor(1710.7946, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 270.0 event: 8100 loss: tensor(1693.2854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 280.0 event: 8400 loss: tensor(1916.0341, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 310.0 event: 9300 loss: tensor(5110.6523, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 320.0 event: 9600 loss: tensor(1652.0262, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 330.0 event: 9900 loss: tensor(1733.9508, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:54.193558
evaluation loss: 1821.9635009765625
epoch: 7 mean loss: 1804.390869140625
epoch: 8 batch 0.0 event: 0 loss: tensor(172.2038, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 10.0 event: 300 loss: tensor(1892.9410, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 30.0 event: 900 loss: tensor(3626.1360, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 40.0 event: 1200 loss: tensor(1890.0985, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 50.0 event: 1500 loss: tensor(1921.2227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 60.0 event: 1800 loss: tensor(1880.4540, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 70.0 event: 2100 loss: tensor(1917.2548, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 80.0 event: 2400 loss: tensor(1837.3938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 100.0 event: 3000 loss: tensor(3448.0603, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 110.0 event: 3300 loss: tensor(1946.0227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 120.0 event: 3600 loss: tensor(1627.0116, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 130.0 event: 3900 loss: tensor(1690.0546, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 140.0 event: 4200 loss: tensor(1680.8563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 150.0 event: 4500 loss: tensor(1907.2914, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 160.0 event: 4800 loss: tensor(1856.7516, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 170.0 event: 5100 loss: tensor(1892.5621, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 180.0 event: 5400 loss: tensor(1955.5674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 190.0 event: 5700 loss: tensor(1916.1227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 200.0 event: 6000 loss: tensor(2031.6934, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 210.0 event: 6300 loss: tensor(1668.1801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 220.0 event: 6600 loss: tensor(1779.2825, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 230.0 event: 6900 loss: tensor(1730.8453, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 240.0 event: 7200 loss: tensor(1606.5839, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 250.0 event: 7500 loss: tensor(1765.4290, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 260.0 event: 7800 loss: tensor(1709.4502, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 270.0 event: 8100 loss: tensor(1692.5664, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 280.0 event: 8400 loss: tensor(1915.8340, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 310.0 event: 9300 loss: tensor(5108.6689, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 320.0 event: 9600 loss: tensor(1652.0771, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 330.0 event: 9900 loss: tensor(1732.0459, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:06:29.866170
evaluation loss: 1822.449462890625
epoch: 8 mean loss: 1802.8701171875
epoch: 9 batch 0.0 event: 0 loss: tensor(171.8617, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 10.0 event: 300 loss: tensor(1891.0472, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 30.0 event: 900 loss: tensor(3627.6692, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 40.0 event: 1200 loss: tensor(1888.6830, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 50.0 event: 1500 loss: tensor(1918.2206, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 60.0 event: 1800 loss: tensor(1877.4623, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 70.0 event: 2100 loss: tensor(1916.7480, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 80.0 event: 2400 loss: tensor(1837.0758, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 100.0 event: 3000 loss: tensor(3445.6321, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 110.0 event: 3300 loss: tensor(1944.1680, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 120.0 event: 3600 loss: tensor(1625.8893, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 130.0 event: 3900 loss: tensor(1692.5028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 140.0 event: 4200 loss: tensor(1681.8397, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 150.0 event: 4500 loss: tensor(1906.5332, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 160.0 event: 4800 loss: tensor(1854.4768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 170.0 event: 5100 loss: tensor(1890.4368, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 180.0 event: 5400 loss: tensor(1954.5365, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 190.0 event: 5700 loss: tensor(1914.9154, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 200.0 event: 6000 loss: tensor(2031.8274, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 210.0 event: 6300 loss: tensor(1668.3287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 220.0 event: 6600 loss: tensor(1777.1786, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 230.0 event: 6900 loss: tensor(1729.2721, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 240.0 event: 7200 loss: tensor(1606.3044, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 250.0 event: 7500 loss: tensor(1764.3369, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 260.0 event: 7800 loss: tensor(1708.1719, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 270.0 event: 8100 loss: tensor(1691.8578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 280.0 event: 8400 loss: tensor(1915.7061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 310.0 event: 9300 loss: tensor(5112.4888, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 320.0 event: 9600 loss: tensor(1652.1332, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 330.0 event: 9900 loss: tensor(1732.1207, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:41.203879
evaluation loss: 1822.3717041015625
epoch: 9 mean loss: 1802.2264404296875
=> saveing checkpoint at epoch 9
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2

outi tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [1.8751, 0.9176, 0.0000,  ..., 0.5360, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
 torch.Size([30, 6796]) 
 tensor(48139.9062, device='cuda:0', grad_fn=<SumBackward0>) 
 tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0') 
 tensor(203880, device='cuda:0')



training loss:
 [1820.41503906 1816.45739746 1813.99230957 1812.03234863 1810.13220215
 1807.66259766 1805.53198242 1804.39086914 1802.87011719 1802.22644043] 

\evaluation loss:
 [1821.91821289 1822.38830566 1822.28088379 1822.22692871 1822.88635254
 1821.99206543 1821.76794434 1821.96350098 1822.44946289 1822.3717041 ]



eval_efficiency:
 [0.53870194 0.53799684 0.53722713 0.53642521 0.5357356  0.53505258
 0.53433701 0.53360252 0.53288473 0.5321471  0.53140215 0.53066528
 0.52994896 0.52926281 0.52841641 0.52767241 0.52692837 0.52631871
 0.52561449 0.52491551 0.52411697 0.52321114 0.52237074 0.52156838
 0.52077554 0.51982028 0.51911287 0.51821244 0.51723919 0.51637322
 0.51552735 0.51473435 0.51383244 0.51278972 0.5117661  0.51077033
 0.50974549 0.5087683  0.50791448 0.50695455 0.50584859 0.50487601
 0.50385943 0.50283781 0.50186571 0.50082061 0.49985503 0.49876078
 0.49764919 0.49675487 0.49568387 0.49474484 0.4937201  0.49264019
 0.49165323 0.49069583 0.48966606 0.48853517 0.48756537 0.4865139
 0.48536926 0.48405703 0.48284113 0.48163991 0.48070099 0.47952193
 0.47825901 0.47709349 0.4759158  0.47469001 0.47359854 0.47226493
 0.47095035 0.46966753 0.46837453 0.46689575 0.46572721 0.46441013
 0.46298337 0.46164809 0.46036308 0.45889837 0.45763648 0.45624558
 0.45479524 0.45348871 0.45191931 0.45038161 0.44912223 0.4476901
 0.44630083 0.44471302 0.44328467 0.44170326 0.44032923 0.43886965
 0.43755343 0.4361132  0.43470381 0.43304103] 


eval_purity:
 [0.89639298 0.89668998 0.89709714 0.89720156 0.8975448  0.89781652
 0.89801386 0.89835197 0.89865117 0.89882301 0.89909058 0.89924721
 0.89951421 0.89977453 0.89992122 0.90012353 0.90035977 0.9006752
 0.90087253 0.90103093 0.90122093 0.90151502 0.90174939 0.90196023
 0.90215297 0.90234767 0.90265383 0.90293629 0.90315391 0.90332031
 0.9034651  0.90370161 0.90386368 0.90404339 0.90433779 0.90448119
 0.9045129  0.90462759 0.90494872 0.90516121 0.90540942 0.90563775
 0.90583116 0.9062415  0.90643903 0.90677047 0.90706411 0.90741801
 0.90765597 0.9079408  0.9081584  0.90844677 0.90862922 0.90887501
 0.90915694 0.90927218 0.90947261 0.90972334 0.90991783 0.91008926
 0.9101989  0.91022928 0.91036127 0.91061727 0.91090871 0.9110813
 0.9113704  0.91161011 0.91175246 0.91186926 0.91202726 0.91228474
 0.91236621 0.91253544 0.91265153 0.91278761 0.91288408 0.91303809
 0.91316327 0.91338172 0.91353044 0.9136553  0.91384729 0.91407878
 0.91418008 0.914399   0.91446886 0.91473174 0.91493768 0.9151174
 0.91522885 0.91525036 0.91540565 0.91568333 0.91581383 0.91608606
 0.91628515 0.91631897 0.91648904 0.91664917]

Passing event 10003 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10003 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0036, 0.0000, 0.0212,  ..., 0.0566, 0.0000, 0.0000],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network before training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0.0000, 1.9272, 2.6225,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network after training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0.0035, 0.0000, 0.0212,  ..., 0.0566, 0.0000, 0.0000],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0000, 1.6239, 0.8411,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0035, 0.0000, 0.0212,  ..., 0.0565, 0.0000, 0.0000],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

real	16m53.266s
user	9m15.905s
sys	4m16.704s
