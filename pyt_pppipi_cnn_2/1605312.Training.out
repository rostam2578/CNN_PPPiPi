0: gpu021.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ac352fa0-e553-4a4b-9138-f546b3cbd7bb)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        C2:44:16:3E:F4:B2:32:61:B4:43:86:F6:64:80:CC:44:95:DA:BA:12
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Thu Sep  1 03:59:41 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1D:00.0 Off |                    0 |
| N/A   34C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2ab58c6c88e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m4.749s
user	0m2.700s
sys	0m0.833s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-b2qc504x because the default path (/besfs5/users/hoseinkk/home/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")




 Training ... 






 The Network ... 







 Loading data ... 



training set shape (20000, 43, 288) 
sum 5279207

target set shape (20000, 6796) 
sum 4575851
Net(
  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=667776, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=6796, bias=True)
)

number of the free parameters: 171805196
parameters of the network conv1.weight 
 torch.Size([256, 1, 3, 3]) 
 True 
 tensor([[[[-0.2586,  0.2639, -0.0153],
          [ 0.1466,  0.0778,  0.1874],
          [-0.0793, -0.1362,  0.3219]]],


        [[[ 0.2050, -0.2480,  0.2068],
          [-0.1282, -0.2044,  0.0225],
          [-0.0116, -0.2751, -0.1024]]],


        [[[ 0.2511, -0.0404,  0.1980],
          [-0.1036, -0.1660,  0.1129],
          [-0.2099,  0.1855,  0.1810]]],


        ...,


        [[[ 0.0224,  0.2655,  0.2990],
          [-0.0503,  0.3105, -0.0595],
          [-0.1711,  0.2353,  0.1965]]],


        [[[-0.1145, -0.1139,  0.1907],
          [ 0.0068,  0.0658, -0.2396],
          [ 0.0453,  0.1602, -0.1621]]],


        [[[ 0.3286, -0.2346, -0.2846],
          [ 0.2231,  0.1831,  0.2225],
          [-0.0536,  0.2999, -0.3294]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[-0.2586,  0.2639, -0.0153],
          [ 0.1466,  0.0778,  0.1874],
          [-0.0793, -0.1362,  0.3219]]],


        [[[ 0.2050, -0.2480,  0.2068],
          [-0.1282, -0.2044,  0.0225],
          [-0.0116, -0.2751, -0.1024]]],


        [[[ 0.2511, -0.0404,  0.1980],
          [-0.1036, -0.1660,  0.1129],
          [-0.2099,  0.1855,  0.1810]]],


        ...,


        [[[ 0.0224,  0.2655,  0.2990],
          [-0.0503,  0.3105, -0.0595],
          [-0.1711,  0.2353,  0.1965]]],


        [[[-0.1145, -0.1139,  0.1907],
          [ 0.0068,  0.0658, -0.2396],
          [ 0.0453,  0.1602, -0.1621]]],


        [[[ 0.3286, -0.2346, -0.2846],
          [ 0.2231,  0.1831,  0.2225],
          [-0.0536,  0.2999, -0.3294]]]], device='cuda:0', requires_grad=True)
parameters of the network conv1.bias 
 torch.Size([256]) 
 True 
 tensor([-1.0072e-01, -1.2330e-01, -1.8543e-01,  1.5162e-01,  1.7952e-01,
         9.7514e-02,  1.3362e-01,  2.4347e-01, -1.6304e-01,  2.7875e-01,
        -2.1062e-01,  1.0663e-01,  2.6008e-01,  2.8895e-01, -2.6001e-01,
         6.3688e-02,  3.2055e-01,  1.8542e-02,  3.0892e-01,  2.3155e-01,
         2.7490e-01,  2.6960e-02,  2.0775e-01, -1.8433e-02, -1.7149e-01,
        -1.7891e-01, -4.2429e-02,  2.1738e-01, -3.5873e-02, -1.6028e-01,
         1.8644e-01,  3.1286e-01,  3.2360e-01, -1.9406e-01, -1.4213e-01,
         5.2512e-02, -1.3847e-01, -9.6022e-02,  1.3852e-01,  3.2750e-01,
         3.1933e-02, -1.1443e-01, -1.1037e-01,  8.3504e-02, -2.1762e-02,
        -1.0821e-01, -1.7336e-02,  2.6392e-01, -2.5098e-01,  1.2898e-01,
        -2.0365e-01,  1.1284e-01, -2.6975e-01, -1.4642e-01,  2.1137e-01,
         5.8294e-02,  2.9173e-01, -7.0527e-02, -2.0686e-01, -2.0137e-01,
        -2.3247e-03,  2.9087e-01, -2.7385e-01, -4.4709e-02, -1.8308e-01,
         3.0543e-01,  2.4275e-01,  3.3128e-01, -2.1604e-01, -1.7946e-01,
         6.1431e-02, -2.2204e-01,  2.8639e-02,  1.1782e-01,  1.4948e-01,
         5.4693e-02,  1.7969e-01,  2.3822e-01,  4.7989e-02,  2.0004e-02,
         2.5483e-01,  8.1116e-02,  1.0721e-02,  1.3309e-01, -6.7397e-02,
        -5.7005e-02,  1.5521e-01,  2.3283e-01,  3.2800e-01,  1.8311e-01,
         1.2351e-01, -2.6619e-01, -2.2297e-01,  4.0439e-03,  1.2702e-01,
         6.5556e-03, -1.3423e-01, -2.3743e-01,  1.3355e-01, -1.3442e-01,
        -8.1462e-02, -3.2754e-01, -1.4128e-01, -1.0481e-02,  1.1005e-02,
         2.6636e-01, -7.2370e-02, -1.4360e-01, -1.9892e-01,  7.6945e-02,
         1.0432e-01,  1.0895e-01,  1.3472e-01, -1.1277e-02, -1.0623e-01,
        -1.5389e-01,  1.2700e-01,  2.6492e-01, -1.8559e-01,  1.0157e-04,
         2.1164e-02, -3.2036e-01,  4.1777e-02,  1.4211e-01,  3.1146e-01,
         3.2284e-01, -3.1149e-01, -5.7627e-02,  2.1831e-01, -3.1216e-01,
        -7.5852e-02,  2.2810e-01,  1.8809e-01, -1.6077e-01,  1.5204e-01,
         2.6719e-01,  3.8770e-02,  2.6966e-01,  1.9062e-01,  5.2768e-02,
         1.3101e-01,  1.5730e-01,  1.8243e-01,  6.8140e-02, -2.4176e-01,
        -2.2278e-01, -2.3250e-01,  1.2296e-01,  3.3363e-02,  8.2122e-02,
        -1.3725e-01,  5.9911e-02,  3.0906e-01, -1.5701e-01, -2.0045e-01,
         2.8734e-01, -1.6960e-01, -9.3580e-02,  1.0647e-01, -3.1541e-01,
         3.3134e-01,  2.5227e-01,  1.8179e-01,  2.0259e-01, -1.3024e-01,
        -1.0273e-01,  3.9943e-02,  2.2974e-01, -2.9765e-02, -1.9286e-01,
        -2.3275e-01, -3.1373e-01, -2.8610e-01,  4.5636e-03, -2.4453e-01,
         2.5503e-01, -2.6201e-01,  1.4037e-01,  3.8652e-02,  3.1319e-01,
         6.5033e-02, -2.5656e-01,  3.1993e-01,  1.4240e-01,  1.6374e-01,
        -2.9859e-01, -5.4849e-02,  2.8966e-01, -3.1064e-01,  2.0778e-01,
        -3.2738e-01, -1.4191e-01,  1.5007e-01,  2.3764e-01,  1.8170e-02,
         3.0685e-01, -9.4692e-02, -1.5503e-01, -8.0529e-02, -1.3341e-01,
         2.1711e-01,  3.1632e-01,  2.8523e-01,  6.3775e-02, -9.7027e-02,
        -2.8778e-01,  9.9837e-02,  2.7223e-01, -2.7598e-01,  2.5152e-01,
        -3.1882e-01, -1.3276e-01, -5.7808e-02, -1.1263e-01,  3.2516e-01,
        -3.3296e-02,  1.8809e-02, -1.1005e-01,  2.0238e-01,  3.6404e-02,
         1.6869e-01,  2.5311e-01,  1.3103e-01,  1.6350e-01,  9.3397e-03,
        -7.8096e-02, -1.9874e-01,  1.2280e-01,  1.6449e-01, -1.4966e-01,
        -1.3796e-01,  1.6483e-01,  2.9937e-01, -1.9524e-01, -1.1995e-01,
         3.0635e-01, -4.0236e-02, -8.9903e-02,  2.7805e-01,  2.7858e-01,
        -3.6876e-02,  1.6492e-01, -1.4350e-01,  1.8033e-01, -2.0045e-01,
         1.3237e-01, -2.9994e-01,  3.1309e-01, -8.9560e-02, -1.9110e-01,
         2.1134e-01,  2.9823e-01, -1.0001e-03,  2.0235e-01, -2.3473e-02,
         7.0600e-02], device='cuda:0') 
 Parameter containing:
tensor([-1.0072e-01, -1.2330e-01, -1.8543e-01,  1.5162e-01,  1.7952e-01,
         9.7514e-02,  1.3362e-01,  2.4347e-01, -1.6304e-01,  2.7875e-01,
        -2.1062e-01,  1.0663e-01,  2.6008e-01,  2.8895e-01, -2.6001e-01,
         6.3688e-02,  3.2055e-01,  1.8542e-02,  3.0892e-01,  2.3155e-01,
         2.7490e-01,  2.6960e-02,  2.0775e-01, -1.8433e-02, -1.7149e-01,
        -1.7891e-01, -4.2429e-02,  2.1738e-01, -3.5873e-02, -1.6028e-01,
         1.8644e-01,  3.1286e-01,  3.2360e-01, -1.9406e-01, -1.4213e-01,
         5.2512e-02, -1.3847e-01, -9.6022e-02,  1.3852e-01,  3.2750e-01,
         3.1933e-02, -1.1443e-01, -1.1037e-01,  8.3504e-02, -2.1762e-02,
        -1.0821e-01, -1.7336e-02,  2.6392e-01, -2.5098e-01,  1.2898e-01,
        -2.0365e-01,  1.1284e-01, -2.6975e-01, -1.4642e-01,  2.1137e-01,
         5.8294e-02,  2.9173e-01, -7.0527e-02, -2.0686e-01, -2.0137e-01,
        -2.3247e-03,  2.9087e-01, -2.7385e-01, -4.4709e-02, -1.8308e-01,
         3.0543e-01,  2.4275e-01,  3.3128e-01, -2.1604e-01, -1.7946e-01,
         6.1431e-02, -2.2204e-01,  2.8639e-02,  1.1782e-01,  1.4948e-01,
         5.4693e-02,  1.7969e-01,  2.3822e-01,  4.7989e-02,  2.0004e-02,
         2.5483e-01,  8.1116e-02,  1.0721e-02,  1.3309e-01, -6.7397e-02,
        -5.7005e-02,  1.5521e-01,  2.3283e-01,  3.2800e-01,  1.8311e-01,
         1.2351e-01, -2.6619e-01, -2.2297e-01,  4.0439e-03,  1.2702e-01,
         6.5556e-03, -1.3423e-01, -2.3743e-01,  1.3355e-01, -1.3442e-01,
        -8.1462e-02, -3.2754e-01, -1.4128e-01, -1.0481e-02,  1.1005e-02,
         2.6636e-01, -7.2370e-02, -1.4360e-01, -1.9892e-01,  7.6945e-02,
         1.0432e-01,  1.0895e-01,  1.3472e-01, -1.1277e-02, -1.0623e-01,
        -1.5389e-01,  1.2700e-01,  2.6492e-01, -1.8559e-01,  1.0157e-04,
         2.1164e-02, -3.2036e-01,  4.1777e-02,  1.4211e-01,  3.1146e-01,
         3.2284e-01, -3.1149e-01, -5.7627e-02,  2.1831e-01, -3.1216e-01,
        -7.5852e-02,  2.2810e-01,  1.8809e-01, -1.6077e-01,  1.5204e-01,
         2.6719e-01,  3.8770e-02,  2.6966e-01,  1.9062e-01,  5.2768e-02,
         1.3101e-01,  1.5730e-01,  1.8243e-01,  6.8140e-02, -2.4176e-01,
        -2.2278e-01, -2.3250e-01,  1.2296e-01,  3.3363e-02,  8.2122e-02,
        -1.3725e-01,  5.9911e-02,  3.0906e-01, -1.5701e-01, -2.0045e-01,
         2.8734e-01, -1.6960e-01, -9.3580e-02,  1.0647e-01, -3.1541e-01,
         3.3134e-01,  2.5227e-01,  1.8179e-01,  2.0259e-01, -1.3024e-01,
        -1.0273e-01,  3.9943e-02,  2.2974e-01, -2.9765e-02, -1.9286e-01,
        -2.3275e-01, -3.1373e-01, -2.8610e-01,  4.5636e-03, -2.4453e-01,
         2.5503e-01, -2.6201e-01,  1.4037e-01,  3.8652e-02,  3.1319e-01,
         6.5033e-02, -2.5656e-01,  3.1993e-01,  1.4240e-01,  1.6374e-01,
        -2.9859e-01, -5.4849e-02,  2.8966e-01, -3.1064e-01,  2.0778e-01,
        -3.2738e-01, -1.4191e-01,  1.5007e-01,  2.3764e-01,  1.8170e-02,
         3.0685e-01, -9.4692e-02, -1.5503e-01, -8.0529e-02, -1.3341e-01,
         2.1711e-01,  3.1632e-01,  2.8523e-01,  6.3775e-02, -9.7027e-02,
        -2.8778e-01,  9.9837e-02,  2.7223e-01, -2.7598e-01,  2.5152e-01,
        -3.1882e-01, -1.3276e-01, -5.7808e-02, -1.1263e-01,  3.2516e-01,
        -3.3296e-02,  1.8809e-02, -1.1005e-01,  2.0238e-01,  3.6404e-02,
         1.6869e-01,  2.5311e-01,  1.3103e-01,  1.6350e-01,  9.3397e-03,
        -7.8096e-02, -1.9874e-01,  1.2280e-01,  1.6449e-01, -1.4966e-01,
        -1.3796e-01,  1.6483e-01,  2.9937e-01, -1.9524e-01, -1.1995e-01,
         3.0635e-01, -4.0236e-02, -8.9903e-02,  2.7805e-01,  2.7858e-01,
        -3.6876e-02,  1.6492e-01, -1.4350e-01,  1.8033e-01, -2.0045e-01,
         1.3237e-01, -2.9994e-01,  3.1309e-01, -8.9560e-02, -1.9110e-01,
         2.1134e-01,  2.9823e-01, -1.0001e-03,  2.0235e-01, -2.3473e-02,
         7.0600e-02], device='cuda:0', requires_grad=True)
parameters of the network conv2.weight 
 torch.Size([128, 256, 3, 3]) 
 True 
 tensor([[[[ 1.5445e-02, -1.7903e-02,  1.8921e-02],
          [ 1.6715e-02, -6.2103e-03,  8.1837e-04],
          [-6.6046e-03,  5.3464e-03, -1.5529e-03]],

         [[ 7.9335e-03,  3.8254e-03,  5.3032e-04],
          [-1.6773e-02, -1.4175e-02, -4.9108e-03],
          [-4.7168e-03, -1.7634e-02, -1.3445e-02]],

         [[-2.4001e-03, -6.4006e-03,  7.3615e-03],
          [ 1.3001e-02,  1.4804e-02,  1.4938e-02],
          [ 8.9934e-03, -1.2597e-02, -7.3571e-03]],

         ...,

         [[ 7.1625e-06, -1.1957e-02, -1.7016e-02],
          [-1.1733e-03,  2.3551e-03,  7.6314e-03],
          [ 3.6911e-03, -1.6979e-02, -1.8280e-02]],

         [[-1.5430e-02, -1.1578e-02, -4.0747e-03],
          [ 2.9956e-03, -2.0633e-02,  5.0344e-03],
          [-1.5825e-02, -1.2372e-03, -1.1575e-02]],

         [[-3.1859e-03,  9.6562e-03,  9.0405e-03],
          [ 1.0813e-02, -5.0778e-03, -1.8803e-03],
          [-1.3148e-02,  1.9169e-02, -2.4435e-03]]],


        [[[-4.0447e-03,  1.1883e-02, -1.8719e-02],
          [ 1.9659e-02,  7.8186e-03, -8.3865e-03],
          [-2.8851e-03,  9.6102e-03,  3.3427e-03]],

         [[-4.2264e-03, -3.0580e-04,  9.8899e-03],
          [-5.0428e-03,  8.0192e-03, -9.5048e-03],
          [-1.4201e-03, -1.9847e-02, -6.3401e-03]],

         [[-2.0573e-03,  2.2969e-03, -1.2725e-02],
          [ 2.0334e-02,  1.7271e-02, -1.4705e-02],
          [ 1.4920e-02,  1.3112e-02, -7.8053e-03]],

         ...,

         [[ 1.1995e-02,  9.1585e-03,  9.3364e-03],
          [-1.0934e-02,  3.9056e-03,  1.8250e-02],
          [-1.5447e-02, -3.9100e-03, -4.9111e-03]],

         [[ 1.9959e-02, -6.6604e-03,  5.9019e-03],
          [ 1.8599e-02,  1.8184e-02, -1.4190e-02],
          [ 7.5382e-03,  3.0942e-03, -1.2813e-02]],

         [[-1.4827e-02, -1.4501e-02,  2.2277e-03],
          [-1.9060e-02,  1.4160e-02,  2.0589e-02],
          [-1.3451e-03,  3.8805e-03, -6.6114e-03]]],


        [[[ 3.1463e-03, -3.4795e-03,  1.0187e-02],
          [-1.5828e-02,  1.9539e-02,  2.4870e-03],
          [ 1.0880e-02,  8.4349e-03, -1.3744e-02]],

         [[-3.5431e-03,  1.9344e-03, -5.4733e-03],
          [ 3.1759e-03, -1.5948e-02, -4.1600e-03],
          [ 3.9260e-03,  1.7939e-02,  1.0473e-02]],

         [[-1.6821e-02, -1.9563e-02,  7.5064e-03],
          [ 4.6424e-03, -1.1306e-02, -1.1485e-02],
          [-1.8123e-02, -1.6292e-02,  1.2474e-02]],

         ...,

         [[ 1.2197e-02,  1.8227e-02,  2.3063e-03],
          [-1.5043e-02,  1.4120e-02,  1.7517e-02],
          [ 4.5164e-03,  1.4148e-02, -9.5078e-03]],

         [[-6.0082e-03,  1.6326e-02, -5.7492e-03],
          [ 7.8608e-03,  1.9027e-02, -1.4712e-02],
          [ 1.2307e-03, -1.9821e-02, -2.0402e-02]],

         [[-1.4277e-02, -2.8396e-03,  3.3077e-03],
          [-1.6285e-03,  5.6107e-03,  3.1740e-03],
          [-2.0762e-02,  1.1241e-03,  6.6935e-03]]],


        ...,


        [[[-1.6161e-02,  7.9056e-03,  1.2176e-02],
          [-2.4288e-03, -6.9450e-03,  4.2533e-04],
          [ 1.0815e-02,  9.4612e-04,  1.9393e-03]],

         [[-2.0342e-02, -1.5701e-02, -5.0219e-03],
          [-7.3469e-04, -5.3496e-03,  9.9101e-03],
          [ 2.6805e-03,  1.1853e-02,  6.6007e-03]],

         [[-5.9367e-04,  6.2941e-03, -7.9180e-04],
          [ 3.7642e-03, -1.0530e-02, -1.6002e-02],
          [-4.5983e-03,  1.4651e-02, -1.7078e-02]],

         ...,

         [[ 1.1678e-02,  2.3147e-03, -1.6725e-02],
          [-1.9970e-02, -6.7362e-03, -5.3966e-03],
          [-1.5828e-02,  1.4247e-02, -1.7210e-02]],

         [[-1.4827e-03, -1.0055e-02, -1.6338e-02],
          [-1.3470e-02,  1.9493e-02,  8.6576e-03],
          [ 1.6726e-02, -9.6819e-03,  1.7314e-02]],

         [[ 4.2082e-03, -1.2702e-02, -3.3091e-03],
          [-2.9900e-04,  1.5016e-02,  1.0178e-02],
          [-1.0622e-02,  1.7115e-02, -2.3187e-03]]],


        [[[ 1.2072e-02,  1.1477e-02, -1.1922e-02],
          [-1.2947e-02,  2.0543e-02,  2.3283e-03],
          [ 3.8216e-03,  1.5515e-02,  5.2753e-04]],

         [[-3.0695e-03,  7.6745e-03, -1.6388e-02],
          [-1.5760e-02,  2.0610e-02, -6.5394e-03],
          [-1.9774e-03, -1.9289e-02, -4.9571e-03]],

         [[-1.5611e-02,  1.3101e-02,  5.6202e-03],
          [-4.9665e-03,  1.4833e-02,  7.8729e-03],
          [-1.0634e-02, -2.5156e-03, -1.5306e-03]],

         ...,

         [[-2.0396e-02,  2.7559e-03,  1.2830e-02],
          [ 6.3746e-03, -4.0164e-03, -3.2573e-03],
          [-1.6879e-03,  1.1471e-02,  1.8568e-02]],

         [[ 5.0048e-03,  4.6718e-03, -2.7646e-03],
          [ 2.0055e-03, -1.3873e-02, -6.9707e-03],
          [ 1.4210e-02,  1.5233e-02, -1.1348e-02]],

         [[ 6.6331e-03,  1.2567e-02, -1.8264e-02],
          [ 1.4762e-02, -4.1131e-03, -1.6368e-02],
          [ 2.0653e-02,  9.4906e-03,  5.9142e-03]]],


        [[[ 8.5196e-03, -1.3971e-02,  4.9387e-03],
          [-7.2033e-03, -1.9523e-02,  6.3919e-03],
          [ 1.2956e-02,  1.6804e-02,  1.9703e-02]],

         [[-2.0119e-02,  2.1726e-03,  1.0893e-02],
          [-5.4343e-03,  1.9906e-02, -2.0601e-02],
          [ 2.0010e-02, -1.0303e-02, -1.2443e-02]],

         [[-3.2107e-03,  1.8303e-02,  2.8200e-03],
          [ 6.2488e-03,  6.9219e-03, -1.6277e-02],
          [ 1.7872e-02,  1.4388e-02, -5.8889e-03]],

         ...,

         [[ 1.7078e-02, -1.8066e-02,  6.1957e-03],
          [-6.3204e-04, -1.8605e-02,  1.4070e-02],
          [-5.3691e-03, -1.3176e-02,  5.8334e-03]],

         [[-1.3425e-02,  1.2359e-02, -5.7116e-03],
          [ 1.2732e-02, -8.7562e-03,  1.7261e-02],
          [-2.3210e-03, -2.1559e-03, -8.1794e-03]],

         [[ 1.1571e-02,  5.8680e-03, -1.8575e-02],
          [ 9.6887e-03,  4.2691e-03, -1.4013e-02],
          [-7.5617e-03,  1.1788e-02, -1.0568e-02]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 1.5445e-02, -1.7903e-02,  1.8921e-02],
          [ 1.6715e-02, -6.2103e-03,  8.1837e-04],
          [-6.6046e-03,  5.3464e-03, -1.5529e-03]],

         [[ 7.9335e-03,  3.8254e-03,  5.3032e-04],
          [-1.6773e-02, -1.4175e-02, -4.9108e-03],
          [-4.7168e-03, -1.7634e-02, -1.3445e-02]],

         [[-2.4001e-03, -6.4006e-03,  7.3615e-03],
          [ 1.3001e-02,  1.4804e-02,  1.4938e-02],
          [ 8.9934e-03, -1.2597e-02, -7.3571e-03]],

         ...,

         [[ 7.1625e-06, -1.1957e-02, -1.7016e-02],
          [-1.1733e-03,  2.3551e-03,  7.6314e-03],
          [ 3.6911e-03, -1.6979e-02, -1.8280e-02]],

         [[-1.5430e-02, -1.1578e-02, -4.0747e-03],
          [ 2.9956e-03, -2.0633e-02,  5.0344e-03],
          [-1.5825e-02, -1.2372e-03, -1.1575e-02]],

         [[-3.1859e-03,  9.6562e-03,  9.0405e-03],
          [ 1.0813e-02, -5.0778e-03, -1.8803e-03],
          [-1.3148e-02,  1.9169e-02, -2.4435e-03]]],


        [[[-4.0447e-03,  1.1883e-02, -1.8719e-02],
          [ 1.9659e-02,  7.8186e-03, -8.3865e-03],
          [-2.8851e-03,  9.6102e-03,  3.3427e-03]],

         [[-4.2264e-03, -3.0580e-04,  9.8899e-03],
          [-5.0428e-03,  8.0192e-03, -9.5048e-03],
          [-1.4201e-03, -1.9847e-02, -6.3401e-03]],

         [[-2.0573e-03,  2.2969e-03, -1.2725e-02],
          [ 2.0334e-02,  1.7271e-02, -1.4705e-02],
          [ 1.4920e-02,  1.3112e-02, -7.8053e-03]],

         ...,

         [[ 1.1995e-02,  9.1585e-03,  9.3364e-03],
          [-1.0934e-02,  3.9056e-03,  1.8250e-02],
          [-1.5447e-02, -3.9100e-03, -4.9111e-03]],

         [[ 1.9959e-02, -6.6604e-03,  5.9019e-03],
          [ 1.8599e-02,  1.8184e-02, -1.4190e-02],
          [ 7.5382e-03,  3.0942e-03, -1.2813e-02]],

         [[-1.4827e-02, -1.4501e-02,  2.2277e-03],
          [-1.9060e-02,  1.4160e-02,  2.0589e-02],
          [-1.3451e-03,  3.8805e-03, -6.6114e-03]]],


        [[[ 3.1463e-03, -3.4795e-03,  1.0187e-02],
          [-1.5828e-02,  1.9539e-02,  2.4870e-03],
          [ 1.0880e-02,  8.4349e-03, -1.3744e-02]],

         [[-3.5431e-03,  1.9344e-03, -5.4733e-03],
          [ 3.1759e-03, -1.5948e-02, -4.1600e-03],
          [ 3.9260e-03,  1.7939e-02,  1.0473e-02]],

         [[-1.6821e-02, -1.9563e-02,  7.5064e-03],
          [ 4.6424e-03, -1.1306e-02, -1.1485e-02],
          [-1.8123e-02, -1.6292e-02,  1.2474e-02]],

         ...,

         [[ 1.2197e-02,  1.8227e-02,  2.3063e-03],
          [-1.5043e-02,  1.4120e-02,  1.7517e-02],
          [ 4.5164e-03,  1.4148e-02, -9.5078e-03]],

         [[-6.0082e-03,  1.6326e-02, -5.7492e-03],
          [ 7.8608e-03,  1.9027e-02, -1.4712e-02],
          [ 1.2307e-03, -1.9821e-02, -2.0402e-02]],

         [[-1.4277e-02, -2.8396e-03,  3.3077e-03],
          [-1.6285e-03,  5.6107e-03,  3.1740e-03],
          [-2.0762e-02,  1.1241e-03,  6.6935e-03]]],


        ...,


        [[[-1.6161e-02,  7.9056e-03,  1.2176e-02],
          [-2.4288e-03, -6.9450e-03,  4.2533e-04],
          [ 1.0815e-02,  9.4612e-04,  1.9393e-03]],

         [[-2.0342e-02, -1.5701e-02, -5.0219e-03],
          [-7.3469e-04, -5.3496e-03,  9.9101e-03],
          [ 2.6805e-03,  1.1853e-02,  6.6007e-03]],

         [[-5.9367e-04,  6.2941e-03, -7.9180e-04],
          [ 3.7642e-03, -1.0530e-02, -1.6002e-02],
          [-4.5983e-03,  1.4651e-02, -1.7078e-02]],

         ...,

         [[ 1.1678e-02,  2.3147e-03, -1.6725e-02],
          [-1.9970e-02, -6.7362e-03, -5.3966e-03],
          [-1.5828e-02,  1.4247e-02, -1.7210e-02]],

         [[-1.4827e-03, -1.0055e-02, -1.6338e-02],
          [-1.3470e-02,  1.9493e-02,  8.6576e-03],
          [ 1.6726e-02, -9.6819e-03,  1.7314e-02]],

         [[ 4.2082e-03, -1.2702e-02, -3.3091e-03],
          [-2.9900e-04,  1.5016e-02,  1.0178e-02],
          [-1.0622e-02,  1.7115e-02, -2.3187e-03]]],


        [[[ 1.2072e-02,  1.1477e-02, -1.1922e-02],
          [-1.2947e-02,  2.0543e-02,  2.3283e-03],
          [ 3.8216e-03,  1.5515e-02,  5.2753e-04]],

         [[-3.0695e-03,  7.6745e-03, -1.6388e-02],
          [-1.5760e-02,  2.0610e-02, -6.5394e-03],
          [-1.9774e-03, -1.9289e-02, -4.9571e-03]],

         [[-1.5611e-02,  1.3101e-02,  5.6202e-03],
          [-4.9665e-03,  1.4833e-02,  7.8729e-03],
          [-1.0634e-02, -2.5156e-03, -1.5306e-03]],

         ...,

         [[-2.0396e-02,  2.7559e-03,  1.2830e-02],
          [ 6.3746e-03, -4.0164e-03, -3.2573e-03],
          [-1.6879e-03,  1.1471e-02,  1.8568e-02]],

         [[ 5.0048e-03,  4.6718e-03, -2.7646e-03],
          [ 2.0055e-03, -1.3873e-02, -6.9707e-03],
          [ 1.4210e-02,  1.5233e-02, -1.1348e-02]],

         [[ 6.6331e-03,  1.2567e-02, -1.8264e-02],
          [ 1.4762e-02, -4.1131e-03, -1.6368e-02],
          [ 2.0653e-02,  9.4906e-03,  5.9142e-03]]],


        [[[ 8.5196e-03, -1.3971e-02,  4.9387e-03],
          [-7.2033e-03, -1.9523e-02,  6.3919e-03],
          [ 1.2956e-02,  1.6804e-02,  1.9703e-02]],

         [[-2.0119e-02,  2.1726e-03,  1.0893e-02],
          [-5.4343e-03,  1.9906e-02, -2.0601e-02],
          [ 2.0010e-02, -1.0303e-02, -1.2443e-02]],

         [[-3.2107e-03,  1.8303e-02,  2.8200e-03],
          [ 6.2488e-03,  6.9219e-03, -1.6277e-02],
          [ 1.7872e-02,  1.4388e-02, -5.8889e-03]],

         ...,

         [[ 1.7078e-02, -1.8066e-02,  6.1957e-03],
          [-6.3204e-04, -1.8605e-02,  1.4070e-02],
          [-5.3691e-03, -1.3176e-02,  5.8334e-03]],

         [[-1.3425e-02,  1.2359e-02, -5.7116e-03],
          [ 1.2732e-02, -8.7562e-03,  1.7261e-02],
          [-2.3210e-03, -2.1559e-03, -8.1794e-03]],

         [[ 1.1571e-02,  5.8680e-03, -1.8575e-02],
          [ 9.6887e-03,  4.2691e-03, -1.4013e-02],
          [-7.5617e-03,  1.1788e-02, -1.0568e-02]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv2.bias 
 torch.Size([128]) 
 True 
 tensor([-0.0093,  0.0137,  0.0100, -0.0053,  0.0065, -0.0106,  0.0066, -0.0083,
         0.0149, -0.0106,  0.0198, -0.0082, -0.0097,  0.0089, -0.0155,  0.0067,
        -0.0076, -0.0028,  0.0123,  0.0067,  0.0082, -0.0090, -0.0182,  0.0067,
        -0.0093,  0.0062,  0.0198, -0.0098, -0.0117,  0.0194, -0.0039, -0.0130,
        -0.0076, -0.0078, -0.0137,  0.0110, -0.0029,  0.0148, -0.0138, -0.0104,
        -0.0178,  0.0137,  0.0174, -0.0098,  0.0140,  0.0180, -0.0132, -0.0168,
        -0.0078, -0.0205, -0.0208,  0.0062, -0.0070, -0.0114, -0.0032, -0.0113,
        -0.0073,  0.0157,  0.0165, -0.0198,  0.0093, -0.0203, -0.0184, -0.0077,
         0.0034,  0.0175, -0.0120,  0.0047,  0.0166, -0.0100, -0.0065,  0.0123,
        -0.0200, -0.0044,  0.0145, -0.0181, -0.0129, -0.0019,  0.0021,  0.0053,
        -0.0079, -0.0114,  0.0104, -0.0099,  0.0068,  0.0200, -0.0061, -0.0054,
        -0.0029, -0.0050,  0.0191, -0.0068,  0.0097, -0.0079,  0.0118,  0.0126,
         0.0173,  0.0173, -0.0025,  0.0108,  0.0110,  0.0152,  0.0192, -0.0110,
         0.0070,  0.0095, -0.0152, -0.0069,  0.0103,  0.0078, -0.0086, -0.0169,
        -0.0141, -0.0082,  0.0053, -0.0003, -0.0200, -0.0029, -0.0193,  0.0100,
         0.0022, -0.0102, -0.0006,  0.0097,  0.0134, -0.0181, -0.0029,  0.0147],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0093,  0.0137,  0.0100, -0.0053,  0.0065, -0.0106,  0.0066, -0.0083,
         0.0149, -0.0106,  0.0198, -0.0082, -0.0097,  0.0089, -0.0155,  0.0067,
        -0.0076, -0.0028,  0.0123,  0.0067,  0.0082, -0.0090, -0.0182,  0.0067,
        -0.0093,  0.0062,  0.0198, -0.0098, -0.0117,  0.0194, -0.0039, -0.0130,
        -0.0076, -0.0078, -0.0137,  0.0110, -0.0029,  0.0148, -0.0138, -0.0104,
        -0.0178,  0.0137,  0.0174, -0.0098,  0.0140,  0.0180, -0.0132, -0.0168,
        -0.0078, -0.0205, -0.0208,  0.0062, -0.0070, -0.0114, -0.0032, -0.0113,
        -0.0073,  0.0157,  0.0165, -0.0198,  0.0093, -0.0203, -0.0184, -0.0077,
         0.0034,  0.0175, -0.0120,  0.0047,  0.0166, -0.0100, -0.0065,  0.0123,
        -0.0200, -0.0044,  0.0145, -0.0181, -0.0129, -0.0019,  0.0021,  0.0053,
        -0.0079, -0.0114,  0.0104, -0.0099,  0.0068,  0.0200, -0.0061, -0.0054,
        -0.0029, -0.0050,  0.0191, -0.0068,  0.0097, -0.0079,  0.0118,  0.0126,
         0.0173,  0.0173, -0.0025,  0.0108,  0.0110,  0.0152,  0.0192, -0.0110,
         0.0070,  0.0095, -0.0152, -0.0069,  0.0103,  0.0078, -0.0086, -0.0169,
        -0.0141, -0.0082,  0.0053, -0.0003, -0.0200, -0.0029, -0.0193,  0.0100,
         0.0022, -0.0102, -0.0006,  0.0097,  0.0134, -0.0181, -0.0029,  0.0147],
       device='cuda:0', requires_grad=True)
parameters of the network conv3.weight 
 torch.Size([64, 128, 3, 3]) 
 True 
 tensor([[[[-2.0335e-02, -1.8943e-02,  2.1011e-02],
          [-2.2873e-02, -9.0510e-03, -2.4277e-02],
          [-3.4195e-03, -8.0344e-03, -2.7159e-02]],

         [[-1.7551e-02, -8.0073e-03, -1.4421e-02],
          [ 2.4762e-02, -2.4696e-02, -2.6845e-03],
          [-2.6929e-02, -3.7466e-03, -2.2167e-03]],

         [[-1.9199e-03, -9.6445e-03, -2.5717e-02],
          [-1.4062e-02, -2.5752e-02,  2.4338e-02],
          [-6.8256e-03,  8.0763e-03,  7.3252e-04]],

         ...,

         [[ 2.5716e-02, -1.0669e-02, -2.0908e-02],
          [-5.4414e-03, -2.2681e-02,  5.2255e-03],
          [ 5.1113e-03, -7.8609e-03, -1.5348e-02]],

         [[ 1.0849e-05, -8.7281e-03,  2.7065e-02],
          [-1.0108e-02,  1.8366e-02, -5.1743e-03],
          [ 3.9547e-03, -5.0138e-03,  2.5776e-02]],

         [[ 2.3248e-02,  2.2485e-02,  2.5785e-02],
          [-2.7805e-02, -1.0161e-02, -3.4728e-03],
          [-1.1635e-02, -2.3267e-02,  2.7119e-02]]],


        [[[ 1.7848e-02,  1.5548e-02, -2.8341e-02],
          [-6.0325e-03,  1.2495e-02, -1.5942e-02],
          [-2.3692e-02,  2.3896e-02,  8.5740e-03]],

         [[ 1.2956e-02, -3.4382e-03, -1.6432e-02],
          [-1.6230e-02, -8.0828e-03, -5.1968e-03],
          [ 5.8603e-03,  7.5265e-03,  9.1958e-03]],

         [[-2.0939e-02,  1.0144e-02,  3.7442e-03],
          [-1.3243e-02, -1.9658e-02, -1.8213e-02],
          [ 9.9382e-04, -1.6813e-02,  2.3445e-02]],

         ...,

         [[ 2.3196e-02, -2.2760e-02, -2.8729e-02],
          [ 7.1154e-05,  1.9915e-02, -1.2242e-02],
          [-1.8725e-02, -1.7378e-02, -2.5560e-03]],

         [[-2.1519e-02,  9.3848e-03,  7.5920e-03],
          [ 1.5542e-02,  9.8714e-03, -2.6344e-02],
          [-1.2815e-02, -2.6897e-02,  2.2194e-02]],

         [[-2.7964e-02, -1.0927e-02,  3.9061e-03],
          [ 2.0608e-02, -4.0801e-03,  2.1212e-03],
          [ 2.6825e-02,  1.8741e-02,  1.5209e-02]]],


        [[[-1.8333e-02, -2.9352e-02,  3.5624e-04],
          [-2.5552e-02, -1.4886e-02,  2.5060e-02],
          [ 1.5511e-02, -4.8805e-03,  2.0659e-02]],

         [[ 1.3767e-02,  1.0974e-02,  8.9105e-03],
          [ 1.0172e-02,  2.2078e-02,  6.3937e-05],
          [-1.3278e-02,  2.5285e-02, -2.1683e-02]],

         [[ 2.4015e-02, -2.7641e-02, -6.6731e-03],
          [ 4.5039e-03, -3.0000e-03, -1.3170e-02],
          [ 2.1252e-02, -2.2653e-02,  1.9064e-02]],

         ...,

         [[-1.4650e-02, -2.5613e-02,  1.4729e-02],
          [-1.9835e-02,  7.3682e-03, -1.8603e-02],
          [-4.6210e-04,  6.6620e-03, -4.9051e-03]],

         [[-1.5800e-02,  2.2821e-02,  2.6501e-02],
          [-2.8521e-02, -1.3115e-02, -2.9267e-03],
          [-1.8790e-02, -2.7739e-02, -1.2483e-02]],

         [[-4.5232e-03, -2.6759e-02,  5.6360e-03],
          [-9.6953e-03,  2.3656e-02,  2.6382e-02],
          [ 2.7870e-02,  1.5524e-02,  3.3803e-03]]],


        ...,


        [[[-1.6195e-02, -2.1035e-02, -2.6565e-02],
          [ 1.3553e-02,  2.8103e-02, -1.1809e-02],
          [ 7.5550e-03,  1.4269e-02, -7.9131e-03]],

         [[-4.7483e-03, -1.6068e-02, -1.2639e-02],
          [ 1.8004e-02,  1.2303e-02,  4.5639e-03],
          [-1.4555e-02,  5.1794e-04,  2.3258e-02]],

         [[ 2.0188e-02, -1.4935e-02,  2.4840e-02],
          [ 1.9424e-02, -3.8606e-03,  2.2102e-02],
          [ 2.6200e-02,  7.8266e-04, -2.3255e-02]],

         ...,

         [[ 1.5019e-02, -2.0241e-02, -4.0621e-03],
          [ 2.7144e-03, -2.3631e-02, -2.8802e-02],
          [-2.9034e-02, -4.7502e-03,  9.4916e-03]],

         [[ 1.7387e-02, -2.5486e-02,  4.7134e-03],
          [-1.0771e-02, -2.5125e-02, -8.4303e-03],
          [-2.9135e-02,  4.6798e-03,  4.1619e-03]],

         [[ 1.3178e-03,  2.3175e-02, -3.5300e-03],
          [-2.1235e-02, -1.8283e-02,  2.1580e-04],
          [-2.5925e-02, -1.5273e-02, -1.4133e-03]]],


        [[[-2.9356e-02, -8.3430e-03,  2.4133e-02],
          [-4.6387e-03, -1.8957e-02, -1.9017e-02],
          [ 3.5142e-03, -1.6038e-02, -1.4890e-02]],

         [[-2.0234e-02,  2.7801e-03, -2.2216e-02],
          [-2.4534e-02,  2.4746e-02, -2.3472e-02],
          [ 1.7840e-02, -1.3882e-02,  8.3177e-03]],

         [[ 1.5112e-02,  7.5562e-03, -2.2383e-02],
          [-2.3059e-02,  2.2455e-02,  2.6443e-02],
          [-1.5038e-02, -1.2160e-02,  1.8045e-02]],

         ...,

         [[-2.7532e-02, -7.6671e-03,  2.6559e-02],
          [-3.1313e-03, -1.4311e-03,  1.0062e-03],
          [-1.3215e-02,  1.9192e-02, -6.3700e-03]],

         [[ 1.0674e-02, -3.0589e-03, -2.0634e-02],
          [ 3.2104e-03,  1.5971e-02, -1.2452e-02],
          [ 1.2818e-03,  1.2660e-02,  2.3122e-03]],

         [[-2.8026e-02,  1.2588e-02, -2.2838e-02],
          [ 8.5991e-03, -2.6353e-02,  2.4774e-02],
          [ 4.4725e-03, -1.2552e-03,  1.0269e-02]]],


        [[[-5.7834e-03, -1.9176e-02,  2.0514e-03],
          [-2.3998e-02,  7.0045e-03, -2.6018e-02],
          [-9.6204e-03, -1.1461e-02, -1.7048e-02]],

         [[-1.0821e-02, -5.0918e-03,  1.5675e-02],
          [-1.4630e-02, -2.8601e-02, -2.4827e-02],
          [ 2.8015e-03, -1.5332e-02, -3.3365e-03]],

         [[-2.1853e-02,  1.4388e-02,  1.6432e-02],
          [-1.8886e-02,  1.7360e-02, -1.8098e-02],
          [ 4.2964e-03,  2.4317e-02, -6.3177e-03]],

         ...,

         [[ 1.1949e-02, -4.6347e-03,  2.0769e-02],
          [ 9.6376e-03, -2.7286e-03, -1.3367e-02],
          [ 2.2196e-02,  2.2651e-02,  1.4820e-02]],

         [[ 2.8649e-02,  4.2766e-03,  8.5383e-03],
          [-2.4199e-02,  8.0588e-03, -1.9844e-02],
          [-1.2827e-02, -2.0321e-02,  5.0322e-03]],

         [[-5.4889e-04, -1.6957e-02, -2.8121e-02],
          [-2.0848e-02, -1.3953e-02,  5.1721e-03],
          [ 1.3229e-03,  2.0599e-02,  5.5775e-03]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[-2.0335e-02, -1.8943e-02,  2.1011e-02],
          [-2.2873e-02, -9.0510e-03, -2.4277e-02],
          [-3.4195e-03, -8.0344e-03, -2.7159e-02]],

         [[-1.7551e-02, -8.0073e-03, -1.4421e-02],
          [ 2.4762e-02, -2.4696e-02, -2.6845e-03],
          [-2.6929e-02, -3.7466e-03, -2.2167e-03]],

         [[-1.9199e-03, -9.6445e-03, -2.5717e-02],
          [-1.4062e-02, -2.5752e-02,  2.4338e-02],
          [-6.8256e-03,  8.0763e-03,  7.3252e-04]],

         ...,

         [[ 2.5716e-02, -1.0669e-02, -2.0908e-02],
          [-5.4414e-03, -2.2681e-02,  5.2255e-03],
          [ 5.1113e-03, -7.8609e-03, -1.5348e-02]],

         [[ 1.0849e-05, -8.7281e-03,  2.7065e-02],
          [-1.0108e-02,  1.8366e-02, -5.1743e-03],
          [ 3.9547e-03, -5.0138e-03,  2.5776e-02]],

         [[ 2.3248e-02,  2.2485e-02,  2.5785e-02],
          [-2.7805e-02, -1.0161e-02, -3.4728e-03],
          [-1.1635e-02, -2.3267e-02,  2.7119e-02]]],


        [[[ 1.7848e-02,  1.5548e-02, -2.8341e-02],
          [-6.0325e-03,  1.2495e-02, -1.5942e-02],
          [-2.3692e-02,  2.3896e-02,  8.5740e-03]],

         [[ 1.2956e-02, -3.4382e-03, -1.6432e-02],
          [-1.6230e-02, -8.0828e-03, -5.1968e-03],
          [ 5.8603e-03,  7.5265e-03,  9.1958e-03]],

         [[-2.0939e-02,  1.0144e-02,  3.7442e-03],
          [-1.3243e-02, -1.9658e-02, -1.8213e-02],
          [ 9.9382e-04, -1.6813e-02,  2.3445e-02]],

         ...,

         [[ 2.3196e-02, -2.2760e-02, -2.8729e-02],
          [ 7.1154e-05,  1.9915e-02, -1.2242e-02],
          [-1.8725e-02, -1.7378e-02, -2.5560e-03]],

         [[-2.1519e-02,  9.3848e-03,  7.5920e-03],
          [ 1.5542e-02,  9.8714e-03, -2.6344e-02],
          [-1.2815e-02, -2.6897e-02,  2.2194e-02]],

         [[-2.7964e-02, -1.0927e-02,  3.9061e-03],
          [ 2.0608e-02, -4.0801e-03,  2.1212e-03],
          [ 2.6825e-02,  1.8741e-02,  1.5209e-02]]],


        [[[-1.8333e-02, -2.9352e-02,  3.5624e-04],
          [-2.5552e-02, -1.4886e-02,  2.5060e-02],
          [ 1.5511e-02, -4.8805e-03,  2.0659e-02]],

         [[ 1.3767e-02,  1.0974e-02,  8.9105e-03],
          [ 1.0172e-02,  2.2078e-02,  6.3937e-05],
          [-1.3278e-02,  2.5285e-02, -2.1683e-02]],

         [[ 2.4015e-02, -2.7641e-02, -6.6731e-03],
          [ 4.5039e-03, -3.0000e-03, -1.3170e-02],
          [ 2.1252e-02, -2.2653e-02,  1.9064e-02]],

         ...,

         [[-1.4650e-02, -2.5613e-02,  1.4729e-02],
          [-1.9835e-02,  7.3682e-03, -1.8603e-02],
          [-4.6210e-04,  6.6620e-03, -4.9051e-03]],

         [[-1.5800e-02,  2.2821e-02,  2.6501e-02],
          [-2.8521e-02, -1.3115e-02, -2.9267e-03],
          [-1.8790e-02, -2.7739e-02, -1.2483e-02]],

         [[-4.5232e-03, -2.6759e-02,  5.6360e-03],
          [-9.6953e-03,  2.3656e-02,  2.6382e-02],
          [ 2.7870e-02,  1.5524e-02,  3.3803e-03]]],


        ...,


        [[[-1.6195e-02, -2.1035e-02, -2.6565e-02],
          [ 1.3553e-02,  2.8103e-02, -1.1809e-02],
          [ 7.5550e-03,  1.4269e-02, -7.9131e-03]],

         [[-4.7483e-03, -1.6068e-02, -1.2639e-02],
          [ 1.8004e-02,  1.2303e-02,  4.5639e-03],
          [-1.4555e-02,  5.1794e-04,  2.3258e-02]],

         [[ 2.0188e-02, -1.4935e-02,  2.4840e-02],
          [ 1.9424e-02, -3.8606e-03,  2.2102e-02],
          [ 2.6200e-02,  7.8266e-04, -2.3255e-02]],

         ...,

         [[ 1.5019e-02, -2.0241e-02, -4.0621e-03],
          [ 2.7144e-03, -2.3631e-02, -2.8802e-02],
          [-2.9034e-02, -4.7502e-03,  9.4916e-03]],

         [[ 1.7387e-02, -2.5486e-02,  4.7134e-03],
          [-1.0771e-02, -2.5125e-02, -8.4303e-03],
          [-2.9135e-02,  4.6798e-03,  4.1619e-03]],

         [[ 1.3178e-03,  2.3175e-02, -3.5300e-03],
          [-2.1235e-02, -1.8283e-02,  2.1580e-04],
          [-2.5925e-02, -1.5273e-02, -1.4133e-03]]],


        [[[-2.9356e-02, -8.3430e-03,  2.4133e-02],
          [-4.6387e-03, -1.8957e-02, -1.9017e-02],
          [ 3.5142e-03, -1.6038e-02, -1.4890e-02]],

         [[-2.0234e-02,  2.7801e-03, -2.2216e-02],
          [-2.4534e-02,  2.4746e-02, -2.3472e-02],
          [ 1.7840e-02, -1.3882e-02,  8.3177e-03]],

         [[ 1.5112e-02,  7.5562e-03, -2.2383e-02],
          [-2.3059e-02,  2.2455e-02,  2.6443e-02],
          [-1.5038e-02, -1.2160e-02,  1.8045e-02]],

         ...,

         [[-2.7532e-02, -7.6671e-03,  2.6559e-02],
          [-3.1313e-03, -1.4311e-03,  1.0062e-03],
          [-1.3215e-02,  1.9192e-02, -6.3700e-03]],

         [[ 1.0674e-02, -3.0589e-03, -2.0634e-02],
          [ 3.2104e-03,  1.5971e-02, -1.2452e-02],
          [ 1.2818e-03,  1.2660e-02,  2.3122e-03]],

         [[-2.8026e-02,  1.2588e-02, -2.2838e-02],
          [ 8.5991e-03, -2.6353e-02,  2.4774e-02],
          [ 4.4725e-03, -1.2552e-03,  1.0269e-02]]],


        [[[-5.7834e-03, -1.9176e-02,  2.0514e-03],
          [-2.3998e-02,  7.0045e-03, -2.6018e-02],
          [-9.6204e-03, -1.1461e-02, -1.7048e-02]],

         [[-1.0821e-02, -5.0918e-03,  1.5675e-02],
          [-1.4630e-02, -2.8601e-02, -2.4827e-02],
          [ 2.8015e-03, -1.5332e-02, -3.3365e-03]],

         [[-2.1853e-02,  1.4388e-02,  1.6432e-02],
          [-1.8886e-02,  1.7360e-02, -1.8098e-02],
          [ 4.2964e-03,  2.4317e-02, -6.3177e-03]],

         ...,

         [[ 1.1949e-02, -4.6347e-03,  2.0769e-02],
          [ 9.6376e-03, -2.7286e-03, -1.3367e-02],
          [ 2.2196e-02,  2.2651e-02,  1.4820e-02]],

         [[ 2.8649e-02,  4.2766e-03,  8.5383e-03],
          [-2.4199e-02,  8.0588e-03, -1.9844e-02],
          [-1.2827e-02, -2.0321e-02,  5.0322e-03]],

         [[-5.4889e-04, -1.6957e-02, -2.8121e-02],
          [-2.0848e-02, -1.3953e-02,  5.1721e-03],
          [ 1.3229e-03,  2.0599e-02,  5.5775e-03]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.bias 
 torch.Size([64]) 
 True 
 tensor([ 0.0167,  0.0220, -0.0237, -0.0266,  0.0269,  0.0150, -0.0040, -0.0084,
         0.0089,  0.0101, -0.0256,  0.0104,  0.0066,  0.0009, -0.0245, -0.0031,
        -0.0122, -0.0176,  0.0027,  0.0024, -0.0115,  0.0003,  0.0108, -0.0141,
         0.0114, -0.0078,  0.0183, -0.0189,  0.0270,  0.0095, -0.0256, -0.0246,
        -0.0131,  0.0063, -0.0283,  0.0182,  0.0028,  0.0151,  0.0226,  0.0265,
        -0.0021, -0.0127, -0.0007,  0.0030, -0.0182, -0.0060, -0.0227,  0.0200,
        -0.0156, -0.0040,  0.0035,  0.0214, -0.0054, -0.0106,  0.0121, -0.0252,
        -0.0055, -0.0293,  0.0273,  0.0247,  0.0159, -0.0128,  0.0180,  0.0027],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0167,  0.0220, -0.0237, -0.0266,  0.0269,  0.0150, -0.0040, -0.0084,
         0.0089,  0.0101, -0.0256,  0.0104,  0.0066,  0.0009, -0.0245, -0.0031,
        -0.0122, -0.0176,  0.0027,  0.0024, -0.0115,  0.0003,  0.0108, -0.0141,
         0.0114, -0.0078,  0.0183, -0.0189,  0.0270,  0.0095, -0.0256, -0.0246,
        -0.0131,  0.0063, -0.0283,  0.0182,  0.0028,  0.0151,  0.0226,  0.0265,
        -0.0021, -0.0127, -0.0007,  0.0030, -0.0182, -0.0060, -0.0227,  0.0200,
        -0.0156, -0.0040,  0.0035,  0.0214, -0.0054, -0.0106,  0.0121, -0.0252,
        -0.0055, -0.0293,  0.0273,  0.0247,  0.0159, -0.0128,  0.0180,  0.0027],
       device='cuda:0', requires_grad=True)
parameters of the network fc1.weight 
 torch.Size([256, 667776]) 
 True 
 tensor([[ 6.2282e-04, -5.0090e-04,  6.6373e-04,  ..., -9.0731e-04,
         -5.5089e-04,  1.0239e-03],
        [ 5.3551e-04,  5.5976e-04, -1.1056e-03,  ..., -7.8204e-04,
          9.2912e-04,  2.1596e-04],
        [-3.8077e-04, -4.4687e-04, -8.6772e-04,  ...,  1.2236e-04,
         -3.6149e-05, -3.8897e-04],
        ...,
        [-2.3334e-05, -4.5233e-04,  7.5829e-04,  ...,  5.0151e-04,
          1.0846e-04,  4.2161e-04],
        [ 1.8659e-04, -3.2477e-05, -8.2097e-04,  ...,  1.0053e-03,
         -4.4850e-04, -1.1421e-03],
        [-5.4720e-04, -6.3873e-04, -7.7911e-04,  ...,  9.9264e-04,
          3.7861e-04, -1.2443e-04]], device='cuda:0') 
 Parameter containing:
tensor([[ 6.2282e-04, -5.0090e-04,  6.6373e-04,  ..., -9.0731e-04,
         -5.5089e-04,  1.0239e-03],
        [ 5.3551e-04,  5.5976e-04, -1.1056e-03,  ..., -7.8204e-04,
          9.2912e-04,  2.1596e-04],
        [-3.8077e-04, -4.4687e-04, -8.6772e-04,  ...,  1.2236e-04,
         -3.6149e-05, -3.8897e-04],
        ...,
        [-2.3334e-05, -4.5233e-04,  7.5829e-04,  ...,  5.0151e-04,
          1.0846e-04,  4.2161e-04],
        [ 1.8659e-04, -3.2477e-05, -8.2097e-04,  ...,  1.0053e-03,
         -4.4850e-04, -1.1421e-03],
        [-5.4720e-04, -6.3873e-04, -7.7911e-04,  ...,  9.9264e-04,
          3.7861e-04, -1.2443e-04]], device='cuda:0', requires_grad=True)
parameters of the network fc1.bias 
 torch.Size([256]) 
 True 
 tensor([-5.0058e-04,  2.2815e-04, -7.1759e-04, -9.0166e-04, -6.9986e-05,
         1.2197e-03, -7.2577e-05,  4.9621e-04,  1.8225e-05,  5.0314e-04,
        -7.2428e-04,  5.7537e-04, -1.0790e-03, -9.0571e-04,  1.1804e-03,
        -2.2972e-04,  1.2359e-04,  4.2579e-04,  7.3164e-04, -6.3905e-04,
         9.8177e-04,  9.8139e-04, -4.5638e-05, -1.2162e-03, -8.7752e-04,
        -1.1298e-03,  8.6273e-04, -2.1386e-06, -7.8988e-04, -2.6887e-04,
        -9.2199e-04, -3.4418e-04, -9.6786e-04, -9.3439e-04, -4.8407e-04,
         4.1811e-04,  4.5966e-04,  2.8910e-04,  6.7775e-04, -3.6409e-04,
        -2.4307e-04, -8.0188e-04, -3.1580e-04, -1.2041e-03, -6.9825e-04,
        -7.3349e-04,  2.8624e-04,  7.6164e-04, -1.0239e-03, -1.7830e-04,
         5.8736e-04,  7.7270e-04,  9.1728e-04, -6.7835e-04,  1.2710e-04,
        -9.1624e-04, -6.5619e-04, -8.8498e-04, -2.4305e-05,  5.1002e-04,
        -2.8746e-04, -8.9988e-04,  2.5546e-04,  7.2862e-04,  3.2014e-04,
         1.5088e-04, -4.3095e-04,  1.0792e-03, -8.3264e-04, -9.9834e-04,
        -9.7590e-05,  8.5525e-04, -5.4824e-04, -9.7399e-04, -6.0961e-04,
        -1.1811e-03, -1.0752e-04,  2.6755e-05, -3.3792e-04, -7.7765e-04,
        -5.4652e-04,  6.2511e-04, -9.7892e-04, -1.6077e-04,  1.1266e-03,
        -7.3074e-04, -3.0066e-04, -2.6070e-04, -5.8102e-04,  6.0571e-04,
        -4.0517e-04, -3.9980e-04,  3.3540e-04,  9.5199e-05,  1.1888e-03,
        -1.1249e-03,  4.0309e-04, -1.0368e-03, -1.0784e-05,  3.0834e-05,
        -8.7691e-04, -1.1756e-03,  7.6466e-05, -2.0934e-04,  1.0731e-03,
         7.9185e-05, -4.4561e-04, -2.3458e-04,  1.0416e-03, -7.3676e-04,
         7.1230e-04,  9.6861e-04, -1.0629e-03,  9.1573e-04,  1.2140e-03,
         3.4684e-04, -7.0770e-04,  1.2224e-03, -1.1059e-03, -1.0400e-03,
        -1.0229e-03,  1.9610e-04, -2.8370e-04, -5.9341e-04,  1.2188e-03,
         2.9048e-04,  1.1757e-04, -1.0357e-03,  9.3108e-04,  9.2069e-04,
        -4.4986e-04, -1.2142e-03, -6.8709e-04, -3.2916e-04, -5.6310e-04,
        -1.0079e-03,  5.9032e-04, -6.5989e-04, -8.8059e-04,  2.0447e-04,
         8.6956e-04,  3.6609e-04, -1.1386e-03,  3.5795e-04,  3.2808e-04,
         2.8007e-04,  1.1002e-03,  9.3386e-04, -9.7015e-04, -3.7416e-04,
         1.0441e-03, -1.4455e-04,  3.4203e-05,  7.2925e-04,  8.9186e-04,
        -8.9831e-04,  3.5553e-04,  5.0719e-04, -7.5471e-04, -2.9982e-04,
        -6.8178e-06,  2.6251e-04,  6.7721e-04, -1.1250e-03, -6.3602e-04,
        -5.4743e-04, -1.9007e-04,  9.3223e-04,  3.8246e-04, -7.9769e-04,
        -9.0668e-04,  9.5952e-04, -1.1641e-03, -7.8773e-04,  1.2084e-03,
         1.2140e-03,  1.2126e-04, -6.4032e-04,  9.9833e-04, -4.0368e-04,
         1.6864e-04,  4.5233e-04,  7.4175e-04, -3.8514e-04,  9.1548e-04,
         4.4427e-04, -3.5758e-04, -4.7528e-04, -7.4248e-04,  7.6679e-04,
        -6.7623e-05, -7.6316e-04, -3.7683e-04,  1.0737e-03, -5.9109e-04,
        -3.2262e-04, -1.0000e-03,  1.0680e-03,  9.1240e-04,  4.2731e-04,
        -6.7015e-04,  3.6247e-04,  5.6764e-04, -1.2882e-04,  7.1686e-04,
        -5.1483e-04,  9.7416e-04,  5.1105e-04,  1.5968e-04,  6.8513e-04,
        -1.8677e-04,  8.7793e-04, -6.5652e-04, -5.5636e-04, -5.3906e-04,
        -1.0760e-03, -4.1568e-04,  9.2203e-04, -1.1259e-03,  6.4595e-04,
         8.4634e-05, -4.7725e-04,  4.3191e-04, -8.6348e-04,  2.3037e-04,
         6.3295e-04,  8.9398e-04,  4.1429e-04,  6.9058e-04,  9.1245e-04,
        -4.8956e-04, -8.0958e-04,  6.6491e-04, -1.2700e-04,  2.3500e-04,
        -1.2042e-03, -4.1909e-04, -1.0299e-03, -5.5377e-05, -2.2813e-04,
         3.8686e-04,  4.8748e-04,  1.4513e-04,  1.1859e-03, -9.1014e-04,
         2.9739e-04, -2.2697e-04, -6.7460e-04,  2.7152e-04,  6.8711e-04,
        -4.8647e-04,  1.3258e-04, -1.0974e-03, -1.0799e-03, -6.1527e-04,
         1.8482e-04], device='cuda:0') 
 Parameter containing:
tensor([-5.0058e-04,  2.2815e-04, -7.1759e-04, -9.0166e-04, -6.9986e-05,
         1.2197e-03, -7.2577e-05,  4.9621e-04,  1.8225e-05,  5.0314e-04,
        -7.2428e-04,  5.7537e-04, -1.0790e-03, -9.0571e-04,  1.1804e-03,
        -2.2972e-04,  1.2359e-04,  4.2579e-04,  7.3164e-04, -6.3905e-04,
         9.8177e-04,  9.8139e-04, -4.5638e-05, -1.2162e-03, -8.7752e-04,
        -1.1298e-03,  8.6273e-04, -2.1386e-06, -7.8988e-04, -2.6887e-04,
        -9.2199e-04, -3.4418e-04, -9.6786e-04, -9.3439e-04, -4.8407e-04,
         4.1811e-04,  4.5966e-04,  2.8910e-04,  6.7775e-04, -3.6409e-04,
        -2.4307e-04, -8.0188e-04, -3.1580e-04, -1.2041e-03, -6.9825e-04,
        -7.3349e-04,  2.8624e-04,  7.6164e-04, -1.0239e-03, -1.7830e-04,
         5.8736e-04,  7.7270e-04,  9.1728e-04, -6.7835e-04,  1.2710e-04,
        -9.1624e-04, -6.5619e-04, -8.8498e-04, -2.4305e-05,  5.1002e-04,
        -2.8746e-04, -8.9988e-04,  2.5546e-04,  7.2862e-04,  3.2014e-04,
         1.5088e-04, -4.3095e-04,  1.0792e-03, -8.3264e-04, -9.9834e-04,
        -9.7590e-05,  8.5525e-04, -5.4824e-04, -9.7399e-04, -6.0961e-04,
        -1.1811e-03, -1.0752e-04,  2.6755e-05, -3.3792e-04, -7.7765e-04,
        -5.4652e-04,  6.2511e-04, -9.7892e-04, -1.6077e-04,  1.1266e-03,
        -7.3074e-04, -3.0066e-04, -2.6070e-04, -5.8102e-04,  6.0571e-04,
        -4.0517e-04, -3.9980e-04,  3.3540e-04,  9.5199e-05,  1.1888e-03,
        -1.1249e-03,  4.0309e-04, -1.0368e-03, -1.0784e-05,  3.0834e-05,
        -8.7691e-04, -1.1756e-03,  7.6466e-05, -2.0934e-04,  1.0731e-03,
         7.9185e-05, -4.4561e-04, -2.3458e-04,  1.0416e-03, -7.3676e-04,
         7.1230e-04,  9.6861e-04, -1.0629e-03,  9.1573e-04,  1.2140e-03,
         3.4684e-04, -7.0770e-04,  1.2224e-03, -1.1059e-03, -1.0400e-03,
        -1.0229e-03,  1.9610e-04, -2.8370e-04, -5.9341e-04,  1.2188e-03,
         2.9048e-04,  1.1757e-04, -1.0357e-03,  9.3108e-04,  9.2069e-04,
        -4.4986e-04, -1.2142e-03, -6.8709e-04, -3.2916e-04, -5.6310e-04,
        -1.0079e-03,  5.9032e-04, -6.5989e-04, -8.8059e-04,  2.0447e-04,
         8.6956e-04,  3.6609e-04, -1.1386e-03,  3.5795e-04,  3.2808e-04,
         2.8007e-04,  1.1002e-03,  9.3386e-04, -9.7015e-04, -3.7416e-04,
         1.0441e-03, -1.4455e-04,  3.4203e-05,  7.2925e-04,  8.9186e-04,
        -8.9831e-04,  3.5553e-04,  5.0719e-04, -7.5471e-04, -2.9982e-04,
        -6.8178e-06,  2.6251e-04,  6.7721e-04, -1.1250e-03, -6.3602e-04,
        -5.4743e-04, -1.9007e-04,  9.3223e-04,  3.8246e-04, -7.9769e-04,
        -9.0668e-04,  9.5952e-04, -1.1641e-03, -7.8773e-04,  1.2084e-03,
         1.2140e-03,  1.2126e-04, -6.4032e-04,  9.9833e-04, -4.0368e-04,
         1.6864e-04,  4.5233e-04,  7.4175e-04, -3.8514e-04,  9.1548e-04,
         4.4427e-04, -3.5758e-04, -4.7528e-04, -7.4248e-04,  7.6679e-04,
        -6.7623e-05, -7.6316e-04, -3.7683e-04,  1.0737e-03, -5.9109e-04,
        -3.2262e-04, -1.0000e-03,  1.0680e-03,  9.1240e-04,  4.2731e-04,
        -6.7015e-04,  3.6247e-04,  5.6764e-04, -1.2882e-04,  7.1686e-04,
        -5.1483e-04,  9.7416e-04,  5.1105e-04,  1.5968e-04,  6.8513e-04,
        -1.8677e-04,  8.7793e-04, -6.5652e-04, -5.5636e-04, -5.3906e-04,
        -1.0760e-03, -4.1568e-04,  9.2203e-04, -1.1259e-03,  6.4595e-04,
         8.4634e-05, -4.7725e-04,  4.3191e-04, -8.6348e-04,  2.3037e-04,
         6.3295e-04,  8.9398e-04,  4.1429e-04,  6.9058e-04,  9.1245e-04,
        -4.8956e-04, -8.0958e-04,  6.6491e-04, -1.2700e-04,  2.3500e-04,
        -1.2042e-03, -4.1909e-04, -1.0299e-03, -5.5377e-05, -2.2813e-04,
         3.8686e-04,  4.8748e-04,  1.4513e-04,  1.1859e-03, -9.1014e-04,
         2.9739e-04, -2.2697e-04, -6.7460e-04,  2.7152e-04,  6.8711e-04,
        -4.8647e-04,  1.3258e-04, -1.0974e-03, -1.0799e-03, -6.1527e-04,
         1.8482e-04], device='cuda:0', requires_grad=True)
parameters of the network fc2.weight 
 torch.Size([128, 256]) 
 True 
 tensor([[ 0.0387,  0.0260,  0.0234,  ...,  0.0174, -0.0568, -0.0127],
        [ 0.0619,  0.0077, -0.0090,  ..., -0.0188,  0.0336,  0.0104],
        [ 0.0560, -0.0175,  0.0336,  ...,  0.0369,  0.0015,  0.0615],
        ...,
        [-0.0127,  0.0548,  0.0531,  ..., -0.0478,  0.0037, -0.0126],
        [ 0.0481, -0.0013, -0.0190,  ..., -0.0444,  0.0572, -0.0546],
        [-0.0296,  0.0435,  0.0388,  ...,  0.0427,  0.0033, -0.0286]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0387,  0.0260,  0.0234,  ...,  0.0174, -0.0568, -0.0127],
        [ 0.0619,  0.0077, -0.0090,  ..., -0.0188,  0.0336,  0.0104],
        [ 0.0560, -0.0175,  0.0336,  ...,  0.0369,  0.0015,  0.0615],
        ...,
        [-0.0127,  0.0548,  0.0531,  ..., -0.0478,  0.0037, -0.0126],
        [ 0.0481, -0.0013, -0.0190,  ..., -0.0444,  0.0572, -0.0546],
        [-0.0296,  0.0435,  0.0388,  ...,  0.0427,  0.0033, -0.0286]],
       device='cuda:0', requires_grad=True)
parameters of the network fc2.bias 
 torch.Size([128]) 
 True 
 tensor([ 0.0071, -0.0321,  0.0106, -0.0622,  0.0399, -0.0201, -0.0217,  0.0355,
        -0.0036, -0.0094, -0.0540, -0.0463, -0.0436,  0.0218,  0.0553,  0.0029,
         0.0399, -0.0301,  0.0174, -0.0210,  0.0161, -0.0340, -0.0401,  0.0528,
         0.0437,  0.0534,  0.0206, -0.0394,  0.0270, -0.0233,  0.0595, -0.0419,
        -0.0528,  0.0567, -0.0052, -0.0447, -0.0194, -0.0502,  0.0381, -0.0503,
        -0.0504, -0.0165, -0.0375, -0.0139, -0.0585, -0.0395,  0.0399,  0.0551,
        -0.0511,  0.0186,  0.0505,  0.0473,  0.0460, -0.0346, -0.0278,  0.0278,
        -0.0588,  0.0513, -0.0130, -0.0369,  0.0111, -0.0250, -0.0348, -0.0453,
         0.0051,  0.0377, -0.0053, -0.0574,  0.0502,  0.0385,  0.0606, -0.0538,
        -0.0133, -0.0214, -0.0255, -0.0146, -0.0087,  0.0519, -0.0150, -0.0515,
         0.0534,  0.0362,  0.0601, -0.0241, -0.0493, -0.0589, -0.0510, -0.0496,
        -0.0007, -0.0351, -0.0233, -0.0134, -0.0270, -0.0024,  0.0400, -0.0202,
        -0.0037,  0.0290, -0.0492,  0.0599, -0.0190,  0.0040, -0.0505,  0.0020,
         0.0205,  0.0305,  0.0169,  0.0556,  0.0447, -0.0608,  0.0498, -0.0018,
        -0.0588,  0.0397, -0.0368, -0.0193, -0.0152,  0.0126,  0.0612, -0.0128,
        -0.0129, -0.0407, -0.0541, -0.0182, -0.0390,  0.0333, -0.0288, -0.0329],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0071, -0.0321,  0.0106, -0.0622,  0.0399, -0.0201, -0.0217,  0.0355,
        -0.0036, -0.0094, -0.0540, -0.0463, -0.0436,  0.0218,  0.0553,  0.0029,
         0.0399, -0.0301,  0.0174, -0.0210,  0.0161, -0.0340, -0.0401,  0.0528,
         0.0437,  0.0534,  0.0206, -0.0394,  0.0270, -0.0233,  0.0595, -0.0419,
        -0.0528,  0.0567, -0.0052, -0.0447, -0.0194, -0.0502,  0.0381, -0.0503,
        -0.0504, -0.0165, -0.0375, -0.0139, -0.0585, -0.0395,  0.0399,  0.0551,
        -0.0511,  0.0186,  0.0505,  0.0473,  0.0460, -0.0346, -0.0278,  0.0278,
        -0.0588,  0.0513, -0.0130, -0.0369,  0.0111, -0.0250, -0.0348, -0.0453,
         0.0051,  0.0377, -0.0053, -0.0574,  0.0502,  0.0385,  0.0606, -0.0538,
        -0.0133, -0.0214, -0.0255, -0.0146, -0.0087,  0.0519, -0.0150, -0.0515,
         0.0534,  0.0362,  0.0601, -0.0241, -0.0493, -0.0589, -0.0510, -0.0496,
        -0.0007, -0.0351, -0.0233, -0.0134, -0.0270, -0.0024,  0.0400, -0.0202,
        -0.0037,  0.0290, -0.0492,  0.0599, -0.0190,  0.0040, -0.0505,  0.0020,
         0.0205,  0.0305,  0.0169,  0.0556,  0.0447, -0.0608,  0.0498, -0.0018,
        -0.0588,  0.0397, -0.0368, -0.0193, -0.0152,  0.0126,  0.0612, -0.0128,
        -0.0129, -0.0407, -0.0541, -0.0182, -0.0390,  0.0333, -0.0288, -0.0329],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.weight 
 torch.Size([64, 128]) 
 True 
 tensor([[-0.0772,  0.0782, -0.0436,  ...,  0.0755, -0.0143, -0.0537],
        [-0.0101,  0.0123,  0.0035,  ...,  0.0847, -0.0211, -0.0484],
        [-0.0353,  0.0079, -0.0283,  ..., -0.0277,  0.0753, -0.0321],
        ...,
        [-0.0575, -0.0508,  0.0630,  ..., -0.0412,  0.0171, -0.0857],
        [-0.0368, -0.0668,  0.0076,  ..., -0.0425, -0.0220, -0.0856],
        [ 0.0397, -0.0048, -0.0070,  ..., -0.0692, -0.0359,  0.0093]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0772,  0.0782, -0.0436,  ...,  0.0755, -0.0143, -0.0537],
        [-0.0101,  0.0123,  0.0035,  ...,  0.0847, -0.0211, -0.0484],
        [-0.0353,  0.0079, -0.0283,  ..., -0.0277,  0.0753, -0.0321],
        ...,
        [-0.0575, -0.0508,  0.0630,  ..., -0.0412,  0.0171, -0.0857],
        [-0.0368, -0.0668,  0.0076,  ..., -0.0425, -0.0220, -0.0856],
        [ 0.0397, -0.0048, -0.0070,  ..., -0.0692, -0.0359,  0.0093]],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.bias 
 torch.Size([64]) 
 True 
 tensor([ 0.0166,  0.0527,  0.0203,  0.0245,  0.0401, -0.0659,  0.0771,  0.0248,
        -0.0822, -0.0879, -0.0409,  0.0819, -0.0497, -0.0091,  0.0074, -0.0633,
        -0.0011,  0.0009,  0.0169,  0.0748, -0.0641,  0.0129, -0.0167,  0.0026,
         0.0311, -0.0291,  0.0282,  0.0480, -0.0802,  0.0671, -0.0024, -0.0015,
         0.0244,  0.0873,  0.0664,  0.0672,  0.0617,  0.0427, -0.0055,  0.0781,
         0.0482,  0.0658, -0.0392,  0.0361,  0.0616,  0.0228,  0.0671, -0.0770,
         0.0405,  0.0518, -0.0349, -0.0131, -0.0861,  0.0061, -0.0149,  0.0259,
         0.0623, -0.0175,  0.0797,  0.0209,  0.0487, -0.0097,  0.0317, -0.0649],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0166,  0.0527,  0.0203,  0.0245,  0.0401, -0.0659,  0.0771,  0.0248,
        -0.0822, -0.0879, -0.0409,  0.0819, -0.0497, -0.0091,  0.0074, -0.0633,
        -0.0011,  0.0009,  0.0169,  0.0748, -0.0641,  0.0129, -0.0167,  0.0026,
         0.0311, -0.0291,  0.0282,  0.0480, -0.0802,  0.0671, -0.0024, -0.0015,
         0.0244,  0.0873,  0.0664,  0.0672,  0.0617,  0.0427, -0.0055,  0.0781,
         0.0482,  0.0658, -0.0392,  0.0361,  0.0616,  0.0228,  0.0671, -0.0770,
         0.0405,  0.0518, -0.0349, -0.0131, -0.0861,  0.0061, -0.0149,  0.0259,
         0.0623, -0.0175,  0.0797,  0.0209,  0.0487, -0.0097,  0.0317, -0.0649],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.weight 
 torch.Size([6796, 64]) 
 True 
 tensor([[ 0.0223,  0.0452, -0.0056,  ..., -0.0891,  0.0636, -0.0112],
        [ 0.0162, -0.0929, -0.0960,  ...,  0.0294, -0.0761, -0.0007],
        [ 0.0128,  0.1218, -0.0719,  ..., -0.0960,  0.1161, -0.0191],
        ...,
        [ 0.0989, -0.1012,  0.0258,  ..., -0.1050,  0.0132, -0.0939],
        [-0.0036, -0.0832,  0.0159,  ..., -0.0771, -0.0307, -0.0540],
        [ 0.0853,  0.0239,  0.0652,  ..., -0.0952,  0.0309, -0.1033]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0223,  0.0452, -0.0056,  ..., -0.0891,  0.0636, -0.0112],
        [ 0.0162, -0.0929, -0.0960,  ...,  0.0294, -0.0761, -0.0007],
        [ 0.0128,  0.1218, -0.0719,  ..., -0.0960,  0.1161, -0.0191],
        ...,
        [ 0.0989, -0.1012,  0.0258,  ..., -0.1050,  0.0132, -0.0939],
        [-0.0036, -0.0832,  0.0159,  ..., -0.0771, -0.0307, -0.0540],
        [ 0.0853,  0.0239,  0.0652,  ..., -0.0952,  0.0309, -0.1033]],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.bias 
 torch.Size([6796]) 
 True 
 tensor([ 0.0391,  0.1179,  0.0637,  ..., -0.0831, -0.0473, -0.1209],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0391,  0.1179,  0.0637,  ..., -0.0831, -0.0473, -0.1209],
       device='cuda:0', requires_grad=True)

Passing event 1007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([[0.5174, 0.5331, 0.5233,  ..., 0.4955, 0.4934, 0.4781],
        [0.5174, 0.5332, 0.5234,  ..., 0.4955, 0.4934, 0.4781],
        [0.5174, 0.5332, 0.5234,  ..., 0.4955, 0.4935, 0.4781],
        ...,
        [0.5174, 0.5331, 0.5234,  ..., 0.4955, 0.4934, 0.4781],
        [0.5173, 0.5332, 0.5233,  ..., 0.4955, 0.4935, 0.4781],
        [0.5174, 0.5332, 0.5233,  ..., 0.4955, 0.4934, 0.4780]],
       device='cuda:0', grad_fn=<SigmoidBackward0>) 
result1.shape: torch.Size([20, 6796])

Passing two random events from the network before training 
result1: tensor([[0.5174, 0.5331, 0.5233,  ..., 0.4955, 0.4934, 0.4781],
        [0.5174, 0.5332, 0.5234,  ..., 0.4955, 0.4934, 0.4781],
        [0.5174, 0.5332, 0.5234,  ..., 0.4955, 0.4935, 0.4781],
        ...,
        [0.5174, 0.5331, 0.5234,  ..., 0.4955, 0.4934, 0.4781],
        [0.5173, 0.5332, 0.5233,  ..., 0.4955, 0.4935, 0.4781],
        [0.5174, 0.5332, 0.5233,  ..., 0.4955, 0.4934, 0.4780]],
       device='cuda:0', grad_fn=<SigmoidBackward0>) 
result1.shape: torch.Size([20, 6796]) 
input: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]



load_model False 
TraEvN 10008 
BatchSize 30 
EpochNum 30 
epoch_save 5 
LrVal 0.001 
weight_decay 0.0001 
startmesh 305 
endmesh 306 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[[[-0.2586,  0.2639, -0.0153],
          [ 0.1466,  0.0778,  0.1874],
          [-0.0793, -0.1362,  0.3219]]],


        [[[ 0.2050, -0.2480,  0.2068],
          [-0.1282, -0.2044,  0.0225],
          [-0.0116, -0.2751, -0.1024]]],


        [[[ 0.2511, -0.0404,  0.1980],
          [-0.1036, -0.1660,  0.1129],
          [-0.2099,  0.1855,  0.1810]]],


        ...,


        [[[ 0.0224,  0.2655,  0.2990],
          [-0.0503,  0.3105, -0.0595],
          [-0.1711,  0.2353,  0.1965]]],


        [[[-0.1145, -0.1139,  0.1907],
          [ 0.0068,  0.0658, -0.2396],
          [ 0.0453,  0.1602, -0.1621]]],


        [[[ 0.3286, -0.2346, -0.2846],
          [ 0.2231,  0.1831,  0.2225],
          [-0.0536,  0.2999, -0.3294]]]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-1.0072e-01, -1.2330e-01, -1.8543e-01,  1.5162e-01,  1.7952e-01,
         9.7514e-02,  1.3362e-01,  2.4347e-01, -1.6304e-01,  2.7875e-01,
        -2.1062e-01,  1.0663e-01,  2.6008e-01,  2.8895e-01, -2.6001e-01,
         6.3688e-02,  3.2055e-01,  1.8542e-02,  3.0892e-01,  2.3155e-01,
         2.7490e-01,  2.6960e-02,  2.0775e-01, -1.8433e-02, -1.7149e-01,
        -1.7891e-01, -4.2429e-02,  2.1738e-01, -3.5873e-02, -1.6028e-01,
         1.8644e-01,  3.1286e-01,  3.2360e-01, -1.9406e-01, -1.4213e-01,
         5.2512e-02, -1.3847e-01, -9.6022e-02,  1.3852e-01,  3.2750e-01,
         3.1933e-02, -1.1443e-01, -1.1037e-01,  8.3504e-02, -2.1762e-02,
        -1.0821e-01, -1.7336e-02,  2.6392e-01, -2.5098e-01,  1.2898e-01,
        -2.0365e-01,  1.1284e-01, -2.6975e-01, -1.4642e-01,  2.1137e-01,
         5.8294e-02,  2.9173e-01, -7.0527e-02, -2.0686e-01, -2.0137e-01,
        -2.3247e-03,  2.9087e-01, -2.7385e-01, -4.4709e-02, -1.8308e-01,
         3.0543e-01,  2.4275e-01,  3.3128e-01, -2.1604e-01, -1.7946e-01,
         6.1431e-02, -2.2204e-01,  2.8639e-02,  1.1782e-01,  1.4948e-01,
         5.4693e-02,  1.7969e-01,  2.3822e-01,  4.7989e-02,  2.0004e-02,
         2.5483e-01,  8.1116e-02,  1.0721e-02,  1.3309e-01, -6.7397e-02,
        -5.7005e-02,  1.5521e-01,  2.3283e-01,  3.2800e-01,  1.8311e-01,
         1.2351e-01, -2.6619e-01, -2.2297e-01,  4.0439e-03,  1.2702e-01,
         6.5556e-03, -1.3423e-01, -2.3743e-01,  1.3355e-01, -1.3442e-01,
        -8.1462e-02, -3.2754e-01, -1.4128e-01, -1.0481e-02,  1.1005e-02,
         2.6636e-01, -7.2370e-02, -1.4360e-01, -1.9892e-01,  7.6945e-02,
         1.0432e-01,  1.0895e-01,  1.3472e-01, -1.1277e-02, -1.0623e-01,
        -1.5389e-01,  1.2700e-01,  2.6492e-01, -1.8559e-01,  1.0157e-04,
         2.1164e-02, -3.2036e-01,  4.1777e-02,  1.4211e-01,  3.1146e-01,
         3.2284e-01, -3.1149e-01, -5.7627e-02,  2.1831e-01, -3.1216e-01,
        -7.5852e-02,  2.2810e-01,  1.8809e-01, -1.6077e-01,  1.5204e-01,
         2.6719e-01,  3.8770e-02,  2.6966e-01,  1.9062e-01,  5.2768e-02,
         1.3101e-01,  1.5730e-01,  1.8243e-01,  6.8140e-02, -2.4176e-01,
        -2.2278e-01, -2.3250e-01,  1.2296e-01,  3.3363e-02,  8.2122e-02,
        -1.3725e-01,  5.9911e-02,  3.0906e-01, -1.5701e-01, -2.0045e-01,
         2.8734e-01, -1.6960e-01, -9.3580e-02,  1.0647e-01, -3.1541e-01,
         3.3134e-01,  2.5227e-01,  1.8179e-01,  2.0259e-01, -1.3024e-01,
        -1.0273e-01,  3.9943e-02,  2.2974e-01, -2.9765e-02, -1.9286e-01,
        -2.3275e-01, -3.1373e-01, -2.8610e-01,  4.5636e-03, -2.4453e-01,
         2.5503e-01, -2.6201e-01,  1.4037e-01,  3.8652e-02,  3.1319e-01,
         6.5033e-02, -2.5656e-01,  3.1993e-01,  1.4240e-01,  1.6374e-01,
        -2.9859e-01, -5.4849e-02,  2.8966e-01, -3.1064e-01,  2.0778e-01,
        -3.2738e-01, -1.4191e-01,  1.5007e-01,  2.3764e-01,  1.8170e-02,
         3.0685e-01, -9.4692e-02, -1.5503e-01, -8.0529e-02, -1.3341e-01,
         2.1711e-01,  3.1632e-01,  2.8523e-01,  6.3775e-02, -9.7027e-02,
        -2.8778e-01,  9.9837e-02,  2.7223e-01, -2.7598e-01,  2.5152e-01,
        -3.1882e-01, -1.3276e-01, -5.7808e-02, -1.1263e-01,  3.2516e-01,
        -3.3296e-02,  1.8809e-02, -1.1005e-01,  2.0238e-01,  3.6404e-02,
         1.6869e-01,  2.5311e-01,  1.3103e-01,  1.6350e-01,  9.3397e-03,
        -7.8096e-02, -1.9874e-01,  1.2280e-01,  1.6449e-01, -1.4966e-01,
        -1.3796e-01,  1.6483e-01,  2.9937e-01, -1.9524e-01, -1.1995e-01,
         3.0635e-01, -4.0236e-02, -8.9903e-02,  2.7805e-01,  2.7858e-01,
        -3.6876e-02,  1.6492e-01, -1.4350e-01,  1.8033e-01, -2.0045e-01,
         1.3237e-01, -2.9994e-01,  3.1309e-01, -8.9560e-02, -1.9110e-01,
         2.1134e-01,  2.9823e-01, -1.0001e-03,  2.0235e-01, -2.3473e-02,
         7.0600e-02], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[ 1.5445e-02, -1.7903e-02,  1.8921e-02],
          [ 1.6715e-02, -6.2103e-03,  8.1837e-04],
          [-6.6046e-03,  5.3464e-03, -1.5529e-03]],

         [[ 7.9335e-03,  3.8254e-03,  5.3032e-04],
          [-1.6773e-02, -1.4175e-02, -4.9108e-03],
          [-4.7168e-03, -1.7634e-02, -1.3445e-02]],

         [[-2.4001e-03, -6.4006e-03,  7.3615e-03],
          [ 1.3001e-02,  1.4804e-02,  1.4938e-02],
          [ 8.9934e-03, -1.2597e-02, -7.3571e-03]],

         ...,

         [[ 7.1625e-06, -1.1957e-02, -1.7016e-02],
          [-1.1733e-03,  2.3551e-03,  7.6314e-03],
          [ 3.6911e-03, -1.6979e-02, -1.8280e-02]],

         [[-1.5430e-02, -1.1578e-02, -4.0747e-03],
          [ 2.9956e-03, -2.0633e-02,  5.0344e-03],
          [-1.5825e-02, -1.2372e-03, -1.1575e-02]],

         [[-3.1859e-03,  9.6562e-03,  9.0405e-03],
          [ 1.0813e-02, -5.0778e-03, -1.8803e-03],
          [-1.3148e-02,  1.9169e-02, -2.4435e-03]]],


        [[[-4.0447e-03,  1.1883e-02, -1.8719e-02],
          [ 1.9659e-02,  7.8186e-03, -8.3865e-03],
          [-2.8851e-03,  9.6102e-03,  3.3427e-03]],

         [[-4.2264e-03, -3.0580e-04,  9.8899e-03],
          [-5.0428e-03,  8.0192e-03, -9.5048e-03],
          [-1.4201e-03, -1.9847e-02, -6.3401e-03]],

         [[-2.0573e-03,  2.2969e-03, -1.2725e-02],
          [ 2.0334e-02,  1.7271e-02, -1.4705e-02],
          [ 1.4920e-02,  1.3112e-02, -7.8053e-03]],

         ...,

         [[ 1.1995e-02,  9.1585e-03,  9.3364e-03],
          [-1.0934e-02,  3.9056e-03,  1.8250e-02],
          [-1.5447e-02, -3.9100e-03, -4.9111e-03]],

         [[ 1.9959e-02, -6.6604e-03,  5.9019e-03],
          [ 1.8599e-02,  1.8184e-02, -1.4190e-02],
          [ 7.5382e-03,  3.0942e-03, -1.2813e-02]],

         [[-1.4827e-02, -1.4501e-02,  2.2277e-03],
          [-1.9060e-02,  1.4160e-02,  2.0589e-02],
          [-1.3451e-03,  3.8805e-03, -6.6114e-03]]],


        [[[ 3.1463e-03, -3.4795e-03,  1.0187e-02],
          [-1.5828e-02,  1.9539e-02,  2.4870e-03],
          [ 1.0880e-02,  8.4349e-03, -1.3744e-02]],

         [[-3.5431e-03,  1.9344e-03, -5.4733e-03],
          [ 3.1759e-03, -1.5948e-02, -4.1600e-03],
          [ 3.9260e-03,  1.7939e-02,  1.0473e-02]],

         [[-1.6821e-02, -1.9563e-02,  7.5064e-03],
          [ 4.6424e-03, -1.1306e-02, -1.1485e-02],
          [-1.8123e-02, -1.6292e-02,  1.2474e-02]],

         ...,

         [[ 1.2197e-02,  1.8227e-02,  2.3063e-03],
          [-1.5043e-02,  1.4120e-02,  1.7517e-02],
          [ 4.5164e-03,  1.4148e-02, -9.5078e-03]],

         [[-6.0082e-03,  1.6326e-02, -5.7492e-03],
          [ 7.8608e-03,  1.9027e-02, -1.4712e-02],
          [ 1.2307e-03, -1.9821e-02, -2.0402e-02]],

         [[-1.4277e-02, -2.8396e-03,  3.3077e-03],
          [-1.6285e-03,  5.6107e-03,  3.1740e-03],
          [-2.0762e-02,  1.1241e-03,  6.6935e-03]]],


        ...,


        [[[-1.6161e-02,  7.9056e-03,  1.2176e-02],
          [-2.4288e-03, -6.9450e-03,  4.2533e-04],
          [ 1.0815e-02,  9.4612e-04,  1.9393e-03]],

         [[-2.0342e-02, -1.5701e-02, -5.0219e-03],
          [-7.3469e-04, -5.3496e-03,  9.9101e-03],
          [ 2.6805e-03,  1.1853e-02,  6.6007e-03]],

         [[-5.9367e-04,  6.2941e-03, -7.9180e-04],
          [ 3.7642e-03, -1.0530e-02, -1.6002e-02],
          [-4.5983e-03,  1.4651e-02, -1.7078e-02]],

         ...,

         [[ 1.1678e-02,  2.3147e-03, -1.6725e-02],
          [-1.9970e-02, -6.7362e-03, -5.3966e-03],
          [-1.5828e-02,  1.4247e-02, -1.7210e-02]],

         [[-1.4827e-03, -1.0055e-02, -1.6338e-02],
          [-1.3470e-02,  1.9493e-02,  8.6576e-03],
          [ 1.6726e-02, -9.6819e-03,  1.7314e-02]],

         [[ 4.2082e-03, -1.2702e-02, -3.3091e-03],
          [-2.9900e-04,  1.5016e-02,  1.0178e-02],
          [-1.0622e-02,  1.7115e-02, -2.3187e-03]]],


        [[[ 1.2072e-02,  1.1477e-02, -1.1922e-02],
          [-1.2947e-02,  2.0543e-02,  2.3283e-03],
          [ 3.8216e-03,  1.5515e-02,  5.2753e-04]],

         [[-3.0695e-03,  7.6745e-03, -1.6388e-02],
          [-1.5760e-02,  2.0610e-02, -6.5394e-03],
          [-1.9774e-03, -1.9289e-02, -4.9571e-03]],

         [[-1.5611e-02,  1.3101e-02,  5.6202e-03],
          [-4.9665e-03,  1.4833e-02,  7.8729e-03],
          [-1.0634e-02, -2.5156e-03, -1.5306e-03]],

         ...,

         [[-2.0396e-02,  2.7559e-03,  1.2830e-02],
          [ 6.3746e-03, -4.0164e-03, -3.2573e-03],
          [-1.6879e-03,  1.1471e-02,  1.8568e-02]],

         [[ 5.0048e-03,  4.6718e-03, -2.7646e-03],
          [ 2.0055e-03, -1.3873e-02, -6.9707e-03],
          [ 1.4210e-02,  1.5233e-02, -1.1348e-02]],

         [[ 6.6331e-03,  1.2567e-02, -1.8264e-02],
          [ 1.4762e-02, -4.1131e-03, -1.6368e-02],
          [ 2.0653e-02,  9.4906e-03,  5.9142e-03]]],


        [[[ 8.5196e-03, -1.3971e-02,  4.9387e-03],
          [-7.2033e-03, -1.9523e-02,  6.3919e-03],
          [ 1.2956e-02,  1.6804e-02,  1.9703e-02]],

         [[-2.0119e-02,  2.1726e-03,  1.0893e-02],
          [-5.4343e-03,  1.9906e-02, -2.0601e-02],
          [ 2.0010e-02, -1.0303e-02, -1.2443e-02]],

         [[-3.2107e-03,  1.8303e-02,  2.8200e-03],
          [ 6.2488e-03,  6.9219e-03, -1.6277e-02],
          [ 1.7872e-02,  1.4388e-02, -5.8889e-03]],

         ...,

         [[ 1.7078e-02, -1.8066e-02,  6.1957e-03],
          [-6.3204e-04, -1.8605e-02,  1.4070e-02],
          [-5.3691e-03, -1.3176e-02,  5.8334e-03]],

         [[-1.3425e-02,  1.2359e-02, -5.7116e-03],
          [ 1.2732e-02, -8.7562e-03,  1.7261e-02],
          [-2.3210e-03, -2.1559e-03, -8.1794e-03]],

         [[ 1.1571e-02,  5.8680e-03, -1.8575e-02],
          [ 9.6887e-03,  4.2691e-03, -1.4013e-02],
          [-7.5617e-03,  1.1788e-02, -1.0568e-02]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([-0.0093,  0.0137,  0.0100, -0.0053,  0.0065, -0.0106,  0.0066, -0.0083,
         0.0149, -0.0106,  0.0198, -0.0082, -0.0097,  0.0089, -0.0155,  0.0067,
        -0.0076, -0.0028,  0.0123,  0.0067,  0.0082, -0.0090, -0.0182,  0.0067,
        -0.0093,  0.0062,  0.0198, -0.0098, -0.0117,  0.0194, -0.0039, -0.0130,
        -0.0076, -0.0078, -0.0137,  0.0110, -0.0029,  0.0148, -0.0138, -0.0104,
        -0.0178,  0.0137,  0.0174, -0.0098,  0.0140,  0.0180, -0.0132, -0.0168,
        -0.0078, -0.0205, -0.0208,  0.0062, -0.0070, -0.0114, -0.0032, -0.0113,
        -0.0073,  0.0157,  0.0165, -0.0198,  0.0093, -0.0203, -0.0184, -0.0077,
         0.0034,  0.0175, -0.0120,  0.0047,  0.0166, -0.0100, -0.0065,  0.0123,
        -0.0200, -0.0044,  0.0145, -0.0181, -0.0129, -0.0019,  0.0021,  0.0053,
        -0.0079, -0.0114,  0.0104, -0.0099,  0.0068,  0.0200, -0.0061, -0.0054,
        -0.0029, -0.0050,  0.0191, -0.0068,  0.0097, -0.0079,  0.0118,  0.0126,
         0.0173,  0.0173, -0.0025,  0.0108,  0.0110,  0.0152,  0.0192, -0.0110,
         0.0070,  0.0095, -0.0152, -0.0069,  0.0103,  0.0078, -0.0086, -0.0169,
        -0.0141, -0.0082,  0.0053, -0.0003, -0.0200, -0.0029, -0.0193,  0.0100,
         0.0022, -0.0102, -0.0006,  0.0097,  0.0134, -0.0181, -0.0029,  0.0147],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[-2.0335e-02, -1.8943e-02,  2.1011e-02],
          [-2.2873e-02, -9.0510e-03, -2.4277e-02],
          [-3.4195e-03, -8.0344e-03, -2.7159e-02]],

         [[-1.7551e-02, -8.0073e-03, -1.4421e-02],
          [ 2.4762e-02, -2.4696e-02, -2.6845e-03],
          [-2.6929e-02, -3.7466e-03, -2.2167e-03]],

         [[-1.9199e-03, -9.6445e-03, -2.5717e-02],
          [-1.4062e-02, -2.5752e-02,  2.4338e-02],
          [-6.8256e-03,  8.0763e-03,  7.3252e-04]],

         ...,

         [[ 2.5716e-02, -1.0669e-02, -2.0908e-02],
          [-5.4414e-03, -2.2681e-02,  5.2255e-03],
          [ 5.1113e-03, -7.8609e-03, -1.5348e-02]],

         [[ 1.0849e-05, -8.7281e-03,  2.7065e-02],
          [-1.0108e-02,  1.8366e-02, -5.1743e-03],
          [ 3.9547e-03, -5.0138e-03,  2.5776e-02]],

         [[ 2.3248e-02,  2.2485e-02,  2.5785e-02],
          [-2.7805e-02, -1.0161e-02, -3.4728e-03],
          [-1.1635e-02, -2.3267e-02,  2.7119e-02]]],


        [[[ 1.7848e-02,  1.5548e-02, -2.8341e-02],
          [-6.0325e-03,  1.2495e-02, -1.5942e-02],
          [-2.3692e-02,  2.3896e-02,  8.5740e-03]],

         [[ 1.2956e-02, -3.4382e-03, -1.6432e-02],
          [-1.6230e-02, -8.0828e-03, -5.1968e-03],
          [ 5.8603e-03,  7.5265e-03,  9.1958e-03]],

         [[-2.0939e-02,  1.0144e-02,  3.7442e-03],
          [-1.3243e-02, -1.9658e-02, -1.8213e-02],
          [ 9.9382e-04, -1.6813e-02,  2.3445e-02]],

         ...,

         [[ 2.3196e-02, -2.2760e-02, -2.8729e-02],
          [ 7.1154e-05,  1.9915e-02, -1.2242e-02],
          [-1.8725e-02, -1.7378e-02, -2.5560e-03]],

         [[-2.1519e-02,  9.3848e-03,  7.5920e-03],
          [ 1.5542e-02,  9.8714e-03, -2.6344e-02],
          [-1.2815e-02, -2.6897e-02,  2.2194e-02]],

         [[-2.7964e-02, -1.0927e-02,  3.9061e-03],
          [ 2.0608e-02, -4.0801e-03,  2.1212e-03],
          [ 2.6825e-02,  1.8741e-02,  1.5209e-02]]],


        [[[-1.8333e-02, -2.9352e-02,  3.5624e-04],
          [-2.5552e-02, -1.4886e-02,  2.5060e-02],
          [ 1.5511e-02, -4.8805e-03,  2.0659e-02]],

         [[ 1.3767e-02,  1.0974e-02,  8.9105e-03],
          [ 1.0172e-02,  2.2078e-02,  6.3937e-05],
          [-1.3278e-02,  2.5285e-02, -2.1683e-02]],

         [[ 2.4015e-02, -2.7641e-02, -6.6731e-03],
          [ 4.5039e-03, -3.0000e-03, -1.3170e-02],
          [ 2.1252e-02, -2.2653e-02,  1.9064e-02]],

         ...,

         [[-1.4650e-02, -2.5613e-02,  1.4729e-02],
          [-1.9835e-02,  7.3682e-03, -1.8603e-02],
          [-4.6210e-04,  6.6620e-03, -4.9051e-03]],

         [[-1.5800e-02,  2.2821e-02,  2.6501e-02],
          [-2.8521e-02, -1.3115e-02, -2.9267e-03],
          [-1.8790e-02, -2.7739e-02, -1.2483e-02]],

         [[-4.5232e-03, -2.6759e-02,  5.6360e-03],
          [-9.6953e-03,  2.3656e-02,  2.6382e-02],
          [ 2.7870e-02,  1.5524e-02,  3.3803e-03]]],


        ...,


        [[[-1.6195e-02, -2.1035e-02, -2.6565e-02],
          [ 1.3553e-02,  2.8103e-02, -1.1809e-02],
          [ 7.5550e-03,  1.4269e-02, -7.9131e-03]],

         [[-4.7483e-03, -1.6068e-02, -1.2639e-02],
          [ 1.8004e-02,  1.2303e-02,  4.5639e-03],
          [-1.4555e-02,  5.1794e-04,  2.3258e-02]],

         [[ 2.0188e-02, -1.4935e-02,  2.4840e-02],
          [ 1.9424e-02, -3.8606e-03,  2.2102e-02],
          [ 2.6200e-02,  7.8266e-04, -2.3255e-02]],

         ...,

         [[ 1.5019e-02, -2.0241e-02, -4.0621e-03],
          [ 2.7144e-03, -2.3631e-02, -2.8802e-02],
          [-2.9034e-02, -4.7502e-03,  9.4916e-03]],

         [[ 1.7387e-02, -2.5486e-02,  4.7134e-03],
          [-1.0771e-02, -2.5125e-02, -8.4303e-03],
          [-2.9135e-02,  4.6798e-03,  4.1619e-03]],

         [[ 1.3178e-03,  2.3175e-02, -3.5300e-03],
          [-2.1235e-02, -1.8283e-02,  2.1580e-04],
          [-2.5925e-02, -1.5273e-02, -1.4133e-03]]],


        [[[-2.9356e-02, -8.3430e-03,  2.4133e-02],
          [-4.6387e-03, -1.8957e-02, -1.9017e-02],
          [ 3.5142e-03, -1.6038e-02, -1.4890e-02]],

         [[-2.0234e-02,  2.7801e-03, -2.2216e-02],
          [-2.4534e-02,  2.4746e-02, -2.3472e-02],
          [ 1.7840e-02, -1.3882e-02,  8.3177e-03]],

         [[ 1.5112e-02,  7.5562e-03, -2.2383e-02],
          [-2.3059e-02,  2.2455e-02,  2.6443e-02],
          [-1.5038e-02, -1.2160e-02,  1.8045e-02]],

         ...,

         [[-2.7532e-02, -7.6671e-03,  2.6559e-02],
          [-3.1313e-03, -1.4311e-03,  1.0062e-03],
          [-1.3215e-02,  1.9192e-02, -6.3700e-03]],

         [[ 1.0674e-02, -3.0589e-03, -2.0634e-02],
          [ 3.2104e-03,  1.5971e-02, -1.2452e-02],
          [ 1.2818e-03,  1.2660e-02,  2.3122e-03]],

         [[-2.8026e-02,  1.2588e-02, -2.2838e-02],
          [ 8.5991e-03, -2.6353e-02,  2.4774e-02],
          [ 4.4725e-03, -1.2552e-03,  1.0269e-02]]],


        [[[-5.7834e-03, -1.9176e-02,  2.0514e-03],
          [-2.3998e-02,  7.0045e-03, -2.6018e-02],
          [-9.6204e-03, -1.1461e-02, -1.7048e-02]],

         [[-1.0821e-02, -5.0918e-03,  1.5675e-02],
          [-1.4630e-02, -2.8601e-02, -2.4827e-02],
          [ 2.8015e-03, -1.5332e-02, -3.3365e-03]],

         [[-2.1853e-02,  1.4388e-02,  1.6432e-02],
          [-1.8886e-02,  1.7360e-02, -1.8098e-02],
          [ 4.2964e-03,  2.4317e-02, -6.3177e-03]],

         ...,

         [[ 1.1949e-02, -4.6347e-03,  2.0769e-02],
          [ 9.6376e-03, -2.7286e-03, -1.3367e-02],
          [ 2.2196e-02,  2.2651e-02,  1.4820e-02]],

         [[ 2.8649e-02,  4.2766e-03,  8.5383e-03],
          [-2.4199e-02,  8.0588e-03, -1.9844e-02],
          [-1.2827e-02, -2.0321e-02,  5.0322e-03]],

         [[-5.4889e-04, -1.6957e-02, -2.8121e-02],
          [-2.0848e-02, -1.3953e-02,  5.1721e-03],
          [ 1.3229e-03,  2.0599e-02,  5.5775e-03]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([ 0.0167,  0.0220, -0.0237, -0.0266,  0.0269,  0.0150, -0.0040, -0.0084,
         0.0089,  0.0101, -0.0256,  0.0104,  0.0066,  0.0009, -0.0245, -0.0031,
        -0.0122, -0.0176,  0.0027,  0.0024, -0.0115,  0.0003,  0.0108, -0.0141,
         0.0114, -0.0078,  0.0183, -0.0189,  0.0270,  0.0095, -0.0256, -0.0246,
        -0.0131,  0.0063, -0.0283,  0.0182,  0.0028,  0.0151,  0.0226,  0.0265,
        -0.0021, -0.0127, -0.0007,  0.0030, -0.0182, -0.0060, -0.0227,  0.0200,
        -0.0156, -0.0040,  0.0035,  0.0214, -0.0054, -0.0106,  0.0121, -0.0252,
        -0.0055, -0.0293,  0.0273,  0.0247,  0.0159, -0.0128,  0.0180,  0.0027],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 6.2282e-04, -5.0090e-04,  6.6373e-04,  ..., -9.0731e-04,
         -5.5089e-04,  1.0239e-03],
        [ 5.3551e-04,  5.5976e-04, -1.1056e-03,  ..., -7.8204e-04,
          9.2912e-04,  2.1596e-04],
        [-3.8077e-04, -4.4687e-04, -8.6772e-04,  ...,  1.2236e-04,
         -3.6149e-05, -3.8897e-04],
        ...,
        [-2.3334e-05, -4.5233e-04,  7.5829e-04,  ...,  5.0151e-04,
          1.0846e-04,  4.2161e-04],
        [ 1.8659e-04, -3.2477e-05, -8.2097e-04,  ...,  1.0053e-03,
         -4.4850e-04, -1.1421e-03],
        [-5.4720e-04, -6.3873e-04, -7.7911e-04,  ...,  9.9264e-04,
          3.7861e-04, -1.2443e-04]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-5.0058e-04,  2.2815e-04, -7.1759e-04, -9.0166e-04, -6.9986e-05,
         1.2197e-03, -7.2577e-05,  4.9621e-04,  1.8225e-05,  5.0314e-04,
        -7.2428e-04,  5.7537e-04, -1.0790e-03, -9.0571e-04,  1.1804e-03,
        -2.2972e-04,  1.2359e-04,  4.2579e-04,  7.3164e-04, -6.3905e-04,
         9.8177e-04,  9.8139e-04, -4.5638e-05, -1.2162e-03, -8.7752e-04,
        -1.1298e-03,  8.6273e-04, -2.1386e-06, -7.8988e-04, -2.6887e-04,
        -9.2199e-04, -3.4418e-04, -9.6786e-04, -9.3439e-04, -4.8407e-04,
         4.1811e-04,  4.5966e-04,  2.8910e-04,  6.7775e-04, -3.6409e-04,
        -2.4307e-04, -8.0188e-04, -3.1580e-04, -1.2041e-03, -6.9825e-04,
        -7.3349e-04,  2.8624e-04,  7.6164e-04, -1.0239e-03, -1.7830e-04,
         5.8736e-04,  7.7270e-04,  9.1728e-04, -6.7835e-04,  1.2710e-04,
        -9.1624e-04, -6.5619e-04, -8.8498e-04, -2.4305e-05,  5.1002e-04,
        -2.8746e-04, -8.9988e-04,  2.5546e-04,  7.2862e-04,  3.2014e-04,
         1.5088e-04, -4.3095e-04,  1.0792e-03, -8.3264e-04, -9.9834e-04,
        -9.7590e-05,  8.5525e-04, -5.4824e-04, -9.7399e-04, -6.0961e-04,
        -1.1811e-03, -1.0752e-04,  2.6755e-05, -3.3792e-04, -7.7765e-04,
        -5.4652e-04,  6.2511e-04, -9.7892e-04, -1.6077e-04,  1.1266e-03,
        -7.3074e-04, -3.0066e-04, -2.6070e-04, -5.8102e-04,  6.0571e-04,
        -4.0517e-04, -3.9980e-04,  3.3540e-04,  9.5199e-05,  1.1888e-03,
        -1.1249e-03,  4.0309e-04, -1.0368e-03, -1.0784e-05,  3.0834e-05,
        -8.7691e-04, -1.1756e-03,  7.6466e-05, -2.0934e-04,  1.0731e-03,
         7.9185e-05, -4.4561e-04, -2.3458e-04,  1.0416e-03, -7.3676e-04,
         7.1230e-04,  9.6861e-04, -1.0629e-03,  9.1573e-04,  1.2140e-03,
         3.4684e-04, -7.0770e-04,  1.2224e-03, -1.1059e-03, -1.0400e-03,
        -1.0229e-03,  1.9610e-04, -2.8370e-04, -5.9341e-04,  1.2188e-03,
         2.9048e-04,  1.1757e-04, -1.0357e-03,  9.3108e-04,  9.2069e-04,
        -4.4986e-04, -1.2142e-03, -6.8709e-04, -3.2916e-04, -5.6310e-04,
        -1.0079e-03,  5.9032e-04, -6.5989e-04, -8.8059e-04,  2.0447e-04,
         8.6956e-04,  3.6609e-04, -1.1386e-03,  3.5795e-04,  3.2808e-04,
         2.8007e-04,  1.1002e-03,  9.3386e-04, -9.7015e-04, -3.7416e-04,
         1.0441e-03, -1.4455e-04,  3.4203e-05,  7.2925e-04,  8.9186e-04,
        -8.9831e-04,  3.5553e-04,  5.0719e-04, -7.5471e-04, -2.9982e-04,
        -6.8178e-06,  2.6251e-04,  6.7721e-04, -1.1250e-03, -6.3602e-04,
        -5.4743e-04, -1.9007e-04,  9.3223e-04,  3.8246e-04, -7.9769e-04,
        -9.0668e-04,  9.5952e-04, -1.1641e-03, -7.8773e-04,  1.2084e-03,
         1.2140e-03,  1.2126e-04, -6.4032e-04,  9.9833e-04, -4.0368e-04,
         1.6864e-04,  4.5233e-04,  7.4175e-04, -3.8514e-04,  9.1548e-04,
         4.4427e-04, -3.5758e-04, -4.7528e-04, -7.4248e-04,  7.6679e-04,
        -6.7623e-05, -7.6316e-04, -3.7683e-04,  1.0737e-03, -5.9109e-04,
        -3.2262e-04, -1.0000e-03,  1.0680e-03,  9.1240e-04,  4.2731e-04,
        -6.7015e-04,  3.6247e-04,  5.6764e-04, -1.2882e-04,  7.1686e-04,
        -5.1483e-04,  9.7416e-04,  5.1105e-04,  1.5968e-04,  6.8513e-04,
        -1.8677e-04,  8.7793e-04, -6.5652e-04, -5.5636e-04, -5.3906e-04,
        -1.0760e-03, -4.1568e-04,  9.2203e-04, -1.1259e-03,  6.4595e-04,
         8.4634e-05, -4.7725e-04,  4.3191e-04, -8.6348e-04,  2.3037e-04,
         6.3295e-04,  8.9398e-04,  4.1429e-04,  6.9058e-04,  9.1245e-04,
        -4.8956e-04, -8.0958e-04,  6.6491e-04, -1.2700e-04,  2.3500e-04,
        -1.2042e-03, -4.1909e-04, -1.0299e-03, -5.5377e-05, -2.2813e-04,
         3.8686e-04,  4.8748e-04,  1.4513e-04,  1.1859e-03, -9.1014e-04,
         2.9739e-04, -2.2697e-04, -6.7460e-04,  2.7152e-04,  6.8711e-04,
        -4.8647e-04,  1.3258e-04, -1.0974e-03, -1.0799e-03, -6.1527e-04,
         1.8482e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0387,  0.0260,  0.0234,  ...,  0.0174, -0.0568, -0.0127],
        [ 0.0619,  0.0077, -0.0090,  ..., -0.0188,  0.0336,  0.0104],
        [ 0.0560, -0.0175,  0.0336,  ...,  0.0369,  0.0015,  0.0615],
        ...,
        [-0.0127,  0.0548,  0.0531,  ..., -0.0478,  0.0037, -0.0126],
        [ 0.0481, -0.0013, -0.0190,  ..., -0.0444,  0.0572, -0.0546],
        [-0.0296,  0.0435,  0.0388,  ...,  0.0427,  0.0033, -0.0286]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0071, -0.0321,  0.0106, -0.0622,  0.0399, -0.0201, -0.0217,  0.0355,
        -0.0036, -0.0094, -0.0540, -0.0463, -0.0436,  0.0218,  0.0553,  0.0029,
         0.0399, -0.0301,  0.0174, -0.0210,  0.0161, -0.0340, -0.0401,  0.0528,
         0.0437,  0.0534,  0.0206, -0.0394,  0.0270, -0.0233,  0.0595, -0.0419,
        -0.0528,  0.0567, -0.0052, -0.0447, -0.0194, -0.0502,  0.0381, -0.0503,
        -0.0504, -0.0165, -0.0375, -0.0139, -0.0585, -0.0395,  0.0399,  0.0551,
        -0.0511,  0.0186,  0.0505,  0.0473,  0.0460, -0.0346, -0.0278,  0.0278,
        -0.0588,  0.0513, -0.0130, -0.0369,  0.0111, -0.0250, -0.0348, -0.0453,
         0.0051,  0.0377, -0.0053, -0.0574,  0.0502,  0.0385,  0.0606, -0.0538,
        -0.0133, -0.0214, -0.0255, -0.0146, -0.0087,  0.0519, -0.0150, -0.0515,
         0.0534,  0.0362,  0.0601, -0.0241, -0.0493, -0.0589, -0.0510, -0.0496,
        -0.0007, -0.0351, -0.0233, -0.0134, -0.0270, -0.0024,  0.0400, -0.0202,
        -0.0037,  0.0290, -0.0492,  0.0599, -0.0190,  0.0040, -0.0505,  0.0020,
         0.0205,  0.0305,  0.0169,  0.0556,  0.0447, -0.0608,  0.0498, -0.0018,
        -0.0588,  0.0397, -0.0368, -0.0193, -0.0152,  0.0126,  0.0612, -0.0128,
        -0.0129, -0.0407, -0.0541, -0.0182, -0.0390,  0.0333, -0.0288, -0.0329],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0772,  0.0782, -0.0436,  ...,  0.0755, -0.0143, -0.0537],
        [-0.0101,  0.0123,  0.0035,  ...,  0.0847, -0.0211, -0.0484],
        [-0.0353,  0.0079, -0.0283,  ..., -0.0277,  0.0753, -0.0321],
        ...,
        [-0.0575, -0.0508,  0.0630,  ..., -0.0412,  0.0171, -0.0857],
        [-0.0368, -0.0668,  0.0076,  ..., -0.0425, -0.0220, -0.0856],
        [ 0.0397, -0.0048, -0.0070,  ..., -0.0692, -0.0359,  0.0093]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0166,  0.0527,  0.0203,  0.0245,  0.0401, -0.0659,  0.0771,  0.0248,
        -0.0822, -0.0879, -0.0409,  0.0819, -0.0497, -0.0091,  0.0074, -0.0633,
        -0.0011,  0.0009,  0.0169,  0.0748, -0.0641,  0.0129, -0.0167,  0.0026,
         0.0311, -0.0291,  0.0282,  0.0480, -0.0802,  0.0671, -0.0024, -0.0015,
         0.0244,  0.0873,  0.0664,  0.0672,  0.0617,  0.0427, -0.0055,  0.0781,
         0.0482,  0.0658, -0.0392,  0.0361,  0.0616,  0.0228,  0.0671, -0.0770,
         0.0405,  0.0518, -0.0349, -0.0131, -0.0861,  0.0061, -0.0149,  0.0259,
         0.0623, -0.0175,  0.0797,  0.0209,  0.0487, -0.0097,  0.0317, -0.0649],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0223,  0.0452, -0.0056,  ..., -0.0891,  0.0636, -0.0112],
        [ 0.0162, -0.0929, -0.0960,  ...,  0.0294, -0.0761, -0.0007],
        [ 0.0128,  0.1218, -0.0719,  ..., -0.0960,  0.1161, -0.0191],
        ...,
        [ 0.0989, -0.1012,  0.0258,  ..., -0.1050,  0.0132, -0.0939],
        [-0.0036, -0.0832,  0.0159,  ..., -0.0771, -0.0307, -0.0540],
        [ 0.0853,  0.0239,  0.0652,  ..., -0.0952,  0.0309, -0.1033]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0391,  0.1179,  0.0637,  ..., -0.0831, -0.0473, -0.1209],
       device='cuda:0', requires_grad=True)], 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}]
epoch: 0 batch 0.0 event: 0 loss: tensor(184.3639, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 10.0 event: 300 loss: tensor(1804.5784, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 20.0 event: 600 loss: tensor(1803.0389, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 30.0 event: 900 loss: tensor(1885.3759, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 40.0 event: 1200 loss: tensor(1811.2850, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 50.0 event: 1500 loss: tensor(1837.5145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 60.0 event: 1800 loss: tensor(1989.6907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 70.0 event: 2100 loss: tensor(1828.9202, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 80.0 event: 2400 loss: tensor(1945.8597, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 90.0 event: 2700 loss: tensor(1825.3473, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 100.0 event: 3000 loss: tensor(1758.8411, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 110.0 event: 3300 loss: tensor(2051.4265, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 120.0 event: 3600 loss: tensor(1706.8427, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 130.0 event: 3900 loss: tensor(1985.5533, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 140.0 event: 4200 loss: tensor(1799.5033, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 150.0 event: 4500 loss: tensor(2012.0367, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 160.0 event: 4800 loss: tensor(1750.5811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 170.0 event: 5100 loss: tensor(1997.6227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 180.0 event: 5400 loss: tensor(1852.5029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 190.0 event: 5700 loss: tensor(1806.7816, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 200.0 event: 6000 loss: tensor(2137.0989, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 210.0 event: 6300 loss: tensor(1777.3287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 220.0 event: 6600 loss: tensor(2067.2263, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 230.0 event: 6900 loss: tensor(2036.7445, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 240.0 event: 7200 loss: tensor(2094.2559, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 250.0 event: 7500 loss: tensor(2072.7332, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 260.0 event: 7800 loss: tensor(1785.9801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 270.0 event: 8100 loss: tensor(1982.4999, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 280.0 event: 8400 loss: tensor(2012.8563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 290.0 event: 8700 loss: tensor(1933.0385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 300.0 event: 9000 loss: tensor(1410.5126, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 310.0 event: 9300 loss: tensor(1768.1854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 320.0 event: 9600 loss: tensor(1915.6432, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 330.0 event: 9900 loss: tensor(2018.0292, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:00:22.299587
evaluation loss: 1939.0526123046875
epoch: 0 mean loss: 1899.654296875
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 1 batch 0.0 event: 0 loss: tensor(180.3081, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 10.0 event: 300 loss: tensor(1768.7969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 20.0 event: 600 loss: tensor(1765.7288, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 30.0 event: 900 loss: tensor(1846.5803, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 40.0 event: 1200 loss: tensor(1771.9281, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 50.0 event: 1500 loss: tensor(1799.9205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 60.0 event: 1800 loss: tensor(1948.9198, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 70.0 event: 2100 loss: tensor(1792.9657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 80.0 event: 2400 loss: tensor(1905.2393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 90.0 event: 2700 loss: tensor(1788.6539, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 100.0 event: 3000 loss: tensor(1721.4056, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 110.0 event: 3300 loss: tensor(2007.5585, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 120.0 event: 3600 loss: tensor(1668.0189, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 130.0 event: 3900 loss: tensor(1941.0293, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 140.0 event: 4200 loss: tensor(1758.9873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 150.0 event: 4500 loss: tensor(1969.8082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 160.0 event: 4800 loss: tensor(1709.6132, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 170.0 event: 5100 loss: tensor(1952.5670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 180.0 event: 5400 loss: tensor(1808.5471, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 190.0 event: 5700 loss: tensor(1761.7299, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 200.0 event: 6000 loss: tensor(2085.3152, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 210.0 event: 6300 loss: tensor(1730.1830, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 220.0 event: 6600 loss: tensor(2017.1315, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 230.0 event: 6900 loss: tensor(1986.4059, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 240.0 event: 7200 loss: tensor(2043.0303, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 250.0 event: 7500 loss: tensor(2021.3824, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 260.0 event: 7800 loss: tensor(1738.7177, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 270.0 event: 8100 loss: tensor(1931.0950, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 280.0 event: 8400 loss: tensor(1964.7225, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 290.0 event: 8700 loss: tensor(1890.3275, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 300.0 event: 9000 loss: tensor(1381.0522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 310.0 event: 9300 loss: tensor(1732.0732, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 320.0 event: 9600 loss: tensor(1880.0367, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 330.0 event: 9900 loss: tensor(1984.8016, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:04.313742
evaluation loss: 1898.5
epoch: 1 mean loss: 1857.4617919921875
epoch: 2 batch 0.0 event: 0 loss: tensor(177.4410, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 10.0 event: 300 loss: tensor(1740.3828, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 20.0 event: 600 loss: tensor(1737.8473, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 30.0 event: 900 loss: tensor(1820.2469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 40.0 event: 1200 loss: tensor(1746.5983, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 50.0 event: 1500 loss: tensor(1774.8870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 60.0 event: 1800 loss: tensor(1921.7649, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 70.0 event: 2100 loss: tensor(1768.7572, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 80.0 event: 2400 loss: tensor(1881.0624, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 90.0 event: 2700 loss: tensor(1766.5088, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 100.0 event: 3000 loss: tensor(1702.0233, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 110.0 event: 3300 loss: tensor(1985.0892, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 120.0 event: 3600 loss: tensor(1648.2416, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 130.0 event: 3900 loss: tensor(1919.6625, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 140.0 event: 4200 loss: tensor(1739.3906, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 150.0 event: 4500 loss: tensor(1948.7305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 160.0 event: 4800 loss: tensor(1691.3864, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 170.0 event: 5100 loss: tensor(1931.3340, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 180.0 event: 5400 loss: tensor(1791.5940, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 190.0 event: 5700 loss: tensor(1743.3119, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 200.0 event: 6000 loss: tensor(2066.7317, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 210.0 event: 6300 loss: tensor(1714.2767, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 220.0 event: 6600 loss: tensor(1999.9391, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 230.0 event: 6900 loss: tensor(1967.5078, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 240.0 event: 7200 loss: tensor(2025.3018, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 250.0 event: 7500 loss: tensor(2005.0442, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 260.0 event: 7800 loss: tensor(1724.0287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 270.0 event: 8100 loss: tensor(1916.0592, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 280.0 event: 8400 loss: tensor(1949.3668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 290.0 event: 8700 loss: tensor(1875.8217, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 300.0 event: 9000 loss: tensor(1371.4114, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 310.0 event: 9300 loss: tensor(1718.9030, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 320.0 event: 9600 loss: tensor(1866.0511, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 330.0 event: 9900 loss: tensor(1971.2246, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:39.277064
evaluation loss: 1879.2984619140625
epoch: 2 mean loss: 1837.9122314453125
epoch: 3 batch 0.0 event: 0 loss: tensor(176.1035, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 10.0 event: 300 loss: tensor(1728.1044, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 20.0 event: 600 loss: tensor(1726.7548, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 30.0 event: 900 loss: tensor(1808.2246, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 40.0 event: 1200 loss: tensor(1735.2875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 50.0 event: 1500 loss: tensor(1763.6820, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 60.0 event: 1800 loss: tensor(1909.8313, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 70.0 event: 2100 loss: tensor(1757.5186, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 80.0 event: 2400 loss: tensor(1869.5059, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 90.0 event: 2700 loss: tensor(1756.2128, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 100.0 event: 3000 loss: tensor(1693.0850, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 110.0 event: 3300 loss: tensor(1973.9169, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 120.0 event: 3600 loss: tensor(1638.9172, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 130.0 event: 3900 loss: tensor(1909.4846, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 140.0 event: 4200 loss: tensor(1729.8430, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 150.0 event: 4500 loss: tensor(1938.3529, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 160.0 event: 4800 loss: tensor(1682.8721, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 170.0 event: 5100 loss: tensor(1921.7633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 180.0 event: 5400 loss: tensor(1783.5358, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 190.0 event: 5700 loss: tensor(1735.1406, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 200.0 event: 6000 loss: tensor(2057.6721, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 210.0 event: 6300 loss: tensor(1706.7242, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 220.0 event: 6600 loss: tensor(1991.4598, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 230.0 event: 6900 loss: tensor(1958.8348, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 240.0 event: 7200 loss: tensor(2017.2836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 250.0 event: 7500 loss: tensor(1997.1348, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 260.0 event: 7800 loss: tensor(1716.8073, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 270.0 event: 8100 loss: tensor(1909.1244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 280.0 event: 8400 loss: tensor(1942.3993, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 290.0 event: 8700 loss: tensor(1868.6416, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 300.0 event: 9000 loss: tensor(1366.0916, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 310.0 event: 9300 loss: tensor(1712.9247, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 320.0 event: 9600 loss: tensor(1859.3147, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 330.0 event: 9900 loss: tensor(1964.8121, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:14.234602
evaluation loss: 1870.7174072265625
epoch: 3 mean loss: 1828.8211669921875
epoch: 4 batch 0.0 event: 0 loss: tensor(175.5702, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 10.0 event: 300 loss: tensor(1722.2750, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 20.0 event: 600 loss: tensor(1721.0338, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 30.0 event: 900 loss: tensor(1802.7946, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 40.0 event: 1200 loss: tensor(1730.3148, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 50.0 event: 1500 loss: tensor(1758.3881, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 60.0 event: 1800 loss: tensor(1904.3715, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 70.0 event: 2100 loss: tensor(1752.4916, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 80.0 event: 2400 loss: tensor(1864.0286, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 90.0 event: 2700 loss: tensor(1751.7717, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 100.0 event: 3000 loss: tensor(1688.6201, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 110.0 event: 3300 loss: tensor(1968.6438, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 120.0 event: 3600 loss: tensor(1634.6796, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 130.0 event: 3900 loss: tensor(1904.9434, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 140.0 event: 4200 loss: tensor(1725.0863, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 150.0 event: 4500 loss: tensor(1933.2499, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 160.0 event: 4800 loss: tensor(1678.3109, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 170.0 event: 5100 loss: tensor(1917.1332, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 180.0 event: 5400 loss: tensor(1778.7324, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 190.0 event: 5700 loss: tensor(1730.2838, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 200.0 event: 6000 loss: tensor(2052.9792, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 210.0 event: 6300 loss: tensor(1702.9061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 220.0 event: 6600 loss: tensor(1987.5121, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 230.0 event: 6900 loss: tensor(1954.3121, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 240.0 event: 7200 loss: tensor(2012.7772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 250.0 event: 7500 loss: tensor(1993.0502, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 260.0 event: 7800 loss: tensor(1713.4846, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 270.0 event: 8100 loss: tensor(1905.5555, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 280.0 event: 8400 loss: tensor(1938.6819, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 290.0 event: 8700 loss: tensor(1865.4045, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 300.0 event: 9000 loss: tensor(1364.1713, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 310.0 event: 9300 loss: tensor(1709.5690, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 320.0 event: 9600 loss: tensor(1855.8688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 330.0 event: 9900 loss: tensor(1961.4930, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:49.200031
evaluation loss: 1867.2894287109375
epoch: 4 mean loss: 1824.388427734375
epoch: 5 batch 0.0 event: 0 loss: tensor(175.3640, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 10.0 event: 300 loss: tensor(1718.9156, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 20.0 event: 600 loss: tensor(1717.6879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 30.0 event: 900 loss: tensor(1800.0604, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 40.0 event: 1200 loss: tensor(1727.4086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 50.0 event: 1500 loss: tensor(1755.2551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 60.0 event: 1800 loss: tensor(1900.9838, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 70.0 event: 2100 loss: tensor(1749.4384, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 80.0 event: 2400 loss: tensor(1861.3602, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 90.0 event: 2700 loss: tensor(1749.3440, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 100.0 event: 3000 loss: tensor(1686.4340, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 110.0 event: 3300 loss: tensor(1965.8379, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 120.0 event: 3600 loss: tensor(1632.8318, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 130.0 event: 3900 loss: tensor(1902.1445, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 140.0 event: 4200 loss: tensor(1722.5614, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 150.0 event: 4500 loss: tensor(1930.1127, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 160.0 event: 4800 loss: tensor(1675.5449, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 170.0 event: 5100 loss: tensor(1913.9203, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 180.0 event: 5400 loss: tensor(1775.6855, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 190.0 event: 5700 loss: tensor(1727.7555, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 200.0 event: 6000 loss: tensor(2050.1260, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 210.0 event: 6300 loss: tensor(1699.9268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 220.0 event: 6600 loss: tensor(1984.5090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 230.0 event: 6900 loss: tensor(1951.1718, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 240.0 event: 7200 loss: tensor(2010.2366, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 250.0 event: 7500 loss: tensor(1990.3860, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 260.0 event: 7800 loss: tensor(1710.9768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 270.0 event: 8100 loss: tensor(1902.7708, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 280.0 event: 8400 loss: tensor(1936.1832, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 290.0 event: 8700 loss: tensor(1862.7805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 300.0 event: 9000 loss: tensor(1361.8784, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 310.0 event: 9300 loss: tensor(1706.7709, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 320.0 event: 9600 loss: tensor(1853.3055, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 330.0 event: 9900 loss: tensor(1958.3926, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:24.152221
evaluation loss: 1865.4608154296875
epoch: 5 mean loss: 1821.586181640625
=> saveing checkpoint at epoch 5
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 6 batch 0.0 event: 0 loss: tensor(175.1731, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 10.0 event: 300 loss: tensor(1717.1801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 20.0 event: 600 loss: tensor(1716.1405, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 30.0 event: 900 loss: tensor(1797.8629, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 40.0 event: 1200 loss: tensor(1724.9739, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 50.0 event: 1500 loss: tensor(1752.9969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 60.0 event: 1800 loss: tensor(1898.4789, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 70.0 event: 2100 loss: tensor(1747.3099, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 80.0 event: 2400 loss: tensor(1858.1305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 90.0 event: 2700 loss: tensor(1745.9287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 100.0 event: 3000 loss: tensor(1683.5531, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 110.0 event: 3300 loss: tensor(1963.0184, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 120.0 event: 3600 loss: tensor(1630.0415, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 130.0 event: 3900 loss: tensor(1899.9241, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 140.0 event: 4200 loss: tensor(1720.6820, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 150.0 event: 4500 loss: tensor(1927.8870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 160.0 event: 4800 loss: tensor(1673.8127, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 170.0 event: 5100 loss: tensor(1912.2969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 180.0 event: 5400 loss: tensor(1774.2672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 190.0 event: 5700 loss: tensor(1725.7782, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 200.0 event: 6000 loss: tensor(2048.1401, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 210.0 event: 6300 loss: tensor(1699.3199, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 220.0 event: 6600 loss: tensor(1982.5956, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 230.0 event: 6900 loss: tensor(1949.0590, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 240.0 event: 7200 loss: tensor(2008.4305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 250.0 event: 7500 loss: tensor(1988.7590, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 260.0 event: 7800 loss: tensor(1708.8036, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 270.0 event: 8100 loss: tensor(1900.3873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 280.0 event: 8400 loss: tensor(1933.5979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 290.0 event: 8700 loss: tensor(1859.7543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 300.0 event: 9000 loss: tensor(1360.1790, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 310.0 event: 9300 loss: tensor(1705.1643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 320.0 event: 9600 loss: tensor(1851.3729, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 330.0 event: 9900 loss: tensor(1956.5209, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:04.125325
evaluation loss: 1864.2528076171875
epoch: 6 mean loss: 1819.44970703125
epoch: 7 batch 0.0 event: 0 loss: tensor(175.0917, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 10.0 event: 300 loss: tensor(1715.3021, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 20.0 event: 600 loss: tensor(1713.9424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 30.0 event: 900 loss: tensor(1795.4268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 40.0 event: 1200 loss: tensor(1723.5559, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 50.0 event: 1500 loss: tensor(1751.0280, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 60.0 event: 1800 loss: tensor(1896.7181, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 70.0 event: 2100 loss: tensor(1746.0205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 80.0 event: 2400 loss: tensor(1856.6962, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 90.0 event: 2700 loss: tensor(1744.9489, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 100.0 event: 3000 loss: tensor(1682.0840, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 110.0 event: 3300 loss: tensor(1962.1500, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 120.0 event: 3600 loss: tensor(1629.2631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 130.0 event: 3900 loss: tensor(1898.3352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 140.0 event: 4200 loss: tensor(1718.6055, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 150.0 event: 4500 loss: tensor(1926.2821, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 160.0 event: 4800 loss: tensor(1672.8301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 170.0 event: 5100 loss: tensor(1911.1064, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 180.0 event: 5400 loss: tensor(1773.1366, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 190.0 event: 5700 loss: tensor(1724.4608, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 200.0 event: 6000 loss: tensor(2046.2656, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 210.0 event: 6300 loss: tensor(1697.8998, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 220.0 event: 6600 loss: tensor(1981.3801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 230.0 event: 6900 loss: tensor(1947.3539, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 240.0 event: 7200 loss: tensor(2007.2430, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 250.0 event: 7500 loss: tensor(1987.4893, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 260.0 event: 7800 loss: tensor(1707.4280, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 270.0 event: 8100 loss: tensor(1898.8285, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 280.0 event: 8400 loss: tensor(1932.0350, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 290.0 event: 8700 loss: tensor(1857.9062, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 300.0 event: 9000 loss: tensor(1359.0468, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 310.0 event: 9300 loss: tensor(1703.5358, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 320.0 event: 9600 loss: tensor(1850.1122, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 330.0 event: 9900 loss: tensor(1955.8655, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:39.270802
evaluation loss: 1862.8677978515625
epoch: 7 mean loss: 1817.9844970703125
epoch: 8 batch 0.0 event: 0 loss: tensor(174.9176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 10.0 event: 300 loss: tensor(1714.4950, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 20.0 event: 600 loss: tensor(1713.1672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 30.0 event: 900 loss: tensor(1794.3610, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 40.0 event: 1200 loss: tensor(1721.8629, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 50.0 event: 1500 loss: tensor(1749.2606, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 60.0 event: 1800 loss: tensor(1895.1962, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 70.0 event: 2100 loss: tensor(1743.9957, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 80.0 event: 2400 loss: tensor(1855.0475, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 90.0 event: 2700 loss: tensor(1742.8910, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 100.0 event: 3000 loss: tensor(1680.4395, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 110.0 event: 3300 loss: tensor(1960.7252, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 120.0 event: 3600 loss: tensor(1627.9493, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 130.0 event: 3900 loss: tensor(1896.9805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 140.0 event: 4200 loss: tensor(1718.2504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 150.0 event: 4500 loss: tensor(1924.6787, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 160.0 event: 4800 loss: tensor(1671.5791, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 170.0 event: 5100 loss: tensor(1909.7972, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 180.0 event: 5400 loss: tensor(1772.5485, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 190.0 event: 5700 loss: tensor(1723.1908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 200.0 event: 6000 loss: tensor(2044.3899, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 210.0 event: 6300 loss: tensor(1696.2157, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 220.0 event: 6600 loss: tensor(1979.6155, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 230.0 event: 6900 loss: tensor(1945.6406, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 240.0 event: 7200 loss: tensor(2004.6630, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 250.0 event: 7500 loss: tensor(1984.8641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 260.0 event: 7800 loss: tensor(1705.2958, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 270.0 event: 8100 loss: tensor(1896.7305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 280.0 event: 8400 loss: tensor(1930.2186, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 290.0 event: 8700 loss: tensor(1857.2266, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 300.0 event: 9000 loss: tensor(1358.0752, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 310.0 event: 9300 loss: tensor(1701.9967, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 320.0 event: 9600 loss: tensor(1848.2474, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 330.0 event: 9900 loss: tensor(1953.7190, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:14.476554
evaluation loss: 1862.4146728515625
epoch: 8 mean loss: 1816.4405517578125
epoch: 9 batch 0.0 event: 0 loss: tensor(174.7165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 10.0 event: 300 loss: tensor(1713.2178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 20.0 event: 600 loss: tensor(1711.9963, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 30.0 event: 900 loss: tensor(1793.9283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 40.0 event: 1200 loss: tensor(1721.3430, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 50.0 event: 1500 loss: tensor(1748.5614, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 60.0 event: 1800 loss: tensor(1894.0811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 70.0 event: 2100 loss: tensor(1743.0013, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 80.0 event: 2400 loss: tensor(1853.5446, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 90.0 event: 2700 loss: tensor(1741.3309, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 100.0 event: 3000 loss: tensor(1678.7145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 110.0 event: 3300 loss: tensor(1958.6171, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 120.0 event: 3600 loss: tensor(1626.4608, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 130.0 event: 3900 loss: tensor(1896.0231, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 140.0 event: 4200 loss: tensor(1716.8049, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 150.0 event: 4500 loss: tensor(1923.5344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 160.0 event: 4800 loss: tensor(1670.2655, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 170.0 event: 5100 loss: tensor(1908.3236, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 180.0 event: 5400 loss: tensor(1771.1168, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 190.0 event: 5700 loss: tensor(1722.1461, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 200.0 event: 6000 loss: tensor(2042.6865, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 210.0 event: 6300 loss: tensor(1694.4095, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 220.0 event: 6600 loss: tensor(1978.0745, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 230.0 event: 6900 loss: tensor(1944.5494, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 240.0 event: 7200 loss: tensor(2003.0139, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 250.0 event: 7500 loss: tensor(1983.4017, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 260.0 event: 7800 loss: tensor(1703.7288, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 270.0 event: 8100 loss: tensor(1895.1581, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 280.0 event: 8400 loss: tensor(1928.6024, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 290.0 event: 8700 loss: tensor(1855.6156, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 300.0 event: 9000 loss: tensor(1357.1727, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 310.0 event: 9300 loss: tensor(1700.7463, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 320.0 event: 9600 loss: tensor(1847.3395, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 330.0 event: 9900 loss: tensor(1952.6278, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:49.654182
evaluation loss: 1861.7830810546875
epoch: 9 mean loss: 1815.123779296875
epoch: 10 batch 0.0 event: 0 loss: tensor(174.5324, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 10.0 event: 300 loss: tensor(1711.5992, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 20.0 event: 600 loss: tensor(1710.1373, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 30.0 event: 900 loss: tensor(1792.6965, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 40.0 event: 1200 loss: tensor(1720.2188, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 50.0 event: 1500 loss: tensor(1748.5961, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 60.0 event: 1800 loss: tensor(1893.2758, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 70.0 event: 2100 loss: tensor(1742.5332, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 80.0 event: 2400 loss: tensor(1853.1561, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 90.0 event: 2700 loss: tensor(1740.4375, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 100.0 event: 3000 loss: tensor(1678.1096, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 110.0 event: 3300 loss: tensor(1957.1591, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 120.0 event: 3600 loss: tensor(1625.4740, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 130.0 event: 3900 loss: tensor(1894.2291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 140.0 event: 4200 loss: tensor(1715.0254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 150.0 event: 4500 loss: tensor(1921.6991, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 160.0 event: 4800 loss: tensor(1669.1002, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 170.0 event: 5100 loss: tensor(1907.1318, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 180.0 event: 5400 loss: tensor(1769.7366, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 190.0 event: 5700 loss: tensor(1720.8182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 200.0 event: 6000 loss: tensor(2041.1116, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 210.0 event: 6300 loss: tensor(1693.4899, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 220.0 event: 6600 loss: tensor(1976.7992, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 230.0 event: 6900 loss: tensor(1943.2383, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 240.0 event: 7200 loss: tensor(2001.7577, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 250.0 event: 7500 loss: tensor(1982.6879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 260.0 event: 7800 loss: tensor(1703.0970, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 270.0 event: 8100 loss: tensor(1894.1338, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 280.0 event: 8400 loss: tensor(1927.4043, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 290.0 event: 8700 loss: tensor(1854.6227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 300.0 event: 9000 loss: tensor(1357.0328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 310.0 event: 9300 loss: tensor(1700.0033, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 320.0 event: 9600 loss: tensor(1845.7694, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 330.0 event: 9900 loss: tensor(1951.1083, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:06:24.825189
evaluation loss: 1861.2711181640625
epoch: 10 mean loss: 1814.004150390625
=> saveing checkpoint at epoch 10
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 11 batch 0.0 event: 0 loss: tensor(174.5136, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 10.0 event: 300 loss: tensor(1710.9729, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 20.0 event: 600 loss: tensor(1709.0608, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 30.0 event: 900 loss: tensor(1791.6555, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 40.0 event: 1200 loss: tensor(1719.2704, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 50.0 event: 1500 loss: tensor(1747.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 60.0 event: 1800 loss: tensor(1893.2307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 70.0 event: 2100 loss: tensor(1742.4315, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 80.0 event: 2400 loss: tensor(1852.1354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 90.0 event: 2700 loss: tensor(1739.8219, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 100.0 event: 3000 loss: tensor(1677.1842, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 110.0 event: 3300 loss: tensor(1956.2946, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 120.0 event: 3600 loss: tensor(1624.4192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 130.0 event: 3900 loss: tensor(1893.4141, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 140.0 event: 4200 loss: tensor(1714.2177, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 150.0 event: 4500 loss: tensor(1921.0106, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 160.0 event: 4800 loss: tensor(1667.9938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 170.0 event: 5100 loss: tensor(1906.1781, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 180.0 event: 5400 loss: tensor(1769.3453, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 190.0 event: 5700 loss: tensor(1720.7582, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 200.0 event: 6000 loss: tensor(2040.1385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 210.0 event: 6300 loss: tensor(1692.5619, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 220.0 event: 6600 loss: tensor(1975.6986, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 230.0 event: 6900 loss: tensor(1942.0791, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 240.0 event: 7200 loss: tensor(2000.5463, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 250.0 event: 7500 loss: tensor(1981.6270, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 260.0 event: 7800 loss: tensor(1701.8658, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 270.0 event: 8100 loss: tensor(1893.7209, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 280.0 event: 8400 loss: tensor(1926.3094, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 290.0 event: 8700 loss: tensor(1853.6260, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 300.0 event: 9000 loss: tensor(1356.2010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 310.0 event: 9300 loss: tensor(1699.7825, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 320.0 event: 9600 loss: tensor(1844.7440, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 330.0 event: 9900 loss: tensor(1950.1106, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:05.228698
evaluation loss: 1860.5526123046875
epoch: 11 mean loss: 1813.1695556640625
epoch: 12 batch 0.0 event: 0 loss: tensor(174.3568, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 10.0 event: 300 loss: tensor(1709.2938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 20.0 event: 600 loss: tensor(1708.6838, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 30.0 event: 900 loss: tensor(1791.0807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 40.0 event: 1200 loss: tensor(1718.9105, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 50.0 event: 1500 loss: tensor(1746.4037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 60.0 event: 1800 loss: tensor(1892.2670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 70.0 event: 2100 loss: tensor(1742.0082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 80.0 event: 2400 loss: tensor(1852.2061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 90.0 event: 2700 loss: tensor(1740.3082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 100.0 event: 3000 loss: tensor(1677.0829, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 110.0 event: 3300 loss: tensor(1956.4250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 120.0 event: 3600 loss: tensor(1624.6063, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 130.0 event: 3900 loss: tensor(1893.2393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 140.0 event: 4200 loss: tensor(1714.2780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 150.0 event: 4500 loss: tensor(1920.8173, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 160.0 event: 4800 loss: tensor(1667.2821, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 170.0 event: 5100 loss: tensor(1905.2155, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 180.0 event: 5400 loss: tensor(1768.1252, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 190.0 event: 5700 loss: tensor(1719.1244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 200.0 event: 6000 loss: tensor(2039.2971, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 210.0 event: 6300 loss: tensor(1691.9863, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 220.0 event: 6600 loss: tensor(1974.4774, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 230.0 event: 6900 loss: tensor(1941.0146, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 240.0 event: 7200 loss: tensor(1998.8121, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 250.0 event: 7500 loss: tensor(1980.3323, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 260.0 event: 7800 loss: tensor(1701.4752, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 270.0 event: 8100 loss: tensor(1893.3486, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 280.0 event: 8400 loss: tensor(1925.9299, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 290.0 event: 8700 loss: tensor(1853.1770, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 300.0 event: 9000 loss: tensor(1354.8920, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 310.0 event: 9300 loss: tensor(1698.4371, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 320.0 event: 9600 loss: tensor(1843.8134, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 330.0 event: 9900 loss: tensor(1948.9359, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:40.450279
evaluation loss: 1860.3773193359375
epoch: 12 mean loss: 1812.46923828125
epoch: 13 batch 0.0 event: 0 loss: tensor(174.2150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 10.0 event: 300 loss: tensor(1708.2043, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 20.0 event: 600 loss: tensor(1707.2421, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 30.0 event: 900 loss: tensor(1788.8063, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 40.0 event: 1200 loss: tensor(1716.9215, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 50.0 event: 1500 loss: tensor(1745.1686, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 60.0 event: 1800 loss: tensor(1891.4280, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 70.0 event: 2100 loss: tensor(1741.5488, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 80.0 event: 2400 loss: tensor(1851.5331, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 90.0 event: 2700 loss: tensor(1738.1428, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 100.0 event: 3000 loss: tensor(1675.1393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 110.0 event: 3300 loss: tensor(1955.2040, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 120.0 event: 3600 loss: tensor(1623.8889, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 130.0 event: 3900 loss: tensor(1892.3265, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 140.0 event: 4200 loss: tensor(1713.2567, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 150.0 event: 4500 loss: tensor(1919.5676, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 160.0 event: 4800 loss: tensor(1666.4076, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 170.0 event: 5100 loss: tensor(1904.3069, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 180.0 event: 5400 loss: tensor(1766.8844, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 190.0 event: 5700 loss: tensor(1718.4156, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 200.0 event: 6000 loss: tensor(2038.5758, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 210.0 event: 6300 loss: tensor(1691.2272, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 220.0 event: 6600 loss: tensor(1973.7109, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 230.0 event: 6900 loss: tensor(1939.6399, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 240.0 event: 7200 loss: tensor(1997.5543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 250.0 event: 7500 loss: tensor(1979.4486, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 260.0 event: 7800 loss: tensor(1700.4264, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 270.0 event: 8100 loss: tensor(1892.3508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 280.0 event: 8400 loss: tensor(1924.8978, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 290.0 event: 8700 loss: tensor(1852.4188, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 300.0 event: 9000 loss: tensor(1354.6698, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 310.0 event: 9300 loss: tensor(1698.1370, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 320.0 event: 9600 loss: tensor(1842.6207, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 330.0 event: 9900 loss: tensor(1947.7279, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:15.678766
evaluation loss: 1860.1981201171875
epoch: 13 mean loss: 1811.396484375
epoch: 14 batch 0.0 event: 0 loss: tensor(174.0767, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 10.0 event: 300 loss: tensor(1707.0442, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 20.0 event: 600 loss: tensor(1706.0741, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 30.0 event: 900 loss: tensor(1788.3597, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 40.0 event: 1200 loss: tensor(1715.4618, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 50.0 event: 1500 loss: tensor(1743.0461, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 60.0 event: 1800 loss: tensor(1889.3008, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 70.0 event: 2100 loss: tensor(1739.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 80.0 event: 2400 loss: tensor(1851.4584, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 90.0 event: 2700 loss: tensor(1738.7795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 100.0 event: 3000 loss: tensor(1674.5707, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 110.0 event: 3300 loss: tensor(1953.8392, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 120.0 event: 3600 loss: tensor(1622.5563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 130.0 event: 3900 loss: tensor(1891.2327, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 140.0 event: 4200 loss: tensor(1712.9352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 150.0 event: 4500 loss: tensor(1918.1034, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 160.0 event: 4800 loss: tensor(1665.2028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 170.0 event: 5100 loss: tensor(1902.8723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 180.0 event: 5400 loss: tensor(1765.9856, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 190.0 event: 5700 loss: tensor(1717.3368, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 200.0 event: 6000 loss: tensor(2037.4125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 210.0 event: 6300 loss: tensor(1689.9553, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 220.0 event: 6600 loss: tensor(1973.1884, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 230.0 event: 6900 loss: tensor(1938.4622, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 240.0 event: 7200 loss: tensor(1996.8082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 250.0 event: 7500 loss: tensor(1978.3756, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 260.0 event: 7800 loss: tensor(1699.0795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 270.0 event: 8100 loss: tensor(1890.5891, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 280.0 event: 8400 loss: tensor(1923.5807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 290.0 event: 8700 loss: tensor(1851.1473, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 300.0 event: 9000 loss: tensor(1353.5745, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 310.0 event: 9300 loss: tensor(1696.7197, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 320.0 event: 9600 loss: tensor(1842.6071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 330.0 event: 9900 loss: tensor(1947.8547, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:50.909814
evaluation loss: 1859.6357421875
epoch: 14 mean loss: 1810.34619140625
epoch: 15 batch 0.0 event: 0 loss: tensor(173.9728, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 10.0 event: 300 loss: tensor(1706.3551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 20.0 event: 600 loss: tensor(1705.7499, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 30.0 event: 900 loss: tensor(1787.9348, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 40.0 event: 1200 loss: tensor(1715.7787, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 50.0 event: 1500 loss: tensor(1742.1689, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 60.0 event: 1800 loss: tensor(1887.9602, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 70.0 event: 2100 loss: tensor(1738.2250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 80.0 event: 2400 loss: tensor(1848.8541, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 90.0 event: 2700 loss: tensor(1736.4512, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 100.0 event: 3000 loss: tensor(1674.0009, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 110.0 event: 3300 loss: tensor(1953.3436, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 120.0 event: 3600 loss: tensor(1621.4714, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 130.0 event: 3900 loss: tensor(1889.5072, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 140.0 event: 4200 loss: tensor(1710.7672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 150.0 event: 4500 loss: tensor(1917.0316, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 160.0 event: 4800 loss: tensor(1664.3967, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 170.0 event: 5100 loss: tensor(1901.7893, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 180.0 event: 5400 loss: tensor(1765.0194, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 190.0 event: 5700 loss: tensor(1716.7559, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 200.0 event: 6000 loss: tensor(2037.2627, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 210.0 event: 6300 loss: tensor(1690.9153, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 220.0 event: 6600 loss: tensor(1973.6047, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 230.0 event: 6900 loss: tensor(1939.0214, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 240.0 event: 7200 loss: tensor(1997.3167, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 250.0 event: 7500 loss: tensor(1977.8990, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 260.0 event: 7800 loss: tensor(1699.1107, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 270.0 event: 8100 loss: tensor(1891.1731, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 280.0 event: 8400 loss: tensor(1923.7822, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 290.0 event: 8700 loss: tensor(1851.0930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 300.0 event: 9000 loss: tensor(1354.0179, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 310.0 event: 9300 loss: tensor(1697.2766, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 320.0 event: 9600 loss: tensor(1842.4225, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 330.0 event: 9900 loss: tensor(1948.1237, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:09:26.196948
evaluation loss: 1859.1522216796875
epoch: 15 mean loss: 1809.8341064453125
=> saveing checkpoint at epoch 15
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 16 batch 0.0 event: 0 loss: tensor(173.8942, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 10.0 event: 300 loss: tensor(1705.3759, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 20.0 event: 600 loss: tensor(1704.9965, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 30.0 event: 900 loss: tensor(1786.8070, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 40.0 event: 1200 loss: tensor(1713.9791, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 50.0 event: 1500 loss: tensor(1741.9635, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 60.0 event: 1800 loss: tensor(1888.3235, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 70.0 event: 2100 loss: tensor(1737.4442, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 80.0 event: 2400 loss: tensor(1847.7151, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 90.0 event: 2700 loss: tensor(1735.9291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 100.0 event: 3000 loss: tensor(1673.5482, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 110.0 event: 3300 loss: tensor(1953.1641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 120.0 event: 3600 loss: tensor(1621.5262, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 130.0 event: 3900 loss: tensor(1890.1019, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 140.0 event: 4200 loss: tensor(1711.2506, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 150.0 event: 4500 loss: tensor(1917.1996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 160.0 event: 4800 loss: tensor(1664.1376, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 170.0 event: 5100 loss: tensor(1901.5016, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 180.0 event: 5400 loss: tensor(1764.7350, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 190.0 event: 5700 loss: tensor(1716.3069, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 200.0 event: 6000 loss: tensor(2036.5563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 210.0 event: 6300 loss: tensor(1689.8625, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 220.0 event: 6600 loss: tensor(1972.1389, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 230.0 event: 6900 loss: tensor(1937.9524, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 240.0 event: 7200 loss: tensor(1995.9462, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 250.0 event: 7500 loss: tensor(1976.8535, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 260.0 event: 7800 loss: tensor(1698.2402, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 270.0 event: 8100 loss: tensor(1889.1337, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 280.0 event: 8400 loss: tensor(1921.6575, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 290.0 event: 8700 loss: tensor(1849.3270, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 300.0 event: 9000 loss: tensor(1352.4213, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 310.0 event: 9300 loss: tensor(1694.7748, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 320.0 event: 9600 loss: tensor(1840.7177, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 330.0 event: 9900 loss: tensor(1946.2172, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:10:06.378182
evaluation loss: 1858.721923828125
epoch: 16 mean loss: 1808.9754638671875
epoch: 17 batch 0.0 event: 0 loss: tensor(173.9222, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 10.0 event: 300 loss: tensor(1704.9515, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 20.0 event: 600 loss: tensor(1703.9049, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 30.0 event: 900 loss: tensor(1786.0643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 40.0 event: 1200 loss: tensor(1713.0518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 50.0 event: 1500 loss: tensor(1739.8418, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 60.0 event: 1800 loss: tensor(1886.8424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 70.0 event: 2100 loss: tensor(1737.5116, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 80.0 event: 2400 loss: tensor(1847.9600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 90.0 event: 2700 loss: tensor(1736.3226, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 100.0 event: 3000 loss: tensor(1672.4319, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 110.0 event: 3300 loss: tensor(1952.4723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 120.0 event: 3600 loss: tensor(1620.2234, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 130.0 event: 3900 loss: tensor(1888.4371, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 140.0 event: 4200 loss: tensor(1710.2385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 150.0 event: 4500 loss: tensor(1916.2448, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 160.0 event: 4800 loss: tensor(1663.1649, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 170.0 event: 5100 loss: tensor(1900.3801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 180.0 event: 5400 loss: tensor(1763.1630, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 190.0 event: 5700 loss: tensor(1714.5458, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 200.0 event: 6000 loss: tensor(2034.4926, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 210.0 event: 6300 loss: tensor(1688.3597, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 220.0 event: 6600 loss: tensor(1971.2236, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 230.0 event: 6900 loss: tensor(1936.8199, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 240.0 event: 7200 loss: tensor(1994.7670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 250.0 event: 7500 loss: tensor(1975.4713, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 260.0 event: 7800 loss: tensor(1697.2675, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 270.0 event: 8100 loss: tensor(1888.6871, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 280.0 event: 8400 loss: tensor(1921.2122, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 290.0 event: 8700 loss: tensor(1848.5624, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 300.0 event: 9000 loss: tensor(1352.1530, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 310.0 event: 9300 loss: tensor(1694.3268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 320.0 event: 9600 loss: tensor(1840.1937, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 330.0 event: 9900 loss: tensor(1944.7816, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:10:41.654918
evaluation loss: 1858.6197509765625
epoch: 17 mean loss: 1808.0120849609375
epoch: 18 batch 0.0 event: 0 loss: tensor(173.8960, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 10.0 event: 300 loss: tensor(1705.1484, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 20.0 event: 600 loss: tensor(1704.3485, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 30.0 event: 900 loss: tensor(1785.9745, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 40.0 event: 1200 loss: tensor(1713.8199, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 50.0 event: 1500 loss: tensor(1740.3817, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 60.0 event: 1800 loss: tensor(1885.6442, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 70.0 event: 2100 loss: tensor(1736.7086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 80.0 event: 2400 loss: tensor(1846.1689, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 90.0 event: 2700 loss: tensor(1734.5781, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 100.0 event: 3000 loss: tensor(1671.6379, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 110.0 event: 3300 loss: tensor(1951.0986, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 120.0 event: 3600 loss: tensor(1619.2509, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 130.0 event: 3900 loss: tensor(1887.9193, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 140.0 event: 4200 loss: tensor(1709.4022, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 150.0 event: 4500 loss: tensor(1915.2825, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 160.0 event: 4800 loss: tensor(1662.1464, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 170.0 event: 5100 loss: tensor(1899.5629, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 180.0 event: 5400 loss: tensor(1763.0826, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 190.0 event: 5700 loss: tensor(1714.5389, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 200.0 event: 6000 loss: tensor(2034.3534, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 210.0 event: 6300 loss: tensor(1688.0250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 220.0 event: 6600 loss: tensor(1970.7747, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 230.0 event: 6900 loss: tensor(1936.2430, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 240.0 event: 7200 loss: tensor(1995.5477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 250.0 event: 7500 loss: tensor(1976.5719, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 260.0 event: 7800 loss: tensor(1697.2112, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 270.0 event: 8100 loss: tensor(1888.8969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 280.0 event: 8400 loss: tensor(1921.4746, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 290.0 event: 8700 loss: tensor(1848.3887, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 300.0 event: 9000 loss: tensor(1352.3119, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 310.0 event: 9300 loss: tensor(1694.4062, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 320.0 event: 9600 loss: tensor(1840.3700, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 330.0 event: 9900 loss: tensor(1944.5703, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:11:16.936993
evaluation loss: 1858.4947509765625
epoch: 18 mean loss: 1807.7010498046875
epoch: 19 batch 0.0 event: 0 loss: tensor(173.8204, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 10.0 event: 300 loss: tensor(1704.3293, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 20.0 event: 600 loss: tensor(1703.8597, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 30.0 event: 900 loss: tensor(1784.8596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 40.0 event: 1200 loss: tensor(1712.0829, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 50.0 event: 1500 loss: tensor(1740.0746, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 60.0 event: 1800 loss: tensor(1885.3655, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 70.0 event: 2100 loss: tensor(1736.3085, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 80.0 event: 2400 loss: tensor(1846.2467, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 90.0 event: 2700 loss: tensor(1734.1532, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 100.0 event: 3000 loss: tensor(1671.1230, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 110.0 event: 3300 loss: tensor(1949.8987, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 120.0 event: 3600 loss: tensor(1618.3579, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 130.0 event: 3900 loss: tensor(1886.6520, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 140.0 event: 4200 loss: tensor(1709.2288, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 150.0 event: 4500 loss: tensor(1914.9010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 160.0 event: 4800 loss: tensor(1662.2372, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 170.0 event: 5100 loss: tensor(1898.6487, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 180.0 event: 5400 loss: tensor(1762.0071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 190.0 event: 5700 loss: tensor(1713.3945, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 200.0 event: 6000 loss: tensor(2033.5826, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 210.0 event: 6300 loss: tensor(1687.9606, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 220.0 event: 6600 loss: tensor(1971.1823, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 230.0 event: 6900 loss: tensor(1935.6211, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 240.0 event: 7200 loss: tensor(1993.5690, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 250.0 event: 7500 loss: tensor(1974.7836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 260.0 event: 7800 loss: tensor(1696.0817, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 270.0 event: 8100 loss: tensor(1886.7963, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 280.0 event: 8400 loss: tensor(1919.5012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 290.0 event: 8700 loss: tensor(1846.2313, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 300.0 event: 9000 loss: tensor(1350.3595, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 310.0 event: 9300 loss: tensor(1693.0293, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 320.0 event: 9600 loss: tensor(1839.2793, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 330.0 event: 9900 loss: tensor(1944.8287, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:11:52.219465
evaluation loss: 1858.2613525390625
epoch: 19 mean loss: 1806.816162109375
epoch: 20 batch 0.0 event: 0 loss: tensor(173.9119, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 10.0 event: 300 loss: tensor(1703.9491, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 20.0 event: 600 loss: tensor(1704.0723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 30.0 event: 900 loss: tensor(1785.9252, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 40.0 event: 1200 loss: tensor(1712.6067, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 50.0 event: 1500 loss: tensor(1740.1455, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 60.0 event: 1800 loss: tensor(1885.2230, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 70.0 event: 2100 loss: tensor(1735.6923, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 80.0 event: 2400 loss: tensor(1844.3729, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 90.0 event: 2700 loss: tensor(1732.9941, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 100.0 event: 3000 loss: tensor(1670.7502, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 110.0 event: 3300 loss: tensor(1949.8192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 120.0 event: 3600 loss: tensor(1617.4618, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 130.0 event: 3900 loss: tensor(1885.6754, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 140.0 event: 4200 loss: tensor(1708.6722, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 150.0 event: 4500 loss: tensor(1914.2402, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 160.0 event: 4800 loss: tensor(1661.6194, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 170.0 event: 5100 loss: tensor(1897.9954, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 180.0 event: 5400 loss: tensor(1761.8309, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 190.0 event: 5700 loss: tensor(1713.3311, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 200.0 event: 6000 loss: tensor(2032.7611, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 210.0 event: 6300 loss: tensor(1686.7223, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 220.0 event: 6600 loss: tensor(1970.4160, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 230.0 event: 6900 loss: tensor(1935.4606, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 240.0 event: 7200 loss: tensor(1993.2543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 250.0 event: 7500 loss: tensor(1975.5726, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 260.0 event: 7800 loss: tensor(1696.8485, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 270.0 event: 8100 loss: tensor(1887.0082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 280.0 event: 8400 loss: tensor(1918.9652, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 290.0 event: 8700 loss: tensor(1845.3004, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 300.0 event: 9000 loss: tensor(1349.5369, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 310.0 event: 9300 loss: tensor(1691.7578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 320.0 event: 9600 loss: tensor(1837.5110, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 330.0 event: 9900 loss: tensor(1943.0863, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:12:27.500966
evaluation loss: 1858.0111083984375
epoch: 20 mean loss: 1806.332763671875
=> saveing checkpoint at epoch 20
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 21 batch 0.0 event: 0 loss: tensor(173.7165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 10.0 event: 300 loss: tensor(1703.2321, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 20.0 event: 600 loss: tensor(1702.9762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 30.0 event: 900 loss: tensor(1784.4817, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 40.0 event: 1200 loss: tensor(1711.8363, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 50.0 event: 1500 loss: tensor(1739.2523, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 60.0 event: 1800 loss: tensor(1884.7777, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 70.0 event: 2100 loss: tensor(1734.7054, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 80.0 event: 2400 loss: tensor(1844.1195, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 90.0 event: 2700 loss: tensor(1731.5199, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 100.0 event: 3000 loss: tensor(1668.8138, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 110.0 event: 3300 loss: tensor(1948.2249, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 120.0 event: 3600 loss: tensor(1617.1224, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 130.0 event: 3900 loss: tensor(1884.5719, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 140.0 event: 4200 loss: tensor(1707.0361, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 150.0 event: 4500 loss: tensor(1913.2963, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 160.0 event: 4800 loss: tensor(1661.9127, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 170.0 event: 5100 loss: tensor(1897.8824, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 180.0 event: 5400 loss: tensor(1761.0399, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 190.0 event: 5700 loss: tensor(1712.1393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 200.0 event: 6000 loss: tensor(2032.2479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 210.0 event: 6300 loss: tensor(1686.1135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 220.0 event: 6600 loss: tensor(1969.6256, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 230.0 event: 6900 loss: tensor(1935.5131, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 240.0 event: 7200 loss: tensor(1992.8125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 250.0 event: 7500 loss: tensor(1974.5234, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 260.0 event: 7800 loss: tensor(1696.4313, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 270.0 event: 8100 loss: tensor(1886.9557, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 280.0 event: 8400 loss: tensor(1919.6741, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 290.0 event: 8700 loss: tensor(1847.0022, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 300.0 event: 9000 loss: tensor(1350.6434, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 310.0 event: 9300 loss: tensor(1692.1865, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 320.0 event: 9600 loss: tensor(1836.9584, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 330.0 event: 9900 loss: tensor(1941.7184, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:13:08.480452
evaluation loss: 1857.7581787109375
epoch: 21 mean loss: 1805.7369384765625
epoch: 22 batch 0.0 event: 0 loss: tensor(173.7095, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 10.0 event: 300 loss: tensor(1701.7352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 20.0 event: 600 loss: tensor(1702.0598, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 30.0 event: 900 loss: tensor(1783.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 40.0 event: 1200 loss: tensor(1711.7076, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 50.0 event: 1500 loss: tensor(1738.9828, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 60.0 event: 1800 loss: tensor(1884.7070, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 70.0 event: 2100 loss: tensor(1734.6210, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 80.0 event: 2400 loss: tensor(1843.1141, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 90.0 event: 2700 loss: tensor(1731.6674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 100.0 event: 3000 loss: tensor(1668.8672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 110.0 event: 3300 loss: tensor(1947.9384, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 120.0 event: 3600 loss: tensor(1616.4720, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 130.0 event: 3900 loss: tensor(1883.6830, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 140.0 event: 4200 loss: tensor(1706.2994, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 150.0 event: 4500 loss: tensor(1911.6703, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 160.0 event: 4800 loss: tensor(1660.4340, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 170.0 event: 5100 loss: tensor(1898.1549, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 180.0 event: 5400 loss: tensor(1762.0140, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 190.0 event: 5700 loss: tensor(1713.0970, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 200.0 event: 6000 loss: tensor(2032.0436, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 210.0 event: 6300 loss: tensor(1686.6692, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 220.0 event: 6600 loss: tensor(1969.4170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 230.0 event: 6900 loss: tensor(1937.1536, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 240.0 event: 7200 loss: tensor(1993.9485, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 250.0 event: 7500 loss: tensor(1975.4961, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 260.0 event: 7800 loss: tensor(1697.2518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 270.0 event: 8100 loss: tensor(1887.6172, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 280.0 event: 8400 loss: tensor(1920.1055, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 290.0 event: 8700 loss: tensor(1846.2284, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 300.0 event: 9000 loss: tensor(1350.0544, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 310.0 event: 9300 loss: tensor(1691.8043, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 320.0 event: 9600 loss: tensor(1838.0139, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 330.0 event: 9900 loss: tensor(1942.6973, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:13:43.785315
evaluation loss: 1857.7392578125
epoch: 22 mean loss: 1805.677734375
epoch: 23 batch 0.0 event: 0 loss: tensor(173.6685, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 10.0 event: 300 loss: tensor(1701.5969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 20.0 event: 600 loss: tensor(1701.9348, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 30.0 event: 900 loss: tensor(1783.0941, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 40.0 event: 1200 loss: tensor(1711.0374, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 50.0 event: 1500 loss: tensor(1738.2454, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 60.0 event: 1800 loss: tensor(1883.9078, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 70.0 event: 2100 loss: tensor(1734.3698, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 80.0 event: 2400 loss: tensor(1843.3319, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 90.0 event: 2700 loss: tensor(1730.8066, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 100.0 event: 3000 loss: tensor(1668.2762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 110.0 event: 3300 loss: tensor(1947.2893, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 120.0 event: 3600 loss: tensor(1616.9589, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 130.0 event: 3900 loss: tensor(1883.6995, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 140.0 event: 4200 loss: tensor(1705.9481, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 150.0 event: 4500 loss: tensor(1912.0771, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 160.0 event: 4800 loss: tensor(1660.1989, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 170.0 event: 5100 loss: tensor(1897.1327, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 180.0 event: 5400 loss: tensor(1760.5452, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 190.0 event: 5700 loss: tensor(1711.0657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 200.0 event: 6000 loss: tensor(2030.4271, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 210.0 event: 6300 loss: tensor(1685.3938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 220.0 event: 6600 loss: tensor(1967.5391, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 230.0 event: 6900 loss: tensor(1934.2360, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 240.0 event: 7200 loss: tensor(1991.2538, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 250.0 event: 7500 loss: tensor(1971.7581, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 260.0 event: 7800 loss: tensor(1694.5145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 270.0 event: 8100 loss: tensor(1885.3262, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 280.0 event: 8400 loss: tensor(1917.3245, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 290.0 event: 8700 loss: tensor(1844.3909, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 300.0 event: 9000 loss: tensor(1348.7291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 310.0 event: 9300 loss: tensor(1690.5957, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 320.0 event: 9600 loss: tensor(1835.7936, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 330.0 event: 9900 loss: tensor(1941.5516, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:14:19.073358
evaluation loss: 1857.3099365234375
epoch: 23 mean loss: 1804.505859375
epoch: 24 batch 0.0 event: 0 loss: tensor(173.6335, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 10.0 event: 300 loss: tensor(1701.7577, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 20.0 event: 600 loss: tensor(1702.0758, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 30.0 event: 900 loss: tensor(1784.3326, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 40.0 event: 1200 loss: tensor(1711.3176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 50.0 event: 1500 loss: tensor(1737.3212, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 60.0 event: 1800 loss: tensor(1883.3623, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 70.0 event: 2100 loss: tensor(1734.5986, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 80.0 event: 2400 loss: tensor(1843.3076, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 90.0 event: 2700 loss: tensor(1731.6270, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 100.0 event: 3000 loss: tensor(1668.9730, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 110.0 event: 3300 loss: tensor(1946.9219, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 120.0 event: 3600 loss: tensor(1616.5743, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 130.0 event: 3900 loss: tensor(1884.2614, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 140.0 event: 4200 loss: tensor(1705.5833, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 150.0 event: 4500 loss: tensor(1910.9691, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 160.0 event: 4800 loss: tensor(1659.3822, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 170.0 event: 5100 loss: tensor(1895.7977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 180.0 event: 5400 loss: tensor(1759.5966, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 190.0 event: 5700 loss: tensor(1710.7164, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 200.0 event: 6000 loss: tensor(2030.0195, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 210.0 event: 6300 loss: tensor(1685.3138, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 220.0 event: 6600 loss: tensor(1967.2457, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 230.0 event: 6900 loss: tensor(1932.8512, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 240.0 event: 7200 loss: tensor(1992.0533, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 250.0 event: 7500 loss: tensor(1972.4335, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 260.0 event: 7800 loss: tensor(1693.8700, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 270.0 event: 8100 loss: tensor(1883.8177, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 280.0 event: 8400 loss: tensor(1916.9746, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 290.0 event: 8700 loss: tensor(1843.6136, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 300.0 event: 9000 loss: tensor(1348.0291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 310.0 event: 9300 loss: tensor(1690.3192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 320.0 event: 9600 loss: tensor(1834.5693, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 330.0 event: 9900 loss: tensor(1939.8584, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:14:54.378613
evaluation loss: 1857.2679443359375
epoch: 24 mean loss: 1804.154541015625
epoch: 25 batch 0.0 event: 0 loss: tensor(173.4432, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 10.0 event: 300 loss: tensor(1701.6151, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 20.0 event: 600 loss: tensor(1700.6090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 30.0 event: 900 loss: tensor(1782.8236, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 40.0 event: 1200 loss: tensor(1711.9426, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 50.0 event: 1500 loss: tensor(1738.1943, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 60.0 event: 1800 loss: tensor(1883.9196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 70.0 event: 2100 loss: tensor(1734.1342, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 80.0 event: 2400 loss: tensor(1842.6676, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 90.0 event: 2700 loss: tensor(1730.7363, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 100.0 event: 3000 loss: tensor(1668.5223, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 110.0 event: 3300 loss: tensor(1946.6399, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 120.0 event: 3600 loss: tensor(1616.2606, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 130.0 event: 3900 loss: tensor(1884.0413, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 140.0 event: 4200 loss: tensor(1706.5028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 150.0 event: 4500 loss: tensor(1911.2714, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 160.0 event: 4800 loss: tensor(1659.5565, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 170.0 event: 5100 loss: tensor(1895.5699, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 180.0 event: 5400 loss: tensor(1758.4696, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 190.0 event: 5700 loss: tensor(1709.9030, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 200.0 event: 6000 loss: tensor(2029.0596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 210.0 event: 6300 loss: tensor(1684.8854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 220.0 event: 6600 loss: tensor(1967.0961, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 230.0 event: 6900 loss: tensor(1932.6250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 240.0 event: 7200 loss: tensor(1990.5475, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 250.0 event: 7500 loss: tensor(1971.7328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 260.0 event: 7800 loss: tensor(1694.2649, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 270.0 event: 8100 loss: tensor(1884.2914, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 280.0 event: 8400 loss: tensor(1917.3320, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 290.0 event: 8700 loss: tensor(1844.5586, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 300.0 event: 9000 loss: tensor(1348.7362, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 310.0 event: 9300 loss: tensor(1690.1780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 320.0 event: 9600 loss: tensor(1835.1543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 330.0 event: 9900 loss: tensor(1940.0502, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:15:29.655504
evaluation loss: 1857.3199462890625
epoch: 25 mean loss: 1803.980712890625
=> saveing checkpoint at epoch 25
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 26 batch 0.0 event: 0 loss: tensor(173.3413, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 10.0 event: 300 loss: tensor(1699.9121, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 20.0 event: 600 loss: tensor(1699.6305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 30.0 event: 900 loss: tensor(1781.1957, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 40.0 event: 1200 loss: tensor(1708.9323, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 50.0 event: 1500 loss: tensor(1735.5198, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 60.0 event: 1800 loss: tensor(1881.8375, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 70.0 event: 2100 loss: tensor(1732.5856, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 80.0 event: 2400 loss: tensor(1840.7640, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 90.0 event: 2700 loss: tensor(1729.5920, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 100.0 event: 3000 loss: tensor(1667.5208, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 110.0 event: 3300 loss: tensor(1945.2943, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 120.0 event: 3600 loss: tensor(1615.5033, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 130.0 event: 3900 loss: tensor(1882.7770, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 140.0 event: 4200 loss: tensor(1704.4745, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 150.0 event: 4500 loss: tensor(1910.1932, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 160.0 event: 4800 loss: tensor(1659.1307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 170.0 event: 5100 loss: tensor(1896.0703, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 180.0 event: 5400 loss: tensor(1759.3090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 190.0 event: 5700 loss: tensor(1710.4551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 200.0 event: 6000 loss: tensor(2028.8801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 210.0 event: 6300 loss: tensor(1684.2562, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 220.0 event: 6600 loss: tensor(1966.0543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 230.0 event: 6900 loss: tensor(1933.2079, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 240.0 event: 7200 loss: tensor(1990.4852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 250.0 event: 7500 loss: tensor(1971.5311, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 260.0 event: 7800 loss: tensor(1694.0725, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 270.0 event: 8100 loss: tensor(1884.8890, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 280.0 event: 8400 loss: tensor(1917.2268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 290.0 event: 8700 loss: tensor(1844.4260, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 300.0 event: 9000 loss: tensor(1348.3596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 310.0 event: 9300 loss: tensor(1690.2264, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 320.0 event: 9600 loss: tensor(1835.7701, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 330.0 event: 9900 loss: tensor(1940.2391, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:16:10.464021
evaluation loss: 1857.2640380859375
epoch: 26 mean loss: 1803.26416015625
epoch: 27 batch 0.0 event: 0 loss: tensor(173.3169, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 10.0 event: 300 loss: tensor(1700.7170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 20.0 event: 600 loss: tensor(1699.6786, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 30.0 event: 900 loss: tensor(1782.1949, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 40.0 event: 1200 loss: tensor(1709.7714, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 50.0 event: 1500 loss: tensor(1736.0596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 60.0 event: 1800 loss: tensor(1881.1647, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 70.0 event: 2100 loss: tensor(1732.0934, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 80.0 event: 2400 loss: tensor(1840.9446, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 90.0 event: 2700 loss: tensor(1730.3926, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 100.0 event: 3000 loss: tensor(1667.2518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 110.0 event: 3300 loss: tensor(1945.0657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 120.0 event: 3600 loss: tensor(1614.3447, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 130.0 event: 3900 loss: tensor(1882.3236, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 140.0 event: 4200 loss: tensor(1703.9990, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 150.0 event: 4500 loss: tensor(1908.9133, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 160.0 event: 4800 loss: tensor(1657.9703, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 170.0 event: 5100 loss: tensor(1894.8463, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 180.0 event: 5400 loss: tensor(1758.6713, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 190.0 event: 5700 loss: tensor(1710.2128, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 200.0 event: 6000 loss: tensor(2029.2297, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 210.0 event: 6300 loss: tensor(1684.1012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 220.0 event: 6600 loss: tensor(1966.4176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 230.0 event: 6900 loss: tensor(1932.0133, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 240.0 event: 7200 loss: tensor(1990.0038, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 250.0 event: 7500 loss: tensor(1971.1022, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 260.0 event: 7800 loss: tensor(1694.2352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 270.0 event: 8100 loss: tensor(1884.2518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 280.0 event: 8400 loss: tensor(1917.6786, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 290.0 event: 8700 loss: tensor(1844.4901, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 300.0 event: 9000 loss: tensor(1348.3894, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 310.0 event: 9300 loss: tensor(1690.4471, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 320.0 event: 9600 loss: tensor(1835.6930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 330.0 event: 9900 loss: tensor(1940.2167, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:16:45.751850
evaluation loss: 1857.590087890625
epoch: 27 mean loss: 1803.104736328125
epoch: 28 batch 0.0 event: 0 loss: tensor(173.1861, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 10.0 event: 300 loss: tensor(1699.4100, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 20.0 event: 600 loss: tensor(1698.6497, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 30.0 event: 900 loss: tensor(1780.0883, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 40.0 event: 1200 loss: tensor(1707.8219, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 50.0 event: 1500 loss: tensor(1735.1698, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 60.0 event: 1800 loss: tensor(1880.4709, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 70.0 event: 2100 loss: tensor(1731.5292, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 80.0 event: 2400 loss: tensor(1840.9857, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 90.0 event: 2700 loss: tensor(1729.4950, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 100.0 event: 3000 loss: tensor(1667.2211, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 110.0 event: 3300 loss: tensor(1945.1390, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 120.0 event: 3600 loss: tensor(1614.4459, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 130.0 event: 3900 loss: tensor(1882.6028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 140.0 event: 4200 loss: tensor(1704.6624, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 150.0 event: 4500 loss: tensor(1909.5127, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 160.0 event: 4800 loss: tensor(1658.2633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 170.0 event: 5100 loss: tensor(1894.8323, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 180.0 event: 5400 loss: tensor(1758.6943, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 190.0 event: 5700 loss: tensor(1710.2109, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 200.0 event: 6000 loss: tensor(2028.6161, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 210.0 event: 6300 loss: tensor(1683.2479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 220.0 event: 6600 loss: tensor(1965.6533, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 230.0 event: 6900 loss: tensor(1932.5120, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 240.0 event: 7200 loss: tensor(1990.2512, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 250.0 event: 7500 loss: tensor(1971.0287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 260.0 event: 7800 loss: tensor(1692.8510, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 270.0 event: 8100 loss: tensor(1883.9906, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 280.0 event: 8400 loss: tensor(1916.5762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 290.0 event: 8700 loss: tensor(1843.6748, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 300.0 event: 9000 loss: tensor(1347.5125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 310.0 event: 9300 loss: tensor(1689.8021, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 320.0 event: 9600 loss: tensor(1834.5643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 330.0 event: 9900 loss: tensor(1939.8958, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:17:21.043665
evaluation loss: 1856.689453125
epoch: 28 mean loss: 1802.6351318359375
epoch: 29 batch 0.0 event: 0 loss: tensor(173.4682, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 10.0 event: 300 loss: tensor(1699.4647, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 20.0 event: 600 loss: tensor(1699.4423, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 30.0 event: 900 loss: tensor(1780.1721, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 40.0 event: 1200 loss: tensor(1708.7588, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 50.0 event: 1500 loss: tensor(1734.6510, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 60.0 event: 1800 loss: tensor(1879.7356, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 70.0 event: 2100 loss: tensor(1730.9957, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 80.0 event: 2400 loss: tensor(1839.7616, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 90.0 event: 2700 loss: tensor(1728.4323, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 100.0 event: 3000 loss: tensor(1666.4697, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 110.0 event: 3300 loss: tensor(1944.8646, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 120.0 event: 3600 loss: tensor(1614.7385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 130.0 event: 3900 loss: tensor(1882.0712, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 140.0 event: 4200 loss: tensor(1704.0292, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 150.0 event: 4500 loss: tensor(1908.2191, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 160.0 event: 4800 loss: tensor(1658.0387, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 170.0 event: 5100 loss: tensor(1894.8209, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 180.0 event: 5400 loss: tensor(1758.0768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 190.0 event: 5700 loss: tensor(1709.4091, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 200.0 event: 6000 loss: tensor(2027.9836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 210.0 event: 6300 loss: tensor(1683.5931, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 220.0 event: 6600 loss: tensor(1965.7445, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 230.0 event: 6900 loss: tensor(1931.4374, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 240.0 event: 7200 loss: tensor(1989.7225, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 250.0 event: 7500 loss: tensor(1971.4254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 260.0 event: 7800 loss: tensor(1693.1244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 270.0 event: 8100 loss: tensor(1883.6588, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 280.0 event: 8400 loss: tensor(1916.2770, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 290.0 event: 8700 loss: tensor(1843.1683, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 300.0 event: 9000 loss: tensor(1347.4873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 310.0 event: 9300 loss: tensor(1688.8290, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 320.0 event: 9600 loss: tensor(1833.8086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 330.0 event: 9900 loss: tensor(1939.0289, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:19:15.326088
evaluation loss: 1856.7718505859375
epoch: 29 mean loss: 1802.266357421875
=> saveing checkpoint at epoch 29
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2

outi tensor([[1.7470e-12, 2.7052e-19, 1.4211e-08,  ..., 7.4948e-36, 9.2866e-32,
         0.0000e+00],
        [1.5984e-18, 4.4919e-15, 2.2067e-07,  ..., 1.5645e-25, 3.5791e-32,
         6.5143e-29],
        [9.9999e-01, 5.9322e-08, 3.4800e-10,  ..., 2.0687e-22, 3.0660e-24,
         2.8555e-28],
        ...,
        [3.1579e-07, 9.4700e-06, 1.0000e+00,  ..., 4.0709e-17, 8.2581e-19,
         2.2119e-15],
        [1.6175e-10, 5.4644e-16, 3.1157e-14,  ..., 3.1501e-17, 1.2103e-15,
         3.1054e-20],
        [8.0776e-13, 9.7939e-01, 1.0000e+00,  ..., 5.0473e-25, 2.8994e-35,
         1.9706e-26]], device='cuda:0', grad_fn=<SigmoidBackward0>) 
 torch.Size([30, 6796]) 
 tensor(47072.2656, device='cuda:0', grad_fn=<SumBackward0>) 
 tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0') 
 tensor(203880, device='cuda:0')



training loss:
 [1899.65429688 1857.46179199 1837.91223145 1828.82116699 1824.38842773
 1821.58618164 1819.44970703 1817.98449707 1816.44055176 1815.1237793
 1814.00415039 1813.16955566 1812.46923828 1811.39648438 1810.34619141
 1809.83410645 1808.97546387 1808.01208496 1807.7010498  1806.81616211
 1806.33276367 1805.73693848 1805.67773438 1804.50585938 1804.15454102
 1803.98071289 1803.26416016 1803.10473633 1802.63513184 1802.26635742] 

\evaluation loss:
 [1939.0526123  1898.5        1879.29846191 1870.71740723 1867.28942871
 1865.46081543 1864.25280762 1862.86779785 1862.41467285 1861.78308105
 1861.27111816 1860.5526123  1860.37731934 1860.19812012 1859.63574219
 1859.15222168 1858.72192383 1858.61975098 1858.49475098 1858.26135254
 1858.0111084  1857.75817871 1857.73925781 1857.30993652 1857.26794434
 1857.31994629 1857.26403809 1857.59008789 1856.68945312 1856.77185059]



eval_efficiency:
 [0.99745663 0.81428665 0.80803835 0.80439027 0.80166942 0.79952352
 0.7977083  0.79604108 0.79452213 0.79328056 0.7922151  0.79126806
 0.79061464 0.78943437 0.78857808 0.78767274 0.78682984 0.78607578
 0.78546477 0.78478673 0.78423546 0.78362085 0.78305562 0.78243159
 0.78182826 0.78118786 0.78069107 0.78023352 0.77966033 0.7791307
 0.77862174 0.77814127 0.77774521 0.77728919 0.77667753 0.77612508
 0.77574307 0.77513385 0.77470706 0.77421769 0.7738021  0.77339677
 0.77279454 0.77243024 0.77193009 0.77156204 0.77115242 0.77072753
 0.77046069 0.77010757 0.76962469 0.76917986 0.76870427 0.76836692
 0.76787941 0.76741725 0.76703305 0.76654695 0.76600628 0.76559024
 0.76507561 0.76461824 0.76413333 0.76364832 0.76307498 0.76262392
 0.76199212 0.76148061 0.76088749 0.76040124 0.75977468 0.75911619
 0.75860761 0.75800363 0.75738318 0.7567921  0.75610491 0.75553032
 0.75486598 0.75414454 0.75337908 0.75258262 0.75184873 0.75101346
 0.75029161 0.74955893 0.74850396 0.74757786 0.74632349 0.74523134
 0.74404963 0.74255411 0.74102728 0.73933687 0.73723249 0.73462696
 0.73156143 0.72744368 0.72170005 0.71254794] 


eval_purity:
 [0.83920415 0.91383487 0.91436594 0.91480026 0.91519035 0.91545552
 0.91563783 0.91578053 0.91592782 0.9160979  0.91618406 0.91626138
 0.91634789 0.91643831 0.91652667 0.91656206 0.91666733 0.91671317
 0.91679723 0.91683028 0.9168571  0.91684448 0.91696299 0.91698293
 0.91703626 0.91705194 0.91709895 0.91710203 0.91720571 0.91723586
 0.91729859 0.91736507 0.91741599 0.91743606 0.91751516 0.91751955
 0.91756846 0.91758949 0.91761512 0.91762704 0.91765752 0.91771837
 0.91779067 0.9178211  0.91784526 0.91788318 0.91795674 0.91799345
 0.91806514 0.91813013 0.91815365 0.91817594 0.91825477 0.91831164
 0.91832086 0.91835888 0.91842484 0.91850339 0.91853328 0.91856412
 0.91861997 0.91864109 0.9187199  0.91880003 0.91884547 0.91889318
 0.91896144 0.91900648 0.91899613 0.91905153 0.91905791 0.91906028
 0.91911489 0.91918029 0.91922126 0.9192164  0.91927142 0.91931197
 0.91936322 0.9194019  0.91943112 0.91950964 0.91952505 0.9196
 0.9196324  0.91966928 0.91970569 0.91970676 0.91974642 0.91987049
 0.91995806 0.91996505 0.92008588 0.92025975 0.92036304 0.92048456
 0.92070468 0.92087239 0.92103301 0.9216978 ]

Passing event 10003 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([5.8293e-15, 8.1076e-14, 7.8755e-16,  ..., 4.1579e-18, 1.7648e-23,
        5.4302e-25], device='cuda:0', grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10003 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.5057, 0.5063, 0.5086,  ..., 0.5150, 0.4845, 0.4806],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network before training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 4.9569e-08, 2.2098e-12,
        9.9999e-01], device='cuda:0', grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network after training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0.5057, 0.5063, 0.5086,  ..., 0.5150, 0.4845, 0.4806],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([2.8148e-04, 9.9999e-01, 1.0000e+00,  ..., 2.4101e-12, 2.5311e-15,
        8.4290e-07], device='cuda:0', grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.5057, 0.5063, 0.5086,  ..., 0.5150, 0.4844, 0.4806],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

real	19m59.819s
user	21m54.487s
sys	10m28.612s
