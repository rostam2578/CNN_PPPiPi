0: gpu015.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-70960025-1050-8c52-3f5d-db0d0fca0636)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        1A:4C:BC:79:AC:F4:80:9B:25:8E:21:10:C0:C4:44:9C:1F:5B:BD:6E
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Thu Sep  1 03:18:54 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1E:00.0 Off |                    0 |
| N/A   41C    P0    45W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b9d155468e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m12.968s
user	0m3.397s
sys	0m1.834s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-2p31fbo1 because the default path (/besfs5/users/hoseinkk/home/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2/Model1.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = F.softmax(self.fc4(x))




 Training ... 






 The Network ... 







 Loading data ... 



training set shape (20000, 43, 288) 
sum 5279207

target set shape (20000, 6796) 
sum 4575851
Net(
  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=667776, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=6796, bias=True)
)

number of the free parameters: 171805196
parameters of the network conv1.weight 
 torch.Size([256, 1, 3, 3]) 
 True 
 tensor([[[[ 0.2383,  0.1575, -0.0435],
          [ 0.0569, -0.2188, -0.1998],
          [-0.0270, -0.1831, -0.2389]]],


        [[[-0.2850,  0.1435,  0.3125],
          [-0.1816, -0.1380,  0.1669],
          [-0.0226, -0.3060, -0.0633]]],


        [[[ 0.2465, -0.0663, -0.1445],
          [-0.3184,  0.3057, -0.2877],
          [-0.0132,  0.1813, -0.0591]]],


        ...,


        [[[-0.3151, -0.2271,  0.3241],
          [ 0.1955,  0.0635,  0.0644],
          [ 0.1088,  0.0897,  0.3138]]],


        [[[ 0.0420, -0.1841, -0.0102],
          [ 0.2455, -0.1698,  0.1422],
          [ 0.1488,  0.2610,  0.1555]]],


        [[[-0.2617, -0.3333, -0.3231],
          [ 0.3116, -0.0205, -0.1662],
          [ 0.0109,  0.0397, -0.0266]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 0.2383,  0.1575, -0.0435],
          [ 0.0569, -0.2188, -0.1998],
          [-0.0270, -0.1831, -0.2389]]],


        [[[-0.2850,  0.1435,  0.3125],
          [-0.1816, -0.1380,  0.1669],
          [-0.0226, -0.3060, -0.0633]]],


        [[[ 0.2465, -0.0663, -0.1445],
          [-0.3184,  0.3057, -0.2877],
          [-0.0132,  0.1813, -0.0591]]],


        ...,


        [[[-0.3151, -0.2271,  0.3241],
          [ 0.1955,  0.0635,  0.0644],
          [ 0.1088,  0.0897,  0.3138]]],


        [[[ 0.0420, -0.1841, -0.0102],
          [ 0.2455, -0.1698,  0.1422],
          [ 0.1488,  0.2610,  0.1555]]],


        [[[-0.2617, -0.3333, -0.3231],
          [ 0.3116, -0.0205, -0.1662],
          [ 0.0109,  0.0397, -0.0266]]]], device='cuda:0', requires_grad=True)
parameters of the network conv1.bias 
 torch.Size([256]) 
 True 
 tensor([-0.0185, -0.1267,  0.1294, -0.1903,  0.2338, -0.0782, -0.1303, -0.0748,
         0.1189,  0.1698, -0.1671,  0.3086, -0.1953,  0.3068,  0.0723, -0.0747,
         0.1020,  0.1195,  0.0546,  0.0812, -0.3067, -0.1737,  0.1010, -0.1478,
        -0.0986, -0.0523,  0.3317, -0.0189, -0.1229, -0.2630,  0.2896,  0.3328,
         0.0126,  0.0710,  0.3076, -0.1535,  0.0972,  0.1198, -0.0280, -0.1401,
        -0.3053, -0.1457, -0.0563, -0.2556, -0.2083,  0.0595, -0.1547, -0.2478,
         0.3162,  0.0363, -0.0533, -0.3205,  0.1221,  0.2718, -0.3093, -0.1514,
         0.0300,  0.1155,  0.2883,  0.2100, -0.0973,  0.1131,  0.2504,  0.2171,
         0.1765,  0.1052, -0.2090, -0.3102, -0.2029,  0.3228, -0.2588, -0.0415,
        -0.0831,  0.0677,  0.2075, -0.1880,  0.2397, -0.0937, -0.0155, -0.1706,
         0.1221,  0.1347, -0.1905,  0.2649, -0.3038, -0.0025, -0.0080, -0.3279,
        -0.2510,  0.2898, -0.0918,  0.3210, -0.2206,  0.1057, -0.2229, -0.2039,
        -0.2493,  0.2751, -0.1990,  0.3275, -0.0646,  0.1853,  0.0072,  0.0439,
        -0.0068, -0.0258,  0.2684, -0.0400,  0.0982, -0.2672, -0.2272, -0.1329,
        -0.2423, -0.0904,  0.3314, -0.1477, -0.2881, -0.2131, -0.2503, -0.2731,
        -0.2992, -0.0048, -0.1193, -0.2922,  0.2040, -0.1593, -0.3030,  0.2042,
         0.1657, -0.0981,  0.0564, -0.1416,  0.1127,  0.3042, -0.0188,  0.0320,
        -0.1461, -0.1469, -0.1316, -0.0077,  0.2906,  0.1858,  0.0941, -0.0235,
         0.0076,  0.3007, -0.2217,  0.0163,  0.0691,  0.0948, -0.2421, -0.2986,
         0.2494, -0.0400,  0.2069,  0.1248,  0.1810, -0.0326, -0.0351, -0.3118,
        -0.2438,  0.2671, -0.3244,  0.1757, -0.1733,  0.0246, -0.0351,  0.1500,
        -0.2434,  0.1079,  0.3046, -0.2871, -0.1103,  0.2959, -0.0700,  0.1239,
        -0.1808,  0.3012, -0.2461, -0.0819,  0.1563,  0.0621,  0.2886,  0.0689,
        -0.2838,  0.1578, -0.3159, -0.1053, -0.3067, -0.2897, -0.2367, -0.2575,
        -0.1779,  0.3066, -0.2242,  0.0012, -0.3256,  0.2263,  0.0078, -0.0604,
        -0.2311, -0.0567,  0.2515, -0.2258,  0.1421,  0.0317,  0.0249, -0.3192,
         0.2068,  0.0467,  0.3249,  0.1557, -0.0289,  0.0573,  0.1321,  0.1813,
        -0.0284, -0.1451,  0.1927,  0.1483, -0.1850, -0.2059,  0.3142, -0.1563,
        -0.0666, -0.0391,  0.0493,  0.3168,  0.1107,  0.2505,  0.2268, -0.3006,
         0.3256,  0.0104, -0.0067, -0.1143, -0.1870, -0.0560, -0.0997, -0.0430,
         0.1666,  0.1634,  0.0367,  0.0502, -0.2819,  0.0481,  0.2934,  0.2168,
        -0.1861, -0.3161, -0.1477, -0.0369,  0.2916,  0.0761, -0.2699, -0.0284],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0185, -0.1267,  0.1294, -0.1903,  0.2338, -0.0782, -0.1303, -0.0748,
         0.1189,  0.1698, -0.1671,  0.3086, -0.1953,  0.3068,  0.0723, -0.0747,
         0.1020,  0.1195,  0.0546,  0.0812, -0.3067, -0.1737,  0.1010, -0.1478,
        -0.0986, -0.0523,  0.3317, -0.0189, -0.1229, -0.2630,  0.2896,  0.3328,
         0.0126,  0.0710,  0.3076, -0.1535,  0.0972,  0.1198, -0.0280, -0.1401,
        -0.3053, -0.1457, -0.0563, -0.2556, -0.2083,  0.0595, -0.1547, -0.2478,
         0.3162,  0.0363, -0.0533, -0.3205,  0.1221,  0.2718, -0.3093, -0.1514,
         0.0300,  0.1155,  0.2883,  0.2100, -0.0973,  0.1131,  0.2504,  0.2171,
         0.1765,  0.1052, -0.2090, -0.3102, -0.2029,  0.3228, -0.2588, -0.0415,
        -0.0831,  0.0677,  0.2075, -0.1880,  0.2397, -0.0937, -0.0155, -0.1706,
         0.1221,  0.1347, -0.1905,  0.2649, -0.3038, -0.0025, -0.0080, -0.3279,
        -0.2510,  0.2898, -0.0918,  0.3210, -0.2206,  0.1057, -0.2229, -0.2039,
        -0.2493,  0.2751, -0.1990,  0.3275, -0.0646,  0.1853,  0.0072,  0.0439,
        -0.0068, -0.0258,  0.2684, -0.0400,  0.0982, -0.2672, -0.2272, -0.1329,
        -0.2423, -0.0904,  0.3314, -0.1477, -0.2881, -0.2131, -0.2503, -0.2731,
        -0.2992, -0.0048, -0.1193, -0.2922,  0.2040, -0.1593, -0.3030,  0.2042,
         0.1657, -0.0981,  0.0564, -0.1416,  0.1127,  0.3042, -0.0188,  0.0320,
        -0.1461, -0.1469, -0.1316, -0.0077,  0.2906,  0.1858,  0.0941, -0.0235,
         0.0076,  0.3007, -0.2217,  0.0163,  0.0691,  0.0948, -0.2421, -0.2986,
         0.2494, -0.0400,  0.2069,  0.1248,  0.1810, -0.0326, -0.0351, -0.3118,
        -0.2438,  0.2671, -0.3244,  0.1757, -0.1733,  0.0246, -0.0351,  0.1500,
        -0.2434,  0.1079,  0.3046, -0.2871, -0.1103,  0.2959, -0.0700,  0.1239,
        -0.1808,  0.3012, -0.2461, -0.0819,  0.1563,  0.0621,  0.2886,  0.0689,
        -0.2838,  0.1578, -0.3159, -0.1053, -0.3067, -0.2897, -0.2367, -0.2575,
        -0.1779,  0.3066, -0.2242,  0.0012, -0.3256,  0.2263,  0.0078, -0.0604,
        -0.2311, -0.0567,  0.2515, -0.2258,  0.1421,  0.0317,  0.0249, -0.3192,
         0.2068,  0.0467,  0.3249,  0.1557, -0.0289,  0.0573,  0.1321,  0.1813,
        -0.0284, -0.1451,  0.1927,  0.1483, -0.1850, -0.2059,  0.3142, -0.1563,
        -0.0666, -0.0391,  0.0493,  0.3168,  0.1107,  0.2505,  0.2268, -0.3006,
         0.3256,  0.0104, -0.0067, -0.1143, -0.1870, -0.0560, -0.0997, -0.0430,
         0.1666,  0.1634,  0.0367,  0.0502, -0.2819,  0.0481,  0.2934,  0.2168,
        -0.1861, -0.3161, -0.1477, -0.0369,  0.2916,  0.0761, -0.2699, -0.0284],
       device='cuda:0', requires_grad=True)
parameters of the network conv2.weight 
 torch.Size([128, 256, 3, 3]) 
 True 
 tensor([[[[ 1.8518e-02,  1.7343e-02,  1.6491e-02],
          [-1.3222e-02,  2.6858e-03, -2.0318e-03],
          [-1.5090e-04, -1.6452e-02,  3.1283e-03]],

         [[ 5.5905e-04, -1.3446e-02,  1.8126e-02],
          [ 9.9819e-03,  1.0818e-02, -6.8022e-03],
          [-2.7990e-03,  6.3931e-03, -8.4826e-03]],

         [[-1.5281e-02,  8.3341e-03,  6.5729e-03],
          [-1.8624e-02,  1.6971e-02, -9.1123e-03],
          [-2.9290e-03,  9.3015e-03, -5.7409e-03]],

         ...,

         [[-2.2820e-03, -2.0114e-02, -8.5909e-03],
          [-6.2805e-03,  6.5119e-03, -8.0568e-03],
          [-5.3270e-03,  3.4531e-03, -1.2583e-02]],

         [[-6.5223e-03,  1.0483e-02, -1.2318e-02],
          [ 1.3707e-03, -8.3808e-03, -4.2296e-03],
          [-7.2243e-03, -1.2766e-02,  1.5881e-02]],

         [[-1.7502e-02,  5.1128e-05,  1.8182e-02],
          [ 7.6667e-04, -1.7604e-02,  1.5878e-02],
          [ 1.8874e-02, -1.1421e-04,  9.1849e-03]]],


        [[[ 9.4916e-03,  1.6092e-02, -1.7230e-03],
          [ 1.2185e-02, -1.1458e-02, -1.9427e-02],
          [-5.8144e-03, -5.7467e-03,  1.5769e-03]],

         [[ 1.5999e-02, -6.6052e-03, -1.3966e-02],
          [-8.5006e-03, -7.1113e-03,  1.8794e-03],
          [ 1.6646e-02, -1.6013e-02, -1.6310e-02]],

         [[-8.8369e-03,  1.9738e-02,  6.7687e-04],
          [ 1.8551e-02,  1.2582e-02, -1.0046e-02],
          [-1.2806e-02, -1.3561e-02, -1.6215e-02]],

         ...,

         [[-1.3553e-02,  1.7977e-02, -5.0749e-03],
          [-1.5342e-02,  4.0731e-03, -6.1313e-03],
          [ 9.3063e-03,  1.8088e-02, -7.0382e-03]],

         [[-2.0349e-02, -1.3965e-02, -8.3833e-03],
          [ 4.7798e-03, -9.1987e-03,  5.0925e-03],
          [-1.5929e-03,  1.1142e-02,  1.3469e-02]],

         [[-2.5020e-03,  1.7009e-02,  1.1172e-02],
          [ 7.0514e-03, -1.3873e-02, -6.5967e-03],
          [-2.0045e-02, -7.8256e-03, -1.7041e-02]]],


        [[[ 1.6269e-02,  1.5927e-02, -1.8475e-02],
          [-1.3888e-02,  2.4544e-03,  1.5529e-02],
          [ 1.5180e-02, -1.8267e-02, -1.1479e-02]],

         [[-4.1011e-04, -1.2225e-02,  2.3379e-03],
          [-6.7566e-03, -1.9061e-02,  1.5387e-03],
          [-8.1653e-03,  3.0268e-03,  1.4101e-02]],

         [[-7.4434e-03,  2.0690e-02,  1.7805e-02],
          [-5.5702e-03,  4.6546e-03,  1.6559e-02],
          [-1.5657e-02, -9.4924e-03, -1.8271e-02]],

         ...,

         [[ 8.8958e-03,  9.6594e-03,  1.4067e-02],
          [-6.9624e-03, -4.1259e-03, -1.7170e-02],
          [ 7.4064e-03, -5.6641e-03, -1.1783e-02]],

         [[ 1.0967e-02, -1.0706e-02,  6.2122e-03],
          [ 8.1177e-03,  1.4647e-02,  1.7037e-02],
          [ 1.9177e-02, -4.9361e-03,  1.9788e-02]],

         [[-8.0832e-04, -1.7109e-02,  1.2186e-02],
          [-3.1744e-03,  6.0315e-03,  1.6562e-02],
          [ 6.3938e-04, -6.7061e-03,  1.7078e-02]]],


        ...,


        [[[ 7.0668e-04,  1.3391e-02,  5.0596e-03],
          [ 1.4484e-02, -1.1923e-02,  1.2358e-03],
          [ 1.0214e-02, -1.5241e-04,  3.5349e-03]],

         [[-1.9553e-02,  4.9087e-03,  1.6317e-02],
          [-1.1088e-02, -6.5627e-04,  1.5402e-03],
          [-7.7368e-04,  2.5010e-03, -1.2583e-02]],

         [[ 7.7782e-03, -1.9910e-02,  1.4544e-02],
          [ 1.6985e-02,  1.7548e-02, -2.3733e-03],
          [-5.2540e-04,  4.7942e-03, -1.8358e-02]],

         ...,

         [[ 1.8878e-02,  1.6916e-02, -1.4352e-02],
          [ 1.3252e-02,  1.3036e-02, -5.8544e-04],
          [ 1.5168e-02,  7.6178e-03, -3.4094e-03]],

         [[-1.0495e-03, -1.4098e-03, -1.4868e-02],
          [ 3.7459e-03,  1.7560e-02,  5.0871e-03],
          [-4.8853e-03, -1.6629e-02, -1.0997e-02]],

         [[-1.2365e-02,  4.1890e-04, -1.8931e-02],
          [-3.2404e-03, -1.5077e-02, -2.6005e-03],
          [-8.6292e-03,  1.6760e-02,  8.0258e-03]]],


        [[[-7.7165e-03, -1.5468e-02, -1.6146e-02],
          [ 4.9172e-04, -1.3479e-02, -1.2056e-02],
          [-1.2283e-03, -4.4910e-03,  1.6560e-02]],

         [[-1.1789e-02, -1.7096e-02, -9.5391e-03],
          [ 9.6148e-03,  2.4343e-04, -5.5385e-03],
          [ 2.8805e-03, -2.0257e-02,  4.1763e-04]],

         [[ 6.4463e-03,  5.8187e-03, -4.1769e-03],
          [-6.5868e-03, -1.7491e-02, -1.4908e-02],
          [ 1.2062e-02, -1.7756e-02,  1.6574e-02]],

         ...,

         [[-1.5205e-03,  7.7329e-03, -1.0404e-02],
          [-3.1625e-04, -2.9982e-03, -2.0099e-02],
          [ 1.1491e-02,  1.3096e-02,  1.6636e-02]],

         [[-9.5561e-03, -4.0303e-03, -1.8900e-02],
          [-7.8985e-03, -1.0210e-03,  2.4811e-03],
          [ 6.7835e-03,  1.9087e-02, -7.4041e-03]],

         [[ 8.5488e-03, -1.8454e-02, -1.3822e-04],
          [ 4.7280e-03, -2.3073e-03,  1.0949e-02],
          [-1.5782e-03,  1.5257e-02, -1.5300e-02]]],


        [[[-6.2741e-03, -1.3099e-02,  1.3305e-02],
          [-1.6291e-02,  1.1201e-02, -1.0343e-02],
          [ 4.9102e-03,  1.7024e-02,  1.2227e-02]],

         [[-2.9121e-04, -1.9380e-02, -1.3003e-02],
          [-1.4697e-02, -1.2720e-02, -5.7799e-03],
          [-1.8195e-02, -1.3924e-02, -1.9482e-02]],

         [[-3.8990e-03,  4.3739e-03, -9.5573e-03],
          [ 1.3160e-03,  1.6507e-02,  1.5016e-02],
          [ 1.6845e-03,  2.5929e-03,  1.0615e-02]],

         ...,

         [[ 1.6231e-02,  1.2877e-02, -1.5514e-02],
          [ 3.4954e-04,  1.3122e-03,  1.4617e-02],
          [ 2.0279e-02, -1.3344e-02,  3.1980e-03]],

         [[ 9.2230e-03,  1.5310e-02, -3.8817e-03],
          [ 1.6615e-02,  1.6276e-02,  2.0688e-02],
          [ 8.0918e-04,  1.9210e-02,  3.8404e-04]],

         [[ 1.5321e-02,  1.5612e-02,  4.1096e-03],
          [ 7.6520e-04,  8.6669e-03, -1.6070e-02],
          [ 9.3083e-03, -4.3352e-05, -3.3455e-03]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 1.8518e-02,  1.7343e-02,  1.6491e-02],
          [-1.3222e-02,  2.6858e-03, -2.0318e-03],
          [-1.5090e-04, -1.6452e-02,  3.1283e-03]],

         [[ 5.5905e-04, -1.3446e-02,  1.8126e-02],
          [ 9.9819e-03,  1.0818e-02, -6.8022e-03],
          [-2.7990e-03,  6.3931e-03, -8.4826e-03]],

         [[-1.5281e-02,  8.3341e-03,  6.5729e-03],
          [-1.8624e-02,  1.6971e-02, -9.1123e-03],
          [-2.9290e-03,  9.3015e-03, -5.7409e-03]],

         ...,

         [[-2.2820e-03, -2.0114e-02, -8.5909e-03],
          [-6.2805e-03,  6.5119e-03, -8.0568e-03],
          [-5.3270e-03,  3.4531e-03, -1.2583e-02]],

         [[-6.5223e-03,  1.0483e-02, -1.2318e-02],
          [ 1.3707e-03, -8.3808e-03, -4.2296e-03],
          [-7.2243e-03, -1.2766e-02,  1.5881e-02]],

         [[-1.7502e-02,  5.1128e-05,  1.8182e-02],
          [ 7.6667e-04, -1.7604e-02,  1.5878e-02],
          [ 1.8874e-02, -1.1421e-04,  9.1849e-03]]],


        [[[ 9.4916e-03,  1.6092e-02, -1.7230e-03],
          [ 1.2185e-02, -1.1458e-02, -1.9427e-02],
          [-5.8144e-03, -5.7467e-03,  1.5769e-03]],

         [[ 1.5999e-02, -6.6052e-03, -1.3966e-02],
          [-8.5006e-03, -7.1113e-03,  1.8794e-03],
          [ 1.6646e-02, -1.6013e-02, -1.6310e-02]],

         [[-8.8369e-03,  1.9738e-02,  6.7687e-04],
          [ 1.8551e-02,  1.2582e-02, -1.0046e-02],
          [-1.2806e-02, -1.3561e-02, -1.6215e-02]],

         ...,

         [[-1.3553e-02,  1.7977e-02, -5.0749e-03],
          [-1.5342e-02,  4.0731e-03, -6.1313e-03],
          [ 9.3063e-03,  1.8088e-02, -7.0382e-03]],

         [[-2.0349e-02, -1.3965e-02, -8.3833e-03],
          [ 4.7798e-03, -9.1987e-03,  5.0925e-03],
          [-1.5929e-03,  1.1142e-02,  1.3469e-02]],

         [[-2.5020e-03,  1.7009e-02,  1.1172e-02],
          [ 7.0514e-03, -1.3873e-02, -6.5967e-03],
          [-2.0045e-02, -7.8256e-03, -1.7041e-02]]],


        [[[ 1.6269e-02,  1.5927e-02, -1.8475e-02],
          [-1.3888e-02,  2.4544e-03,  1.5529e-02],
          [ 1.5180e-02, -1.8267e-02, -1.1479e-02]],

         [[-4.1011e-04, -1.2225e-02,  2.3379e-03],
          [-6.7566e-03, -1.9061e-02,  1.5387e-03],
          [-8.1653e-03,  3.0268e-03,  1.4101e-02]],

         [[-7.4434e-03,  2.0690e-02,  1.7805e-02],
          [-5.5702e-03,  4.6546e-03,  1.6559e-02],
          [-1.5657e-02, -9.4924e-03, -1.8271e-02]],

         ...,

         [[ 8.8958e-03,  9.6594e-03,  1.4067e-02],
          [-6.9624e-03, -4.1259e-03, -1.7170e-02],
          [ 7.4064e-03, -5.6641e-03, -1.1783e-02]],

         [[ 1.0967e-02, -1.0706e-02,  6.2122e-03],
          [ 8.1177e-03,  1.4647e-02,  1.7037e-02],
          [ 1.9177e-02, -4.9361e-03,  1.9788e-02]],

         [[-8.0832e-04, -1.7109e-02,  1.2186e-02],
          [-3.1744e-03,  6.0315e-03,  1.6562e-02],
          [ 6.3938e-04, -6.7061e-03,  1.7078e-02]]],


        ...,


        [[[ 7.0668e-04,  1.3391e-02,  5.0596e-03],
          [ 1.4484e-02, -1.1923e-02,  1.2358e-03],
          [ 1.0214e-02, -1.5241e-04,  3.5349e-03]],

         [[-1.9553e-02,  4.9087e-03,  1.6317e-02],
          [-1.1088e-02, -6.5627e-04,  1.5402e-03],
          [-7.7368e-04,  2.5010e-03, -1.2583e-02]],

         [[ 7.7782e-03, -1.9910e-02,  1.4544e-02],
          [ 1.6985e-02,  1.7548e-02, -2.3733e-03],
          [-5.2540e-04,  4.7942e-03, -1.8358e-02]],

         ...,

         [[ 1.8878e-02,  1.6916e-02, -1.4352e-02],
          [ 1.3252e-02,  1.3036e-02, -5.8544e-04],
          [ 1.5168e-02,  7.6178e-03, -3.4094e-03]],

         [[-1.0495e-03, -1.4098e-03, -1.4868e-02],
          [ 3.7459e-03,  1.7560e-02,  5.0871e-03],
          [-4.8853e-03, -1.6629e-02, -1.0997e-02]],

         [[-1.2365e-02,  4.1890e-04, -1.8931e-02],
          [-3.2404e-03, -1.5077e-02, -2.6005e-03],
          [-8.6292e-03,  1.6760e-02,  8.0258e-03]]],


        [[[-7.7165e-03, -1.5468e-02, -1.6146e-02],
          [ 4.9172e-04, -1.3479e-02, -1.2056e-02],
          [-1.2283e-03, -4.4910e-03,  1.6560e-02]],

         [[-1.1789e-02, -1.7096e-02, -9.5391e-03],
          [ 9.6148e-03,  2.4343e-04, -5.5385e-03],
          [ 2.8805e-03, -2.0257e-02,  4.1763e-04]],

         [[ 6.4463e-03,  5.8187e-03, -4.1769e-03],
          [-6.5868e-03, -1.7491e-02, -1.4908e-02],
          [ 1.2062e-02, -1.7756e-02,  1.6574e-02]],

         ...,

         [[-1.5205e-03,  7.7329e-03, -1.0404e-02],
          [-3.1625e-04, -2.9982e-03, -2.0099e-02],
          [ 1.1491e-02,  1.3096e-02,  1.6636e-02]],

         [[-9.5561e-03, -4.0303e-03, -1.8900e-02],
          [-7.8985e-03, -1.0210e-03,  2.4811e-03],
          [ 6.7835e-03,  1.9087e-02, -7.4041e-03]],

         [[ 8.5488e-03, -1.8454e-02, -1.3822e-04],
          [ 4.7280e-03, -2.3073e-03,  1.0949e-02],
          [-1.5782e-03,  1.5257e-02, -1.5300e-02]]],


        [[[-6.2741e-03, -1.3099e-02,  1.3305e-02],
          [-1.6291e-02,  1.1201e-02, -1.0343e-02],
          [ 4.9102e-03,  1.7024e-02,  1.2227e-02]],

         [[-2.9121e-04, -1.9380e-02, -1.3003e-02],
          [-1.4697e-02, -1.2720e-02, -5.7799e-03],
          [-1.8195e-02, -1.3924e-02, -1.9482e-02]],

         [[-3.8990e-03,  4.3739e-03, -9.5573e-03],
          [ 1.3160e-03,  1.6507e-02,  1.5016e-02],
          [ 1.6845e-03,  2.5929e-03,  1.0615e-02]],

         ...,

         [[ 1.6231e-02,  1.2877e-02, -1.5514e-02],
          [ 3.4954e-04,  1.3122e-03,  1.4617e-02],
          [ 2.0279e-02, -1.3344e-02,  3.1980e-03]],

         [[ 9.2230e-03,  1.5310e-02, -3.8817e-03],
          [ 1.6615e-02,  1.6276e-02,  2.0688e-02],
          [ 8.0918e-04,  1.9210e-02,  3.8404e-04]],

         [[ 1.5321e-02,  1.5612e-02,  4.1096e-03],
          [ 7.6520e-04,  8.6669e-03, -1.6070e-02],
          [ 9.3083e-03, -4.3352e-05, -3.3455e-03]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv2.bias 
 torch.Size([128]) 
 True 
 tensor([-1.0661e-02, -7.3722e-03,  1.5022e-02, -7.6840e-03, -3.1631e-03,
         6.8702e-03, -1.4887e-02, -5.9313e-03, -1.2507e-02,  8.9485e-04,
        -1.3247e-02, -1.3811e-02,  6.1957e-03, -1.8992e-03,  1.2227e-02,
         6.9227e-03,  1.6830e-02,  1.3891e-03,  8.9434e-03,  7.3975e-03,
         7.1849e-03,  5.5500e-03,  1.9451e-02, -1.2300e-02, -9.1325e-03,
        -1.3117e-02, -1.3138e-03,  1.4218e-02, -3.7476e-04, -6.6686e-04,
         1.8878e-02,  8.6152e-03,  2.1042e-03,  1.0414e-02, -1.9897e-02,
         1.1188e-02, -1.6170e-02, -1.1193e-03,  1.6834e-02,  6.5573e-05,
        -1.0926e-02,  1.1527e-02, -4.7833e-03,  1.0574e-02,  1.6873e-02,
         5.3255e-03, -1.6099e-02, -1.3154e-02,  8.9463e-04, -1.0303e-03,
         1.1128e-02,  2.9959e-03,  2.4695e-03,  3.9455e-03,  4.3082e-03,
         1.0356e-02, -1.3612e-03,  1.6151e-02,  1.1467e-02, -1.4060e-02,
         1.8191e-02, -1.1460e-02,  2.0166e-02, -1.9615e-02,  8.9328e-03,
         7.1829e-03, -1.3071e-02, -3.8185e-03,  7.6717e-03, -1.4157e-03,
        -4.7270e-03,  1.2372e-02, -2.0595e-02, -9.3040e-03,  6.8968e-03,
        -1.9427e-02,  1.1662e-02, -1.2214e-03, -1.4400e-02, -1.7940e-02,
        -7.7246e-03, -1.4954e-02,  1.5864e-02,  3.2722e-03,  9.0347e-03,
        -1.3284e-02,  8.4715e-03,  1.1226e-02, -7.0620e-04, -1.2915e-02,
         1.2222e-02,  1.1555e-02,  2.0457e-02,  1.2750e-02, -2.3105e-03,
        -7.0542e-03, -1.5973e-03,  2.9079e-03,  4.0541e-03, -2.0366e-02,
         1.7087e-02,  1.9270e-02, -8.2075e-03, -6.5670e-03, -1.9624e-02,
         2.3342e-03, -9.8628e-03, -1.1768e-02, -1.6328e-02, -1.2034e-02,
         8.4950e-03,  3.8774e-04, -9.8469e-03,  1.9726e-02,  1.9069e-02,
        -4.4115e-03,  2.0037e-02,  1.4195e-02,  1.5454e-02,  1.4273e-02,
         2.0243e-02, -7.4614e-03,  1.5089e-02,  4.4564e-03,  6.1203e-03,
        -1.6315e-02,  2.0524e-02,  7.5452e-03], device='cuda:0') 
 Parameter containing:
tensor([-1.0661e-02, -7.3722e-03,  1.5022e-02, -7.6840e-03, -3.1631e-03,
         6.8702e-03, -1.4887e-02, -5.9313e-03, -1.2507e-02,  8.9485e-04,
        -1.3247e-02, -1.3811e-02,  6.1957e-03, -1.8992e-03,  1.2227e-02,
         6.9227e-03,  1.6830e-02,  1.3891e-03,  8.9434e-03,  7.3975e-03,
         7.1849e-03,  5.5500e-03,  1.9451e-02, -1.2300e-02, -9.1325e-03,
        -1.3117e-02, -1.3138e-03,  1.4218e-02, -3.7476e-04, -6.6686e-04,
         1.8878e-02,  8.6152e-03,  2.1042e-03,  1.0414e-02, -1.9897e-02,
         1.1188e-02, -1.6170e-02, -1.1193e-03,  1.6834e-02,  6.5573e-05,
        -1.0926e-02,  1.1527e-02, -4.7833e-03,  1.0574e-02,  1.6873e-02,
         5.3255e-03, -1.6099e-02, -1.3154e-02,  8.9463e-04, -1.0303e-03,
         1.1128e-02,  2.9959e-03,  2.4695e-03,  3.9455e-03,  4.3082e-03,
         1.0356e-02, -1.3612e-03,  1.6151e-02,  1.1467e-02, -1.4060e-02,
         1.8191e-02, -1.1460e-02,  2.0166e-02, -1.9615e-02,  8.9328e-03,
         7.1829e-03, -1.3071e-02, -3.8185e-03,  7.6717e-03, -1.4157e-03,
        -4.7270e-03,  1.2372e-02, -2.0595e-02, -9.3040e-03,  6.8968e-03,
        -1.9427e-02,  1.1662e-02, -1.2214e-03, -1.4400e-02, -1.7940e-02,
        -7.7246e-03, -1.4954e-02,  1.5864e-02,  3.2722e-03,  9.0347e-03,
        -1.3284e-02,  8.4715e-03,  1.1226e-02, -7.0620e-04, -1.2915e-02,
         1.2222e-02,  1.1555e-02,  2.0457e-02,  1.2750e-02, -2.3105e-03,
        -7.0542e-03, -1.5973e-03,  2.9079e-03,  4.0541e-03, -2.0366e-02,
         1.7087e-02,  1.9270e-02, -8.2075e-03, -6.5670e-03, -1.9624e-02,
         2.3342e-03, -9.8628e-03, -1.1768e-02, -1.6328e-02, -1.2034e-02,
         8.4950e-03,  3.8774e-04, -9.8469e-03,  1.9726e-02,  1.9069e-02,
        -4.4115e-03,  2.0037e-02,  1.4195e-02,  1.5454e-02,  1.4273e-02,
         2.0243e-02, -7.4614e-03,  1.5089e-02,  4.4564e-03,  6.1203e-03,
        -1.6315e-02,  2.0524e-02,  7.5452e-03], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.weight 
 torch.Size([64, 128, 3, 3]) 
 True 
 tensor([[[[-4.3908e-03, -9.2284e-03, -1.1357e-02],
          [ 1.2326e-02,  3.0150e-03, -2.5972e-02],
          [-7.6797e-03,  4.1868e-03, -1.2618e-03]],

         [[-2.6891e-02,  2.3341e-02,  2.6466e-02],
          [-1.1972e-02,  2.8040e-02, -2.6045e-02],
          [-2.0380e-02,  2.6181e-04, -2.4062e-02]],

         [[-1.4853e-02,  2.5842e-03, -4.8739e-03],
          [-1.3772e-02,  1.7624e-02,  1.5821e-02],
          [-6.3581e-03,  2.4121e-03,  3.5872e-04]],

         ...,

         [[-2.2315e-02, -8.1604e-04, -1.7639e-02],
          [ 5.5457e-03,  1.7125e-02,  2.6313e-02],
          [ 2.7994e-02,  1.2100e-02, -5.6877e-03]],

         [[-1.5831e-02, -1.5097e-02, -2.0584e-02],
          [ 5.7343e-03,  2.1362e-02,  4.7113e-03],
          [ 2.7005e-02, -2.6926e-02,  2.9216e-02]],

         [[-2.4600e-03,  2.8147e-02, -1.5797e-02],
          [ 2.1335e-02,  9.9940e-03, -2.1425e-04],
          [-5.0555e-03,  3.9014e-03,  1.1591e-02]]],


        [[[ 2.1335e-02, -5.2331e-03,  7.3965e-03],
          [-2.6638e-02, -2.2801e-02,  8.2257e-03],
          [-7.8383e-03, -1.9158e-03,  2.4187e-02]],

         [[ 2.8499e-02,  9.1198e-03, -2.1059e-02],
          [ 6.3718e-03,  2.9197e-02, -1.1862e-02],
          [-2.8194e-02, -4.5023e-03,  8.4672e-03]],

         [[-2.8568e-02, -1.3489e-02,  3.2426e-03],
          [-1.0344e-02,  1.1973e-02, -2.1668e-02],
          [-1.0498e-02, -8.1254e-03, -1.7106e-02]],

         ...,

         [[ 2.4321e-03,  8.8229e-03, -2.6985e-02],
          [-1.0584e-02, -1.1485e-02,  1.9927e-03],
          [-2.6250e-02,  1.8878e-03,  7.1036e-04]],

         [[-7.8223e-03,  1.4530e-03, -8.0090e-03],
          [-5.2018e-03, -1.3081e-02, -2.0686e-03],
          [ 3.1905e-04,  2.7505e-02,  1.0362e-02]],

         [[-2.7917e-02, -1.1721e-02, -2.3744e-02],
          [-9.5473e-03,  7.5707e-03,  6.1408e-05],
          [ 2.4583e-03, -1.5994e-02, -2.6756e-02]]],


        [[[ 2.6299e-02, -2.4068e-02,  2.2644e-02],
          [-1.4244e-02,  2.6490e-02, -1.8916e-03],
          [-2.4077e-03,  1.6003e-03,  1.9854e-02]],

         [[ 1.2576e-02, -3.7182e-03, -2.2213e-02],
          [-1.0799e-02,  2.0975e-02, -1.0845e-02],
          [ 1.8667e-03, -2.3084e-03, -3.4898e-03]],

         [[-2.2652e-02,  7.3843e-04,  2.2932e-02],
          [ 1.7516e-02, -1.8209e-02,  3.7196e-03],
          [-5.5556e-03,  1.8537e-02, -1.1702e-02]],

         ...,

         [[-1.1670e-02,  2.7190e-02,  1.6082e-02],
          [ 8.1316e-03, -1.6936e-04,  9.8936e-03],
          [-6.9734e-03, -7.1382e-03,  2.6867e-03]],

         [[ 4.5082e-03,  2.7902e-02,  1.6686e-03],
          [-1.2354e-02,  1.4156e-02,  1.0012e-02],
          [-2.3134e-02, -1.6461e-02, -1.6942e-02]],

         [[-5.7916e-03, -1.2662e-02,  6.3359e-03],
          [ 9.6221e-04, -2.4896e-02, -1.8141e-02],
          [ 1.0687e-02,  2.1398e-02, -5.1098e-04]]],


        ...,


        [[[-4.7506e-03, -9.5420e-03, -3.0319e-03],
          [ 6.9646e-03,  2.3172e-02, -2.0009e-04],
          [ 2.6703e-02, -6.9262e-03, -1.8446e-02]],

         [[ 2.8918e-02, -2.9153e-02,  2.0735e-02],
          [ 2.8724e-02, -6.0497e-03,  1.9217e-03],
          [ 9.4781e-03, -1.5977e-02, -1.8906e-02]],

         [[ 1.5177e-02,  2.9124e-02,  2.8688e-02],
          [-1.2596e-02, -1.7628e-02, -2.8208e-02],
          [-2.7940e-02,  1.6117e-02,  2.0961e-02]],

         ...,

         [[ 1.4059e-02, -2.1528e-02, -4.6699e-03],
          [-1.2288e-02,  1.2542e-02,  2.7214e-02],
          [ 2.0415e-02, -2.7473e-02, -6.5005e-03]],

         [[-2.6200e-02,  9.3109e-03,  8.6454e-03],
          [-9.9466e-03, -5.2611e-03,  1.3639e-02],
          [-2.7207e-02, -3.9231e-03, -2.6526e-02]],

         [[ 6.8747e-03, -2.2610e-02, -2.0907e-02],
          [ 1.7191e-02, -1.6938e-02, -1.8445e-02],
          [ 2.4833e-02, -2.0741e-02,  1.4480e-02]]],


        [[[ 3.6748e-03, -2.3662e-02, -1.5052e-02],
          [-7.0739e-03,  1.1882e-02,  1.5156e-02],
          [-1.9089e-02,  2.4223e-02, -2.0887e-02]],

         [[ 8.5363e-03,  2.1410e-03,  7.9238e-03],
          [ 2.3154e-02, -4.3042e-03,  5.2406e-03],
          [-1.7242e-02, -1.8961e-02,  1.3820e-02]],

         [[-1.9734e-02,  2.3396e-02,  2.5331e-03],
          [-1.6541e-02,  1.7866e-02,  2.7201e-02],
          [-2.1394e-02, -2.6928e-02,  1.2790e-02]],

         ...,

         [[-2.2539e-02, -3.1202e-03, -1.1055e-03],
          [-1.2820e-02,  1.7844e-03,  2.5592e-02],
          [ 2.4354e-02,  2.7895e-02, -5.0889e-03]],

         [[ 1.0229e-02, -1.5838e-04, -1.7941e-02],
          [ 1.8212e-02,  4.0009e-03,  1.9115e-03],
          [-3.0285e-03,  2.1345e-02, -8.6629e-03]],

         [[ 4.4500e-03,  1.7151e-02,  2.4417e-02],
          [ 2.5774e-03,  2.4546e-02, -4.5034e-03],
          [ 5.4779e-03,  1.0743e-02,  2.6645e-02]]],


        [[[-6.8536e-03,  9.5256e-03,  1.7994e-02],
          [-7.2615e-03, -7.4189e-03, -2.7795e-02],
          [-1.4793e-02,  2.2437e-03,  2.8357e-03]],

         [[ 1.8654e-02, -2.1784e-02,  2.5422e-02],
          [-2.7589e-02,  2.3178e-02, -2.7953e-02],
          [-1.0264e-02, -7.5492e-04, -2.6603e-02]],

         [[-9.2084e-03,  1.8254e-02, -1.2496e-02],
          [ 4.8627e-04,  1.0046e-03,  1.0144e-02],
          [ 2.3606e-02, -9.0638e-04, -2.2524e-02]],

         ...,

         [[-1.4839e-03,  1.7410e-02,  1.2871e-02],
          [-1.5144e-02, -6.2327e-03, -1.3436e-02],
          [ 2.5017e-02,  3.5588e-03,  2.9083e-02]],

         [[-2.0323e-02, -1.8001e-02, -9.0115e-03],
          [ 6.3355e-03,  1.3046e-02, -1.6894e-02],
          [ 1.7688e-02, -1.1434e-02,  5.4853e-03]],

         [[ 2.0193e-02, -8.7135e-04,  1.5516e-02],
          [-2.6453e-02,  2.0490e-03, -1.7318e-02],
          [-3.3640e-03, -1.1853e-02,  2.0941e-03]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[-4.3908e-03, -9.2284e-03, -1.1357e-02],
          [ 1.2326e-02,  3.0150e-03, -2.5972e-02],
          [-7.6797e-03,  4.1868e-03, -1.2618e-03]],

         [[-2.6891e-02,  2.3341e-02,  2.6466e-02],
          [-1.1972e-02,  2.8040e-02, -2.6045e-02],
          [-2.0380e-02,  2.6181e-04, -2.4062e-02]],

         [[-1.4853e-02,  2.5842e-03, -4.8739e-03],
          [-1.3772e-02,  1.7624e-02,  1.5821e-02],
          [-6.3581e-03,  2.4121e-03,  3.5872e-04]],

         ...,

         [[-2.2315e-02, -8.1604e-04, -1.7639e-02],
          [ 5.5457e-03,  1.7125e-02,  2.6313e-02],
          [ 2.7994e-02,  1.2100e-02, -5.6877e-03]],

         [[-1.5831e-02, -1.5097e-02, -2.0584e-02],
          [ 5.7343e-03,  2.1362e-02,  4.7113e-03],
          [ 2.7005e-02, -2.6926e-02,  2.9216e-02]],

         [[-2.4600e-03,  2.8147e-02, -1.5797e-02],
          [ 2.1335e-02,  9.9940e-03, -2.1425e-04],
          [-5.0555e-03,  3.9014e-03,  1.1591e-02]]],


        [[[ 2.1335e-02, -5.2331e-03,  7.3965e-03],
          [-2.6638e-02, -2.2801e-02,  8.2257e-03],
          [-7.8383e-03, -1.9158e-03,  2.4187e-02]],

         [[ 2.8499e-02,  9.1198e-03, -2.1059e-02],
          [ 6.3718e-03,  2.9197e-02, -1.1862e-02],
          [-2.8194e-02, -4.5023e-03,  8.4672e-03]],

         [[-2.8568e-02, -1.3489e-02,  3.2426e-03],
          [-1.0344e-02,  1.1973e-02, -2.1668e-02],
          [-1.0498e-02, -8.1254e-03, -1.7106e-02]],

         ...,

         [[ 2.4321e-03,  8.8229e-03, -2.6985e-02],
          [-1.0584e-02, -1.1485e-02,  1.9927e-03],
          [-2.6250e-02,  1.8878e-03,  7.1036e-04]],

         [[-7.8223e-03,  1.4530e-03, -8.0090e-03],
          [-5.2018e-03, -1.3081e-02, -2.0686e-03],
          [ 3.1905e-04,  2.7505e-02,  1.0362e-02]],

         [[-2.7917e-02, -1.1721e-02, -2.3744e-02],
          [-9.5473e-03,  7.5707e-03,  6.1408e-05],
          [ 2.4583e-03, -1.5994e-02, -2.6756e-02]]],


        [[[ 2.6299e-02, -2.4068e-02,  2.2644e-02],
          [-1.4244e-02,  2.6490e-02, -1.8916e-03],
          [-2.4077e-03,  1.6003e-03,  1.9854e-02]],

         [[ 1.2576e-02, -3.7182e-03, -2.2213e-02],
          [-1.0799e-02,  2.0975e-02, -1.0845e-02],
          [ 1.8667e-03, -2.3084e-03, -3.4898e-03]],

         [[-2.2652e-02,  7.3843e-04,  2.2932e-02],
          [ 1.7516e-02, -1.8209e-02,  3.7196e-03],
          [-5.5556e-03,  1.8537e-02, -1.1702e-02]],

         ...,

         [[-1.1670e-02,  2.7190e-02,  1.6082e-02],
          [ 8.1316e-03, -1.6936e-04,  9.8936e-03],
          [-6.9734e-03, -7.1382e-03,  2.6867e-03]],

         [[ 4.5082e-03,  2.7902e-02,  1.6686e-03],
          [-1.2354e-02,  1.4156e-02,  1.0012e-02],
          [-2.3134e-02, -1.6461e-02, -1.6942e-02]],

         [[-5.7916e-03, -1.2662e-02,  6.3359e-03],
          [ 9.6221e-04, -2.4896e-02, -1.8141e-02],
          [ 1.0687e-02,  2.1398e-02, -5.1098e-04]]],


        ...,


        [[[-4.7506e-03, -9.5420e-03, -3.0319e-03],
          [ 6.9646e-03,  2.3172e-02, -2.0009e-04],
          [ 2.6703e-02, -6.9262e-03, -1.8446e-02]],

         [[ 2.8918e-02, -2.9153e-02,  2.0735e-02],
          [ 2.8724e-02, -6.0497e-03,  1.9217e-03],
          [ 9.4781e-03, -1.5977e-02, -1.8906e-02]],

         [[ 1.5177e-02,  2.9124e-02,  2.8688e-02],
          [-1.2596e-02, -1.7628e-02, -2.8208e-02],
          [-2.7940e-02,  1.6117e-02,  2.0961e-02]],

         ...,

         [[ 1.4059e-02, -2.1528e-02, -4.6699e-03],
          [-1.2288e-02,  1.2542e-02,  2.7214e-02],
          [ 2.0415e-02, -2.7473e-02, -6.5005e-03]],

         [[-2.6200e-02,  9.3109e-03,  8.6454e-03],
          [-9.9466e-03, -5.2611e-03,  1.3639e-02],
          [-2.7207e-02, -3.9231e-03, -2.6526e-02]],

         [[ 6.8747e-03, -2.2610e-02, -2.0907e-02],
          [ 1.7191e-02, -1.6938e-02, -1.8445e-02],
          [ 2.4833e-02, -2.0741e-02,  1.4480e-02]]],


        [[[ 3.6748e-03, -2.3662e-02, -1.5052e-02],
          [-7.0739e-03,  1.1882e-02,  1.5156e-02],
          [-1.9089e-02,  2.4223e-02, -2.0887e-02]],

         [[ 8.5363e-03,  2.1410e-03,  7.9238e-03],
          [ 2.3154e-02, -4.3042e-03,  5.2406e-03],
          [-1.7242e-02, -1.8961e-02,  1.3820e-02]],

         [[-1.9734e-02,  2.3396e-02,  2.5331e-03],
          [-1.6541e-02,  1.7866e-02,  2.7201e-02],
          [-2.1394e-02, -2.6928e-02,  1.2790e-02]],

         ...,

         [[-2.2539e-02, -3.1202e-03, -1.1055e-03],
          [-1.2820e-02,  1.7844e-03,  2.5592e-02],
          [ 2.4354e-02,  2.7895e-02, -5.0889e-03]],

         [[ 1.0229e-02, -1.5838e-04, -1.7941e-02],
          [ 1.8212e-02,  4.0009e-03,  1.9115e-03],
          [-3.0285e-03,  2.1345e-02, -8.6629e-03]],

         [[ 4.4500e-03,  1.7151e-02,  2.4417e-02],
          [ 2.5774e-03,  2.4546e-02, -4.5034e-03],
          [ 5.4779e-03,  1.0743e-02,  2.6645e-02]]],


        [[[-6.8536e-03,  9.5256e-03,  1.7994e-02],
          [-7.2615e-03, -7.4189e-03, -2.7795e-02],
          [-1.4793e-02,  2.2437e-03,  2.8357e-03]],

         [[ 1.8654e-02, -2.1784e-02,  2.5422e-02],
          [-2.7589e-02,  2.3178e-02, -2.7953e-02],
          [-1.0264e-02, -7.5492e-04, -2.6603e-02]],

         [[-9.2084e-03,  1.8254e-02, -1.2496e-02],
          [ 4.8627e-04,  1.0046e-03,  1.0144e-02],
          [ 2.3606e-02, -9.0638e-04, -2.2524e-02]],

         ...,

         [[-1.4839e-03,  1.7410e-02,  1.2871e-02],
          [-1.5144e-02, -6.2327e-03, -1.3436e-02],
          [ 2.5017e-02,  3.5588e-03,  2.9083e-02]],

         [[-2.0323e-02, -1.8001e-02, -9.0115e-03],
          [ 6.3355e-03,  1.3046e-02, -1.6894e-02],
          [ 1.7688e-02, -1.1434e-02,  5.4853e-03]],

         [[ 2.0193e-02, -8.7135e-04,  1.5516e-02],
          [-2.6453e-02,  2.0490e-03, -1.7318e-02],
          [-3.3640e-03, -1.1853e-02,  2.0941e-03]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.bias 
 torch.Size([64]) 
 True 
 tensor([ 0.0107, -0.0232, -0.0218, -0.0193,  0.0026,  0.0202,  0.0025,  0.0005,
        -0.0007,  0.0114,  0.0245, -0.0133,  0.0021, -0.0011, -0.0009,  0.0238,
         0.0126,  0.0066,  0.0169, -0.0026,  0.0222, -0.0016,  0.0221, -0.0242,
         0.0250, -0.0207, -0.0081,  0.0215,  0.0196, -0.0102,  0.0281, -0.0016,
        -0.0184, -0.0134, -0.0171, -0.0008, -0.0182, -0.0072, -0.0228, -0.0252,
        -0.0048, -0.0170,  0.0056,  0.0033,  0.0034, -0.0125,  0.0236,  0.0113,
         0.0081, -0.0123,  0.0124,  0.0151,  0.0268, -0.0220,  0.0019, -0.0066,
        -0.0164,  0.0252,  0.0280,  0.0055, -0.0284, -0.0232, -0.0209, -0.0100],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0107, -0.0232, -0.0218, -0.0193,  0.0026,  0.0202,  0.0025,  0.0005,
        -0.0007,  0.0114,  0.0245, -0.0133,  0.0021, -0.0011, -0.0009,  0.0238,
         0.0126,  0.0066,  0.0169, -0.0026,  0.0222, -0.0016,  0.0221, -0.0242,
         0.0250, -0.0207, -0.0081,  0.0215,  0.0196, -0.0102,  0.0281, -0.0016,
        -0.0184, -0.0134, -0.0171, -0.0008, -0.0182, -0.0072, -0.0228, -0.0252,
        -0.0048, -0.0170,  0.0056,  0.0033,  0.0034, -0.0125,  0.0236,  0.0113,
         0.0081, -0.0123,  0.0124,  0.0151,  0.0268, -0.0220,  0.0019, -0.0066,
        -0.0164,  0.0252,  0.0280,  0.0055, -0.0284, -0.0232, -0.0209, -0.0100],
       device='cuda:0', requires_grad=True)
parameters of the network fc1.weight 
 torch.Size([256, 667776]) 
 True 
 tensor([[-1.0069e-03, -4.2835e-04,  5.5927e-04,  ..., -2.6651e-04,
          2.0578e-04,  6.2249e-04],
        [-1.7987e-04, -8.8207e-04, -6.0186e-04,  ...,  9.7394e-04,
          9.9115e-04, -5.8017e-04],
        [-4.4770e-04,  3.0353e-04,  7.8043e-04,  ...,  9.0856e-04,
          9.1818e-04, -1.0956e-03],
        ...,
        [ 2.8898e-04, -7.5632e-04, -5.0165e-04,  ..., -7.2234e-04,
          6.5324e-05,  6.4748e-04],
        [-1.5189e-05, -5.3029e-04, -2.0269e-04,  ...,  1.3982e-04,
         -9.3320e-04,  1.1364e-03],
        [-1.2590e-05, -1.0263e-04,  5.5427e-05,  ...,  8.2428e-04,
          4.6360e-04, -1.0691e-03]], device='cuda:0') 
 Parameter containing:
tensor([[-1.0069e-03, -4.2835e-04,  5.5927e-04,  ..., -2.6651e-04,
          2.0578e-04,  6.2249e-04],
        [-1.7987e-04, -8.8207e-04, -6.0186e-04,  ...,  9.7394e-04,
          9.9115e-04, -5.8017e-04],
        [-4.4770e-04,  3.0353e-04,  7.8043e-04,  ...,  9.0856e-04,
          9.1818e-04, -1.0956e-03],
        ...,
        [ 2.8898e-04, -7.5632e-04, -5.0165e-04,  ..., -7.2234e-04,
          6.5324e-05,  6.4748e-04],
        [-1.5189e-05, -5.3029e-04, -2.0269e-04,  ...,  1.3982e-04,
         -9.3320e-04,  1.1364e-03],
        [-1.2590e-05, -1.0263e-04,  5.5427e-05,  ...,  8.2428e-04,
          4.6360e-04, -1.0691e-03]], device='cuda:0', requires_grad=True)
parameters of the network fc1.bias 
 torch.Size([256]) 
 True 
 tensor([-1.9868e-04, -6.5322e-04,  3.1079e-04,  8.7414e-04, -2.6902e-04,
         1.0841e-03, -7.8641e-04, -1.0841e-03, -8.8710e-04,  1.1107e-03,
        -1.1858e-03, -9.3978e-04,  9.4834e-04, -1.0113e-03,  9.6737e-04,
        -7.7943e-04, -5.1047e-04, -2.7240e-04, -1.1960e-04,  1.7706e-04,
        -6.8124e-04, -2.2787e-04,  1.0520e-03,  9.3661e-05, -5.4447e-04,
        -6.3177e-04, -5.1637e-04, -9.6086e-04, -1.1808e-03,  9.1154e-04,
        -5.0478e-04,  1.0298e-03, -1.0494e-03, -8.5195e-04,  1.1964e-03,
        -8.4524e-04,  1.1904e-03,  3.0823e-05,  7.2413e-04, -5.1238e-05,
         6.1476e-04,  8.6862e-04, -5.6277e-04, -1.0875e-03,  3.6217e-04,
        -6.8563e-05, -5.7160e-04,  8.7438e-04,  8.4144e-04,  6.4988e-04,
        -6.0289e-06, -9.2713e-05,  8.6604e-04,  6.1060e-04,  9.6793e-04,
         2.5401e-04,  4.4369e-05, -7.2673e-05, -9.8421e-05,  3.6526e-04,
         1.0712e-03, -9.1274e-04, -3.7051e-04, -1.0755e-03,  3.3543e-04,
        -4.2438e-04,  4.2967e-06, -1.0063e-03, -7.9797e-04,  1.1395e-03,
         6.1615e-04, -1.2197e-03, -5.8928e-04,  4.5548e-04,  1.1451e-03,
        -3.3951e-04, -9.5144e-04,  3.2460e-04, -3.6818e-04,  6.4165e-04,
         6.3020e-05,  2.9548e-04,  6.6696e-04,  4.5011e-04,  1.7483e-04,
        -5.8180e-04,  4.9593e-04, -9.7360e-04, -5.2503e-04,  3.9657e-04,
         3.6857e-04,  4.0723e-05, -4.1842e-04, -9.4489e-04,  7.9753e-04,
        -2.5187e-04, -3.4937e-04,  1.1962e-03, -3.9985e-04,  1.3554e-04,
        -9.4407e-04, -7.1777e-04,  1.0846e-03, -3.1123e-04,  9.7740e-04,
         3.6228e-04,  6.4617e-04, -8.1485e-04,  3.4383e-04,  6.5994e-04,
         5.5419e-04,  4.4969e-04,  1.1356e-04,  1.0222e-03, -7.2488e-04,
         5.6160e-04,  4.2961e-04, -8.3396e-04,  9.7888e-04,  8.0554e-04,
         5.7216e-04,  5.9225e-04, -4.9787e-05,  5.6773e-04, -2.9481e-04,
        -1.0236e-03,  9.3050e-04, -6.4180e-04,  8.6711e-04, -3.0254e-04,
        -7.7913e-04, -6.6708e-06,  5.7409e-04,  2.1673e-04, -5.1889e-04,
        -6.2778e-04,  3.0688e-04,  1.5896e-04,  4.0276e-04,  1.0732e-03,
        -4.7194e-04, -5.0734e-04,  7.5965e-04, -2.8849e-04, -1.1213e-03,
         1.0868e-03,  8.0458e-05,  3.4724e-04, -3.0055e-04, -1.1001e-03,
        -6.3223e-04, -3.5182e-04, -5.4852e-04, -6.7745e-04,  4.6680e-04,
        -1.0534e-04,  3.2940e-04,  1.1672e-03, -5.2357e-04, -1.1693e-04,
         6.0950e-05, -9.6347e-04,  6.4593e-04,  1.0592e-03, -2.6240e-04,
         4.4288e-04, -5.6069e-04,  1.1217e-04,  4.9361e-04, -2.5963e-04,
         1.0633e-03, -3.8942e-04, -1.1419e-03, -5.8253e-04, -3.5626e-04,
        -1.7291e-04,  5.0060e-04, -6.4484e-05, -9.9419e-04,  3.8482e-04,
         8.4598e-04,  6.5673e-04, -1.0965e-03, -3.9392e-04,  1.1545e-03,
        -4.5222e-04, -5.1766e-04,  2.7600e-04, -1.6467e-04,  5.7618e-04,
        -4.3876e-05,  9.1180e-05, -1.1645e-03, -2.5324e-04, -7.4876e-04,
         8.5504e-04,  4.4987e-05, -7.8022e-04,  4.7926e-04,  3.3961e-04,
        -7.2469e-04,  2.0454e-04,  9.3872e-04,  6.4037e-04, -1.0785e-03,
        -7.2606e-04, -8.8986e-04, -1.2054e-03,  4.2361e-04,  4.7338e-04,
        -3.2620e-04, -1.1597e-03, -2.8077e-04,  2.0685e-04, -9.2665e-04,
         2.3485e-04, -3.8964e-06,  7.6020e-04,  3.6314e-04,  1.1977e-03,
         3.8969e-04,  9.7070e-04,  8.8695e-05,  9.6368e-04,  3.9366e-04,
         6.4887e-05,  1.0831e-03, -4.3377e-04,  1.0111e-03, -4.4993e-04,
         2.8770e-04, -4.5037e-04,  7.9821e-04,  1.0237e-03, -7.3373e-05,
         4.8081e-04,  6.3564e-04, -6.2319e-04,  2.0364e-04, -1.2924e-04,
         6.5789e-05,  1.1983e-03, -3.3132e-04,  7.1323e-04,  3.9204e-05,
         9.3435e-04,  6.0188e-04, -9.1264e-04,  1.6947e-05,  4.7986e-04,
        -6.1832e-04,  1.1514e-03,  6.5274e-04,  5.3600e-04, -1.0364e-03,
         1.2034e-03], device='cuda:0') 
 Parameter containing:
tensor([-1.9868e-04, -6.5322e-04,  3.1079e-04,  8.7414e-04, -2.6902e-04,
         1.0841e-03, -7.8641e-04, -1.0841e-03, -8.8710e-04,  1.1107e-03,
        -1.1858e-03, -9.3978e-04,  9.4834e-04, -1.0113e-03,  9.6737e-04,
        -7.7943e-04, -5.1047e-04, -2.7240e-04, -1.1960e-04,  1.7706e-04,
        -6.8124e-04, -2.2787e-04,  1.0520e-03,  9.3661e-05, -5.4447e-04,
        -6.3177e-04, -5.1637e-04, -9.6086e-04, -1.1808e-03,  9.1154e-04,
        -5.0478e-04,  1.0298e-03, -1.0494e-03, -8.5195e-04,  1.1964e-03,
        -8.4524e-04,  1.1904e-03,  3.0823e-05,  7.2413e-04, -5.1238e-05,
         6.1476e-04,  8.6862e-04, -5.6277e-04, -1.0875e-03,  3.6217e-04,
        -6.8563e-05, -5.7160e-04,  8.7438e-04,  8.4144e-04,  6.4988e-04,
        -6.0289e-06, -9.2713e-05,  8.6604e-04,  6.1060e-04,  9.6793e-04,
         2.5401e-04,  4.4369e-05, -7.2673e-05, -9.8421e-05,  3.6526e-04,
         1.0712e-03, -9.1274e-04, -3.7051e-04, -1.0755e-03,  3.3543e-04,
        -4.2438e-04,  4.2967e-06, -1.0063e-03, -7.9797e-04,  1.1395e-03,
         6.1615e-04, -1.2197e-03, -5.8928e-04,  4.5548e-04,  1.1451e-03,
        -3.3951e-04, -9.5144e-04,  3.2460e-04, -3.6818e-04,  6.4165e-04,
         6.3020e-05,  2.9548e-04,  6.6696e-04,  4.5011e-04,  1.7483e-04,
        -5.8180e-04,  4.9593e-04, -9.7360e-04, -5.2503e-04,  3.9657e-04,
         3.6857e-04,  4.0723e-05, -4.1842e-04, -9.4489e-04,  7.9753e-04,
        -2.5187e-04, -3.4937e-04,  1.1962e-03, -3.9985e-04,  1.3554e-04,
        -9.4407e-04, -7.1777e-04,  1.0846e-03, -3.1123e-04,  9.7740e-04,
         3.6228e-04,  6.4617e-04, -8.1485e-04,  3.4383e-04,  6.5994e-04,
         5.5419e-04,  4.4969e-04,  1.1356e-04,  1.0222e-03, -7.2488e-04,
         5.6160e-04,  4.2961e-04, -8.3396e-04,  9.7888e-04,  8.0554e-04,
         5.7216e-04,  5.9225e-04, -4.9787e-05,  5.6773e-04, -2.9481e-04,
        -1.0236e-03,  9.3050e-04, -6.4180e-04,  8.6711e-04, -3.0254e-04,
        -7.7913e-04, -6.6708e-06,  5.7409e-04,  2.1673e-04, -5.1889e-04,
        -6.2778e-04,  3.0688e-04,  1.5896e-04,  4.0276e-04,  1.0732e-03,
        -4.7194e-04, -5.0734e-04,  7.5965e-04, -2.8849e-04, -1.1213e-03,
         1.0868e-03,  8.0458e-05,  3.4724e-04, -3.0055e-04, -1.1001e-03,
        -6.3223e-04, -3.5182e-04, -5.4852e-04, -6.7745e-04,  4.6680e-04,
        -1.0534e-04,  3.2940e-04,  1.1672e-03, -5.2357e-04, -1.1693e-04,
         6.0950e-05, -9.6347e-04,  6.4593e-04,  1.0592e-03, -2.6240e-04,
         4.4288e-04, -5.6069e-04,  1.1217e-04,  4.9361e-04, -2.5963e-04,
         1.0633e-03, -3.8942e-04, -1.1419e-03, -5.8253e-04, -3.5626e-04,
        -1.7291e-04,  5.0060e-04, -6.4484e-05, -9.9419e-04,  3.8482e-04,
         8.4598e-04,  6.5673e-04, -1.0965e-03, -3.9392e-04,  1.1545e-03,
        -4.5222e-04, -5.1766e-04,  2.7600e-04, -1.6467e-04,  5.7618e-04,
        -4.3876e-05,  9.1180e-05, -1.1645e-03, -2.5324e-04, -7.4876e-04,
         8.5504e-04,  4.4987e-05, -7.8022e-04,  4.7926e-04,  3.3961e-04,
        -7.2469e-04,  2.0454e-04,  9.3872e-04,  6.4037e-04, -1.0785e-03,
        -7.2606e-04, -8.8986e-04, -1.2054e-03,  4.2361e-04,  4.7338e-04,
        -3.2620e-04, -1.1597e-03, -2.8077e-04,  2.0685e-04, -9.2665e-04,
         2.3485e-04, -3.8964e-06,  7.6020e-04,  3.6314e-04,  1.1977e-03,
         3.8969e-04,  9.7070e-04,  8.8695e-05,  9.6368e-04,  3.9366e-04,
         6.4887e-05,  1.0831e-03, -4.3377e-04,  1.0111e-03, -4.4993e-04,
         2.8770e-04, -4.5037e-04,  7.9821e-04,  1.0237e-03, -7.3373e-05,
         4.8081e-04,  6.3564e-04, -6.2319e-04,  2.0364e-04, -1.2924e-04,
         6.5789e-05,  1.1983e-03, -3.3132e-04,  7.1323e-04,  3.9204e-05,
         9.3435e-04,  6.0188e-04, -9.1264e-04,  1.6947e-05,  4.7986e-04,
        -6.1832e-04,  1.1514e-03,  6.5274e-04,  5.3600e-04, -1.0364e-03,
         1.2034e-03], device='cuda:0', requires_grad=True)
parameters of the network fc2.weight 
 torch.Size([128, 256]) 
 True 
 tensor([[-0.0578,  0.0109, -0.0130,  ...,  0.0087,  0.0478,  0.0243],
        [ 0.0039, -0.0555, -0.0310,  ...,  0.0540,  0.0312,  0.0452],
        [ 0.0097, -0.0291, -0.0055,  ..., -0.0219, -0.0069, -0.0258],
        ...,
        [ 0.0009,  0.0088, -0.0162,  ..., -0.0610,  0.0469, -0.0375],
        [ 0.0283, -0.0357,  0.0466,  ...,  0.0587,  0.0155, -0.0042],
        [ 0.0083, -0.0125, -0.0245,  ..., -0.0553, -0.0334, -0.0087]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0578,  0.0109, -0.0130,  ...,  0.0087,  0.0478,  0.0243],
        [ 0.0039, -0.0555, -0.0310,  ...,  0.0540,  0.0312,  0.0452],
        [ 0.0097, -0.0291, -0.0055,  ..., -0.0219, -0.0069, -0.0258],
        ...,
        [ 0.0009,  0.0088, -0.0162,  ..., -0.0610,  0.0469, -0.0375],
        [ 0.0283, -0.0357,  0.0466,  ...,  0.0587,  0.0155, -0.0042],
        [ 0.0083, -0.0125, -0.0245,  ..., -0.0553, -0.0334, -0.0087]],
       device='cuda:0', requires_grad=True)
parameters of the network fc2.bias 
 torch.Size([128]) 
 True 
 tensor([-2.9207e-02,  1.5706e-02, -3.2602e-02, -2.7015e-02, -2.8522e-02,
         4.5340e-02,  2.0749e-02, -4.1373e-02,  4.5492e-02, -6.0043e-02,
        -5.5097e-02,  3.4724e-02,  3.7333e-03,  6.9489e-03, -5.8734e-02,
         1.4666e-02, -2.3624e-03,  4.3246e-02,  4.4298e-02,  1.2674e-02,
         2.3007e-02, -3.0631e-02, -6.2189e-02,  5.1874e-02, -2.0188e-03,
         6.1057e-02, -2.0172e-02, -9.6709e-03, -3.5532e-02, -2.6449e-02,
        -3.2679e-02, -4.9587e-03,  2.2409e-02, -5.9538e-02, -9.7833e-03,
        -2.9544e-02,  5.2589e-02, -5.5791e-02, -2.6498e-02, -1.1810e-02,
         3.9486e-02,  3.4092e-02, -6.0169e-02,  1.6759e-02,  1.5416e-02,
        -7.7781e-03,  2.8942e-02,  1.7677e-02,  5.4727e-02,  5.8224e-02,
         1.4309e-02,  6.1338e-02, -3.8081e-02,  6.0045e-02,  2.7429e-02,
         8.4990e-03, -3.7907e-02,  4.5780e-02,  3.5873e-02, -1.6329e-02,
        -1.7929e-02,  5.9549e-02, -5.6194e-02, -5.1788e-02, -3.2651e-02,
        -1.9704e-02, -4.2261e-02, -2.2614e-02, -1.5842e-02,  1.4555e-02,
         2.8809e-02,  1.4073e-04, -1.1537e-02,  4.0577e-02,  5.9474e-02,
        -5.9570e-03,  5.8946e-02, -1.0062e-02,  5.2686e-02, -4.5359e-03,
        -7.6780e-04, -2.3783e-02, -4.0555e-02,  5.7888e-02,  3.2923e-02,
        -4.4481e-02, -8.4466e-03, -5.5579e-02, -4.1793e-02, -2.6176e-02,
        -1.7661e-02, -5.6940e-02,  4.7470e-02, -2.2159e-03, -4.5972e-02,
        -1.7529e-02, -4.3725e-02,  4.5855e-02,  1.2337e-02, -5.5626e-02,
         3.7301e-02, -1.5783e-02, -1.9327e-02,  6.0086e-02, -4.4511e-02,
        -5.0981e-02, -3.7804e-02, -3.5842e-02,  3.1752e-02, -1.0386e-02,
         3.2067e-02, -4.8630e-02,  3.0688e-02, -4.6747e-02,  1.3841e-02,
         4.8572e-03, -5.2261e-02, -4.5858e-02, -3.3692e-02, -5.8050e-02,
         1.7790e-02, -4.1422e-03, -8.0347e-05,  6.0635e-02, -5.3912e-02,
         3.3161e-02, -2.1043e-02, -3.8206e-02], device='cuda:0') 
 Parameter containing:
tensor([-2.9207e-02,  1.5706e-02, -3.2602e-02, -2.7015e-02, -2.8522e-02,
         4.5340e-02,  2.0749e-02, -4.1373e-02,  4.5492e-02, -6.0043e-02,
        -5.5097e-02,  3.4724e-02,  3.7333e-03,  6.9489e-03, -5.8734e-02,
         1.4666e-02, -2.3624e-03,  4.3246e-02,  4.4298e-02,  1.2674e-02,
         2.3007e-02, -3.0631e-02, -6.2189e-02,  5.1874e-02, -2.0188e-03,
         6.1057e-02, -2.0172e-02, -9.6709e-03, -3.5532e-02, -2.6449e-02,
        -3.2679e-02, -4.9587e-03,  2.2409e-02, -5.9538e-02, -9.7833e-03,
        -2.9544e-02,  5.2589e-02, -5.5791e-02, -2.6498e-02, -1.1810e-02,
         3.9486e-02,  3.4092e-02, -6.0169e-02,  1.6759e-02,  1.5416e-02,
        -7.7781e-03,  2.8942e-02,  1.7677e-02,  5.4727e-02,  5.8224e-02,
         1.4309e-02,  6.1338e-02, -3.8081e-02,  6.0045e-02,  2.7429e-02,
         8.4990e-03, -3.7907e-02,  4.5780e-02,  3.5873e-02, -1.6329e-02,
        -1.7929e-02,  5.9549e-02, -5.6194e-02, -5.1788e-02, -3.2651e-02,
        -1.9704e-02, -4.2261e-02, -2.2614e-02, -1.5842e-02,  1.4555e-02,
         2.8809e-02,  1.4073e-04, -1.1537e-02,  4.0577e-02,  5.9474e-02,
        -5.9570e-03,  5.8946e-02, -1.0062e-02,  5.2686e-02, -4.5359e-03,
        -7.6780e-04, -2.3783e-02, -4.0555e-02,  5.7888e-02,  3.2923e-02,
        -4.4481e-02, -8.4466e-03, -5.5579e-02, -4.1793e-02, -2.6176e-02,
        -1.7661e-02, -5.6940e-02,  4.7470e-02, -2.2159e-03, -4.5972e-02,
        -1.7529e-02, -4.3725e-02,  4.5855e-02,  1.2337e-02, -5.5626e-02,
         3.7301e-02, -1.5783e-02, -1.9327e-02,  6.0086e-02, -4.4511e-02,
        -5.0981e-02, -3.7804e-02, -3.5842e-02,  3.1752e-02, -1.0386e-02,
         3.2067e-02, -4.8630e-02,  3.0688e-02, -4.6747e-02,  1.3841e-02,
         4.8572e-03, -5.2261e-02, -4.5858e-02, -3.3692e-02, -5.8050e-02,
         1.7790e-02, -4.1422e-03, -8.0347e-05,  6.0635e-02, -5.3912e-02,
         3.3161e-02, -2.1043e-02, -3.8206e-02], device='cuda:0',
       requires_grad=True)
parameters of the network fc3.weight 
 torch.Size([64, 128]) 
 True 
 tensor([[-0.0465,  0.0120,  0.0612,  ..., -0.0828, -0.0811, -0.0016],
        [-0.0356,  0.0641,  0.0445,  ...,  0.0049,  0.0320, -0.0881],
        [ 0.0800, -0.0671,  0.0319,  ...,  0.0038,  0.0581, -0.0066],
        ...,
        [-0.0762, -0.0507, -0.0871,  ...,  0.0135, -0.0394,  0.0354],
        [ 0.0851, -0.0234,  0.0126,  ..., -0.0038, -0.0056, -0.0705],
        [-0.0075,  0.0411,  0.0047,  ..., -0.0608, -0.0613,  0.0220]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0465,  0.0120,  0.0612,  ..., -0.0828, -0.0811, -0.0016],
        [-0.0356,  0.0641,  0.0445,  ...,  0.0049,  0.0320, -0.0881],
        [ 0.0800, -0.0671,  0.0319,  ...,  0.0038,  0.0581, -0.0066],
        ...,
        [-0.0762, -0.0507, -0.0871,  ...,  0.0135, -0.0394,  0.0354],
        [ 0.0851, -0.0234,  0.0126,  ..., -0.0038, -0.0056, -0.0705],
        [-0.0075,  0.0411,  0.0047,  ..., -0.0608, -0.0613,  0.0220]],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.bias 
 torch.Size([64]) 
 True 
 tensor([ 0.0203, -0.0349, -0.0280,  0.0878, -0.0732,  0.0817,  0.0425, -0.0364,
        -0.0294,  0.0174,  0.0476, -0.0258,  0.0288,  0.0141,  0.0870,  0.0102,
         0.0870, -0.0399, -0.0458,  0.0217, -0.0150,  0.0186, -0.0034, -0.0095,
        -0.0525, -0.0080,  0.0050, -0.0714, -0.0636, -0.0262,  0.0822,  0.0223,
         0.0447, -0.0212,  0.0032, -0.0263,  0.0422, -0.0074, -0.0869,  0.0279,
        -0.0514,  0.0639, -0.0747, -0.0667,  0.0573,  0.0151,  0.0235,  0.0877,
         0.0429, -0.0103,  0.0395, -0.0233, -0.0701,  0.0855,  0.0848,  0.0832,
        -0.0837, -0.0295,  0.0207, -0.0594, -0.0027, -0.0609, -0.0557,  0.0115],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0203, -0.0349, -0.0280,  0.0878, -0.0732,  0.0817,  0.0425, -0.0364,
        -0.0294,  0.0174,  0.0476, -0.0258,  0.0288,  0.0141,  0.0870,  0.0102,
         0.0870, -0.0399, -0.0458,  0.0217, -0.0150,  0.0186, -0.0034, -0.0095,
        -0.0525, -0.0080,  0.0050, -0.0714, -0.0636, -0.0262,  0.0822,  0.0223,
         0.0447, -0.0212,  0.0032, -0.0263,  0.0422, -0.0074, -0.0869,  0.0279,
        -0.0514,  0.0639, -0.0747, -0.0667,  0.0573,  0.0151,  0.0235,  0.0877,
         0.0429, -0.0103,  0.0395, -0.0233, -0.0701,  0.0855,  0.0848,  0.0832,
        -0.0837, -0.0295,  0.0207, -0.0594, -0.0027, -0.0609, -0.0557,  0.0115],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.weight 
 torch.Size([6796, 64]) 
 True 
 tensor([[ 0.0088,  0.1027, -0.1012,  ..., -0.1120, -0.0032,  0.0612],
        [ 0.0103,  0.1100, -0.0491,  ..., -0.0154, -0.0554, -0.0462],
        [ 0.0094,  0.0197, -0.0532,  ..., -0.1090, -0.0474,  0.0767],
        ...,
        [-0.0554, -0.1176, -0.0281,  ..., -0.0485,  0.0725,  0.0539],
        [ 0.1062,  0.0788,  0.0290,  ...,  0.0956, -0.0364, -0.1089],
        [ 0.1023,  0.0788,  0.0898,  ...,  0.0456, -0.0971, -0.0338]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0088,  0.1027, -0.1012,  ..., -0.1120, -0.0032,  0.0612],
        [ 0.0103,  0.1100, -0.0491,  ..., -0.0154, -0.0554, -0.0462],
        [ 0.0094,  0.0197, -0.0532,  ..., -0.1090, -0.0474,  0.0767],
        ...,
        [-0.0554, -0.1176, -0.0281,  ..., -0.0485,  0.0725,  0.0539],
        [ 0.1062,  0.0788,  0.0290,  ...,  0.0956, -0.0364, -0.1089],
        [ 0.1023,  0.0788,  0.0898,  ...,  0.0456, -0.0971, -0.0338]],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.bias 
 torch.Size([6796]) 
 True 
 tensor([-0.0055,  0.0117, -0.0362,  ...,  0.1242, -0.0348, -0.0679],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0055,  0.0117, -0.0362,  ...,  0.1242, -0.0348, -0.0679],
       device='cuda:0', requires_grad=True)

Passing event 1007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([[0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        ...,
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>) 
result1.shape: torch.Size([20, 6796])

Passing two random events from the network before training 
result1: tensor([[0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        ...,
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001],
        [0.0001, 0.0001, 0.0001,  ..., 0.0002, 0.0001, 0.0001]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>) 
result1.shape: torch.Size([20, 6796]) 
input: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]



load_model False 
TraEvN 10008 
BatchSize 30 
EpochNum 30 
epoch_save 5 
LrVal 0.001 
weight_decay 0.0001 
startmesh 305 
endmesh 306 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[[[ 0.2383,  0.1575, -0.0435],
          [ 0.0569, -0.2188, -0.1998],
          [-0.0270, -0.1831, -0.2389]]],


        [[[-0.2850,  0.1435,  0.3125],
          [-0.1816, -0.1380,  0.1669],
          [-0.0226, -0.3060, -0.0633]]],


        [[[ 0.2465, -0.0663, -0.1445],
          [-0.3184,  0.3057, -0.2877],
          [-0.0132,  0.1813, -0.0591]]],


        ...,


        [[[-0.3151, -0.2271,  0.3241],
          [ 0.1955,  0.0635,  0.0644],
          [ 0.1088,  0.0897,  0.3138]]],


        [[[ 0.0420, -0.1841, -0.0102],
          [ 0.2455, -0.1698,  0.1422],
          [ 0.1488,  0.2610,  0.1555]]],


        [[[-0.2617, -0.3333, -0.3231],
          [ 0.3116, -0.0205, -0.1662],
          [ 0.0109,  0.0397, -0.0266]]]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0185, -0.1267,  0.1294, -0.1903,  0.2338, -0.0782, -0.1303, -0.0748,
         0.1189,  0.1698, -0.1671,  0.3086, -0.1953,  0.3068,  0.0723, -0.0747,
         0.1020,  0.1195,  0.0546,  0.0812, -0.3067, -0.1737,  0.1010, -0.1478,
        -0.0986, -0.0523,  0.3317, -0.0189, -0.1229, -0.2630,  0.2896,  0.3328,
         0.0126,  0.0710,  0.3076, -0.1535,  0.0972,  0.1198, -0.0280, -0.1401,
        -0.3053, -0.1457, -0.0563, -0.2556, -0.2083,  0.0595, -0.1547, -0.2478,
         0.3162,  0.0363, -0.0533, -0.3205,  0.1221,  0.2718, -0.3093, -0.1514,
         0.0300,  0.1155,  0.2883,  0.2100, -0.0973,  0.1131,  0.2504,  0.2171,
         0.1765,  0.1052, -0.2090, -0.3102, -0.2029,  0.3228, -0.2588, -0.0415,
        -0.0831,  0.0677,  0.2075, -0.1880,  0.2397, -0.0937, -0.0155, -0.1706,
         0.1221,  0.1347, -0.1905,  0.2649, -0.3038, -0.0025, -0.0080, -0.3279,
        -0.2510,  0.2898, -0.0918,  0.3210, -0.2206,  0.1057, -0.2229, -0.2039,
        -0.2493,  0.2751, -0.1990,  0.3275, -0.0646,  0.1853,  0.0072,  0.0439,
        -0.0068, -0.0258,  0.2684, -0.0400,  0.0982, -0.2672, -0.2272, -0.1329,
        -0.2423, -0.0904,  0.3314, -0.1477, -0.2881, -0.2131, -0.2503, -0.2731,
        -0.2992, -0.0048, -0.1193, -0.2922,  0.2040, -0.1593, -0.3030,  0.2042,
         0.1657, -0.0981,  0.0564, -0.1416,  0.1127,  0.3042, -0.0188,  0.0320,
        -0.1461, -0.1469, -0.1316, -0.0077,  0.2906,  0.1858,  0.0941, -0.0235,
         0.0076,  0.3007, -0.2217,  0.0163,  0.0691,  0.0948, -0.2421, -0.2986,
         0.2494, -0.0400,  0.2069,  0.1248,  0.1810, -0.0326, -0.0351, -0.3118,
        -0.2438,  0.2671, -0.3244,  0.1757, -0.1733,  0.0246, -0.0351,  0.1500,
        -0.2434,  0.1079,  0.3046, -0.2871, -0.1103,  0.2959, -0.0700,  0.1239,
        -0.1808,  0.3012, -0.2461, -0.0819,  0.1563,  0.0621,  0.2886,  0.0689,
        -0.2838,  0.1578, -0.3159, -0.1053, -0.3067, -0.2897, -0.2367, -0.2575,
        -0.1779,  0.3066, -0.2242,  0.0012, -0.3256,  0.2263,  0.0078, -0.0604,
        -0.2311, -0.0567,  0.2515, -0.2258,  0.1421,  0.0317,  0.0249, -0.3192,
         0.2068,  0.0467,  0.3249,  0.1557, -0.0289,  0.0573,  0.1321,  0.1813,
        -0.0284, -0.1451,  0.1927,  0.1483, -0.1850, -0.2059,  0.3142, -0.1563,
        -0.0666, -0.0391,  0.0493,  0.3168,  0.1107,  0.2505,  0.2268, -0.3006,
         0.3256,  0.0104, -0.0067, -0.1143, -0.1870, -0.0560, -0.0997, -0.0430,
         0.1666,  0.1634,  0.0367,  0.0502, -0.2819,  0.0481,  0.2934,  0.2168,
        -0.1861, -0.3161, -0.1477, -0.0369,  0.2916,  0.0761, -0.2699, -0.0284],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[ 1.8518e-02,  1.7343e-02,  1.6491e-02],
          [-1.3222e-02,  2.6858e-03, -2.0318e-03],
          [-1.5090e-04, -1.6452e-02,  3.1283e-03]],

         [[ 5.5905e-04, -1.3446e-02,  1.8126e-02],
          [ 9.9819e-03,  1.0818e-02, -6.8022e-03],
          [-2.7990e-03,  6.3931e-03, -8.4826e-03]],

         [[-1.5281e-02,  8.3341e-03,  6.5729e-03],
          [-1.8624e-02,  1.6971e-02, -9.1123e-03],
          [-2.9290e-03,  9.3015e-03, -5.7409e-03]],

         ...,

         [[-2.2820e-03, -2.0114e-02, -8.5909e-03],
          [-6.2805e-03,  6.5119e-03, -8.0568e-03],
          [-5.3270e-03,  3.4531e-03, -1.2583e-02]],

         [[-6.5223e-03,  1.0483e-02, -1.2318e-02],
          [ 1.3707e-03, -8.3808e-03, -4.2296e-03],
          [-7.2243e-03, -1.2766e-02,  1.5881e-02]],

         [[-1.7502e-02,  5.1128e-05,  1.8182e-02],
          [ 7.6667e-04, -1.7604e-02,  1.5878e-02],
          [ 1.8874e-02, -1.1421e-04,  9.1849e-03]]],


        [[[ 9.4916e-03,  1.6092e-02, -1.7230e-03],
          [ 1.2185e-02, -1.1458e-02, -1.9427e-02],
          [-5.8144e-03, -5.7467e-03,  1.5769e-03]],

         [[ 1.5999e-02, -6.6052e-03, -1.3966e-02],
          [-8.5006e-03, -7.1113e-03,  1.8794e-03],
          [ 1.6646e-02, -1.6013e-02, -1.6310e-02]],

         [[-8.8369e-03,  1.9738e-02,  6.7687e-04],
          [ 1.8551e-02,  1.2582e-02, -1.0046e-02],
          [-1.2806e-02, -1.3561e-02, -1.6215e-02]],

         ...,

         [[-1.3553e-02,  1.7977e-02, -5.0749e-03],
          [-1.5342e-02,  4.0731e-03, -6.1313e-03],
          [ 9.3063e-03,  1.8088e-02, -7.0382e-03]],

         [[-2.0349e-02, -1.3965e-02, -8.3833e-03],
          [ 4.7798e-03, -9.1987e-03,  5.0925e-03],
          [-1.5929e-03,  1.1142e-02,  1.3469e-02]],

         [[-2.5020e-03,  1.7009e-02,  1.1172e-02],
          [ 7.0514e-03, -1.3873e-02, -6.5967e-03],
          [-2.0045e-02, -7.8256e-03, -1.7041e-02]]],


        [[[ 1.6269e-02,  1.5927e-02, -1.8475e-02],
          [-1.3888e-02,  2.4544e-03,  1.5529e-02],
          [ 1.5180e-02, -1.8267e-02, -1.1479e-02]],

         [[-4.1011e-04, -1.2225e-02,  2.3379e-03],
          [-6.7566e-03, -1.9061e-02,  1.5387e-03],
          [-8.1653e-03,  3.0268e-03,  1.4101e-02]],

         [[-7.4434e-03,  2.0690e-02,  1.7805e-02],
          [-5.5702e-03,  4.6546e-03,  1.6559e-02],
          [-1.5657e-02, -9.4924e-03, -1.8271e-02]],

         ...,

         [[ 8.8958e-03,  9.6594e-03,  1.4067e-02],
          [-6.9624e-03, -4.1259e-03, -1.7170e-02],
          [ 7.4064e-03, -5.6641e-03, -1.1783e-02]],

         [[ 1.0967e-02, -1.0706e-02,  6.2122e-03],
          [ 8.1177e-03,  1.4647e-02,  1.7037e-02],
          [ 1.9177e-02, -4.9361e-03,  1.9788e-02]],

         [[-8.0832e-04, -1.7109e-02,  1.2186e-02],
          [-3.1744e-03,  6.0315e-03,  1.6562e-02],
          [ 6.3938e-04, -6.7061e-03,  1.7078e-02]]],


        ...,


        [[[ 7.0668e-04,  1.3391e-02,  5.0596e-03],
          [ 1.4484e-02, -1.1923e-02,  1.2358e-03],
          [ 1.0214e-02, -1.5241e-04,  3.5349e-03]],

         [[-1.9553e-02,  4.9087e-03,  1.6317e-02],
          [-1.1088e-02, -6.5627e-04,  1.5402e-03],
          [-7.7368e-04,  2.5010e-03, -1.2583e-02]],

         [[ 7.7782e-03, -1.9910e-02,  1.4544e-02],
          [ 1.6985e-02,  1.7548e-02, -2.3733e-03],
          [-5.2540e-04,  4.7942e-03, -1.8358e-02]],

         ...,

         [[ 1.8878e-02,  1.6916e-02, -1.4352e-02],
          [ 1.3252e-02,  1.3036e-02, -5.8544e-04],
          [ 1.5168e-02,  7.6178e-03, -3.4094e-03]],

         [[-1.0495e-03, -1.4098e-03, -1.4868e-02],
          [ 3.7459e-03,  1.7560e-02,  5.0871e-03],
          [-4.8853e-03, -1.6629e-02, -1.0997e-02]],

         [[-1.2365e-02,  4.1890e-04, -1.8931e-02],
          [-3.2404e-03, -1.5077e-02, -2.6005e-03],
          [-8.6292e-03,  1.6760e-02,  8.0258e-03]]],


        [[[-7.7165e-03, -1.5468e-02, -1.6146e-02],
          [ 4.9172e-04, -1.3479e-02, -1.2056e-02],
          [-1.2283e-03, -4.4910e-03,  1.6560e-02]],

         [[-1.1789e-02, -1.7096e-02, -9.5391e-03],
          [ 9.6148e-03,  2.4343e-04, -5.5385e-03],
          [ 2.8805e-03, -2.0257e-02,  4.1763e-04]],

         [[ 6.4463e-03,  5.8187e-03, -4.1769e-03],
          [-6.5868e-03, -1.7491e-02, -1.4908e-02],
          [ 1.2062e-02, -1.7756e-02,  1.6574e-02]],

         ...,

         [[-1.5205e-03,  7.7329e-03, -1.0404e-02],
          [-3.1625e-04, -2.9982e-03, -2.0099e-02],
          [ 1.1491e-02,  1.3096e-02,  1.6636e-02]],

         [[-9.5561e-03, -4.0303e-03, -1.8900e-02],
          [-7.8985e-03, -1.0210e-03,  2.4811e-03],
          [ 6.7835e-03,  1.9087e-02, -7.4041e-03]],

         [[ 8.5488e-03, -1.8454e-02, -1.3822e-04],
          [ 4.7280e-03, -2.3073e-03,  1.0949e-02],
          [-1.5782e-03,  1.5257e-02, -1.5300e-02]]],


        [[[-6.2741e-03, -1.3099e-02,  1.3305e-02],
          [-1.6291e-02,  1.1201e-02, -1.0343e-02],
          [ 4.9102e-03,  1.7024e-02,  1.2227e-02]],

         [[-2.9121e-04, -1.9380e-02, -1.3003e-02],
          [-1.4697e-02, -1.2720e-02, -5.7799e-03],
          [-1.8195e-02, -1.3924e-02, -1.9482e-02]],

         [[-3.8990e-03,  4.3739e-03, -9.5573e-03],
          [ 1.3160e-03,  1.6507e-02,  1.5016e-02],
          [ 1.6845e-03,  2.5929e-03,  1.0615e-02]],

         ...,

         [[ 1.6231e-02,  1.2877e-02, -1.5514e-02],
          [ 3.4954e-04,  1.3122e-03,  1.4617e-02],
          [ 2.0279e-02, -1.3344e-02,  3.1980e-03]],

         [[ 9.2230e-03,  1.5310e-02, -3.8817e-03],
          [ 1.6615e-02,  1.6276e-02,  2.0688e-02],
          [ 8.0918e-04,  1.9210e-02,  3.8404e-04]],

         [[ 1.5321e-02,  1.5612e-02,  4.1096e-03],
          [ 7.6520e-04,  8.6669e-03, -1.6070e-02],
          [ 9.3083e-03, -4.3352e-05, -3.3455e-03]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([-1.0661e-02, -7.3722e-03,  1.5022e-02, -7.6840e-03, -3.1631e-03,
         6.8702e-03, -1.4887e-02, -5.9313e-03, -1.2507e-02,  8.9485e-04,
        -1.3247e-02, -1.3811e-02,  6.1957e-03, -1.8992e-03,  1.2227e-02,
         6.9227e-03,  1.6830e-02,  1.3891e-03,  8.9434e-03,  7.3975e-03,
         7.1849e-03,  5.5500e-03,  1.9451e-02, -1.2300e-02, -9.1325e-03,
        -1.3117e-02, -1.3138e-03,  1.4218e-02, -3.7476e-04, -6.6686e-04,
         1.8878e-02,  8.6152e-03,  2.1042e-03,  1.0414e-02, -1.9897e-02,
         1.1188e-02, -1.6170e-02, -1.1193e-03,  1.6834e-02,  6.5573e-05,
        -1.0926e-02,  1.1527e-02, -4.7833e-03,  1.0574e-02,  1.6873e-02,
         5.3255e-03, -1.6099e-02, -1.3154e-02,  8.9463e-04, -1.0303e-03,
         1.1128e-02,  2.9959e-03,  2.4695e-03,  3.9455e-03,  4.3082e-03,
         1.0356e-02, -1.3612e-03,  1.6151e-02,  1.1467e-02, -1.4060e-02,
         1.8191e-02, -1.1460e-02,  2.0166e-02, -1.9615e-02,  8.9328e-03,
         7.1829e-03, -1.3071e-02, -3.8185e-03,  7.6717e-03, -1.4157e-03,
        -4.7270e-03,  1.2372e-02, -2.0595e-02, -9.3040e-03,  6.8968e-03,
        -1.9427e-02,  1.1662e-02, -1.2214e-03, -1.4400e-02, -1.7940e-02,
        -7.7246e-03, -1.4954e-02,  1.5864e-02,  3.2722e-03,  9.0347e-03,
        -1.3284e-02,  8.4715e-03,  1.1226e-02, -7.0620e-04, -1.2915e-02,
         1.2222e-02,  1.1555e-02,  2.0457e-02,  1.2750e-02, -2.3105e-03,
        -7.0542e-03, -1.5973e-03,  2.9079e-03,  4.0541e-03, -2.0366e-02,
         1.7087e-02,  1.9270e-02, -8.2075e-03, -6.5670e-03, -1.9624e-02,
         2.3342e-03, -9.8628e-03, -1.1768e-02, -1.6328e-02, -1.2034e-02,
         8.4950e-03,  3.8774e-04, -9.8469e-03,  1.9726e-02,  1.9069e-02,
        -4.4115e-03,  2.0037e-02,  1.4195e-02,  1.5454e-02,  1.4273e-02,
         2.0243e-02, -7.4614e-03,  1.5089e-02,  4.4564e-03,  6.1203e-03,
        -1.6315e-02,  2.0524e-02,  7.5452e-03], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[[[-4.3908e-03, -9.2284e-03, -1.1357e-02],
          [ 1.2326e-02,  3.0150e-03, -2.5972e-02],
          [-7.6797e-03,  4.1868e-03, -1.2618e-03]],

         [[-2.6891e-02,  2.3341e-02,  2.6466e-02],
          [-1.1972e-02,  2.8040e-02, -2.6045e-02],
          [-2.0380e-02,  2.6181e-04, -2.4062e-02]],

         [[-1.4853e-02,  2.5842e-03, -4.8739e-03],
          [-1.3772e-02,  1.7624e-02,  1.5821e-02],
          [-6.3581e-03,  2.4121e-03,  3.5872e-04]],

         ...,

         [[-2.2315e-02, -8.1604e-04, -1.7639e-02],
          [ 5.5457e-03,  1.7125e-02,  2.6313e-02],
          [ 2.7994e-02,  1.2100e-02, -5.6877e-03]],

         [[-1.5831e-02, -1.5097e-02, -2.0584e-02],
          [ 5.7343e-03,  2.1362e-02,  4.7113e-03],
          [ 2.7005e-02, -2.6926e-02,  2.9216e-02]],

         [[-2.4600e-03,  2.8147e-02, -1.5797e-02],
          [ 2.1335e-02,  9.9940e-03, -2.1425e-04],
          [-5.0555e-03,  3.9014e-03,  1.1591e-02]]],


        [[[ 2.1335e-02, -5.2331e-03,  7.3965e-03],
          [-2.6638e-02, -2.2801e-02,  8.2257e-03],
          [-7.8383e-03, -1.9158e-03,  2.4187e-02]],

         [[ 2.8499e-02,  9.1198e-03, -2.1059e-02],
          [ 6.3718e-03,  2.9197e-02, -1.1862e-02],
          [-2.8194e-02, -4.5023e-03,  8.4672e-03]],

         [[-2.8568e-02, -1.3489e-02,  3.2426e-03],
          [-1.0344e-02,  1.1973e-02, -2.1668e-02],
          [-1.0498e-02, -8.1254e-03, -1.7106e-02]],

         ...,

         [[ 2.4321e-03,  8.8229e-03, -2.6985e-02],
          [-1.0584e-02, -1.1485e-02,  1.9927e-03],
          [-2.6250e-02,  1.8878e-03,  7.1036e-04]],

         [[-7.8223e-03,  1.4530e-03, -8.0090e-03],
          [-5.2018e-03, -1.3081e-02, -2.0686e-03],
          [ 3.1905e-04,  2.7505e-02,  1.0362e-02]],

         [[-2.7917e-02, -1.1721e-02, -2.3744e-02],
          [-9.5473e-03,  7.5707e-03,  6.1408e-05],
          [ 2.4583e-03, -1.5994e-02, -2.6756e-02]]],


        [[[ 2.6299e-02, -2.4068e-02,  2.2644e-02],
          [-1.4244e-02,  2.6490e-02, -1.8916e-03],
          [-2.4077e-03,  1.6003e-03,  1.9854e-02]],

         [[ 1.2576e-02, -3.7182e-03, -2.2213e-02],
          [-1.0799e-02,  2.0975e-02, -1.0845e-02],
          [ 1.8667e-03, -2.3084e-03, -3.4898e-03]],

         [[-2.2652e-02,  7.3843e-04,  2.2932e-02],
          [ 1.7516e-02, -1.8209e-02,  3.7196e-03],
          [-5.5556e-03,  1.8537e-02, -1.1702e-02]],

         ...,

         [[-1.1670e-02,  2.7190e-02,  1.6082e-02],
          [ 8.1316e-03, -1.6936e-04,  9.8936e-03],
          [-6.9734e-03, -7.1382e-03,  2.6867e-03]],

         [[ 4.5082e-03,  2.7902e-02,  1.6686e-03],
          [-1.2354e-02,  1.4156e-02,  1.0012e-02],
          [-2.3134e-02, -1.6461e-02, -1.6942e-02]],

         [[-5.7916e-03, -1.2662e-02,  6.3359e-03],
          [ 9.6221e-04, -2.4896e-02, -1.8141e-02],
          [ 1.0687e-02,  2.1398e-02, -5.1098e-04]]],


        ...,


        [[[-4.7506e-03, -9.5420e-03, -3.0319e-03],
          [ 6.9646e-03,  2.3172e-02, -2.0009e-04],
          [ 2.6703e-02, -6.9262e-03, -1.8446e-02]],

         [[ 2.8918e-02, -2.9153e-02,  2.0735e-02],
          [ 2.8724e-02, -6.0497e-03,  1.9217e-03],
          [ 9.4781e-03, -1.5977e-02, -1.8906e-02]],

         [[ 1.5177e-02,  2.9124e-02,  2.8688e-02],
          [-1.2596e-02, -1.7628e-02, -2.8208e-02],
          [-2.7940e-02,  1.6117e-02,  2.0961e-02]],

         ...,

         [[ 1.4059e-02, -2.1528e-02, -4.6699e-03],
          [-1.2288e-02,  1.2542e-02,  2.7214e-02],
          [ 2.0415e-02, -2.7473e-02, -6.5005e-03]],

         [[-2.6200e-02,  9.3109e-03,  8.6454e-03],
          [-9.9466e-03, -5.2611e-03,  1.3639e-02],
          [-2.7207e-02, -3.9231e-03, -2.6526e-02]],

         [[ 6.8747e-03, -2.2610e-02, -2.0907e-02],
          [ 1.7191e-02, -1.6938e-02, -1.8445e-02],
          [ 2.4833e-02, -2.0741e-02,  1.4480e-02]]],


        [[[ 3.6748e-03, -2.3662e-02, -1.5052e-02],
          [-7.0739e-03,  1.1882e-02,  1.5156e-02],
          [-1.9089e-02,  2.4223e-02, -2.0887e-02]],

         [[ 8.5363e-03,  2.1410e-03,  7.9238e-03],
          [ 2.3154e-02, -4.3042e-03,  5.2406e-03],
          [-1.7242e-02, -1.8961e-02,  1.3820e-02]],

         [[-1.9734e-02,  2.3396e-02,  2.5331e-03],
          [-1.6541e-02,  1.7866e-02,  2.7201e-02],
          [-2.1394e-02, -2.6928e-02,  1.2790e-02]],

         ...,

         [[-2.2539e-02, -3.1202e-03, -1.1055e-03],
          [-1.2820e-02,  1.7844e-03,  2.5592e-02],
          [ 2.4354e-02,  2.7895e-02, -5.0889e-03]],

         [[ 1.0229e-02, -1.5838e-04, -1.7941e-02],
          [ 1.8212e-02,  4.0009e-03,  1.9115e-03],
          [-3.0285e-03,  2.1345e-02, -8.6629e-03]],

         [[ 4.4500e-03,  1.7151e-02,  2.4417e-02],
          [ 2.5774e-03,  2.4546e-02, -4.5034e-03],
          [ 5.4779e-03,  1.0743e-02,  2.6645e-02]]],


        [[[-6.8536e-03,  9.5256e-03,  1.7994e-02],
          [-7.2615e-03, -7.4189e-03, -2.7795e-02],
          [-1.4793e-02,  2.2437e-03,  2.8357e-03]],

         [[ 1.8654e-02, -2.1784e-02,  2.5422e-02],
          [-2.7589e-02,  2.3178e-02, -2.7953e-02],
          [-1.0264e-02, -7.5492e-04, -2.6603e-02]],

         [[-9.2084e-03,  1.8254e-02, -1.2496e-02],
          [ 4.8627e-04,  1.0046e-03,  1.0144e-02],
          [ 2.3606e-02, -9.0638e-04, -2.2524e-02]],

         ...,

         [[-1.4839e-03,  1.7410e-02,  1.2871e-02],
          [-1.5144e-02, -6.2327e-03, -1.3436e-02],
          [ 2.5017e-02,  3.5588e-03,  2.9083e-02]],

         [[-2.0323e-02, -1.8001e-02, -9.0115e-03],
          [ 6.3355e-03,  1.3046e-02, -1.6894e-02],
          [ 1.7688e-02, -1.1434e-02,  5.4853e-03]],

         [[ 2.0193e-02, -8.7135e-04,  1.5516e-02],
          [-2.6453e-02,  2.0490e-03, -1.7318e-02],
          [-3.3640e-03, -1.1853e-02,  2.0941e-03]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([ 0.0107, -0.0232, -0.0218, -0.0193,  0.0026,  0.0202,  0.0025,  0.0005,
        -0.0007,  0.0114,  0.0245, -0.0133,  0.0021, -0.0011, -0.0009,  0.0238,
         0.0126,  0.0066,  0.0169, -0.0026,  0.0222, -0.0016,  0.0221, -0.0242,
         0.0250, -0.0207, -0.0081,  0.0215,  0.0196, -0.0102,  0.0281, -0.0016,
        -0.0184, -0.0134, -0.0171, -0.0008, -0.0182, -0.0072, -0.0228, -0.0252,
        -0.0048, -0.0170,  0.0056,  0.0033,  0.0034, -0.0125,  0.0236,  0.0113,
         0.0081, -0.0123,  0.0124,  0.0151,  0.0268, -0.0220,  0.0019, -0.0066,
        -0.0164,  0.0252,  0.0280,  0.0055, -0.0284, -0.0232, -0.0209, -0.0100],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-1.0069e-03, -4.2835e-04,  5.5927e-04,  ..., -2.6651e-04,
          2.0578e-04,  6.2249e-04],
        [-1.7987e-04, -8.8207e-04, -6.0186e-04,  ...,  9.7394e-04,
          9.9115e-04, -5.8017e-04],
        [-4.4770e-04,  3.0353e-04,  7.8043e-04,  ...,  9.0856e-04,
          9.1818e-04, -1.0956e-03],
        ...,
        [ 2.8898e-04, -7.5632e-04, -5.0165e-04,  ..., -7.2234e-04,
          6.5324e-05,  6.4748e-04],
        [-1.5189e-05, -5.3029e-04, -2.0269e-04,  ...,  1.3982e-04,
         -9.3320e-04,  1.1364e-03],
        [-1.2590e-05, -1.0263e-04,  5.5427e-05,  ...,  8.2428e-04,
          4.6360e-04, -1.0691e-03]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-1.9868e-04, -6.5322e-04,  3.1079e-04,  8.7414e-04, -2.6902e-04,
         1.0841e-03, -7.8641e-04, -1.0841e-03, -8.8710e-04,  1.1107e-03,
        -1.1858e-03, -9.3978e-04,  9.4834e-04, -1.0113e-03,  9.6737e-04,
        -7.7943e-04, -5.1047e-04, -2.7240e-04, -1.1960e-04,  1.7706e-04,
        -6.8124e-04, -2.2787e-04,  1.0520e-03,  9.3661e-05, -5.4447e-04,
        -6.3177e-04, -5.1637e-04, -9.6086e-04, -1.1808e-03,  9.1154e-04,
        -5.0478e-04,  1.0298e-03, -1.0494e-03, -8.5195e-04,  1.1964e-03,
        -8.4524e-04,  1.1904e-03,  3.0823e-05,  7.2413e-04, -5.1238e-05,
         6.1476e-04,  8.6862e-04, -5.6277e-04, -1.0875e-03,  3.6217e-04,
        -6.8563e-05, -5.7160e-04,  8.7438e-04,  8.4144e-04,  6.4988e-04,
        -6.0289e-06, -9.2713e-05,  8.6604e-04,  6.1060e-04,  9.6793e-04,
         2.5401e-04,  4.4369e-05, -7.2673e-05, -9.8421e-05,  3.6526e-04,
         1.0712e-03, -9.1274e-04, -3.7051e-04, -1.0755e-03,  3.3543e-04,
        -4.2438e-04,  4.2967e-06, -1.0063e-03, -7.9797e-04,  1.1395e-03,
         6.1615e-04, -1.2197e-03, -5.8928e-04,  4.5548e-04,  1.1451e-03,
        -3.3951e-04, -9.5144e-04,  3.2460e-04, -3.6818e-04,  6.4165e-04,
         6.3020e-05,  2.9548e-04,  6.6696e-04,  4.5011e-04,  1.7483e-04,
        -5.8180e-04,  4.9593e-04, -9.7360e-04, -5.2503e-04,  3.9657e-04,
         3.6857e-04,  4.0723e-05, -4.1842e-04, -9.4489e-04,  7.9753e-04,
        -2.5187e-04, -3.4937e-04,  1.1962e-03, -3.9985e-04,  1.3554e-04,
        -9.4407e-04, -7.1777e-04,  1.0846e-03, -3.1123e-04,  9.7740e-04,
         3.6228e-04,  6.4617e-04, -8.1485e-04,  3.4383e-04,  6.5994e-04,
         5.5419e-04,  4.4969e-04,  1.1356e-04,  1.0222e-03, -7.2488e-04,
         5.6160e-04,  4.2961e-04, -8.3396e-04,  9.7888e-04,  8.0554e-04,
         5.7216e-04,  5.9225e-04, -4.9787e-05,  5.6773e-04, -2.9481e-04,
        -1.0236e-03,  9.3050e-04, -6.4180e-04,  8.6711e-04, -3.0254e-04,
        -7.7913e-04, -6.6708e-06,  5.7409e-04,  2.1673e-04, -5.1889e-04,
        -6.2778e-04,  3.0688e-04,  1.5896e-04,  4.0276e-04,  1.0732e-03,
        -4.7194e-04, -5.0734e-04,  7.5965e-04, -2.8849e-04, -1.1213e-03,
         1.0868e-03,  8.0458e-05,  3.4724e-04, -3.0055e-04, -1.1001e-03,
        -6.3223e-04, -3.5182e-04, -5.4852e-04, -6.7745e-04,  4.6680e-04,
        -1.0534e-04,  3.2940e-04,  1.1672e-03, -5.2357e-04, -1.1693e-04,
         6.0950e-05, -9.6347e-04,  6.4593e-04,  1.0592e-03, -2.6240e-04,
         4.4288e-04, -5.6069e-04,  1.1217e-04,  4.9361e-04, -2.5963e-04,
         1.0633e-03, -3.8942e-04, -1.1419e-03, -5.8253e-04, -3.5626e-04,
        -1.7291e-04,  5.0060e-04, -6.4484e-05, -9.9419e-04,  3.8482e-04,
         8.4598e-04,  6.5673e-04, -1.0965e-03, -3.9392e-04,  1.1545e-03,
        -4.5222e-04, -5.1766e-04,  2.7600e-04, -1.6467e-04,  5.7618e-04,
        -4.3876e-05,  9.1180e-05, -1.1645e-03, -2.5324e-04, -7.4876e-04,
         8.5504e-04,  4.4987e-05, -7.8022e-04,  4.7926e-04,  3.3961e-04,
        -7.2469e-04,  2.0454e-04,  9.3872e-04,  6.4037e-04, -1.0785e-03,
        -7.2606e-04, -8.8986e-04, -1.2054e-03,  4.2361e-04,  4.7338e-04,
        -3.2620e-04, -1.1597e-03, -2.8077e-04,  2.0685e-04, -9.2665e-04,
         2.3485e-04, -3.8964e-06,  7.6020e-04,  3.6314e-04,  1.1977e-03,
         3.8969e-04,  9.7070e-04,  8.8695e-05,  9.6368e-04,  3.9366e-04,
         6.4887e-05,  1.0831e-03, -4.3377e-04,  1.0111e-03, -4.4993e-04,
         2.8770e-04, -4.5037e-04,  7.9821e-04,  1.0237e-03, -7.3373e-05,
         4.8081e-04,  6.3564e-04, -6.2319e-04,  2.0364e-04, -1.2924e-04,
         6.5789e-05,  1.1983e-03, -3.3132e-04,  7.1323e-04,  3.9204e-05,
         9.3435e-04,  6.0188e-04, -9.1264e-04,  1.6947e-05,  4.7986e-04,
        -6.1832e-04,  1.1514e-03,  6.5274e-04,  5.3600e-04, -1.0364e-03,
         1.2034e-03], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0578,  0.0109, -0.0130,  ...,  0.0087,  0.0478,  0.0243],
        [ 0.0039, -0.0555, -0.0310,  ...,  0.0540,  0.0312,  0.0452],
        [ 0.0097, -0.0291, -0.0055,  ..., -0.0219, -0.0069, -0.0258],
        ...,
        [ 0.0009,  0.0088, -0.0162,  ..., -0.0610,  0.0469, -0.0375],
        [ 0.0283, -0.0357,  0.0466,  ...,  0.0587,  0.0155, -0.0042],
        [ 0.0083, -0.0125, -0.0245,  ..., -0.0553, -0.0334, -0.0087]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-2.9207e-02,  1.5706e-02, -3.2602e-02, -2.7015e-02, -2.8522e-02,
         4.5340e-02,  2.0749e-02, -4.1373e-02,  4.5492e-02, -6.0043e-02,
        -5.5097e-02,  3.4724e-02,  3.7333e-03,  6.9489e-03, -5.8734e-02,
         1.4666e-02, -2.3624e-03,  4.3246e-02,  4.4298e-02,  1.2674e-02,
         2.3007e-02, -3.0631e-02, -6.2189e-02,  5.1874e-02, -2.0188e-03,
         6.1057e-02, -2.0172e-02, -9.6709e-03, -3.5532e-02, -2.6449e-02,
        -3.2679e-02, -4.9587e-03,  2.2409e-02, -5.9538e-02, -9.7833e-03,
        -2.9544e-02,  5.2589e-02, -5.5791e-02, -2.6498e-02, -1.1810e-02,
         3.9486e-02,  3.4092e-02, -6.0169e-02,  1.6759e-02,  1.5416e-02,
        -7.7781e-03,  2.8942e-02,  1.7677e-02,  5.4727e-02,  5.8224e-02,
         1.4309e-02,  6.1338e-02, -3.8081e-02,  6.0045e-02,  2.7429e-02,
         8.4990e-03, -3.7907e-02,  4.5780e-02,  3.5873e-02, -1.6329e-02,
        -1.7929e-02,  5.9549e-02, -5.6194e-02, -5.1788e-02, -3.2651e-02,
        -1.9704e-02, -4.2261e-02, -2.2614e-02, -1.5842e-02,  1.4555e-02,
         2.8809e-02,  1.4073e-04, -1.1537e-02,  4.0577e-02,  5.9474e-02,
        -5.9570e-03,  5.8946e-02, -1.0062e-02,  5.2686e-02, -4.5359e-03,
        -7.6780e-04, -2.3783e-02, -4.0555e-02,  5.7888e-02,  3.2923e-02,
        -4.4481e-02, -8.4466e-03, -5.5579e-02, -4.1793e-02, -2.6176e-02,
        -1.7661e-02, -5.6940e-02,  4.7470e-02, -2.2159e-03, -4.5972e-02,
        -1.7529e-02, -4.3725e-02,  4.5855e-02,  1.2337e-02, -5.5626e-02,
         3.7301e-02, -1.5783e-02, -1.9327e-02,  6.0086e-02, -4.4511e-02,
        -5.0981e-02, -3.7804e-02, -3.5842e-02,  3.1752e-02, -1.0386e-02,
         3.2067e-02, -4.8630e-02,  3.0688e-02, -4.6747e-02,  1.3841e-02,
         4.8572e-03, -5.2261e-02, -4.5858e-02, -3.3692e-02, -5.8050e-02,
         1.7790e-02, -4.1422e-03, -8.0347e-05,  6.0635e-02, -5.3912e-02,
         3.3161e-02, -2.1043e-02, -3.8206e-02], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[-0.0465,  0.0120,  0.0612,  ..., -0.0828, -0.0811, -0.0016],
        [-0.0356,  0.0641,  0.0445,  ...,  0.0049,  0.0320, -0.0881],
        [ 0.0800, -0.0671,  0.0319,  ...,  0.0038,  0.0581, -0.0066],
        ...,
        [-0.0762, -0.0507, -0.0871,  ...,  0.0135, -0.0394,  0.0354],
        [ 0.0851, -0.0234,  0.0126,  ..., -0.0038, -0.0056, -0.0705],
        [-0.0075,  0.0411,  0.0047,  ..., -0.0608, -0.0613,  0.0220]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0203, -0.0349, -0.0280,  0.0878, -0.0732,  0.0817,  0.0425, -0.0364,
        -0.0294,  0.0174,  0.0476, -0.0258,  0.0288,  0.0141,  0.0870,  0.0102,
         0.0870, -0.0399, -0.0458,  0.0217, -0.0150,  0.0186, -0.0034, -0.0095,
        -0.0525, -0.0080,  0.0050, -0.0714, -0.0636, -0.0262,  0.0822,  0.0223,
         0.0447, -0.0212,  0.0032, -0.0263,  0.0422, -0.0074, -0.0869,  0.0279,
        -0.0514,  0.0639, -0.0747, -0.0667,  0.0573,  0.0151,  0.0235,  0.0877,
         0.0429, -0.0103,  0.0395, -0.0233, -0.0701,  0.0855,  0.0848,  0.0832,
        -0.0837, -0.0295,  0.0207, -0.0594, -0.0027, -0.0609, -0.0557,  0.0115],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0088,  0.1027, -0.1012,  ..., -0.1120, -0.0032,  0.0612],
        [ 0.0103,  0.1100, -0.0491,  ..., -0.0154, -0.0554, -0.0462],
        [ 0.0094,  0.0197, -0.0532,  ..., -0.1090, -0.0474,  0.0767],
        ...,
        [-0.0554, -0.1176, -0.0281,  ..., -0.0485,  0.0725,  0.0539],
        [ 0.1062,  0.0788,  0.0290,  ...,  0.0956, -0.0364, -0.1089],
        [ 0.1023,  0.0788,  0.0898,  ...,  0.0456, -0.0971, -0.0338]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0055,  0.0117, -0.0362,  ...,  0.1242, -0.0348, -0.0679],
       device='cuda:0', requires_grad=True)], 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}]
epoch: 0 batch 0.0 event: 0 loss: tensor(184.3646, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 10.0 event: 300 loss: tensor(1802.6204, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 20.0 event: 600 loss: tensor(1770.0277, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 30.0 event: 900 loss: tensor(1857.2777, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 50.0 event: 1500 loss: tensor(3864.7075, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 60.0 event: 1800 loss: tensor(1800.3346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 70.0 event: 2100 loss: tensor(2031.5979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 80.0 event: 2400 loss: tensor(1954.5907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 90.0 event: 2700 loss: tensor(2070.4941, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 110.0 event: 3300 loss: tensor(3667.1365, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 120.0 event: 3600 loss: tensor(1925.9052, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 130.0 event: 3900 loss: tensor(1811.6104, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 140.0 event: 4200 loss: tensor(1985.6884, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 150.0 event: 4500 loss: tensor(2023.8324, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 170.0 event: 5100 loss: tensor(3385.6301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 180.0 event: 5400 loss: tensor(2070.3650, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 190.0 event: 5700 loss: tensor(1816.1041, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 200.0 event: 6000 loss: tensor(2147.8210, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 210.0 event: 6300 loss: tensor(1544.1674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 220.0 event: 6600 loss: tensor(1892.0918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 230.0 event: 6900 loss: tensor(2049.1653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 240.0 event: 7200 loss: tensor(2107.6150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 250.0 event: 7500 loss: tensor(2088.0896, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 260.0 event: 7800 loss: tensor(2027.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 270.0 event: 8100 loss: tensor(1810.3977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 280.0 event: 8400 loss: tensor(2032.7352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 290.0 event: 8700 loss: tensor(1957.2870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 310.0 event: 9300 loss: tensor(1607.6576, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 320.0 event: 9600 loss: tensor(1758.1543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 330.0 event: 9900 loss: tensor(2054.4563, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:00:22.114545
evaluation loss: 2005.7994384765625
epoch: 0 mean loss: 1908.9144287109375
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 1 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 10.0 event: 300 loss: tensor(1802.6029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 30.0 event: 900 loss: tensor(1857.3011, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 50.0 event: 1500 loss: tensor(3864.6775, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 60.0 event: 1800 loss: tensor(1800.3580, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 70.0 event: 2100 loss: tensor(2031.5879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 80.0 event: 2400 loss: tensor(1954.6073, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 90.0 event: 2700 loss: tensor(2070.4607, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 110.0 event: 3300 loss: tensor(3667.1628, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 120.0 event: 3600 loss: tensor(1925.9250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 130.0 event: 3900 loss: tensor(1811.6205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 150.0 event: 4500 loss: tensor(2023.8524, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 170.0 event: 5100 loss: tensor(3385.6404, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 180.0 event: 5400 loss: tensor(2070.3730, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 190.0 event: 5700 loss: tensor(1816.1210, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 200.0 event: 6000 loss: tensor(2147.7913, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 210.0 event: 6300 loss: tensor(1544.1674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 220.0 event: 6600 loss: tensor(1892.0918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 230.0 event: 6900 loss: tensor(2049.1653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 240.0 event: 7200 loss: tensor(2107.6150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 250.0 event: 7500 loss: tensor(2088.0896, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 260.0 event: 7800 loss: tensor(2027.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 270.0 event: 8100 loss: tensor(1810.3977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 280.0 event: 8400 loss: tensor(2032.7352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 290.0 event: 8700 loss: tensor(1957.2870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 310.0 event: 9300 loss: tensor(1607.6576, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 320.0 event: 9600 loss: tensor(1758.1543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 330.0 event: 9900 loss: tensor(2054.4424, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:04.786496
evaluation loss: 2005.7974853515625
epoch: 1 mean loss: 1908.9161376953125
epoch: 2 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 10.0 event: 300 loss: tensor(1802.6029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 30.0 event: 900 loss: tensor(1857.3011, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 50.0 event: 1500 loss: tensor(3864.6775, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 60.0 event: 1800 loss: tensor(1800.3580, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 70.0 event: 2100 loss: tensor(2031.5879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 80.0 event: 2400 loss: tensor(1954.6073, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 90.0 event: 2700 loss: tensor(2070.4607, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 110.0 event: 3300 loss: tensor(3667.1628, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 120.0 event: 3600 loss: tensor(1925.9250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 130.0 event: 3900 loss: tensor(1811.6205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 150.0 event: 4500 loss: tensor(2023.8524, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 170.0 event: 5100 loss: tensor(3385.6404, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 180.0 event: 5400 loss: tensor(2070.3730, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 190.0 event: 5700 loss: tensor(1816.1210, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 200.0 event: 6000 loss: tensor(2147.7913, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 210.0 event: 6300 loss: tensor(1544.1674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 220.0 event: 6600 loss: tensor(1892.0918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 230.0 event: 6900 loss: tensor(2049.1653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 240.0 event: 7200 loss: tensor(2107.6150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 250.0 event: 7500 loss: tensor(2088.0896, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 260.0 event: 7800 loss: tensor(2027.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 270.0 event: 8100 loss: tensor(1810.3977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 280.0 event: 8400 loss: tensor(2032.7352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 290.0 event: 8700 loss: tensor(1957.2870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 310.0 event: 9300 loss: tensor(1607.6576, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 320.0 event: 9600 loss: tensor(1758.1543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 330.0 event: 9900 loss: tensor(2054.4424, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:39.766755
evaluation loss: 2005.7974853515625
epoch: 2 mean loss: 1908.9161376953125
epoch: 3 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 10.0 event: 300 loss: tensor(1802.6029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 30.0 event: 900 loss: tensor(1857.3011, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 50.0 event: 1500 loss: tensor(3864.6775, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 60.0 event: 1800 loss: tensor(1800.3580, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 70.0 event: 2100 loss: tensor(2031.5879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 80.0 event: 2400 loss: tensor(1954.6073, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 90.0 event: 2700 loss: tensor(2070.4607, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 110.0 event: 3300 loss: tensor(3667.1628, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 120.0 event: 3600 loss: tensor(1925.9250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 130.0 event: 3900 loss: tensor(1811.6205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 150.0 event: 4500 loss: tensor(2023.8524, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 170.0 event: 5100 loss: tensor(3385.6404, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 180.0 event: 5400 loss: tensor(2070.3730, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 190.0 event: 5700 loss: tensor(1816.1210, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 200.0 event: 6000 loss: tensor(2147.7913, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 210.0 event: 6300 loss: tensor(1544.1674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 220.0 event: 6600 loss: tensor(1892.0918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 230.0 event: 6900 loss: tensor(2049.1653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 240.0 event: 7200 loss: tensor(2107.6150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 250.0 event: 7500 loss: tensor(2088.0896, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 260.0 event: 7800 loss: tensor(2027.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 270.0 event: 8100 loss: tensor(1810.3977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 280.0 event: 8400 loss: tensor(2032.7352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 290.0 event: 8700 loss: tensor(1957.2870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 310.0 event: 9300 loss: tensor(1607.6576, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 320.0 event: 9600 loss: tensor(1758.1543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 330.0 event: 9900 loss: tensor(2054.4424, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:14.607068
evaluation loss: 2005.7974853515625
epoch: 3 mean loss: 1908.9161376953125
epoch: 4 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 10.0 event: 300 loss: tensor(1802.6029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 20.0 event: 600 loss: tensor(1770.0487, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 30.0 event: 900 loss: tensor(1857.3011, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 50.0 event: 1500 loss: tensor(3864.6775, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 60.0 event: 1800 loss: tensor(1800.3580, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 70.0 event: 2100 loss: tensor(2031.5879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 80.0 event: 2400 loss: tensor(1954.6039, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 90.0 event: 2700 loss: tensor(2070.4744, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 110.0 event: 3300 loss: tensor(3667.1628, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 120.0 event: 3600 loss: tensor(1925.9250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 130.0 event: 3900 loss: tensor(1811.6205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 150.0 event: 4500 loss: tensor(2023.8414, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 170.0 event: 5100 loss: tensor(3385.6404, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 180.0 event: 5400 loss: tensor(2070.3730, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 190.0 event: 5700 loss: tensor(1816.1135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 200.0 event: 6000 loss: tensor(2147.7979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 210.0 event: 6300 loss: tensor(1544.1973, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 220.0 event: 6600 loss: tensor(1892.0852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 230.0 event: 6900 loss: tensor(2049.1653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 240.0 event: 7200 loss: tensor(2107.6150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 250.0 event: 7500 loss: tensor(2088.0896, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 260.0 event: 7800 loss: tensor(2027.1061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 270.0 event: 8100 loss: tensor(1810.3844, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 280.0 event: 8400 loss: tensor(2032.7383, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 290.0 event: 8700 loss: tensor(1957.2903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 300.0 event: 9000 loss: tensor(1847.6918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 310.0 event: 9300 loss: tensor(1607.6176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 320.0 event: 9600 loss: tensor(1758.1276, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 330.0 event: 9900 loss: tensor(2054.4792, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:49.194380
evaluation loss: 2005.8157958984375
epoch: 4 mean loss: 1908.916748046875
epoch: 5 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 10.0 event: 300 loss: tensor(1802.6129, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 20.0 event: 600 loss: tensor(1770.0277, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 30.0 event: 900 loss: tensor(1857.2811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 50.0 event: 1500 loss: tensor(3864.6775, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 60.0 event: 1800 loss: tensor(1800.3580, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 70.0 event: 2100 loss: tensor(2031.5879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 80.0 event: 2400 loss: tensor(1954.6073, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 90.0 event: 2700 loss: tensor(2070.4607, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 110.0 event: 3300 loss: tensor(3667.1628, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 120.0 event: 3600 loss: tensor(1925.9250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 130.0 event: 3900 loss: tensor(1811.6205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 140.0 event: 4200 loss: tensor(1985.6825, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 150.0 event: 4500 loss: tensor(2023.8124, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 170.0 event: 5100 loss: tensor(3385.6101, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 180.0 event: 5400 loss: tensor(2070.3562, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 190.0 event: 5700 loss: tensor(1816.1074, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 200.0 event: 6000 loss: tensor(2147.7979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 210.0 event: 6300 loss: tensor(1544.1973, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 220.0 event: 6600 loss: tensor(1892.0785, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 230.0 event: 6900 loss: tensor(2049.1584, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 240.0 event: 7200 loss: tensor(2107.6216, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 250.0 event: 7500 loss: tensor(2088.0698, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 260.0 event: 7800 loss: tensor(2027.1110, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 270.0 event: 8100 loss: tensor(1810.3844, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 280.0 event: 8400 loss: tensor(2032.7383, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 290.0 event: 8700 loss: tensor(1957.2933, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 300.0 event: 9000 loss: tensor(1847.6918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 310.0 event: 9300 loss: tensor(1607.6376, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 320.0 event: 9600 loss: tensor(1758.1543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 330.0 event: 9900 loss: tensor(2054.4424, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:23.784507
evaluation loss: 2005.815673828125
epoch: 5 mean loss: 1908.9127197265625
=> saveing checkpoint at epoch 5
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 6 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 10.0 event: 300 loss: tensor(1802.6063, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 20.0 event: 600 loss: tensor(1770.0277, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 30.0 event: 900 loss: tensor(1857.2777, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 50.0 event: 1500 loss: tensor(3864.7075, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 60.0 event: 1800 loss: tensor(1800.3314, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 70.0 event: 2100 loss: tensor(2031.5979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 80.0 event: 2400 loss: tensor(1954.5907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 90.0 event: 2700 loss: tensor(2070.4941, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 110.0 event: 3300 loss: tensor(3667.1365, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 120.0 event: 3600 loss: tensor(1925.9052, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 130.0 event: 3900 loss: tensor(1811.6104, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 140.0 event: 4200 loss: tensor(1985.6820, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 150.0 event: 4500 loss: tensor(2023.8124, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 170.0 event: 5100 loss: tensor(3385.6101, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 180.0 event: 5400 loss: tensor(2070.3762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 190.0 event: 5700 loss: tensor(1816.1210, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 200.0 event: 6000 loss: tensor(2147.7913, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 210.0 event: 6300 loss: tensor(1544.1672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 220.0 event: 6600 loss: tensor(1892.0918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 230.0 event: 6900 loss: tensor(2049.1626, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 240.0 event: 7200 loss: tensor(2107.6150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 250.0 event: 7500 loss: tensor(2088.0896, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 260.0 event: 7800 loss: tensor(2027.0811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 270.0 event: 8100 loss: tensor(1810.3977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 280.0 event: 8400 loss: tensor(2032.7352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 290.0 event: 8700 loss: tensor(1957.2910, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 310.0 event: 9300 loss: tensor(1607.6576, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 320.0 event: 9600 loss: tensor(1758.1543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 330.0 event: 9900 loss: tensor(2054.4424, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:03.119907
evaluation loss: 2005.8021240234375
epoch: 6 mean loss: 1908.912353515625
epoch: 7 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 10.0 event: 300 loss: tensor(1802.6029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 20.0 event: 600 loss: tensor(1770.0403, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 30.0 event: 900 loss: tensor(1857.2777, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 50.0 event: 1500 loss: tensor(3864.6833, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 130.0 event: 3900 loss: tensor(1811.5936, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 150.0 event: 4500 loss: tensor(2023.8170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 260.0 event: 7800 loss: tensor(2027.0608, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 270.0 event: 8100 loss: tensor(1810.3815, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:37.611256
evaluation loss: 2005.8330078125
epoch: 7 mean loss: 1908.90869140625
epoch: 8 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 50.0 event: 1500 loss: tensor(3864.6653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 110.0 event: 3300 loss: tensor(3667.1270, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 120.0 event: 3600 loss: tensor(1925.9052, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 130.0 event: 3900 loss: tensor(1811.6104, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 140.0 event: 4200 loss: tensor(1985.6820, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 150.0 event: 4500 loss: tensor(2023.8170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 220.0 event: 6600 loss: tensor(1892.0674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:12.013844
evaluation loss: 2005.8323974609375
epoch: 8 mean loss: 1908.90869140625
epoch: 9 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:46.380548
evaluation loss: 2005.834228515625
epoch: 9 mean loss: 1908.908447265625
epoch: 10 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:06:20.878535
evaluation loss: 2005.834228515625
epoch: 10 mean loss: 1908.908447265625
=> saveing checkpoint at epoch 10
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 11 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:00.265708
evaluation loss: 2005.834228515625
epoch: 11 mean loss: 1908.908447265625
epoch: 12 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 170.0 event: 5100 loss: tensor(3385.6501, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 180.0 event: 5400 loss: tensor(2070.3494, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:34.959727
evaluation loss: 2005.834228515625
epoch: 12 mean loss: 1908.908447265625
epoch: 13 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 140.0 event: 4200 loss: tensor(1985.6862, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:09.782832
evaluation loss: 2005.834228515625
epoch: 13 mean loss: 1908.908447265625
epoch: 14 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:44.662252
evaluation loss: 2005.834228515625
epoch: 14 mean loss: 1908.908447265625
epoch: 15 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:09:19.510731
evaluation loss: 2005.834228515625
epoch: 15 mean loss: 1908.908447265625
=> saveing checkpoint at epoch 15
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 16 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 10.0 event: 300 loss: tensor(1802.5793, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 30.0 event: 900 loss: tensor(1857.2949, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 50.0 event: 1500 loss: tensor(3864.6736, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 180.0 event: 5400 loss: tensor(2070.3501, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:09:59.027609
evaluation loss: 2005.834228515625
epoch: 16 mean loss: 1908.90869140625
epoch: 17 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 170.0 event: 5100 loss: tensor(3385.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:10:33.789174
evaluation loss: 2005.834228515625
epoch: 17 mean loss: 1908.908447265625
epoch: 18 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 60.0 event: 1800 loss: tensor(1800.3553, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 170.0 event: 5100 loss: tensor(3385.6501, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 180.0 event: 5400 loss: tensor(2070.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 190.0 event: 5700 loss: tensor(1816.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 200.0 event: 6000 loss: tensor(2147.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 210.0 event: 6300 loss: tensor(1544.1772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 230.0 event: 6900 loss: tensor(2049.1587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 250.0 event: 7500 loss: tensor(2088.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 270.0 event: 8100 loss: tensor(1810.3778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 280.0 event: 8400 loss: tensor(2032.7354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 290.0 event: 8700 loss: tensor(1957.2734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 310.0 event: 9300 loss: tensor(1607.6244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 320.0 event: 9600 loss: tensor(1758.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 330.0 event: 9900 loss: tensor(2054.4658, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:11:08.559165
evaluation loss: 2005.834228515625
epoch: 18 mean loss: 1908.908447265625
epoch: 19 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 20.0 event: 600 loss: tensor(1770.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 30.0 event: 900 loss: tensor(1857.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 50.0 event: 1500 loss: tensor(3864.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 60.0 event: 1800 loss: tensor(1800.3578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 70.0 event: 2100 loss: tensor(2031.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 80.0 event: 2400 loss: tensor(1954.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 90.0 event: 2700 loss: tensor(2070.4773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 110.0 event: 3300 loss: tensor(3667.1267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 120.0 event: 3600 loss: tensor(1925.9183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 130.0 event: 3900 loss: tensor(1811.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 140.0 event: 4200 loss: tensor(1985.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 170.0 event: 5100 loss: tensor(3385.6621, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 180.0 event: 5400 loss: tensor(2070.3469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 190.0 event: 5700 loss: tensor(1816.1221, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 200.0 event: 6000 loss: tensor(2147.7988, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 210.0 event: 6300 loss: tensor(1544.1674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 220.0 event: 6600 loss: tensor(1892.0654, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 230.0 event: 6900 loss: tensor(2049.1450, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 240.0 event: 7200 loss: tensor(2107.5916, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 250.0 event: 7500 loss: tensor(2088.1084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 260.0 event: 7800 loss: tensor(2027.0908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 270.0 event: 8100 loss: tensor(1810.4178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 280.0 event: 8400 loss: tensor(2032.7084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 290.0 event: 8700 loss: tensor(1957.3170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 300.0 event: 9000 loss: tensor(1847.7086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 310.0 event: 9300 loss: tensor(1607.6310, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 320.0 event: 9600 loss: tensor(1758.1477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 330.0 event: 9900 loss: tensor(2054.4912, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:11:43.327815
evaluation loss: 2005.8359375
epoch: 19 mean loss: 1908.9122314453125
epoch: 20 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 10.0 event: 300 loss: tensor(1802.6165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 20.0 event: 600 loss: tensor(1770.0110, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 30.0 event: 900 loss: tensor(1857.2844, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 50.0 event: 1500 loss: tensor(3864.6711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 60.0 event: 1800 loss: tensor(1800.3346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 70.0 event: 2100 loss: tensor(2031.6045, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 80.0 event: 2400 loss: tensor(1954.5774, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 90.0 event: 2700 loss: tensor(2070.4841, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 110.0 event: 3300 loss: tensor(3667.1531, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 120.0 event: 3600 loss: tensor(1925.9149, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 130.0 event: 3900 loss: tensor(1811.5869, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 140.0 event: 4200 loss: tensor(1985.6752, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 150.0 event: 4500 loss: tensor(2023.8359, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 170.0 event: 5100 loss: tensor(3385.5969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 180.0 event: 5400 loss: tensor(2070.3596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 190.0 event: 5700 loss: tensor(1816.1041, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 200.0 event: 6000 loss: tensor(2147.8081, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 210.0 event: 6300 loss: tensor(1544.1906, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 230.0 event: 6900 loss: tensor(2049.1450, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 240.0 event: 7200 loss: tensor(2107.5916, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 250.0 event: 7500 loss: tensor(2088.1096, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 260.0 event: 7800 loss: tensor(2027.0908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 270.0 event: 8100 loss: tensor(1810.4178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 280.0 event: 8400 loss: tensor(2032.7084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 290.0 event: 8700 loss: tensor(1957.3168, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 300.0 event: 9000 loss: tensor(1847.7070, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 310.0 event: 9300 loss: tensor(1607.6281, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 320.0 event: 9600 loss: tensor(1758.1477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 330.0 event: 9900 loss: tensor(2054.4729, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:12:17.473544
evaluation loss: 2005.83203125
epoch: 20 mean loss: 1908.9107666015625
=> saveing checkpoint at epoch 20
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 21 batch 0.0 event: 0 loss: tensor(184.3599, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 10.0 event: 300 loss: tensor(1802.5663, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 20.0 event: 600 loss: tensor(1770.0594, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 30.0 event: 900 loss: tensor(1857.2852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 50.0 event: 1500 loss: tensor(3864.6536, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 60.0 event: 1800 loss: tensor(1800.3346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 70.0 event: 2100 loss: tensor(2031.6045, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 80.0 event: 2400 loss: tensor(1954.5774, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 90.0 event: 2700 loss: tensor(2070.4841, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 110.0 event: 3300 loss: tensor(3667.1531, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 120.0 event: 3600 loss: tensor(1925.9149, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 130.0 event: 3900 loss: tensor(1811.5869, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 140.0 event: 4200 loss: tensor(1985.6752, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 150.0 event: 4500 loss: tensor(2023.8359, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 170.0 event: 5100 loss: tensor(3385.5969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 180.0 event: 5400 loss: tensor(2070.3596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 190.0 event: 5700 loss: tensor(1816.1041, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 200.0 event: 6000 loss: tensor(2147.8081, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 210.0 event: 6300 loss: tensor(1544.1906, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 220.0 event: 6600 loss: tensor(1892.0651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 230.0 event: 6900 loss: tensor(2049.1365, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 240.0 event: 7200 loss: tensor(2107.5916, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 250.0 event: 7500 loss: tensor(2088.1096, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 260.0 event: 7800 loss: tensor(2027.0908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 270.0 event: 8100 loss: tensor(1810.4178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 280.0 event: 8400 loss: tensor(2032.7084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 290.0 event: 8700 loss: tensor(1957.3170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 300.0 event: 9000 loss: tensor(1847.7086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 310.0 event: 9300 loss: tensor(1607.6310, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 320.0 event: 9600 loss: tensor(1758.1477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 330.0 event: 9900 loss: tensor(2054.4858, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:12:56.117327
evaluation loss: 2005.8309326171875
epoch: 21 mean loss: 1908.909912109375
epoch: 22 batch 0.0 event: 0 loss: tensor(184.3666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 10.0 event: 300 loss: tensor(1802.6165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 20.0 event: 600 loss: tensor(1770.0110, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 30.0 event: 900 loss: tensor(1857.2844, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 50.0 event: 1500 loss: tensor(3864.6680, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 60.0 event: 1800 loss: tensor(1800.3346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 70.0 event: 2100 loss: tensor(2031.6045, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 80.0 event: 2400 loss: tensor(1954.5781, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 90.0 event: 2700 loss: tensor(2070.4392, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 110.0 event: 3300 loss: tensor(3667.0759, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 120.0 event: 3600 loss: tensor(1925.9149, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 130.0 event: 3900 loss: tensor(1811.5980, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 140.0 event: 4200 loss: tensor(1985.6719, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 170.0 event: 5100 loss: tensor(3385.5903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 180.0 event: 5400 loss: tensor(2070.3196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 190.0 event: 5700 loss: tensor(1816.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 200.0 event: 6000 loss: tensor(2147.7966, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 210.0 event: 6300 loss: tensor(1544.1406, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 220.0 event: 6600 loss: tensor(1892.0684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 230.0 event: 6900 loss: tensor(2049.1453, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 240.0 event: 7200 loss: tensor(2107.6082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 250.0 event: 7500 loss: tensor(2088.0930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 260.0 event: 7800 loss: tensor(2027.0514, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 270.0 event: 8100 loss: tensor(1810.3965, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 280.0 event: 8400 loss: tensor(2032.7284, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 290.0 event: 8700 loss: tensor(1957.3037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 300.0 event: 9000 loss: tensor(1847.7021, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 310.0 event: 9300 loss: tensor(1607.5809, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 320.0 event: 9600 loss: tensor(1758.1768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 330.0 event: 9900 loss: tensor(2054.4626, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:13:30.152396
evaluation loss: 2005.8189697265625
epoch: 22 mean loss: 1908.9000244140625
epoch: 23 batch 0.0 event: 0 loss: tensor(184.3566, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 10.0 event: 300 loss: tensor(1802.6028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 20.0 event: 600 loss: tensor(1770.0176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 30.0 event: 900 loss: tensor(1857.2582, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 50.0 event: 1500 loss: tensor(3864.6777, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 60.0 event: 1800 loss: tensor(1800.3348, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 70.0 event: 2100 loss: tensor(2031.6057, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 80.0 event: 2400 loss: tensor(1954.5807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 90.0 event: 2700 loss: tensor(2070.4373, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 110.0 event: 3300 loss: tensor(3667.0867, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 120.0 event: 3600 loss: tensor(1925.8981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 130.0 event: 3900 loss: tensor(1811.5804, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 140.0 event: 4200 loss: tensor(1985.6650, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 150.0 event: 4500 loss: tensor(2023.8241, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 170.0 event: 5100 loss: tensor(3385.5903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 180.0 event: 5400 loss: tensor(2070.3196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 190.0 event: 5700 loss: tensor(1816.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 200.0 event: 6000 loss: tensor(2147.7878, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 210.0 event: 6300 loss: tensor(1544.1627, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 220.0 event: 6600 loss: tensor(1892.0985, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 230.0 event: 6900 loss: tensor(2049.1086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 240.0 event: 7200 loss: tensor(2107.5781, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 250.0 event: 7500 loss: tensor(2088.0928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 260.0 event: 7800 loss: tensor(2027.0508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 270.0 event: 8100 loss: tensor(1810.3912, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 280.0 event: 8400 loss: tensor(2032.7284, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 290.0 event: 8700 loss: tensor(1957.3018, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 300.0 event: 9000 loss: tensor(1847.6975, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 310.0 event: 9300 loss: tensor(1607.6010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 320.0 event: 9600 loss: tensor(1758.1409, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 330.0 event: 9900 loss: tensor(2054.4392, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:14:03.632277
evaluation loss: 2005.8133544921875
epoch: 23 mean loss: 1908.896484375
epoch: 24 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 10.0 event: 300 loss: tensor(1802.6328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 20.0 event: 600 loss: tensor(1770.0209, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 30.0 event: 900 loss: tensor(1857.2645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 50.0 event: 1500 loss: tensor(3864.5977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 60.0 event: 1800 loss: tensor(1800.3180, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 70.0 event: 2100 loss: tensor(2031.5979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 80.0 event: 2400 loss: tensor(1954.5807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 90.0 event: 2700 loss: tensor(2070.4377, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 110.0 event: 3300 loss: tensor(3667.0867, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 120.0 event: 3600 loss: tensor(1925.8981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 130.0 event: 3900 loss: tensor(1811.5804, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 140.0 event: 4200 loss: tensor(1985.6653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 150.0 event: 4500 loss: tensor(2023.8324, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 170.0 event: 5100 loss: tensor(3385.5903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 180.0 event: 5400 loss: tensor(2070.3196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 190.0 event: 5700 loss: tensor(1816.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 200.0 event: 6000 loss: tensor(2147.7878, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 210.0 event: 6300 loss: tensor(1544.1639, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 220.0 event: 6600 loss: tensor(1892.0985, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 230.0 event: 6900 loss: tensor(2049.1084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 240.0 event: 7200 loss: tensor(2107.5781, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 250.0 event: 7500 loss: tensor(2088.0928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 260.0 event: 7800 loss: tensor(2027.0555, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 270.0 event: 8100 loss: tensor(1810.3912, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 280.0 event: 8400 loss: tensor(2032.7284, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 290.0 event: 8700 loss: tensor(1957.3037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 300.0 event: 9000 loss: tensor(1847.7020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 310.0 event: 9300 loss: tensor(1607.5809, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 320.0 event: 9600 loss: tensor(1758.1709, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 330.0 event: 9900 loss: tensor(2054.4558, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:14:37.096687
evaluation loss: 2005.8323974609375
epoch: 24 mean loss: 1908.895751953125
epoch: 25 batch 0.0 event: 0 loss: tensor(184.3600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 10.0 event: 300 loss: tensor(1802.5793, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 20.0 event: 600 loss: tensor(1770.0178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 30.0 event: 900 loss: tensor(1857.2640, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 50.0 event: 1500 loss: tensor(3864.5981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 60.0 event: 1800 loss: tensor(1800.3182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 70.0 event: 2100 loss: tensor(2031.5869, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 80.0 event: 2400 loss: tensor(1954.5741, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 90.0 event: 2700 loss: tensor(2070.4805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 110.0 event: 3300 loss: tensor(3667.1099, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 120.0 event: 3600 loss: tensor(1925.8918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 130.0 event: 3900 loss: tensor(1811.6071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 140.0 event: 4200 loss: tensor(1985.6543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 150.0 event: 4500 loss: tensor(2023.8192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 170.0 event: 5100 loss: tensor(3385.6301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 180.0 event: 5400 loss: tensor(2070.3528, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 190.0 event: 5700 loss: tensor(1816.1074, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 200.0 event: 6000 loss: tensor(2147.7781, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 210.0 event: 6300 loss: tensor(1544.1873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 220.0 event: 6600 loss: tensor(1892.0585, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 230.0 event: 6900 loss: tensor(2049.1287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 240.0 event: 7200 loss: tensor(2107.6082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 250.0 event: 7500 loss: tensor(2088.0930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 270.0 event: 8100 loss: tensor(1810.4012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 280.0 event: 8400 loss: tensor(2032.7186, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 290.0 event: 8700 loss: tensor(1957.2899, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 300.0 event: 9000 loss: tensor(1847.6953, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 310.0 event: 9300 loss: tensor(1607.6010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 320.0 event: 9600 loss: tensor(1758.1409, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 330.0 event: 9900 loss: tensor(2054.4392, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:15:10.574641
evaluation loss: 2005.8275146484375
epoch: 25 mean loss: 1908.897705078125
=> saveing checkpoint at epoch 25
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 26 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 10.0 event: 300 loss: tensor(1802.6328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 20.0 event: 600 loss: tensor(1770.0305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 30.0 event: 900 loss: tensor(1857.2645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 50.0 event: 1500 loss: tensor(3864.6609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 60.0 event: 1800 loss: tensor(1800.3414, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 70.0 event: 2100 loss: tensor(2031.5680, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 80.0 event: 2400 loss: tensor(1954.5741, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 90.0 event: 2700 loss: tensor(2070.4805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 110.0 event: 3300 loss: tensor(3667.1082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 120.0 event: 3600 loss: tensor(1925.8918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 130.0 event: 3900 loss: tensor(1811.6071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 140.0 event: 4200 loss: tensor(1985.6517, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 150.0 event: 4500 loss: tensor(2023.8170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 170.0 event: 5100 loss: tensor(3385.6301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 180.0 event: 5400 loss: tensor(2070.3528, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 190.0 event: 5700 loss: tensor(1816.1080, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 200.0 event: 6000 loss: tensor(2147.8054, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 210.0 event: 6300 loss: tensor(1544.1873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 220.0 event: 6600 loss: tensor(1892.0585, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 230.0 event: 6900 loss: tensor(2049.1287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 240.0 event: 7200 loss: tensor(2107.6082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 250.0 event: 7500 loss: tensor(2088.0930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 260.0 event: 7800 loss: tensor(2027.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 270.0 event: 8100 loss: tensor(1810.4010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 280.0 event: 8400 loss: tensor(2032.7181, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 290.0 event: 8700 loss: tensor(1957.2899, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 300.0 event: 9000 loss: tensor(1847.6904, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 310.0 event: 9300 loss: tensor(1607.6010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 320.0 event: 9600 loss: tensor(1758.1409, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 330.0 event: 9900 loss: tensor(2054.4392, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:15:48.801112
evaluation loss: 2005.8128662109375
epoch: 26 mean loss: 1908.9022216796875
epoch: 27 batch 0.0 event: 0 loss: tensor(184.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 10.0 event: 300 loss: tensor(1802.6328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 20.0 event: 600 loss: tensor(1770.0282, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 30.0 event: 900 loss: tensor(1857.2645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 50.0 event: 1500 loss: tensor(3864.6609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 60.0 event: 1800 loss: tensor(1800.3246, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 70.0 event: 2100 loss: tensor(2031.5979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 80.0 event: 2400 loss: tensor(1954.5807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 90.0 event: 2700 loss: tensor(2070.4805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 110.0 event: 3300 loss: tensor(3667.1067, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 120.0 event: 3600 loss: tensor(1925.8981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 130.0 event: 3900 loss: tensor(1811.5804, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 140.0 event: 4200 loss: tensor(1985.6653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 150.0 event: 4500 loss: tensor(2023.8324, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 170.0 event: 5100 loss: tensor(3385.5903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 180.0 event: 5400 loss: tensor(2070.3196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 190.0 event: 5700 loss: tensor(1816.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 200.0 event: 6000 loss: tensor(2147.7878, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 210.0 event: 6300 loss: tensor(1544.1906, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 220.0 event: 6600 loss: tensor(1892.0585, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 230.0 event: 6900 loss: tensor(2049.1287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 240.0 event: 7200 loss: tensor(2107.6033, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 250.0 event: 7500 loss: tensor(2088.0928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 260.0 event: 7800 loss: tensor(2027.0508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 270.0 event: 8100 loss: tensor(1810.3910, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 280.0 event: 8400 loss: tensor(2032.7344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 290.0 event: 8700 loss: tensor(1957.3037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 300.0 event: 9000 loss: tensor(1847.7028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 310.0 event: 9300 loss: tensor(1607.5809, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 320.0 event: 9600 loss: tensor(1758.1709, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 330.0 event: 9900 loss: tensor(2054.4558, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:16:22.103308
evaluation loss: 2005.8109130859375
epoch: 27 mean loss: 1908.9007568359375
epoch: 28 batch 0.0 event: 0 loss: tensor(184.3600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 20.0 event: 600 loss: tensor(1770.0178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 30.0 event: 900 loss: tensor(1857.2645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 50.0 event: 1500 loss: tensor(3864.6035, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 60.0 event: 1800 loss: tensor(1800.3182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 70.0 event: 2100 loss: tensor(2031.5977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 80.0 event: 2400 loss: tensor(1954.5878, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 90.0 event: 2700 loss: tensor(2070.4595, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 110.0 event: 3300 loss: tensor(3667.1099, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 120.0 event: 3600 loss: tensor(1925.9149, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 130.0 event: 3900 loss: tensor(1811.5872, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 140.0 event: 4200 loss: tensor(1985.6719, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 150.0 event: 4500 loss: tensor(2023.8158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 170.0 event: 5100 loss: tensor(3385.5833, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 180.0 event: 5400 loss: tensor(2070.3162, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 190.0 event: 5700 loss: tensor(1816.0842, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 200.0 event: 6000 loss: tensor(2147.7979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 210.0 event: 6300 loss: tensor(1544.1406, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 220.0 event: 6600 loss: tensor(1892.0684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 230.0 event: 6900 loss: tensor(2049.1453, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 250.0 event: 7500 loss: tensor(2088.0896, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 260.0 event: 7800 loss: tensor(2027.0443, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 270.0 event: 8100 loss: tensor(1810.3945, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 280.0 event: 8400 loss: tensor(2032.7084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 290.0 event: 8700 loss: tensor(1957.2903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 300.0 event: 9000 loss: tensor(1847.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 310.0 event: 9300 loss: tensor(1607.5776, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 320.0 event: 9600 loss: tensor(1758.1624, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 330.0 event: 9900 loss: tensor(2054.4558, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:16:55.476447
evaluation loss: 2005.82421875
epoch: 28 mean loss: 1908.89404296875
epoch: 29 batch 0.0 event: 0 loss: tensor(184.3600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 10.0 event: 300 loss: tensor(1802.5795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 20.0 event: 600 loss: tensor(1770.0178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 30.0 event: 900 loss: tensor(1857.2645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 50.0 event: 1500 loss: tensor(3864.5977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 60.0 event: 1800 loss: tensor(1800.3182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 70.0 event: 2100 loss: tensor(2031.5979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 80.0 event: 2400 loss: tensor(1954.5807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 90.0 event: 2700 loss: tensor(2070.4373, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 110.0 event: 3300 loss: tensor(3667.0867, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 120.0 event: 3600 loss: tensor(1925.8981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 130.0 event: 3900 loss: tensor(1811.5804, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 140.0 event: 4200 loss: tensor(1985.6653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 150.0 event: 4500 loss: tensor(2023.8324, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 170.0 event: 5100 loss: tensor(3385.5898, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 180.0 event: 5400 loss: tensor(2070.3196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 190.0 event: 5700 loss: tensor(1816.0742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 200.0 event: 6000 loss: tensor(2147.7844, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 210.0 event: 6300 loss: tensor(1544.1406, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 220.0 event: 6600 loss: tensor(1892.0684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 230.0 event: 6900 loss: tensor(2049.1479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 240.0 event: 7200 loss: tensor(2107.6050, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 250.0 event: 7500 loss: tensor(2088.0896, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 260.0 event: 7800 loss: tensor(2027.0443, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 270.0 event: 8100 loss: tensor(1810.3945, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 280.0 event: 8400 loss: tensor(2032.7084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 290.0 event: 8700 loss: tensor(1957.2903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 300.0 event: 9000 loss: tensor(1847.6852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 310.0 event: 9300 loss: tensor(1607.5776, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 320.0 event: 9600 loss: tensor(1758.1644, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 330.0 event: 9900 loss: tensor(2054.4446, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:18:48.119356
evaluation loss: 2005.8291015625
epoch: 29 mean loss: 1908.891357421875
=> saveing checkpoint at epoch 29
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2

outi tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>) 
 torch.Size([30, 6796]) 
 tensor(30., device='cuda:0', grad_fn=<SumBackward0>) 
 tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0') 
 tensor(203880, device='cuda:0')



training loss:
 [1908.91442871 1908.9161377  1908.9161377  1908.9161377  1908.91674805
 1908.91271973 1908.91235352 1908.90869141 1908.90869141 1908.90844727
 1908.90844727 1908.90844727 1908.90844727 1908.90844727 1908.90844727
 1908.90844727 1908.90869141 1908.90844727 1908.90844727 1908.91223145
 1908.9107666  1908.90991211 1908.90002441 1908.89648438 1908.89575195
 1908.89770508 1908.90222168 1908.90075684 1908.89404297 1908.89135742] 

\evaluation loss:
 [2005.79943848 2005.79748535 2005.79748535 2005.79748535 2005.8157959
 2005.81567383 2005.80212402 2005.83300781 2005.83239746 2005.83422852
 2005.83422852 2005.83422852 2005.83422852 2005.83422852 2005.83422852
 2005.83422852 2005.83422852 2005.83422852 2005.83422852 2005.8359375
 2005.83203125 2005.83093262 2005.81896973 2005.81335449 2005.83239746
 2005.82751465 2005.81286621 2005.81091309 2005.82421875 2005.82910156]



eval_efficiency:
 [5.50813438e-01 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04
 3.04728682e-04 3.04728682e-04 3.04728682e-04 3.04728682e-04] 


eval_purity:
 [0.65789268 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963 0.61712963
 0.61712963 0.61712963 0.61712963 0.61712963]

Passing event 10003 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10003 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0002, 0.0001, 0.0002,  ..., 0.0001, 0.0001, 0.0001],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network before training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network after training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0.0002, 0.0001, 0.0002,  ..., 0.0001, 0.0001, 0.0001],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0002, 0.0001, 0.0002,  ..., 0.0001, 0.0001, 0.0001],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

real	19m47.954s
user	21m30.496s
sys	10m27.334s
