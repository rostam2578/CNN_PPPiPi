0: gpu018.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-c1d83309-47a6-d349-ff49-5d32ce964552)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        D8:BA:A2:A6:17:3A:6A:66:7E:63:9A:FF:A2:7B:4C:BC:81:49:0A:25
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Wed Aug 31 22:26:45 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1D:00.0 Off |                    0 |
| N/A   33C    P0    42W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2acd2d9ab8e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	1m5.722s
user	0m3.853s
sys	0m2.353s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 







 Loading data ... 



training set shape (20000, 43, 288) 
sum 5279207

target set shape (20000, 6796) 
sum 4575851
Net(
  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=667776, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=6796, bias=True)
)

number of the free parameters: 171805196
parameters of the network conv1.weight 
 torch.Size([256, 1, 3, 3]) 
 True 
 tensor([[[[-2.0398e-01, -2.9605e-02,  2.8054e-01],
          [-9.3370e-02, -3.1241e-01, -1.2519e-01],
          [ 2.3969e-01,  2.3517e-01,  4.7538e-02]]],


        [[[-7.0754e-02,  1.6585e-01, -1.4771e-01],
          [-1.8516e-01,  2.6302e-01, -2.7053e-02],
          [ 2.5971e-01,  2.1148e-01, -2.3888e-01]]],


        [[[ 3.2468e-01,  1.5463e-01,  1.6438e-01],
          [-6.5189e-02, -3.1756e-01, -2.4698e-02],
          [-1.7666e-01, -1.9984e-01,  3.8150e-02]]],


        ...,


        [[[-3.1153e-01, -6.9985e-02,  3.3095e-01],
          [ 5.4394e-02, -3.0168e-01, -2.4001e-01],
          [ 2.4003e-01, -1.6397e-01,  4.7403e-02]]],


        [[[ 1.6284e-02,  3.0769e-01, -1.7738e-04],
          [-1.3932e-02,  4.5840e-02,  2.4604e-01],
          [-1.8356e-01, -2.3762e-01,  5.0211e-02]]],


        [[[ 8.3402e-02,  1.5008e-01,  2.2725e-01],
          [ 2.9246e-01, -1.7252e-01, -2.6796e-01],
          [ 9.4189e-02, -3.1463e-01,  1.9451e-01]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[-2.0398e-01, -2.9605e-02,  2.8054e-01],
          [-9.3370e-02, -3.1241e-01, -1.2519e-01],
          [ 2.3969e-01,  2.3517e-01,  4.7538e-02]]],


        [[[-7.0754e-02,  1.6585e-01, -1.4771e-01],
          [-1.8516e-01,  2.6302e-01, -2.7053e-02],
          [ 2.5971e-01,  2.1148e-01, -2.3888e-01]]],


        [[[ 3.2468e-01,  1.5463e-01,  1.6438e-01],
          [-6.5189e-02, -3.1756e-01, -2.4698e-02],
          [-1.7666e-01, -1.9984e-01,  3.8150e-02]]],


        ...,


        [[[-3.1153e-01, -6.9985e-02,  3.3095e-01],
          [ 5.4394e-02, -3.0168e-01, -2.4001e-01],
          [ 2.4003e-01, -1.6397e-01,  4.7403e-02]]],


        [[[ 1.6284e-02,  3.0769e-01, -1.7738e-04],
          [-1.3932e-02,  4.5840e-02,  2.4604e-01],
          [-1.8356e-01, -2.3762e-01,  5.0211e-02]]],


        [[[ 8.3402e-02,  1.5008e-01,  2.2725e-01],
          [ 2.9246e-01, -1.7252e-01, -2.6796e-01],
          [ 9.4189e-02, -3.1463e-01,  1.9451e-01]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv1.bias 
 torch.Size([256]) 
 True 
 tensor([ 0.0414, -0.2960,  0.2426,  0.1694, -0.1745, -0.0890,  0.0918,  0.2630,
        -0.1678,  0.1184, -0.2292,  0.1818, -0.0098, -0.0493,  0.2791, -0.2524,
         0.0641, -0.2179, -0.3124, -0.3328, -0.2779,  0.0192, -0.2749, -0.0529,
        -0.0331, -0.2358, -0.0617,  0.3066, -0.0350,  0.0592, -0.1329, -0.0847,
        -0.1797,  0.2366, -0.1402, -0.0297, -0.0542,  0.2254,  0.0881, -0.0620,
         0.0101,  0.1710,  0.1826,  0.0540,  0.2723, -0.0795, -0.2086, -0.2188,
        -0.1200,  0.2124, -0.1089, -0.3236, -0.0149, -0.1964,  0.2400, -0.2287,
        -0.0139, -0.1379, -0.2840,  0.2191, -0.3127, -0.1010,  0.0902, -0.1957,
         0.2827,  0.2002, -0.2673, -0.0484, -0.2359,  0.2298,  0.2907,  0.1301,
        -0.2623,  0.1099, -0.2879,  0.0056, -0.1221, -0.0625,  0.3176, -0.0689,
        -0.0561, -0.1978,  0.2992,  0.0101, -0.3236,  0.0524,  0.0783, -0.1694,
         0.2119,  0.2260,  0.2806, -0.1928,  0.1421, -0.0975, -0.1969,  0.0884,
         0.2230, -0.2490,  0.0781, -0.3290, -0.1631, -0.1472, -0.1912, -0.1119,
        -0.2568, -0.2315,  0.1916,  0.3205, -0.1597,  0.2846,  0.2231, -0.1978,
         0.1378, -0.0658,  0.0349, -0.0095,  0.3155,  0.1921, -0.0727, -0.2786,
         0.1249,  0.2489,  0.2408, -0.0992, -0.1297,  0.1222,  0.2202,  0.2613,
         0.3328, -0.0553,  0.0156, -0.2745,  0.0087,  0.0966,  0.0643, -0.1648,
        -0.2017,  0.0993, -0.0545,  0.1049, -0.1956, -0.2533, -0.2878,  0.1359,
        -0.0486, -0.0212, -0.2298, -0.0514,  0.0638, -0.3227, -0.0460, -0.1285,
         0.0208,  0.2851,  0.2976,  0.0349, -0.3218,  0.1174,  0.2393, -0.2074,
        -0.0351,  0.0901,  0.0752,  0.2756, -0.0463,  0.1606,  0.0272, -0.2773,
        -0.3034, -0.1987, -0.1394,  0.2644,  0.1929,  0.1458,  0.1893,  0.0005,
        -0.2044, -0.0688, -0.2019, -0.3066, -0.1724, -0.2259, -0.3030, -0.2808,
         0.3227, -0.2733, -0.3212,  0.0544,  0.0928, -0.0560,  0.1398,  0.2513,
         0.3026,  0.1320,  0.2977,  0.0136,  0.0282,  0.1034,  0.0594,  0.0578,
        -0.1256, -0.1220,  0.0817, -0.2463,  0.2978,  0.0536,  0.1771,  0.2856,
        -0.0662, -0.0822,  0.0286,  0.2253, -0.3002,  0.2524,  0.2267,  0.0363,
         0.1730, -0.1540, -0.2048,  0.2924,  0.0756, -0.0205, -0.0551, -0.2787,
        -0.1578,  0.0796,  0.2978,  0.2474, -0.1097,  0.2120,  0.1949, -0.1911,
         0.1699,  0.3218, -0.1884,  0.1896, -0.0465, -0.0077,  0.2874, -0.1984,
        -0.1262, -0.0751,  0.0686,  0.0193,  0.1655, -0.1463,  0.1005, -0.0691,
        -0.0064, -0.3252,  0.2639, -0.0199,  0.2366,  0.2064,  0.3031, -0.2638],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0414, -0.2960,  0.2426,  0.1694, -0.1745, -0.0890,  0.0918,  0.2630,
        -0.1678,  0.1184, -0.2292,  0.1818, -0.0098, -0.0493,  0.2791, -0.2524,
         0.0641, -0.2179, -0.3124, -0.3328, -0.2779,  0.0192, -0.2749, -0.0529,
        -0.0331, -0.2358, -0.0617,  0.3066, -0.0350,  0.0592, -0.1329, -0.0847,
        -0.1797,  0.2366, -0.1402, -0.0297, -0.0542,  0.2254,  0.0881, -0.0620,
         0.0101,  0.1710,  0.1826,  0.0540,  0.2723, -0.0795, -0.2086, -0.2188,
        -0.1200,  0.2124, -0.1089, -0.3236, -0.0149, -0.1964,  0.2400, -0.2287,
        -0.0139, -0.1379, -0.2840,  0.2191, -0.3127, -0.1010,  0.0902, -0.1957,
         0.2827,  0.2002, -0.2673, -0.0484, -0.2359,  0.2298,  0.2907,  0.1301,
        -0.2623,  0.1099, -0.2879,  0.0056, -0.1221, -0.0625,  0.3176, -0.0689,
        -0.0561, -0.1978,  0.2992,  0.0101, -0.3236,  0.0524,  0.0783, -0.1694,
         0.2119,  0.2260,  0.2806, -0.1928,  0.1421, -0.0975, -0.1969,  0.0884,
         0.2230, -0.2490,  0.0781, -0.3290, -0.1631, -0.1472, -0.1912, -0.1119,
        -0.2568, -0.2315,  0.1916,  0.3205, -0.1597,  0.2846,  0.2231, -0.1978,
         0.1378, -0.0658,  0.0349, -0.0095,  0.3155,  0.1921, -0.0727, -0.2786,
         0.1249,  0.2489,  0.2408, -0.0992, -0.1297,  0.1222,  0.2202,  0.2613,
         0.3328, -0.0553,  0.0156, -0.2745,  0.0087,  0.0966,  0.0643, -0.1648,
        -0.2017,  0.0993, -0.0545,  0.1049, -0.1956, -0.2533, -0.2878,  0.1359,
        -0.0486, -0.0212, -0.2298, -0.0514,  0.0638, -0.3227, -0.0460, -0.1285,
         0.0208,  0.2851,  0.2976,  0.0349, -0.3218,  0.1174,  0.2393, -0.2074,
        -0.0351,  0.0901,  0.0752,  0.2756, -0.0463,  0.1606,  0.0272, -0.2773,
        -0.3034, -0.1987, -0.1394,  0.2644,  0.1929,  0.1458,  0.1893,  0.0005,
        -0.2044, -0.0688, -0.2019, -0.3066, -0.1724, -0.2259, -0.3030, -0.2808,
         0.3227, -0.2733, -0.3212,  0.0544,  0.0928, -0.0560,  0.1398,  0.2513,
         0.3026,  0.1320,  0.2977,  0.0136,  0.0282,  0.1034,  0.0594,  0.0578,
        -0.1256, -0.1220,  0.0817, -0.2463,  0.2978,  0.0536,  0.1771,  0.2856,
        -0.0662, -0.0822,  0.0286,  0.2253, -0.3002,  0.2524,  0.2267,  0.0363,
         0.1730, -0.1540, -0.2048,  0.2924,  0.0756, -0.0205, -0.0551, -0.2787,
        -0.1578,  0.0796,  0.2978,  0.2474, -0.1097,  0.2120,  0.1949, -0.1911,
         0.1699,  0.3218, -0.1884,  0.1896, -0.0465, -0.0077,  0.2874, -0.1984,
        -0.1262, -0.0751,  0.0686,  0.0193,  0.1655, -0.1463,  0.1005, -0.0691,
        -0.0064, -0.3252,  0.2639, -0.0199,  0.2366,  0.2064,  0.3031, -0.2638],
       device='cuda:0', requires_grad=True)
parameters of the network conv2.weight 
 torch.Size([128, 256, 3, 3]) 
 True 
 tensor([[[[ 1.0980e-02, -3.0583e-03,  5.9267e-03],
          [-1.7275e-02,  1.7810e-03,  9.9610e-03],
          [ 6.1392e-04,  1.7695e-02, -1.1370e-02]],

         [[-1.8928e-02, -1.2648e-02,  1.5174e-02],
          [-1.7911e-02, -4.6039e-03,  1.4752e-02],
          [-7.2000e-03, -1.0343e-02, -1.2612e-02]],

         [[-3.4406e-04, -1.4498e-02,  8.4176e-03],
          [ 1.9480e-02,  1.1968e-02,  1.9546e-02],
          [-4.7254e-05, -1.9348e-02,  1.5856e-02]],

         ...,

         [[-1.0647e-02, -5.7845e-03, -4.0049e-05],
          [ 8.9285e-04, -1.1799e-02, -5.4688e-03],
          [-1.6010e-02, -2.2690e-03, -1.7952e-02]],

         [[ 1.4743e-02,  9.9776e-03,  1.3468e-02],
          [ 1.4478e-02, -7.7383e-03,  1.5668e-03],
          [-9.3546e-03, -1.8325e-02, -1.9307e-02]],

         [[-1.1435e-03,  1.6341e-02,  1.4968e-02],
          [ 2.5987e-03,  3.3511e-03, -1.8576e-02],
          [ 1.9012e-02, -1.2623e-02,  3.7860e-03]]],


        [[[ 1.8918e-02, -9.3746e-04, -1.7771e-02],
          [ 1.1834e-02,  3.3368e-03, -1.1336e-03],
          [ 1.2091e-02,  7.4836e-03,  1.9893e-02]],

         [[-1.0330e-02, -1.8456e-02,  1.3898e-02],
          [ 1.7642e-03, -5.7257e-04, -2.7634e-04],
          [-2.9693e-03, -8.0558e-03, -1.5542e-02]],

         [[-5.4925e-03,  1.5265e-02,  3.6480e-03],
          [-8.0906e-03,  1.4224e-02,  2.0026e-02],
          [ 3.8280e-03,  1.1989e-02,  1.2546e-02]],

         ...,

         [[ 1.8067e-02,  5.2891e-03,  4.3080e-03],
          [-9.3305e-03,  1.0467e-02,  1.8638e-02],
          [ 3.2193e-03, -8.0923e-03,  5.8333e-03]],

         [[ 1.2804e-02, -6.9836e-03, -1.6962e-02],
          [ 1.8559e-02,  1.7530e-02, -1.9075e-02],
          [-1.8351e-02, -1.6198e-03, -1.4805e-02]],

         [[ 1.3467e-02,  1.2704e-02, -5.1733e-03],
          [-2.0707e-03, -1.0965e-02, -1.6877e-02],
          [-1.6344e-02,  1.2490e-02,  2.3905e-04]]],


        [[[ 1.2921e-02, -8.7643e-03,  8.7088e-03],
          [-8.4609e-03,  2.0332e-02, -4.0168e-03],
          [-4.5476e-03,  8.8597e-03, -1.6303e-02]],

         [[ 9.4201e-03,  6.7483e-03, -3.5869e-03],
          [-7.5954e-03, -1.3173e-02, -2.7249e-03],
          [-1.2990e-02, -2.0726e-03, -1.4514e-02]],

         [[ 1.7736e-03,  1.0363e-02, -3.2779e-03],
          [-1.2463e-02,  8.6997e-03,  1.7717e-02],
          [ 6.8274e-04, -9.8813e-03, -1.4673e-02]],

         ...,

         [[-7.2950e-03,  1.6039e-02, -1.1032e-02],
          [-1.9258e-02, -1.4673e-02, -8.6701e-03],
          [ 9.6028e-03, -5.7172e-03, -1.8266e-02]],

         [[-9.0014e-04,  1.6442e-02, -7.4226e-03],
          [-1.7335e-02,  1.4119e-02, -1.9193e-02],
          [ 2.1100e-03,  9.9928e-03,  5.7693e-03]],

         [[-9.1809e-03,  1.7495e-02,  1.1899e-02],
          [ 1.6067e-02, -1.6037e-02, -7.5290e-03],
          [-8.0940e-03,  6.8629e-03, -1.8030e-02]]],


        ...,


        [[[ 8.6023e-03,  7.4727e-03, -2.0258e-02],
          [ 9.8171e-03, -5.8424e-03, -7.1430e-03],
          [-8.3503e-03, -3.9787e-03,  9.8354e-03]],

         [[ 4.7253e-03, -7.9315e-03, -4.1153e-03],
          [ 2.1575e-03, -1.8641e-03,  3.0163e-03],
          [-1.2435e-02,  1.5426e-02, -8.5371e-03]],

         [[-2.5869e-03, -1.4686e-02,  9.8198e-03],
          [ 5.7526e-03, -2.4469e-04, -1.6366e-02],
          [-1.5715e-02, -1.5466e-03, -6.2991e-03]],

         ...,

         [[-1.8569e-02,  1.8999e-02,  4.0498e-03],
          [-1.8019e-02, -1.7452e-02,  5.0282e-03],
          [ 5.7188e-03,  1.7588e-02,  4.8335e-04]],

         [[-1.4337e-02,  6.3879e-03,  2.0086e-02],
          [ 1.8289e-02, -1.8576e-02,  3.6949e-03],
          [ 1.2968e-02, -8.6956e-03, -1.2908e-02]],

         [[-2.4897e-03,  2.0235e-02, -3.5811e-03],
          [ 1.8250e-03, -6.9903e-03, -1.4853e-02],
          [ 8.6449e-04,  1.4746e-02, -2.0686e-02]]],


        [[[-6.8508e-03,  6.4726e-03,  1.5629e-02],
          [-6.3384e-03,  1.0424e-02, -1.2660e-02],
          [-1.3235e-02,  1.6905e-02,  1.5466e-02]],

         [[-1.2954e-02,  3.3337e-03, -1.1806e-02],
          [ 1.9502e-02, -1.7583e-02,  9.6571e-03],
          [ 7.4022e-03,  1.7833e-02,  3.1048e-03]],

         [[ 2.0193e-02, -6.5710e-03,  1.5929e-03],
          [ 1.7065e-02,  1.0048e-02,  8.7355e-03],
          [-1.1279e-02, -6.0599e-03,  1.6223e-02]],

         ...,

         [[ 1.6403e-02, -1.7567e-02, -1.8212e-02],
          [-4.5533e-03, -1.2179e-02,  3.7527e-03],
          [ 8.0827e-03,  4.5526e-04, -4.4058e-03]],

         [[ 1.1700e-02,  9.7103e-03,  1.3011e-02],
          [-7.6880e-03,  1.3853e-02,  1.1145e-02],
          [-3.5038e-03, -1.0605e-02,  5.3262e-04]],

         [[ 1.0539e-02,  1.9511e-02, -4.7213e-03],
          [-1.7341e-02, -1.3154e-02, -1.4574e-02],
          [-1.0532e-02,  7.5073e-03,  7.9690e-03]]],


        [[[-1.2776e-02,  6.9259e-03, -7.7401e-03],
          [-1.0939e-02, -1.3695e-02,  3.9282e-03],
          [-1.6066e-02, -5.0568e-03, -1.2688e-02]],

         [[-1.4870e-02,  1.9105e-02,  8.4141e-03],
          [-1.0103e-02,  1.3012e-02,  7.4199e-03],
          [ 7.3135e-03,  1.3748e-02,  1.3061e-02]],

         [[-1.8526e-03,  6.9356e-04,  3.3472e-03],
          [-2.5974e-03,  1.7047e-02, -1.9147e-02],
          [-9.8510e-03, -7.8247e-03,  9.0025e-03]],

         ...,

         [[-9.4782e-03, -1.3314e-02,  3.2988e-03],
          [ 5.1970e-03,  5.2751e-03, -1.1517e-02],
          [-8.6368e-03, -1.8028e-02,  1.6876e-02]],

         [[-1.0642e-02, -1.6383e-02, -1.2492e-02],
          [ 2.9955e-03, -3.2804e-03,  4.6072e-03],
          [-6.0553e-03, -1.7528e-02,  1.4781e-02]],

         [[ 2.0018e-02,  5.1047e-04,  2.0757e-02],
          [ 1.3313e-02, -1.4378e-03,  1.4834e-02],
          [-1.1717e-02, -1.5165e-02, -1.5011e-02]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 1.0980e-02, -3.0583e-03,  5.9267e-03],
          [-1.7275e-02,  1.7810e-03,  9.9610e-03],
          [ 6.1392e-04,  1.7695e-02, -1.1370e-02]],

         [[-1.8928e-02, -1.2648e-02,  1.5174e-02],
          [-1.7911e-02, -4.6039e-03,  1.4752e-02],
          [-7.2000e-03, -1.0343e-02, -1.2612e-02]],

         [[-3.4406e-04, -1.4498e-02,  8.4176e-03],
          [ 1.9480e-02,  1.1968e-02,  1.9546e-02],
          [-4.7254e-05, -1.9348e-02,  1.5856e-02]],

         ...,

         [[-1.0647e-02, -5.7845e-03, -4.0049e-05],
          [ 8.9285e-04, -1.1799e-02, -5.4688e-03],
          [-1.6010e-02, -2.2690e-03, -1.7952e-02]],

         [[ 1.4743e-02,  9.9776e-03,  1.3468e-02],
          [ 1.4478e-02, -7.7383e-03,  1.5668e-03],
          [-9.3546e-03, -1.8325e-02, -1.9307e-02]],

         [[-1.1435e-03,  1.6341e-02,  1.4968e-02],
          [ 2.5987e-03,  3.3511e-03, -1.8576e-02],
          [ 1.9012e-02, -1.2623e-02,  3.7860e-03]]],


        [[[ 1.8918e-02, -9.3746e-04, -1.7771e-02],
          [ 1.1834e-02,  3.3368e-03, -1.1336e-03],
          [ 1.2091e-02,  7.4836e-03,  1.9893e-02]],

         [[-1.0330e-02, -1.8456e-02,  1.3898e-02],
          [ 1.7642e-03, -5.7257e-04, -2.7634e-04],
          [-2.9693e-03, -8.0558e-03, -1.5542e-02]],

         [[-5.4925e-03,  1.5265e-02,  3.6480e-03],
          [-8.0906e-03,  1.4224e-02,  2.0026e-02],
          [ 3.8280e-03,  1.1989e-02,  1.2546e-02]],

         ...,

         [[ 1.8067e-02,  5.2891e-03,  4.3080e-03],
          [-9.3305e-03,  1.0467e-02,  1.8638e-02],
          [ 3.2193e-03, -8.0923e-03,  5.8333e-03]],

         [[ 1.2804e-02, -6.9836e-03, -1.6962e-02],
          [ 1.8559e-02,  1.7530e-02, -1.9075e-02],
          [-1.8351e-02, -1.6198e-03, -1.4805e-02]],

         [[ 1.3467e-02,  1.2704e-02, -5.1733e-03],
          [-2.0707e-03, -1.0965e-02, -1.6877e-02],
          [-1.6344e-02,  1.2490e-02,  2.3905e-04]]],


        [[[ 1.2921e-02, -8.7643e-03,  8.7088e-03],
          [-8.4609e-03,  2.0332e-02, -4.0168e-03],
          [-4.5476e-03,  8.8597e-03, -1.6303e-02]],

         [[ 9.4201e-03,  6.7483e-03, -3.5869e-03],
          [-7.5954e-03, -1.3173e-02, -2.7249e-03],
          [-1.2990e-02, -2.0726e-03, -1.4514e-02]],

         [[ 1.7736e-03,  1.0363e-02, -3.2779e-03],
          [-1.2463e-02,  8.6997e-03,  1.7717e-02],
          [ 6.8274e-04, -9.8813e-03, -1.4673e-02]],

         ...,

         [[-7.2950e-03,  1.6039e-02, -1.1032e-02],
          [-1.9258e-02, -1.4673e-02, -8.6701e-03],
          [ 9.6028e-03, -5.7172e-03, -1.8266e-02]],

         [[-9.0014e-04,  1.6442e-02, -7.4226e-03],
          [-1.7335e-02,  1.4119e-02, -1.9193e-02],
          [ 2.1100e-03,  9.9928e-03,  5.7693e-03]],

         [[-9.1809e-03,  1.7495e-02,  1.1899e-02],
          [ 1.6067e-02, -1.6037e-02, -7.5290e-03],
          [-8.0940e-03,  6.8629e-03, -1.8030e-02]]],


        ...,


        [[[ 8.6023e-03,  7.4727e-03, -2.0258e-02],
          [ 9.8171e-03, -5.8424e-03, -7.1430e-03],
          [-8.3503e-03, -3.9787e-03,  9.8354e-03]],

         [[ 4.7253e-03, -7.9315e-03, -4.1153e-03],
          [ 2.1575e-03, -1.8641e-03,  3.0163e-03],
          [-1.2435e-02,  1.5426e-02, -8.5371e-03]],

         [[-2.5869e-03, -1.4686e-02,  9.8198e-03],
          [ 5.7526e-03, -2.4469e-04, -1.6366e-02],
          [-1.5715e-02, -1.5466e-03, -6.2991e-03]],

         ...,

         [[-1.8569e-02,  1.8999e-02,  4.0498e-03],
          [-1.8019e-02, -1.7452e-02,  5.0282e-03],
          [ 5.7188e-03,  1.7588e-02,  4.8335e-04]],

         [[-1.4337e-02,  6.3879e-03,  2.0086e-02],
          [ 1.8289e-02, -1.8576e-02,  3.6949e-03],
          [ 1.2968e-02, -8.6956e-03, -1.2908e-02]],

         [[-2.4897e-03,  2.0235e-02, -3.5811e-03],
          [ 1.8250e-03, -6.9903e-03, -1.4853e-02],
          [ 8.6449e-04,  1.4746e-02, -2.0686e-02]]],


        [[[-6.8508e-03,  6.4726e-03,  1.5629e-02],
          [-6.3384e-03,  1.0424e-02, -1.2660e-02],
          [-1.3235e-02,  1.6905e-02,  1.5466e-02]],

         [[-1.2954e-02,  3.3337e-03, -1.1806e-02],
          [ 1.9502e-02, -1.7583e-02,  9.6571e-03],
          [ 7.4022e-03,  1.7833e-02,  3.1048e-03]],

         [[ 2.0193e-02, -6.5710e-03,  1.5929e-03],
          [ 1.7065e-02,  1.0048e-02,  8.7355e-03],
          [-1.1279e-02, -6.0599e-03,  1.6223e-02]],

         ...,

         [[ 1.6403e-02, -1.7567e-02, -1.8212e-02],
          [-4.5533e-03, -1.2179e-02,  3.7527e-03],
          [ 8.0827e-03,  4.5526e-04, -4.4058e-03]],

         [[ 1.1700e-02,  9.7103e-03,  1.3011e-02],
          [-7.6880e-03,  1.3853e-02,  1.1145e-02],
          [-3.5038e-03, -1.0605e-02,  5.3262e-04]],

         [[ 1.0539e-02,  1.9511e-02, -4.7213e-03],
          [-1.7341e-02, -1.3154e-02, -1.4574e-02],
          [-1.0532e-02,  7.5073e-03,  7.9690e-03]]],


        [[[-1.2776e-02,  6.9259e-03, -7.7401e-03],
          [-1.0939e-02, -1.3695e-02,  3.9282e-03],
          [-1.6066e-02, -5.0568e-03, -1.2688e-02]],

         [[-1.4870e-02,  1.9105e-02,  8.4141e-03],
          [-1.0103e-02,  1.3012e-02,  7.4199e-03],
          [ 7.3135e-03,  1.3748e-02,  1.3061e-02]],

         [[-1.8526e-03,  6.9356e-04,  3.3472e-03],
          [-2.5974e-03,  1.7047e-02, -1.9147e-02],
          [-9.8510e-03, -7.8247e-03,  9.0025e-03]],

         ...,

         [[-9.4782e-03, -1.3314e-02,  3.2988e-03],
          [ 5.1970e-03,  5.2751e-03, -1.1517e-02],
          [-8.6368e-03, -1.8028e-02,  1.6876e-02]],

         [[-1.0642e-02, -1.6383e-02, -1.2492e-02],
          [ 2.9955e-03, -3.2804e-03,  4.6072e-03],
          [-6.0553e-03, -1.7528e-02,  1.4781e-02]],

         [[ 2.0018e-02,  5.1047e-04,  2.0757e-02],
          [ 1.3313e-02, -1.4378e-03,  1.4834e-02],
          [-1.1717e-02, -1.5165e-02, -1.5011e-02]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv2.bias 
 torch.Size([128]) 
 True 
 tensor([ 0.0074,  0.0078, -0.0081,  0.0140,  0.0027,  0.0056,  0.0172,  0.0064,
        -0.0024,  0.0033,  0.0132, -0.0105,  0.0171, -0.0154, -0.0020,  0.0143,
         0.0001,  0.0176, -0.0124,  0.0050, -0.0081, -0.0166,  0.0144, -0.0073,
         0.0060, -0.0069,  0.0172,  0.0009, -0.0056,  0.0200, -0.0008, -0.0163,
         0.0094,  0.0206, -0.0165, -0.0086, -0.0113, -0.0027, -0.0097, -0.0032,
        -0.0052, -0.0109,  0.0145,  0.0125, -0.0041, -0.0057, -0.0168, -0.0204,
        -0.0176, -0.0088,  0.0169,  0.0021,  0.0088,  0.0111,  0.0059,  0.0101,
         0.0189,  0.0170,  0.0183,  0.0050, -0.0206,  0.0193, -0.0007,  0.0172,
         0.0057,  0.0186,  0.0078, -0.0200,  0.0122,  0.0188, -0.0146,  0.0114,
         0.0157,  0.0018, -0.0090, -0.0156,  0.0075,  0.0027, -0.0162, -0.0023,
         0.0034, -0.0027, -0.0038, -0.0045,  0.0034,  0.0043,  0.0067, -0.0006,
        -0.0125, -0.0043,  0.0163,  0.0106,  0.0046,  0.0017,  0.0180,  0.0159,
        -0.0129,  0.0179, -0.0186, -0.0012,  0.0063,  0.0203, -0.0203, -0.0161,
         0.0146, -0.0111,  0.0084, -0.0191, -0.0059, -0.0122,  0.0155,  0.0088,
         0.0052,  0.0159,  0.0083, -0.0092, -0.0143,  0.0031, -0.0108,  0.0155,
        -0.0136,  0.0006, -0.0049, -0.0170, -0.0104, -0.0156,  0.0126, -0.0160],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0074,  0.0078, -0.0081,  0.0140,  0.0027,  0.0056,  0.0172,  0.0064,
        -0.0024,  0.0033,  0.0132, -0.0105,  0.0171, -0.0154, -0.0020,  0.0143,
         0.0001,  0.0176, -0.0124,  0.0050, -0.0081, -0.0166,  0.0144, -0.0073,
         0.0060, -0.0069,  0.0172,  0.0009, -0.0056,  0.0200, -0.0008, -0.0163,
         0.0094,  0.0206, -0.0165, -0.0086, -0.0113, -0.0027, -0.0097, -0.0032,
        -0.0052, -0.0109,  0.0145,  0.0125, -0.0041, -0.0057, -0.0168, -0.0204,
        -0.0176, -0.0088,  0.0169,  0.0021,  0.0088,  0.0111,  0.0059,  0.0101,
         0.0189,  0.0170,  0.0183,  0.0050, -0.0206,  0.0193, -0.0007,  0.0172,
         0.0057,  0.0186,  0.0078, -0.0200,  0.0122,  0.0188, -0.0146,  0.0114,
         0.0157,  0.0018, -0.0090, -0.0156,  0.0075,  0.0027, -0.0162, -0.0023,
         0.0034, -0.0027, -0.0038, -0.0045,  0.0034,  0.0043,  0.0067, -0.0006,
        -0.0125, -0.0043,  0.0163,  0.0106,  0.0046,  0.0017,  0.0180,  0.0159,
        -0.0129,  0.0179, -0.0186, -0.0012,  0.0063,  0.0203, -0.0203, -0.0161,
         0.0146, -0.0111,  0.0084, -0.0191, -0.0059, -0.0122,  0.0155,  0.0088,
         0.0052,  0.0159,  0.0083, -0.0092, -0.0143,  0.0031, -0.0108,  0.0155,
        -0.0136,  0.0006, -0.0049, -0.0170, -0.0104, -0.0156,  0.0126, -0.0160],
       device='cuda:0', requires_grad=True)
parameters of the network conv3.weight 
 torch.Size([64, 128, 3, 3]) 
 True 
 tensor([[[[ 1.4995e-02,  2.9538e-03,  2.4765e-02],
          [-1.6749e-03, -2.3310e-03,  9.5862e-03],
          [ 8.5761e-03,  2.7899e-02,  2.9234e-02]],

         [[-2.1327e-04, -1.4365e-02, -1.4068e-02],
          [ 2.2563e-03,  9.4378e-03, -5.5865e-03],
          [-1.3396e-02, -9.2363e-03, -1.6646e-02]],

         [[-2.6566e-02,  6.6107e-03,  1.4195e-02],
          [-2.4943e-02,  2.4401e-02, -4.4717e-03],
          [-7.7764e-03,  2.4379e-02, -2.8890e-02]],

         ...,

         [[-3.0602e-03, -8.9014e-03,  2.3761e-02],
          [-2.4509e-02, -8.3072e-03, -6.0115e-03],
          [ 1.2102e-03,  9.2597e-03,  6.9187e-03]],

         [[ 2.8506e-02, -4.8277e-03, -2.4041e-02],
          [ 1.8738e-02,  6.1078e-03,  9.2507e-03],
          [-1.5128e-02, -1.5270e-02, -2.2295e-02]],

         [[ 2.9596e-03, -1.1614e-02,  1.7475e-02],
          [-7.7089e-03,  2.2583e-02, -2.6012e-02],
          [-1.2529e-03, -3.2894e-03, -1.9414e-02]]],


        [[[-2.5169e-02, -9.2674e-03,  2.5154e-02],
          [ 1.0318e-02,  5.5203e-03, -2.6800e-02],
          [ 9.8848e-03,  2.5882e-02, -2.3241e-02]],

         [[ 2.6428e-02, -2.3755e-02, -2.2056e-02],
          [-5.1090e-04,  1.7824e-02, -2.5052e-02],
          [ 6.4693e-03,  1.0426e-02,  1.4923e-02]],

         [[-6.9948e-03,  1.9917e-02, -9.1760e-03],
          [ 1.9966e-02,  1.5557e-02,  2.9252e-02],
          [ 1.9640e-03,  6.9813e-03, -1.0449e-02]],

         ...,

         [[ 1.3494e-02, -2.3775e-02,  1.9422e-02],
          [-1.6642e-02,  1.1715e-02,  1.1871e-02],
          [ 2.0673e-02,  2.7840e-02, -5.1891e-03]],

         [[-7.1060e-03, -2.4027e-04,  1.9201e-02],
          [ 1.8036e-02, -1.5842e-03, -2.9181e-02],
          [-3.3564e-03,  9.0310e-03,  1.2152e-02]],

         [[ 2.7070e-02,  2.2903e-02,  5.2671e-03],
          [ 1.2759e-02,  4.9472e-03,  1.2371e-02],
          [ 1.9315e-02, -1.2122e-03,  8.9826e-03]]],


        [[[ 1.7797e-02, -2.6745e-02, -1.8279e-03],
          [ 1.4123e-02,  2.6733e-02,  1.2282e-02],
          [ 1.6328e-02, -2.1423e-02, -1.7077e-02]],

         [[-2.6189e-02, -2.6631e-02, -2.8406e-02],
          [-2.0498e-02, -2.8564e-02,  8.9266e-03],
          [-1.5695e-03, -3.8745e-03,  2.7608e-02]],

         [[-1.0637e-02, -2.5699e-02,  1.4680e-02],
          [-1.3007e-02,  1.2462e-02,  2.7799e-02],
          [ 1.4767e-02,  2.0243e-03, -1.9148e-02]],

         ...,

         [[ 1.2263e-03,  1.2907e-02,  4.2415e-03],
          [ 4.2374e-03,  2.2529e-02, -2.5768e-02],
          [-9.9320e-03,  2.6785e-02,  4.9279e-04]],

         [[ 2.6697e-02, -2.2376e-02, -1.0946e-02],
          [ 7.9390e-03, -2.6125e-02,  1.1276e-02],
          [-2.9234e-03,  2.7162e-02,  2.2313e-02]],

         [[ 2.1732e-02,  2.2376e-02, -5.4339e-03],
          [-5.5450e-03, -1.8329e-02,  1.0245e-02],
          [-1.5445e-02, -5.7477e-03,  1.5438e-02]]],


        ...,


        [[[-2.1985e-02,  2.5681e-02, -1.3849e-02],
          [ 9.5593e-03, -2.8390e-02,  2.1231e-02],
          [ 2.1508e-02,  1.8794e-02,  2.0095e-02]],

         [[ 5.4871e-03,  7.2652e-03,  2.2577e-02],
          [-1.3202e-02, -2.0731e-02,  2.3261e-02],
          [-9.2949e-03,  6.8154e-03,  8.7914e-04]],

         [[-2.1119e-02, -2.2400e-03, -6.9487e-03],
          [-5.5685e-03, -2.7217e-02,  8.0612e-03],
          [ 2.7949e-02,  2.7661e-02,  2.8953e-02]],

         ...,

         [[-2.5745e-02,  1.9926e-02,  2.8667e-02],
          [-2.1113e-02,  9.9951e-04, -7.7089e-04],
          [-2.7096e-02,  1.3695e-02, -4.6133e-04]],

         [[ 4.6616e-03, -1.6056e-02,  2.3351e-02],
          [-2.4630e-02, -2.4305e-02, -1.7746e-02],
          [ 1.8385e-02,  2.3831e-02, -2.6178e-02]],

         [[-2.2325e-02,  5.3172e-03, -8.1483e-03],
          [ 7.8984e-03,  2.5719e-02,  2.8985e-02],
          [-1.7590e-02, -1.5893e-02,  5.9579e-04]]],


        [[[ 5.9634e-03, -1.2130e-02,  1.9050e-02],
          [-1.9482e-02,  5.5951e-03,  2.1306e-03],
          [-2.3532e-02,  6.8345e-03, -1.5932e-02]],

         [[ 2.0597e-02, -6.5871e-03,  3.3986e-03],
          [ 2.6378e-02, -2.4754e-02, -2.8110e-02],
          [-9.4216e-03, -8.0183e-03, -1.4125e-02]],

         [[-1.5617e-02,  6.0500e-03,  7.0060e-03],
          [-1.8150e-02, -2.4260e-02, -2.3837e-02],
          [-1.2389e-02, -2.8620e-02,  2.6872e-02]],

         ...,

         [[-6.7432e-03,  2.0885e-02,  1.5707e-02],
          [ 2.4989e-02,  1.5007e-03, -6.3534e-03],
          [ 2.4163e-02,  2.4098e-02,  2.3916e-03]],

         [[-2.2862e-03,  8.2524e-03, -1.9886e-02],
          [-6.5240e-05,  2.1564e-03,  2.4699e-02],
          [-2.8561e-02,  2.2486e-02, -5.4444e-03]],

         [[ 1.7988e-02, -2.8336e-02, -9.4639e-03],
          [-1.9738e-03, -1.7749e-02, -2.7951e-02],
          [ 2.8462e-02,  1.8017e-02,  1.4010e-02]]],


        [[[-1.9642e-02,  1.1248e-03,  3.9723e-03],
          [ 1.5403e-02, -2.8230e-03,  2.8149e-02],
          [-3.4211e-03, -2.0947e-02, -2.1642e-02]],

         [[-9.6358e-03, -1.3640e-02,  1.5986e-02],
          [-2.4220e-02, -1.1553e-02, -1.1377e-02],
          [-2.6379e-03,  2.3938e-02,  2.0946e-02]],

         [[-2.9904e-03, -2.6380e-02, -2.4718e-02],
          [-9.6611e-03,  2.4723e-02, -2.0469e-02],
          [-5.0206e-03, -4.4438e-04, -6.6330e-03]],

         ...,

         [[ 2.5475e-02, -1.9034e-02,  2.1804e-05],
          [-2.9392e-02,  2.1412e-02, -8.0469e-03],
          [-1.1333e-02,  1.6790e-02, -1.1803e-02]],

         [[ 8.3842e-03, -2.5822e-02,  1.1397e-02],
          [-1.0036e-02,  1.3334e-03, -9.3291e-03],
          [ 5.0056e-03, -4.7771e-03,  2.9892e-03]],

         [[-2.2744e-02,  2.5246e-02,  1.1168e-02],
          [ 7.9987e-03,  1.4131e-02,  1.5381e-02],
          [-9.1869e-03,  1.1710e-02, -1.8271e-02]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 1.4995e-02,  2.9538e-03,  2.4765e-02],
          [-1.6749e-03, -2.3310e-03,  9.5862e-03],
          [ 8.5761e-03,  2.7899e-02,  2.9234e-02]],

         [[-2.1327e-04, -1.4365e-02, -1.4068e-02],
          [ 2.2563e-03,  9.4378e-03, -5.5865e-03],
          [-1.3396e-02, -9.2363e-03, -1.6646e-02]],

         [[-2.6566e-02,  6.6107e-03,  1.4195e-02],
          [-2.4943e-02,  2.4401e-02, -4.4717e-03],
          [-7.7764e-03,  2.4379e-02, -2.8890e-02]],

         ...,

         [[-3.0602e-03, -8.9014e-03,  2.3761e-02],
          [-2.4509e-02, -8.3072e-03, -6.0115e-03],
          [ 1.2102e-03,  9.2597e-03,  6.9187e-03]],

         [[ 2.8506e-02, -4.8277e-03, -2.4041e-02],
          [ 1.8738e-02,  6.1078e-03,  9.2507e-03],
          [-1.5128e-02, -1.5270e-02, -2.2295e-02]],

         [[ 2.9596e-03, -1.1614e-02,  1.7475e-02],
          [-7.7089e-03,  2.2583e-02, -2.6012e-02],
          [-1.2529e-03, -3.2894e-03, -1.9414e-02]]],


        [[[-2.5169e-02, -9.2674e-03,  2.5154e-02],
          [ 1.0318e-02,  5.5203e-03, -2.6800e-02],
          [ 9.8848e-03,  2.5882e-02, -2.3241e-02]],

         [[ 2.6428e-02, -2.3755e-02, -2.2056e-02],
          [-5.1090e-04,  1.7824e-02, -2.5052e-02],
          [ 6.4693e-03,  1.0426e-02,  1.4923e-02]],

         [[-6.9948e-03,  1.9917e-02, -9.1760e-03],
          [ 1.9966e-02,  1.5557e-02,  2.9252e-02],
          [ 1.9640e-03,  6.9813e-03, -1.0449e-02]],

         ...,

         [[ 1.3494e-02, -2.3775e-02,  1.9422e-02],
          [-1.6642e-02,  1.1715e-02,  1.1871e-02],
          [ 2.0673e-02,  2.7840e-02, -5.1891e-03]],

         [[-7.1060e-03, -2.4027e-04,  1.9201e-02],
          [ 1.8036e-02, -1.5842e-03, -2.9181e-02],
          [-3.3564e-03,  9.0310e-03,  1.2152e-02]],

         [[ 2.7070e-02,  2.2903e-02,  5.2671e-03],
          [ 1.2759e-02,  4.9472e-03,  1.2371e-02],
          [ 1.9315e-02, -1.2122e-03,  8.9826e-03]]],


        [[[ 1.7797e-02, -2.6745e-02, -1.8279e-03],
          [ 1.4123e-02,  2.6733e-02,  1.2282e-02],
          [ 1.6328e-02, -2.1423e-02, -1.7077e-02]],

         [[-2.6189e-02, -2.6631e-02, -2.8406e-02],
          [-2.0498e-02, -2.8564e-02,  8.9266e-03],
          [-1.5695e-03, -3.8745e-03,  2.7608e-02]],

         [[-1.0637e-02, -2.5699e-02,  1.4680e-02],
          [-1.3007e-02,  1.2462e-02,  2.7799e-02],
          [ 1.4767e-02,  2.0243e-03, -1.9148e-02]],

         ...,

         [[ 1.2263e-03,  1.2907e-02,  4.2415e-03],
          [ 4.2374e-03,  2.2529e-02, -2.5768e-02],
          [-9.9320e-03,  2.6785e-02,  4.9279e-04]],

         [[ 2.6697e-02, -2.2376e-02, -1.0946e-02],
          [ 7.9390e-03, -2.6125e-02,  1.1276e-02],
          [-2.9234e-03,  2.7162e-02,  2.2313e-02]],

         [[ 2.1732e-02,  2.2376e-02, -5.4339e-03],
          [-5.5450e-03, -1.8329e-02,  1.0245e-02],
          [-1.5445e-02, -5.7477e-03,  1.5438e-02]]],


        ...,


        [[[-2.1985e-02,  2.5681e-02, -1.3849e-02],
          [ 9.5593e-03, -2.8390e-02,  2.1231e-02],
          [ 2.1508e-02,  1.8794e-02,  2.0095e-02]],

         [[ 5.4871e-03,  7.2652e-03,  2.2577e-02],
          [-1.3202e-02, -2.0731e-02,  2.3261e-02],
          [-9.2949e-03,  6.8154e-03,  8.7914e-04]],

         [[-2.1119e-02, -2.2400e-03, -6.9487e-03],
          [-5.5685e-03, -2.7217e-02,  8.0612e-03],
          [ 2.7949e-02,  2.7661e-02,  2.8953e-02]],

         ...,

         [[-2.5745e-02,  1.9926e-02,  2.8667e-02],
          [-2.1113e-02,  9.9951e-04, -7.7089e-04],
          [-2.7096e-02,  1.3695e-02, -4.6133e-04]],

         [[ 4.6616e-03, -1.6056e-02,  2.3351e-02],
          [-2.4630e-02, -2.4305e-02, -1.7746e-02],
          [ 1.8385e-02,  2.3831e-02, -2.6178e-02]],

         [[-2.2325e-02,  5.3172e-03, -8.1483e-03],
          [ 7.8984e-03,  2.5719e-02,  2.8985e-02],
          [-1.7590e-02, -1.5893e-02,  5.9579e-04]]],


        [[[ 5.9634e-03, -1.2130e-02,  1.9050e-02],
          [-1.9482e-02,  5.5951e-03,  2.1306e-03],
          [-2.3532e-02,  6.8345e-03, -1.5932e-02]],

         [[ 2.0597e-02, -6.5871e-03,  3.3986e-03],
          [ 2.6378e-02, -2.4754e-02, -2.8110e-02],
          [-9.4216e-03, -8.0183e-03, -1.4125e-02]],

         [[-1.5617e-02,  6.0500e-03,  7.0060e-03],
          [-1.8150e-02, -2.4260e-02, -2.3837e-02],
          [-1.2389e-02, -2.8620e-02,  2.6872e-02]],

         ...,

         [[-6.7432e-03,  2.0885e-02,  1.5707e-02],
          [ 2.4989e-02,  1.5007e-03, -6.3534e-03],
          [ 2.4163e-02,  2.4098e-02,  2.3916e-03]],

         [[-2.2862e-03,  8.2524e-03, -1.9886e-02],
          [-6.5240e-05,  2.1564e-03,  2.4699e-02],
          [-2.8561e-02,  2.2486e-02, -5.4444e-03]],

         [[ 1.7988e-02, -2.8336e-02, -9.4639e-03],
          [-1.9738e-03, -1.7749e-02, -2.7951e-02],
          [ 2.8462e-02,  1.8017e-02,  1.4010e-02]]],


        [[[-1.9642e-02,  1.1248e-03,  3.9723e-03],
          [ 1.5403e-02, -2.8230e-03,  2.8149e-02],
          [-3.4211e-03, -2.0947e-02, -2.1642e-02]],

         [[-9.6358e-03, -1.3640e-02,  1.5986e-02],
          [-2.4220e-02, -1.1553e-02, -1.1377e-02],
          [-2.6379e-03,  2.3938e-02,  2.0946e-02]],

         [[-2.9904e-03, -2.6380e-02, -2.4718e-02],
          [-9.6611e-03,  2.4723e-02, -2.0469e-02],
          [-5.0206e-03, -4.4438e-04, -6.6330e-03]],

         ...,

         [[ 2.5475e-02, -1.9034e-02,  2.1804e-05],
          [-2.9392e-02,  2.1412e-02, -8.0469e-03],
          [-1.1333e-02,  1.6790e-02, -1.1803e-02]],

         [[ 8.3842e-03, -2.5822e-02,  1.1397e-02],
          [-1.0036e-02,  1.3334e-03, -9.3291e-03],
          [ 5.0056e-03, -4.7771e-03,  2.9892e-03]],

         [[-2.2744e-02,  2.5246e-02,  1.1168e-02],
          [ 7.9987e-03,  1.4131e-02,  1.5381e-02],
          [-9.1869e-03,  1.1710e-02, -1.8271e-02]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.bias 
 torch.Size([64]) 
 True 
 tensor([ 0.0071, -0.0137,  0.0028,  0.0227, -0.0214, -0.0289,  0.0125, -0.0149,
        -0.0030, -0.0261, -0.0130,  0.0259, -0.0082, -0.0026,  0.0048, -0.0199,
        -0.0155,  0.0241,  0.0189, -0.0159, -0.0103,  0.0053, -0.0014,  0.0171,
        -0.0049,  0.0092, -0.0236,  0.0129, -0.0144,  0.0221, -0.0148,  0.0294,
        -0.0066, -0.0193,  0.0134, -0.0172, -0.0069, -0.0150,  0.0092, -0.0129,
        -0.0197,  0.0209, -0.0021,  0.0159, -0.0262,  0.0245,  0.0028, -0.0182,
        -0.0228, -0.0241,  0.0281,  0.0073,  0.0261,  0.0015,  0.0139,  0.0083,
         0.0050,  0.0255,  0.0204,  0.0126,  0.0186, -0.0127,  0.0236,  0.0099],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0071, -0.0137,  0.0028,  0.0227, -0.0214, -0.0289,  0.0125, -0.0149,
        -0.0030, -0.0261, -0.0130,  0.0259, -0.0082, -0.0026,  0.0048, -0.0199,
        -0.0155,  0.0241,  0.0189, -0.0159, -0.0103,  0.0053, -0.0014,  0.0171,
        -0.0049,  0.0092, -0.0236,  0.0129, -0.0144,  0.0221, -0.0148,  0.0294,
        -0.0066, -0.0193,  0.0134, -0.0172, -0.0069, -0.0150,  0.0092, -0.0129,
        -0.0197,  0.0209, -0.0021,  0.0159, -0.0262,  0.0245,  0.0028, -0.0182,
        -0.0228, -0.0241,  0.0281,  0.0073,  0.0261,  0.0015,  0.0139,  0.0083,
         0.0050,  0.0255,  0.0204,  0.0126,  0.0186, -0.0127,  0.0236,  0.0099],
       device='cuda:0', requires_grad=True)
parameters of the network fc1.weight 
 torch.Size([256, 667776]) 
 True 
 tensor([[-2.8923e-05, -4.9506e-04,  1.0559e-03,  ...,  5.4405e-04,
          2.2560e-04, -9.8901e-04],
        [ 9.3498e-04,  4.1099e-04, -2.1536e-04,  ..., -8.9215e-04,
          1.2631e-04, -5.6631e-04],
        [ 3.0156e-04, -8.4646e-05, -6.9296e-05,  ..., -9.8782e-04,
         -3.3526e-04, -1.9834e-04],
        ...,
        [ 1.1046e-05,  8.9054e-04, -4.5025e-04,  ..., -6.6696e-04,
         -4.4027e-04,  7.1344e-04],
        [ 9.7571e-04,  2.3631e-04,  7.8018e-04,  ...,  7.7319e-04,
         -6.2354e-04,  5.3750e-04],
        [-1.6452e-04,  9.9705e-04, -5.0129e-04,  ...,  7.8919e-04,
         -8.4298e-04,  3.9548e-04]], device='cuda:0') 
 Parameter containing:
tensor([[-2.8923e-05, -4.9506e-04,  1.0559e-03,  ...,  5.4405e-04,
          2.2560e-04, -9.8901e-04],
        [ 9.3498e-04,  4.1099e-04, -2.1536e-04,  ..., -8.9215e-04,
          1.2631e-04, -5.6631e-04],
        [ 3.0156e-04, -8.4646e-05, -6.9296e-05,  ..., -9.8782e-04,
         -3.3526e-04, -1.9834e-04],
        ...,
        [ 1.1046e-05,  8.9054e-04, -4.5025e-04,  ..., -6.6696e-04,
         -4.4027e-04,  7.1344e-04],
        [ 9.7571e-04,  2.3631e-04,  7.8018e-04,  ...,  7.7319e-04,
         -6.2354e-04,  5.3750e-04],
        [-1.6452e-04,  9.9705e-04, -5.0129e-04,  ...,  7.8919e-04,
         -8.4298e-04,  3.9548e-04]], device='cuda:0', requires_grad=True)
parameters of the network fc1.bias 
 torch.Size([256]) 
 True 
 tensor([-1.1467e-03, -1.2008e-03, -7.4459e-04, -7.4181e-04, -7.3596e-04,
         8.1156e-04,  8.5572e-05,  7.2543e-04, -6.4928e-04, -5.2898e-04,
        -3.2432e-04, -1.9987e-04, -9.6316e-04, -6.7888e-04,  1.1568e-03,
        -8.7798e-04, -1.1630e-03, -5.6070e-04,  1.1760e-04, -8.2177e-04,
        -9.8517e-04,  2.9762e-04,  1.1628e-04,  1.1715e-03,  5.2048e-04,
         9.4984e-05, -5.4789e-04,  1.0371e-03, -7.2157e-04,  7.8846e-04,
         8.2850e-04,  2.2314e-04, -9.1861e-04, -6.1709e-05,  1.2066e-04,
         1.1035e-03,  1.4824e-04, -7.3203e-04, -1.1443e-03, -7.6581e-04,
         3.0383e-04,  1.7908e-05,  1.0941e-03,  5.2544e-04, -2.0437e-04,
        -4.5885e-04,  1.0352e-03,  3.9374e-04,  7.7689e-04, -2.1761e-05,
        -8.9214e-04, -1.1167e-03, -3.2841e-04,  7.2983e-04,  7.6730e-04,
        -7.4379e-04, -6.6867e-04,  6.4935e-04, -8.4213e-04, -7.3379e-04,
        -1.0049e-03, -4.7604e-04, -1.9173e-04, -3.2727e-04, -2.4761e-04,
        -5.8806e-05, -1.4660e-04, -2.6504e-04,  1.1889e-03,  1.3453e-04,
         2.0991e-04,  8.4389e-04, -4.5741e-04, -1.9076e-04,  1.2254e-04,
         4.7508e-04,  9.6639e-05,  1.0061e-03,  1.7583e-04, -6.0382e-04,
         4.8151e-04, -9.2615e-04,  1.9389e-04,  7.9930e-04,  2.7465e-04,
        -1.0418e-03, -2.1171e-04, -7.4287e-04, -5.5809e-05,  2.9332e-04,
         1.0279e-04, -7.5294e-04,  3.7296e-05, -6.9489e-05, -8.3283e-04,
        -6.9312e-04,  5.2930e-04,  1.1281e-03,  1.4365e-04, -1.1455e-03,
         3.3744e-05,  1.2793e-04, -5.6408e-04,  1.1372e-03, -6.2240e-04,
         7.8196e-05, -1.0055e-03, -6.1793e-04, -9.8126e-04,  6.5084e-04,
        -3.3482e-04,  1.2033e-03,  4.7942e-04,  2.4277e-04,  8.7295e-04,
         3.4872e-04, -4.3775e-04, -1.1849e-03,  1.2135e-03,  9.7790e-04,
        -3.7741e-04, -1.9715e-04,  1.1112e-03, -6.2098e-04, -6.9836e-04,
        -8.0966e-04, -8.7057e-04, -1.3835e-04,  9.0843e-05,  5.9336e-04,
         5.9727e-05, -1.1897e-03, -5.1143e-04, -3.9958e-04, -9.7696e-04,
         9.5459e-04, -8.8846e-04,  1.0615e-03, -9.1705e-04, -1.0659e-03,
         8.1546e-04, -1.1826e-03, -3.4943e-04,  1.0102e-03,  6.7206e-05,
         1.1420e-03,  1.0059e-04, -1.3740e-04, -9.1336e-05, -8.3800e-04,
        -6.4503e-04, -2.3844e-04,  8.3100e-04,  9.3461e-04, -5.8334e-04,
         1.0668e-03,  6.2306e-04,  8.6977e-04, -7.6477e-04,  4.8035e-04,
         8.6838e-04, -7.0304e-04,  3.0423e-04, -2.1485e-04, -4.0763e-05,
         2.9780e-04,  5.1084e-04, -1.8314e-04, -1.0483e-03,  6.3091e-04,
         1.2369e-04,  2.1289e-04, -3.4487e-04,  8.6354e-05,  4.3954e-04,
         8.6012e-04, -7.1668e-04,  8.2637e-04, -7.0420e-04,  1.4311e-04,
        -3.0561e-04, -4.8389e-04,  1.1704e-03,  5.3557e-04,  2.6649e-04,
        -1.5856e-04,  5.6962e-04, -1.4317e-04, -5.4680e-04,  6.7574e-05,
         3.1380e-04,  5.8920e-04,  8.6580e-05, -3.3951e-04,  9.8434e-04,
        -4.8505e-04,  4.1796e-04,  3.3469e-05, -8.4840e-04,  4.8927e-04,
         9.1453e-04,  1.7299e-04,  2.0489e-04,  6.8812e-04, -7.9084e-04,
         1.0508e-03, -1.0280e-03, -4.9350e-04, -2.9374e-04, -7.4680e-04,
         1.1356e-03, -1.3802e-06,  1.0160e-03, -1.0059e-03,  8.6696e-04,
         9.1123e-04,  7.5961e-04, -1.1993e-03, -4.4809e-04, -8.4068e-04,
        -1.2125e-03,  9.6140e-04,  1.1263e-03, -3.6837e-04,  1.1018e-03,
        -6.5244e-04, -4.4177e-04,  3.5635e-04, -3.6708e-04, -3.5945e-05,
         1.2191e-03,  1.0550e-03, -1.2091e-03, -4.1215e-04,  8.4003e-05,
         1.7993e-04, -1.7020e-04,  1.2042e-03, -8.8508e-04, -1.3392e-04,
        -8.9606e-04, -7.9693e-04,  5.5440e-04,  5.1425e-04,  1.1107e-03,
        -9.5151e-04,  1.2150e-03,  2.8304e-04,  7.6735e-04,  3.6014e-04,
        -3.4436e-04, -5.6517e-04,  6.2241e-04, -1.1490e-03, -1.2135e-03,
        -1.1286e-03], device='cuda:0') 
 Parameter containing:
tensor([-1.1467e-03, -1.2008e-03, -7.4459e-04, -7.4181e-04, -7.3596e-04,
         8.1156e-04,  8.5572e-05,  7.2543e-04, -6.4928e-04, -5.2898e-04,
        -3.2432e-04, -1.9987e-04, -9.6316e-04, -6.7888e-04,  1.1568e-03,
        -8.7798e-04, -1.1630e-03, -5.6070e-04,  1.1760e-04, -8.2177e-04,
        -9.8517e-04,  2.9762e-04,  1.1628e-04,  1.1715e-03,  5.2048e-04,
         9.4984e-05, -5.4789e-04,  1.0371e-03, -7.2157e-04,  7.8846e-04,
         8.2850e-04,  2.2314e-04, -9.1861e-04, -6.1709e-05,  1.2066e-04,
         1.1035e-03,  1.4824e-04, -7.3203e-04, -1.1443e-03, -7.6581e-04,
         3.0383e-04,  1.7908e-05,  1.0941e-03,  5.2544e-04, -2.0437e-04,
        -4.5885e-04,  1.0352e-03,  3.9374e-04,  7.7689e-04, -2.1761e-05,
        -8.9214e-04, -1.1167e-03, -3.2841e-04,  7.2983e-04,  7.6730e-04,
        -7.4379e-04, -6.6867e-04,  6.4935e-04, -8.4213e-04, -7.3379e-04,
        -1.0049e-03, -4.7604e-04, -1.9173e-04, -3.2727e-04, -2.4761e-04,
        -5.8806e-05, -1.4660e-04, -2.6504e-04,  1.1889e-03,  1.3453e-04,
         2.0991e-04,  8.4389e-04, -4.5741e-04, -1.9076e-04,  1.2254e-04,
         4.7508e-04,  9.6639e-05,  1.0061e-03,  1.7583e-04, -6.0382e-04,
         4.8151e-04, -9.2615e-04,  1.9389e-04,  7.9930e-04,  2.7465e-04,
        -1.0418e-03, -2.1171e-04, -7.4287e-04, -5.5809e-05,  2.9332e-04,
         1.0279e-04, -7.5294e-04,  3.7296e-05, -6.9489e-05, -8.3283e-04,
        -6.9312e-04,  5.2930e-04,  1.1281e-03,  1.4365e-04, -1.1455e-03,
         3.3744e-05,  1.2793e-04, -5.6408e-04,  1.1372e-03, -6.2240e-04,
         7.8196e-05, -1.0055e-03, -6.1793e-04, -9.8126e-04,  6.5084e-04,
        -3.3482e-04,  1.2033e-03,  4.7942e-04,  2.4277e-04,  8.7295e-04,
         3.4872e-04, -4.3775e-04, -1.1849e-03,  1.2135e-03,  9.7790e-04,
        -3.7741e-04, -1.9715e-04,  1.1112e-03, -6.2098e-04, -6.9836e-04,
        -8.0966e-04, -8.7057e-04, -1.3835e-04,  9.0843e-05,  5.9336e-04,
         5.9727e-05, -1.1897e-03, -5.1143e-04, -3.9958e-04, -9.7696e-04,
         9.5459e-04, -8.8846e-04,  1.0615e-03, -9.1705e-04, -1.0659e-03,
         8.1546e-04, -1.1826e-03, -3.4943e-04,  1.0102e-03,  6.7206e-05,
         1.1420e-03,  1.0059e-04, -1.3740e-04, -9.1336e-05, -8.3800e-04,
        -6.4503e-04, -2.3844e-04,  8.3100e-04,  9.3461e-04, -5.8334e-04,
         1.0668e-03,  6.2306e-04,  8.6977e-04, -7.6477e-04,  4.8035e-04,
         8.6838e-04, -7.0304e-04,  3.0423e-04, -2.1485e-04, -4.0763e-05,
         2.9780e-04,  5.1084e-04, -1.8314e-04, -1.0483e-03,  6.3091e-04,
         1.2369e-04,  2.1289e-04, -3.4487e-04,  8.6354e-05,  4.3954e-04,
         8.6012e-04, -7.1668e-04,  8.2637e-04, -7.0420e-04,  1.4311e-04,
        -3.0561e-04, -4.8389e-04,  1.1704e-03,  5.3557e-04,  2.6649e-04,
        -1.5856e-04,  5.6962e-04, -1.4317e-04, -5.4680e-04,  6.7574e-05,
         3.1380e-04,  5.8920e-04,  8.6580e-05, -3.3951e-04,  9.8434e-04,
        -4.8505e-04,  4.1796e-04,  3.3469e-05, -8.4840e-04,  4.8927e-04,
         9.1453e-04,  1.7299e-04,  2.0489e-04,  6.8812e-04, -7.9084e-04,
         1.0508e-03, -1.0280e-03, -4.9350e-04, -2.9374e-04, -7.4680e-04,
         1.1356e-03, -1.3802e-06,  1.0160e-03, -1.0059e-03,  8.6696e-04,
         9.1123e-04,  7.5961e-04, -1.1993e-03, -4.4809e-04, -8.4068e-04,
        -1.2125e-03,  9.6140e-04,  1.1263e-03, -3.6837e-04,  1.1018e-03,
        -6.5244e-04, -4.4177e-04,  3.5635e-04, -3.6708e-04, -3.5945e-05,
         1.2191e-03,  1.0550e-03, -1.2091e-03, -4.1215e-04,  8.4003e-05,
         1.7993e-04, -1.7020e-04,  1.2042e-03, -8.8508e-04, -1.3392e-04,
        -8.9606e-04, -7.9693e-04,  5.5440e-04,  5.1425e-04,  1.1107e-03,
        -9.5151e-04,  1.2150e-03,  2.8304e-04,  7.6735e-04,  3.6014e-04,
        -3.4436e-04, -5.6517e-04,  6.2241e-04, -1.1490e-03, -1.2135e-03,
        -1.1286e-03], device='cuda:0', requires_grad=True)
parameters of the network fc2.weight 
 torch.Size([128, 256]) 
 True 
 tensor([[ 0.0107, -0.0126, -0.0353,  ...,  0.0545, -0.0569, -0.0094],
        [ 0.0298, -0.0451,  0.0161,  ...,  0.0504, -0.0136,  0.0018],
        [ 0.0572, -0.0123, -0.0263,  ...,  0.0208, -0.0407,  0.0496],
        ...,
        [-0.0383, -0.0094,  0.0161,  ...,  0.0332, -0.0164, -0.0553],
        [ 0.0094, -0.0396,  0.0257,  ...,  0.0136, -0.0117,  0.0036],
        [ 0.0071, -0.0552,  0.0384,  ..., -0.0245,  0.0201, -0.0407]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0107, -0.0126, -0.0353,  ...,  0.0545, -0.0569, -0.0094],
        [ 0.0298, -0.0451,  0.0161,  ...,  0.0504, -0.0136,  0.0018],
        [ 0.0572, -0.0123, -0.0263,  ...,  0.0208, -0.0407,  0.0496],
        ...,
        [-0.0383, -0.0094,  0.0161,  ...,  0.0332, -0.0164, -0.0553],
        [ 0.0094, -0.0396,  0.0257,  ...,  0.0136, -0.0117,  0.0036],
        [ 0.0071, -0.0552,  0.0384,  ..., -0.0245,  0.0201, -0.0407]],
       device='cuda:0', requires_grad=True)
parameters of the network fc2.bias 
 torch.Size([128]) 
 True 
 tensor([-0.0348,  0.0204,  0.0137,  0.0511,  0.0090,  0.0392,  0.0592,  0.0132,
        -0.0070,  0.0165, -0.0249,  0.0305, -0.0004, -0.0176, -0.0306, -0.0076,
        -0.0483, -0.0466,  0.0407,  0.0182, -0.0267,  0.0389, -0.0391,  0.0173,
        -0.0258,  0.0268,  0.0101, -0.0069,  0.0401,  0.0504,  0.0433, -0.0211,
        -0.0389, -0.0208,  0.0462, -0.0457, -0.0375,  0.0412, -0.0558,  0.0051,
        -0.0544,  0.0238,  0.0547, -0.0571, -0.0074,  0.0042, -0.0080,  0.0620,
         0.0403,  0.0580,  0.0470, -0.0576,  0.0608,  0.0622,  0.0060, -0.0018,
         0.0190,  0.0381, -0.0140,  0.0069, -0.0097,  0.0056,  0.0455, -0.0508,
        -0.0250,  0.0109,  0.0363, -0.0163,  0.0497, -0.0143, -0.0452,  0.0116,
        -0.0607,  0.0361, -0.0017, -0.0611, -0.0312,  0.0529,  0.0303,  0.0151,
        -0.0538,  0.0501,  0.0302, -0.0379,  0.0425, -0.0522, -0.0477,  0.0141,
         0.0324,  0.0118,  0.0571,  0.0108,  0.0220, -0.0228, -0.0310, -0.0197,
        -0.0355, -0.0218,  0.0154, -0.0185,  0.0508,  0.0340,  0.0554,  0.0608,
        -0.0266, -0.0489, -0.0081, -0.0084, -0.0177,  0.0026, -0.0106, -0.0294,
         0.0029, -0.0533,  0.0347,  0.0334,  0.0322,  0.0606, -0.0118,  0.0273,
         0.0215, -0.0507,  0.0370,  0.0091, -0.0559, -0.0560,  0.0410,  0.0129],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0348,  0.0204,  0.0137,  0.0511,  0.0090,  0.0392,  0.0592,  0.0132,
        -0.0070,  0.0165, -0.0249,  0.0305, -0.0004, -0.0176, -0.0306, -0.0076,
        -0.0483, -0.0466,  0.0407,  0.0182, -0.0267,  0.0389, -0.0391,  0.0173,
        -0.0258,  0.0268,  0.0101, -0.0069,  0.0401,  0.0504,  0.0433, -0.0211,
        -0.0389, -0.0208,  0.0462, -0.0457, -0.0375,  0.0412, -0.0558,  0.0051,
        -0.0544,  0.0238,  0.0547, -0.0571, -0.0074,  0.0042, -0.0080,  0.0620,
         0.0403,  0.0580,  0.0470, -0.0576,  0.0608,  0.0622,  0.0060, -0.0018,
         0.0190,  0.0381, -0.0140,  0.0069, -0.0097,  0.0056,  0.0455, -0.0508,
        -0.0250,  0.0109,  0.0363, -0.0163,  0.0497, -0.0143, -0.0452,  0.0116,
        -0.0607,  0.0361, -0.0017, -0.0611, -0.0312,  0.0529,  0.0303,  0.0151,
        -0.0538,  0.0501,  0.0302, -0.0379,  0.0425, -0.0522, -0.0477,  0.0141,
         0.0324,  0.0118,  0.0571,  0.0108,  0.0220, -0.0228, -0.0310, -0.0197,
        -0.0355, -0.0218,  0.0154, -0.0185,  0.0508,  0.0340,  0.0554,  0.0608,
        -0.0266, -0.0489, -0.0081, -0.0084, -0.0177,  0.0026, -0.0106, -0.0294,
         0.0029, -0.0533,  0.0347,  0.0334,  0.0322,  0.0606, -0.0118,  0.0273,
         0.0215, -0.0507,  0.0370,  0.0091, -0.0559, -0.0560,  0.0410,  0.0129],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.weight 
 torch.Size([64, 128]) 
 True 
 tensor([[ 0.0092,  0.0578,  0.0200,  ..., -0.0289,  0.0084,  0.0388],
        [-0.0773, -0.0339,  0.0080,  ..., -0.0073, -0.0735,  0.0436],
        [-0.0704,  0.0038,  0.0375,  ..., -0.0346, -0.0476, -0.0286],
        ...,
        [ 0.0820, -0.0617, -0.0134,  ..., -0.0684, -0.0594,  0.0004],
        [-0.0010,  0.0809,  0.0599,  ..., -0.0417, -0.0030, -0.0500],
        [-0.0673,  0.0406, -0.0747,  ...,  0.0609,  0.0671,  0.0131]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0092,  0.0578,  0.0200,  ..., -0.0289,  0.0084,  0.0388],
        [-0.0773, -0.0339,  0.0080,  ..., -0.0073, -0.0735,  0.0436],
        [-0.0704,  0.0038,  0.0375,  ..., -0.0346, -0.0476, -0.0286],
        ...,
        [ 0.0820, -0.0617, -0.0134,  ..., -0.0684, -0.0594,  0.0004],
        [-0.0010,  0.0809,  0.0599,  ..., -0.0417, -0.0030, -0.0500],
        [-0.0673,  0.0406, -0.0747,  ...,  0.0609,  0.0671,  0.0131]],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.bias 
 torch.Size([64]) 
 True 
 tensor([-0.0702,  0.0841,  0.0548, -0.0099, -0.0220, -0.0494, -0.0718,  0.0165,
        -0.0248,  0.0736,  0.0728,  0.0739, -0.0202, -0.0838,  0.0703, -0.0685,
        -0.0552,  0.0150,  0.0224,  0.0305,  0.0795, -0.0664, -0.0495, -0.0508,
         0.0086, -0.0218, -0.0779,  0.0641,  0.0571, -0.0151,  0.0424, -0.0697,
        -0.0020,  0.0001, -0.0620,  0.0326, -0.0781,  0.0370,  0.0186,  0.0385,
         0.0751, -0.0869,  0.0578,  0.0561, -0.0086, -0.0137, -0.0718, -0.0402,
        -0.0525,  0.0049, -0.0025, -0.0772, -0.0723, -0.0268,  0.0252, -0.0758,
         0.0317,  0.0090,  0.0591, -0.0006, -0.0718,  0.0678, -0.0375, -0.0834],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0702,  0.0841,  0.0548, -0.0099, -0.0220, -0.0494, -0.0718,  0.0165,
        -0.0248,  0.0736,  0.0728,  0.0739, -0.0202, -0.0838,  0.0703, -0.0685,
        -0.0552,  0.0150,  0.0224,  0.0305,  0.0795, -0.0664, -0.0495, -0.0508,
         0.0086, -0.0218, -0.0779,  0.0641,  0.0571, -0.0151,  0.0424, -0.0697,
        -0.0020,  0.0001, -0.0620,  0.0326, -0.0781,  0.0370,  0.0186,  0.0385,
         0.0751, -0.0869,  0.0578,  0.0561, -0.0086, -0.0137, -0.0718, -0.0402,
        -0.0525,  0.0049, -0.0025, -0.0772, -0.0723, -0.0268,  0.0252, -0.0758,
         0.0317,  0.0090,  0.0591, -0.0006, -0.0718,  0.0678, -0.0375, -0.0834],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.weight 
 torch.Size([6796, 64]) 
 True 
 tensor([[ 0.0703, -0.1232,  0.0628,  ...,  0.1041,  0.0034, -0.0391],
        [-0.1003,  0.0525,  0.0979,  ...,  0.0240, -0.0804, -0.0846],
        [ 0.0558,  0.0617, -0.1203,  ..., -0.1217, -0.0205,  0.0998],
        ...,
        [ 0.0887,  0.0965,  0.0294,  ..., -0.0884,  0.0185, -0.0856],
        [-0.0311, -0.0460,  0.0979,  ...,  0.0595, -0.1134,  0.0957],
        [ 0.0468, -0.1185, -0.0747,  ..., -0.0025,  0.0833,  0.0282]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0703, -0.1232,  0.0628,  ...,  0.1041,  0.0034, -0.0391],
        [-0.1003,  0.0525,  0.0979,  ...,  0.0240, -0.0804, -0.0846],
        [ 0.0558,  0.0617, -0.1203,  ..., -0.1217, -0.0205,  0.0998],
        ...,
        [ 0.0887,  0.0965,  0.0294,  ..., -0.0884,  0.0185, -0.0856],
        [-0.0311, -0.0460,  0.0979,  ...,  0.0595, -0.1134,  0.0957],
        [ 0.0468, -0.1185, -0.0747,  ..., -0.0025,  0.0833,  0.0282]],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.bias 
 torch.Size([6796]) 
 True 
 tensor([ 0.0135, -0.0632, -0.0646,  ..., -0.0343, -0.0108, -0.0395],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0135, -0.0632, -0.0646,  ..., -0.0343, -0.0108, -0.0395],
       device='cuda:0', requires_grad=True)

Passing event 1007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([[0.0227, 0.0000, 0.0000,  ..., 0.0000, 0.0234, 0.0000],
        [0.0229, 0.0000, 0.0000,  ..., 0.0000, 0.0236, 0.0000],
        [0.0229, 0.0000, 0.0000,  ..., 0.0000, 0.0238, 0.0000],
        ...,
        [0.0230, 0.0000, 0.0000,  ..., 0.0000, 0.0237, 0.0000],
        [0.0228, 0.0000, 0.0000,  ..., 0.0000, 0.0233, 0.0000],
        [0.0229, 0.0000, 0.0000,  ..., 0.0000, 0.0232, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
result1.shape: torch.Size([20, 6796])

Passing two random events from the network before training 
result1: tensor([[0.0227, 0.0000, 0.0000,  ..., 0.0000, 0.0234, 0.0000],
        [0.0229, 0.0000, 0.0000,  ..., 0.0000, 0.0236, 0.0000],
        [0.0229, 0.0000, 0.0000,  ..., 0.0000, 0.0238, 0.0000],
        ...,
        [0.0230, 0.0000, 0.0000,  ..., 0.0000, 0.0237, 0.0000],
        [0.0228, 0.0000, 0.0000,  ..., 0.0000, 0.0233, 0.0000],
        [0.0229, 0.0000, 0.0000,  ..., 0.0000, 0.0232, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
result1.shape: torch.Size([20, 6796]) 
input: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2/checkpoint_dir/1000810305saved_checkpoint.tar



load_model True 
TraEvN 10008 
BatchSize 30 
EpochNum 10 
epoch_save 5 
LrVal 0.001 
weight_decay 0.0001 
startmesh 305 
endmesh 306 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[[[-0.2653, -0.5705, -0.4285],
          [-0.4275, -0.3964, -0.0298],
          [ 0.1828, -0.2277, -0.0020]]],


        [[[ 0.0753, -0.3476, -0.1143],
          [ 0.0561,  0.2771, -0.1868],
          [-0.4956,  0.0755,  0.1116]]],


        [[[-0.4222,  0.0710,  0.1902],
          [ 0.0578,  0.1802,  0.2659],
          [-0.4138, -0.5647, -0.3561]]],


        ...,


        [[[-0.4088, -0.1192,  0.0429],
          [-0.4384,  0.1723, -0.2653],
          [ 0.0080, -0.1984, -0.1139]]],


        [[[ 0.1553,  0.3957,  0.3035],
          [ 0.3315,  0.2353,  0.0857],
          [ 0.3242,  0.2291,  0.0085]]],


        [[[-0.0773, -0.0964, -0.0855],
          [ 0.3572,  0.2802,  0.3552],
          [ 0.0073,  0.1961,  0.2825]]]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 7.6691e-02,  1.1430e-02, -1.2940e-02,  5.3006e-02,  7.7197e-02,
         2.9332e-02, -1.0780e-01, -2.2797e-01, -1.1543e-02,  1.5666e-02,
        -8.2654e-03, -2.5873e-01, -4.7166e-02, -2.5019e-02, -1.1348e-02,
         9.3821e-03, -5.1231e-03, -4.7766e-03, -1.5769e-01, -8.3409e-02,
        -2.5278e-03,  2.1583e-02, -4.1979e-03,  8.1746e-03,  1.4661e-02,
         1.3006e-02, -1.7634e-01, -2.2177e-03, -1.3231e-02,  5.5575e-02,
        -1.5418e-02, -1.2915e-01, -1.6787e-01, -8.4938e-03, -1.1558e-01,
         3.6348e-02, -8.6688e-05, -1.4398e-02, -1.6129e-01, -7.2183e-02,
         3.4289e-02, -7.7798e-02, -1.7891e-02, -1.4726e-03,  7.1855e-02,
        -2.0588e-02,  4.2244e-02,  1.1695e-01, -1.0173e-02, -9.5449e-03,
        -2.9577e-01, -4.7407e-03,  4.6375e-02, -5.6929e-02,  1.7116e-02,
        -4.8313e-02, -1.3798e-02, -1.7877e-01, -1.8261e-01,  5.4438e-02,
        -6.0423e-02, -1.1522e-01, -4.4307e-02,  1.2583e-02, -2.0597e-01,
        -5.8006e-05, -1.6807e-01, -2.3990e-03, -1.3278e-01, -3.6023e-02,
        -3.7411e-02, -1.3773e-01, -1.4274e-01,  2.8203e-02, -9.9255e-03,
        -2.1066e-01, -3.1630e-02, -4.7145e-03, -2.5017e-03,  3.8912e-02,
         6.8011e-02, -1.1912e-04,  2.0416e-02, -3.7840e-02, -5.8690e-03,
        -8.3784e-03, -2.4094e-01,  1.4879e-02, -5.8176e-03,  6.8963e-02,
         1.1232e-02,  9.1545e-03, -2.9115e-02,  1.7095e-02, -2.3766e-02,
         1.1241e-01, -1.2849e-02,  2.5025e-02,  3.9278e-02, -1.4254e-01,
         7.0259e-02, -1.3329e-01, -3.2241e-02,  3.8516e-02, -6.0309e-02,
        -1.6293e-02, -4.4001e-03, -3.9397e-03, -1.9034e-02,  3.0795e-02,
        -2.5475e-01,  1.8856e-02, -1.2326e-01,  3.9572e-02, -8.1744e-03,
        -1.0231e-01,  3.3813e-02, -1.7148e-02, -5.7904e-02, -5.0043e-03,
         2.1629e-02, -3.6458e-02, -2.2334e-02,  5.1748e-02, -1.5012e-01,
         2.9409e-02, -6.3190e-03,  9.5044e-02, -2.6013e-03, -3.0823e-01,
        -9.2528e-03,  5.9004e-03, -2.4992e-02, -9.2686e-03,  1.5231e-02,
         2.1162e-02, -6.9808e-03,  1.0408e-01, -1.9282e-02, -6.7145e-03,
        -9.7405e-03, -2.1204e-01, -8.0371e-03, -2.4727e-03,  1.2596e-02,
         2.4056e-02, -3.5527e-02,  2.3303e-02, -2.7253e-02, -1.2683e-02,
        -5.9278e-03,  1.3293e-02,  1.2976e-01,  6.4438e-02, -8.2163e-03,
        -1.0158e-01,  2.6552e-02, -3.1866e-02, -4.9874e-03, -1.8407e-01,
        -2.3965e-01, -1.4388e-01, -1.8945e-02, -2.0344e-01, -3.4764e-04,
        -1.5783e-02,  1.2418e-02, -2.7150e-02, -7.7530e-03, -2.9728e-02,
        -3.9143e-03,  9.1534e-03,  1.1667e-02,  1.4107e-02,  3.1029e-02,
        -7.3733e-02,  2.3792e-02,  1.6065e-02, -5.3283e-02, -1.6153e-01,
         2.1993e-02, -7.9210e-02, -1.5575e-02, -5.5715e-03, -2.4353e-02,
        -1.2595e-01, -7.7681e-03, -1.9951e-01,  9.0244e-02, -8.5782e-03,
        -1.4573e-01, -2.3485e-01, -5.7029e-03, -1.3055e-01,  3.4613e-02,
        -1.2926e-02, -2.5783e-02,  1.6912e-01,  1.5480e-02, -2.8449e-02,
        -3.3826e-02, -5.4537e-03, -1.3622e-01, -1.2536e-02, -9.5699e-03,
         5.7321e-02,  2.3445e-02, -5.4490e-03,  2.5209e-02, -3.7621e-03,
        -1.3968e-01,  9.0651e-02, -2.1738e-02, -1.6297e-02, -4.4868e-03,
         2.0554e-02, -1.8891e-02, -1.1048e-01,  8.9107e-03, -7.4500e-02,
        -9.0381e-02, -1.3851e-02,  7.0463e-02, -1.7755e-02, -1.4587e-01,
        -2.1481e-02, -7.6561e-03, -1.1836e-01, -3.7520e-03,  1.3869e-02,
        -1.3119e-01, -1.6720e-02, -4.5943e-03,  1.5990e-02, -1.3411e-02,
        -4.6699e-02,  4.6707e-02, -1.9799e-01, -1.4718e-02, -7.1352e-03,
         5.4619e-02, -1.6018e-01, -9.9213e-02, -2.3801e-02, -1.2038e-01,
        -2.2430e-02, -4.5027e-03, -1.2018e-02, -1.4057e-02, -5.0909e-03,
        -8.4555e-03, -8.8147e-02, -1.3567e-01,  1.5610e-02, -1.3337e-02,
        -1.7830e-01], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[-2.9637e-03, -2.7163e-03, -2.4214e-03],
          [-2.7742e-03, -2.5128e-03, -3.0682e-03],
          [-3.1761e-03, -2.6126e-03, -2.5008e-03]],

         [[-2.6067e-03, -3.1269e-03, -2.7053e-03],
          [-4.3454e-03, -3.9436e-03, -4.5021e-03],
          [-3.3888e-03, -3.2660e-03, -2.8891e-03]],

         [[ 1.4062e-03,  2.5609e-03,  3.9110e-03],
          [-1.5132e-03, -7.9069e-04, -1.0761e-03],
          [ 2.8870e-03,  1.9180e-03,  2.8213e-04]],

         ...,

         [[-3.3386e-03, -3.0021e-03, -2.9359e-03],
          [-3.4000e-03, -3.1179e-03, -2.8219e-03],
          [-3.1103e-03, -4.1063e-03, -2.7377e-03]],

         [[-4.6498e-03, -1.3984e-03,  1.0422e-03],
          [-5.6891e-03, -1.2174e-03, -1.6134e-03],
          [-3.3136e-04,  2.7722e-04,  1.1096e-03]],

         [[ 7.9272e-05,  6.1631e-04,  1.6612e-03],
          [-2.6768e-04,  3.7297e-04,  7.5403e-04],
          [ 1.4268e-03,  2.3955e-03,  3.0414e-03]]],


        [[[-5.4945e-03, -4.7579e-02, -2.3241e-02],
          [-5.6901e-03,  2.1684e-02,  2.3296e-02],
          [ 5.8771e-05, -1.1745e-03, -3.4392e-02]],

         [[-2.7822e-02, -2.1214e-02, -4.2183e-02],
          [ 2.0084e-02, -2.1735e-02,  2.9561e-03],
          [-2.6026e-02, -8.2324e-03, -1.3273e-03]],

         [[ 3.2314e-02,  5.9082e-02,  3.1043e-02],
          [-4.4184e-02, -3.6788e-02, -2.0254e-03],
          [-5.2992e-02, -7.5889e-02, -8.6749e-02]],

         ...,

         [[ 1.1507e-02, -8.0798e-03,  2.9393e-03],
          [ 1.1688e-02,  8.3209e-03, -2.5706e-02],
          [ 7.4047e-03, -3.0646e-02, -4.1444e-02]],

         [[-5.3626e-02,  1.2813e-03, -2.1670e-02],
          [-1.7657e-01, -1.3314e-01, -1.4289e-01],
          [-1.5985e-02,  1.0346e-02, -3.2723e-02]],

         [[-1.2005e-01, -1.5097e-01, -2.1443e-01],
          [-1.7874e-01, -1.1030e-01, -1.1743e-01],
          [-1.6472e-01, -2.3562e-01, -1.6646e-01]]],


        [[[-5.4870e-03, -2.2625e-03, -2.1618e-03],
          [ 3.6888e-04, -1.0148e-03, -3.2993e-03],
          [-2.0300e-03, -5.7158e-04, -1.5358e-03]],

         [[-1.1971e-03, -2.7333e-03, -6.5813e-03],
          [-1.1459e-03, -1.4831e-03, -1.0450e-03],
          [-3.8715e-03, -3.1171e-03, -4.3487e-03]],

         [[-3.9421e-05,  1.4721e-04,  1.6776e-04],
          [-3.5015e-07,  1.5649e-07,  1.1146e-05],
          [-2.1788e-08, -8.2670e-08, -2.3602e-06]],

         ...,

         [[-4.6111e-03, -3.6003e-04, -2.4313e-03],
          [-3.4965e-03, -2.2763e-03, -4.0487e-04],
          [-4.6461e-05, -2.2118e-03, -2.5550e-03]],

         [[-2.9674e-03, -2.2398e-03, -8.1109e-05],
          [-2.5577e-03, -8.4500e-04, -3.8096e-04],
          [-1.3304e-03, -8.8362e-04, -1.3343e-03]],

         [[ 1.5287e-41, -6.6063e-41,  8.1303e-42],
          [ 2.9846e-41,  9.2836e-41,  4.5961e-41],
          [-1.1014e-41,  6.8036e-41,  2.4280e-41]]],


        ...,


        [[[-2.3277e-02, -2.1158e-02, -2.3726e-02],
          [-2.3909e-02, -2.2941e-02, -2.3778e-02],
          [-2.6821e-02, -2.3221e-02, -2.4383e-02]],

         [[-2.5817e-02, -2.7394e-02, -2.7552e-02],
          [-2.8571e-02, -2.4675e-02, -2.7932e-02],
          [-2.7893e-02, -2.7362e-02, -2.4608e-02]],

         [[-9.4704e-03, -5.7412e-03, -1.2059e-02],
          [-7.0083e-06,  1.3341e-08, -4.8321e-03],
          [-2.0407e-03, -1.6732e-03, -6.0631e-03]],

         ...,

         [[-2.3275e-02, -1.9860e-02, -2.2948e-02],
          [-2.6499e-02, -2.2043e-02, -2.3054e-02],
          [-2.7413e-02, -2.2975e-02, -2.3579e-02]],

         [[ 3.8692e-02, -2.8997e-02, -2.8612e-02],
          [ 1.0802e-02, -3.0875e-02, -1.7860e-02],
          [-1.2963e-02, -2.3608e-02, -1.6117e-02]],

         [[-7.2859e-03, -2.5061e-04, -2.3616e-04],
          [ 1.2256e-03, -2.8248e-04, -2.2303e-04],
          [-1.3509e-03,  5.9492e-05, -7.0547e-04]]],


        [[[-6.1674e-41, -4.6582e-41,  1.0200e-41],
          [-1.2659e-38,  3.0509e-33, -6.7473e-42],
          [-8.6541e-22, -2.0241e-20, -7.9506e-26]],

         [[-1.4323e-09, -4.1794e-10, -1.1683e-09],
          [-1.1784e-14, -2.1145e-10, -5.3015e-09],
          [-7.1431e-09, -4.0241e-10, -7.7491e-10]],

         [[-2.8196e-26, -3.6124e-35, -3.9340e-41],
          [-1.0780e-26, -2.0039e-31,  1.6725e-37],
          [ 2.9786e-37, -8.6427e-22,  2.2955e-33]],

         ...,

         [[-2.6860e-13, -1.9045e-18, -4.6325e-22],
          [-1.4702e-13, -3.7174e-16, -3.4870e-18],
          [-1.8022e-12, -5.2912e-17, -1.7269e-14]],

         [[-4.2164e-05, -3.4512e-05, -1.5063e-04],
          [-5.0893e-05, -8.2714e-05, -9.3939e-05],
          [-1.9106e-05, -1.8485e-05, -7.1637e-05]],

         [[-2.3676e-20, -4.8110e-19, -5.6631e-26],
          [-1.8082e-23, -2.6036e-17, -1.7020e-14],
          [-2.7560e-19, -1.6161e-18, -2.6426e-21]]],


        [[[ 1.0893e-02, -1.5557e-02, -1.4191e-01],
          [-1.0009e-01, -1.7344e-03, -2.4008e-01],
          [ 3.0311e-02,  3.6113e-02,  2.4610e-02]],

         [[-1.2141e-02,  7.6082e-02, -1.5196e-02],
          [-2.5388e-01, -2.1836e-01, -3.6775e-02],
          [-9.6442e-02, -8.6652e-02, -9.0615e-02]],

         [[ 1.5787e-01,  1.2676e-01, -2.2677e-02],
          [ 1.1700e-01, -1.0931e-01,  3.8975e-02],
          [-1.4914e-01, -1.5855e-01, -1.1777e-01]],

         ...,

         [[-9.8726e-02,  8.7777e-03, -1.3513e-01],
          [ 3.4336e-02, -1.0661e-01, -9.2817e-02],
          [-3.6768e-02, -6.1083e-02, -6.2981e-02]],

         [[-4.0939e-02,  3.6754e-02,  2.9353e-02],
          [ 3.2271e-02,  4.4357e-02, -1.5231e-02],
          [-2.0390e-01, -1.7962e-01, -1.2997e-01]],

         [[ 2.3843e-01,  1.9391e-01,  1.0569e-01],
          [-7.7069e-02, -7.8646e-03,  7.8686e-03],
          [-7.6386e-02, -7.2287e-02, -8.1396e-02]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([-3.8988e-03, -2.1562e-02, -4.2568e-03, -1.5328e-11, -4.5167e-03,
        -2.0084e-03, -4.8997e-03, -3.0326e-03,  1.8094e-02, -5.6450e-03,
        -1.4754e-03, -2.5558e-02, -4.8979e-03, -4.6621e-02, -5.0247e-05,
        -6.5168e-03, -1.6668e-06, -1.8809e-02, -4.9922e-02, -5.9698e-04,
        -4.8539e-03, -1.1941e-02, -3.2395e-08, -6.2890e-03, -2.5254e-04,
        -3.5644e-03, -8.8696e-18, -5.8450e-03, -8.1905e-03, -8.2815e-03,
        -4.5628e-03, -1.3125e-13, -6.9519e-07, -6.0187e-03, -3.0535e-05,
        -6.8158e-03,  3.1179e-02, -6.4746e-03, -4.4747e-03, -3.7955e-02,
        -1.0528e-02, -1.1807e-03, -2.0781e-02, -6.3129e-03, -6.2984e-03,
        -1.1553e-02, -6.8448e-03, -8.5068e-02, -4.3912e-02, -8.0054e-03,
        -4.8774e-03, -2.0644e-04, -4.8550e-03, -1.0843e-02, -7.1729e-03,
        -9.7781e-04, -6.9886e-03, -5.7734e-03, -1.2462e-02, -1.4257e-02,
        -8.3454e-03, -3.6910e-03, -8.7675e-02, -4.4234e-02, -7.1175e-04,
        -5.0741e-03, -1.0843e-08, -4.8626e-03, -2.7093e-03, -7.0110e-04,
        -4.7980e-04, -5.9977e-03, -7.8532e-03, -4.8977e-03, -1.0022e-02,
        -1.6779e-02, -2.4914e-03,  2.4083e-02, -4.8520e-03, -5.3968e-03,
        -6.3088e-03, -4.3517e-03, -4.8482e-03, -2.0949e-02, -3.8935e-02,
        -3.9469e-03, -3.9838e-03, -9.4082e-03, -1.0899e-02, -6.3038e-03,
        -5.6202e-03, -3.9463e-03, -8.4132e-09, -6.4572e-03, -5.3975e-02,
        -6.6850e-03, -4.8741e-03, -5.5520e-03, -5.3742e-03, -9.9549e-06,
        -7.5109e-03, -5.8443e-02, -7.5691e-02, -4.8793e-03, -1.0393e-02,
        -6.8495e-03, -5.8884e-03, -1.1107e-01, -9.6530e-23, -4.5266e-03,
        -2.7583e-06, -2.1720e-03, -1.0355e-06, -3.9814e-03, -4.8602e-03,
        -1.2744e-02, -6.6422e-04, -2.3247e-02, -1.2998e-03, -2.7377e-02,
        -3.8768e-04, -8.0404e-03, -1.0160e-26, -8.8169e-03, -8.7923e-03,
        -4.3509e-02, -5.3938e-04, -1.0825e-01], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[[[ 2.2115e-40, -2.0167e-40,  3.0620e-40],
          [ 1.6402e-40, -1.2802e-40, -2.5810e-40],
          [-7.7780e-41,  2.0573e-40,  7.5806e-41]],

         [[-6.7548e-03, -8.5665e-03, -8.3617e-03],
          [-8.7241e-03, -8.4614e-03, -7.9663e-03],
          [-7.5553e-03, -7.0736e-03, -7.8495e-03]],

         [[ 5.0042e-40, -1.1056e-40, -6.0219e-40],
          [ 5.8002e-40, -6.7112e-41, -5.8767e-40],
          [-6.1118e-40, -6.8882e-41,  9.4034e-41]],

         ...,

         [[ 2.4451e-40, -2.0835e-40,  1.5782e-40],
          [ 1.9588e-40,  2.6244e-40,  6.7484e-41],
          [-7.9964e-41,  3.0649e-40, -2.8884e-40]],

         [[-5.6889e-40, -1.0791e-40, -1.0555e-40],
          [-6.4041e-41, -1.7097e-40,  1.1169e-40],
          [-8.8758e-42,  2.8840e-40, -5.8830e-40]],

         [[-1.2922e-02, -1.3891e-02, -1.3440e-02],
          [-9.9290e-03, -9.8079e-03, -9.1683e-03],
          [-1.0845e-02, -9.2786e-03, -8.5199e-03]]],


        [[[-3.7497e-03, -3.7639e-03, -3.8127e-03],
          [-3.6960e-03, -3.7125e-03, -3.7578e-03],
          [-3.7636e-03, -3.7749e-03, -3.7854e-03]],

         [[-1.4861e-03, -3.8664e-03, -2.2921e-03],
          [-1.3230e-02, -3.4244e-03, -1.1693e-02],
          [-3.4380e-03, -8.0433e-03, -1.3874e-03]],

         [[ 5.4039e-03,  2.8304e-03,  1.9131e-03],
          [ 2.8694e-03,  5.1691e-03,  4.2051e-03],
          [ 2.5840e-03,  3.6190e-03,  5.1381e-03]],

         ...,

         [[-1.3279e-40, -1.6696e-40, -2.0202e-40],
          [-3.5015e-40,  9.9000e-41, -2.5714e-40],
          [ 6.4271e-41,  2.0452e-40, -7.8125e-41]],

         [[-4.4647e-40, -2.9409e-40, -2.5672e-42],
          [-4.1254e-42, -4.0703e-40,  1.2724e-42],
          [ 2.8975e-40, -1.8385e-42, -2.5756e-42]],

         [[-8.6486e-08, -2.6840e-07, -2.4885e-08],
          [-3.7965e-41,  4.0153e-41, -8.2565e-42],
          [ 1.3577e-41,  1.7505e-07,  5.1415e-06]]],


        [[[-2.9622e-20, -6.2414e-19, -2.2067e-18],
          [ 3.0891e-28, -2.0643e-25, -3.6308e-25],
          [-2.5891e-23, -2.6256e-22, -5.7506e-22]],

         [[-3.0935e-02, -3.0344e-02, -2.4586e-02],
          [-2.3531e-02, -2.1685e-02, -2.1720e-02],
          [-2.2297e-02, -2.0048e-02, -1.9778e-02]],

         [[ 1.4987e-40, -1.3607e-40, -2.8077e-40],
          [ 4.2868e-40,  2.5347e-40,  2.8145e-40],
          [ 1.5127e-40,  1.2700e-40,  1.1170e-40]],

         ...,

         [[-1.2392e-40,  2.9869e-40, -2.8528e-40],
          [ 2.2086e-40, -4.6859e-41,  1.6454e-40],
          [ 1.1060e-40,  2.1462e-40,  1.4553e-40]],

         [[-1.2194e-40, -1.4042e-40,  1.6323e-40],
          [ 3.2506e-40, -1.5138e-40,  2.3593e-40],
          [-4.9080e-41,  3.6911e-40, -1.6585e-40]],

         [[-1.9754e-02, -2.0724e-02, -1.8957e-02],
          [-2.2371e-02, -2.0553e-02, -1.8443e-02],
          [-2.2246e-02, -2.1988e-02, -2.4573e-02]]],


        ...,


        [[[-2.3262e-02, -2.4246e-02, -2.2246e-02],
          [-2.0701e-02, -1.9308e-02, -1.9287e-02],
          [-1.8459e-02, -1.7284e-02, -1.8146e-02]],

         [[-2.5575e-01, -3.4686e-01, -2.4685e-01],
          [-8.4605e-02, -3.2481e-02,  1.2773e-02],
          [-1.2262e-01, -1.9181e-01, -1.3016e-01]],

         [[-9.3133e-03, -6.8826e-03, -2.0981e-03],
          [-1.1810e-02, -1.0554e-02, -1.1650e-02],
          [-1.2481e-02, -1.1551e-02, -1.0506e-02]],

         ...,

         [[ 1.4810e-02, -1.8772e-10, -2.7966e-27],
          [ 3.4641e-02,  1.0192e-02,  1.1129e-02],
          [ 3.6487e-02,  3.1911e-02,  2.9426e-02]],

         [[ 3.1608e-41, -1.0695e-14, -2.3878e-07],
          [-7.7326e-41,  3.5638e-41, -2.5046e-38],
          [-3.8110e-28, -3.6146e-41, -1.3873e-43]],

         [[-2.4415e-03, -4.7913e-03,  3.5870e-02],
          [-1.3860e-01, -3.9513e-02, -2.1452e-02],
          [ 4.5018e-02,  1.6432e-02,  3.0213e-03]]],


        [[[-3.0969e-43,  2.7367e-42, -1.5835e-43],
          [ 1.7909e-42,  4.2179e-42,  3.3103e-41],
          [ 4.1149e-41, -1.2956e-41, -4.3090e-42]],

         [[-5.4372e-03, -5.6021e-03, -5.4995e-03],
          [-5.4157e-03, -5.5833e-03, -5.4901e-03],
          [-5.1379e-03, -5.2917e-03, -5.2719e-03]],

         [[ 4.9298e-42,  1.5875e-41, -7.0023e-42],
          [ 6.0038e-40,  1.2386e-41,  1.4756e-42],
          [ 5.5029e-42,  2.1122e-41, -1.0150e-41]],

         ...,

         [[-7.2198e-41,  9.2557e-41, -8.2436e-41],
          [-6.8784e-41,  8.1215e-41, -1.0961e-41],
          [ 1.2387e-42,  1.3698e-41,  4.9222e-41]],

         [[-4.9106e-41,  4.9477e-41,  1.4324e-41],
          [ 1.2280e-41,  2.8806e-40, -3.8962e-41],
          [ 4.6962e-41, -2.1188e-42,  7.9790e-42]],

         [[-5.9561e-04, -5.6693e-04, -5.5174e-04],
          [-8.6406e-04, -1.0176e-03, -1.0020e-03],
          [-1.0757e-03, -1.2001e-03, -1.1835e-03]]],


        [[[-9.2542e-42, -1.6462e-41,  5.8434e-43],
          [-5.9402e-40, -1.5857e-41, -3.0349e-40],
          [-5.1540e-42, -1.9870e-41, -4.4702e-40]],

         [[-4.7066e-03, -4.7094e-03, -4.7067e-03],
          [-4.7008e-03, -4.7033e-03, -4.7021e-03],
          [-4.6945e-03, -4.6946e-03, -4.6937e-03]],

         [[ 4.0303e-41,  4.8975e-42, -9.2654e-42],
          [ 2.9162e-41,  3.6672e-42, -5.4370e-42],
          [-7.4367e-42,  5.4276e-41,  1.3821e-41]],

         ...,

         [[-3.2874e-41, -3.8957e-41,  7.6793e-41],
          [ 1.8372e-41, -7.3334e-41,  1.5578e-41],
          [-2.4827e-41, -5.8584e-41, -5.4309e-41]],

         [[-2.5424e-41, -1.6506e-41,  6.1154e-41],
          [ 5.3112e-41,  4.4452e-41, -3.1898e-41],
          [ 4.5612e-41,  2.3421e-41, -3.5859e-42]],

         [[-9.5666e-07, -7.5169e-07, -8.3271e-07],
          [-6.1278e-07, -6.7731e-07, -9.0501e-07],
          [-5.2394e-07, -5.0709e-07, -5.0463e-07]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([-1.1625e-02, -1.5830e-02, -8.0130e-03, -5.2190e-03,  4.6950e-03,
        -9.6536e-03, -1.4989e-02, -4.4990e-08, -3.1491e-09, -4.4410e-03,
        -3.0387e-03, -6.0061e-03, -2.1876e-03, -4.4934e-03, -1.0399e-04,
        -7.7271e-03, -5.6163e-03, -8.4062e-03, -2.4910e-05, -6.5235e-03,
        -4.1694e-03, -7.6541e-03, -1.2134e-01, -2.3081e-05, -1.1095e-02,
        -5.6679e-03, -8.2201e-03, -2.3663e-02, -2.5456e-02, -3.7859e-02,
        -3.6258e-03, -2.0150e-02,  4.1708e-02, -9.2021e-03, -5.4173e-03,
         4.1016e-02, -1.3618e-02, -7.3910e-02, -2.2283e-02, -1.0386e-02,
        -5.8717e-03, -8.5054e-03, -5.2104e-03, -8.9375e-03, -5.5750e-03,
        -7.3210e-03, -5.8100e-03, -4.3567e-02, -3.3007e-03, -4.3670e-03,
        -1.4616e-03, -5.6136e-03, -9.3769e-03, -5.8225e-03, -2.0110e-02,
        -3.2169e-02, -4.0220e-02, -9.2672e-04,  3.3637e-03, -2.2008e-02,
        -6.7241e-03, -7.8672e-02, -6.7286e-03, -4.6547e-03], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[ 5.8745e-40,  6.2196e-40,  5.5029e-40,  ..., -6.0815e-40,
         -6.0815e-40, -6.0815e-40],
        [-6.0614e-40, -3.5673e-40, -6.1902e-40,  ...,  2.3903e-40,
          3.5530e-40,  6.9747e-41],
        [ 5.7654e-40,  6.1587e-40,  5.6404e-40,  ...,  1.3123e-41,
         -4.1649e-40, -5.5299e-40],
        ...,
        [-5.6534e-40, -1.1505e-42, -5.9084e-40,  ...,  4.8559e-41,
         -3.9800e-40, -6.6248e-41],
        [ 5.7244e-40, -5.5347e-40,  2.9563e-40,  ..., -4.3054e-40,
         -4.3054e-40, -4.3054e-40],
        [ 5.5174e-40,  5.7043e-41,  4.4232e-40,  ..., -1.0041e-40,
         -4.6230e-40, -5.4279e-40]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 7.7495e-04, -4.3165e-03, -2.7152e-02, -9.1375e-02, -3.1260e-02,
        -2.8528e-02, -6.7582e-02, -2.0947e-02,  8.8644e-02, -3.4489e-02,
        -4.1943e-02, -3.1422e-02, -2.6466e-02, -3.8216e-02, -4.1168e-02,
        -3.1620e-02, -8.4314e-04, -3.7219e-03, -4.0892e-02, -1.0772e-02,
        -3.1284e-02, -2.9396e-03, -7.0574e-02, -6.4617e-05, -2.6626e-02,
        -2.0703e-02, -5.7322e-02, -5.8016e-02, -3.4347e-02, -1.5629e-02,
        -7.5317e-03, -5.3188e-02, -7.6759e-03, -3.2932e-02, -3.0958e-02,
        -6.3690e-08, -3.3736e-02, -2.7270e-06, -8.8022e-02, -2.2408e-02,
        -2.5501e-02, -4.8255e-02, -4.2893e-03,  3.8150e-02, -1.1418e-02,
        -2.6131e-02, -5.0086e-02, -7.2594e-02, -3.8331e-03, -5.4136e-02,
        -7.2939e-03, -3.0959e-02, -2.1872e-02, -3.2735e-02, -6.0841e-02,
        -3.3454e-06, -6.0262e-03, -5.1461e-03, -2.4916e-02, -2.2473e-02,
        -2.0731e-02, -4.7606e-02, -2.6234e-06, -3.9658e-02, -1.8431e-02,
        -4.5500e-05, -1.4822e-02, -5.4981e-02, -4.1596e-02, -2.0701e-02,
        -2.3351e-02, -2.2262e-07, -1.4801e-04, -4.7121e-05, -2.5480e-02,
        -2.8545e-02, -3.5303e-02, -2.6073e-06, -2.0255e-10, -7.0924e-04,
        -5.5614e-02, -2.9791e-03, -1.6688e-02, -2.6957e-02, -9.1535e-04,
        -1.2355e-03, -2.4551e-02, -3.1285e-02, -9.1521e-02, -1.2430e-03,
        -4.2171e-02, -6.3260e-03, -5.9074e-03, -3.4509e-03, -4.1166e-02,
        -8.5027e-03, -2.9541e-11, -4.7999e-02, -6.6545e-02, -8.8334e-02,
        -2.4483e-04, -1.7898e-04, -4.7607e-02, -2.3348e-03, -4.8585e-02,
        -1.7850e-02, -7.7807e-04, -3.1875e-02, -2.9536e-02, -2.6004e-15,
        -9.5140e-02, -6.6780e-02, -4.6146e-02, -3.0056e-02, -2.0702e-02,
        -3.7181e-02, -1.3627e-02, -2.0666e-02, -8.6981e-05, -3.7506e-02,
        -6.5785e-02, -1.5552e-02, -2.6665e-06, -2.8433e-02, -3.1483e-02,
        -2.0762e-02, -6.2371e-02, -4.8218e-03,  1.4909e-01, -8.0793e-03,
        -2.4355e-02, -2.3924e-02, -6.6623e-03, -4.2008e-03, -2.5980e-06,
        -2.9637e-02,  6.5626e-02, -1.2640e-02, -3.1249e-02, -7.9809e-03,
        -2.0920e-05, -4.1771e-02, -1.4365e-02, -4.8934e-03, -4.8672e-02,
        -1.3045e-03, -4.6432e-03, -2.0543e-10, -3.7086e-02, -2.7994e-06,
        -1.9613e-04, -5.0300e-02, -2.6198e-06, -3.0407e-02, -2.1515e-02,
        -3.8924e-02, -2.8475e-02, -2.0754e-02, -2.0636e-03, -4.4887e-03,
        -4.1033e-02, -3.4278e-02, -2.8692e-02, -3.4961e-02, -1.2838e-03,
        -5.6739e-02, -2.1882e-02,  2.5332e-02,  1.9325e-03, -4.1262e-02,
        -3.7410e-02, -4.8057e-02, -3.5445e-02, -4.4651e-02, -5.2050e-04,
        -8.0492e-02, -3.2615e-02, -7.8850e-03, -1.8748e-02, -7.0389e-02,
        -6.7525e-03, -9.0657e-02, -2.9110e-02, -7.9973e-02, -2.0746e-02,
        -9.7380e-17, -6.8454e-03,  6.0758e-02, -6.8556e-05, -2.1190e-02,
        -5.2857e-02, -3.0982e-02, -4.5016e-02, -3.0498e-02, -6.2260e-03,
        -1.5517e-02,  1.3432e-01, -2.4201e-02, -5.4636e-02, -3.1869e-02,
        -2.2110e-02, -1.8250e-04, -1.2025e-10, -2.8543e-02, -1.8737e-02,
        -2.7246e-02, -4.5810e-02,  5.4841e-02, -4.2807e-02, -2.5388e-02,
        -6.4178e-10, -2.7340e-02,  1.6584e-01, -2.9457e-02, -5.0564e-04,
        -9.1359e-02, -1.9840e-05, -3.1446e-02, -1.0672e-02, -3.5002e-02,
        -7.2941e-02, -2.6176e-06, -2.2637e-04, -2.1948e-02, -3.2991e-07,
        -3.3834e-02, -4.3961e-03, -5.9306e-06, -3.5561e-02, -2.5941e-06,
        -1.8913e-02,  7.7306e-02, -2.0720e-02, -3.9550e-02, -2.7612e-02,
        -4.1393e-02, -2.9668e-04, -3.4192e-02, -6.7888e-05, -1.4985e-04,
        -4.0278e-02, -4.1929e-03, -6.1587e-04, -2.5989e-06, -3.3131e-02,
        -3.7081e-03, -2.1490e-02, -9.2418e-09,  5.1029e-02,  1.3009e-01,
        -2.6299e-06, -2.0589e-03, -3.2848e-02, -3.1207e-02, -1.0699e-02,
        -3.1487e-02], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-1.3167e-40,  4.9569e-40,  1.5936e-40,  ...,  2.2892e-41,
         -7.9860e-42,  1.6448e-41],
        [-8.8352e-42,  2.0128e-41, -1.4651e-41,  ...,  1.3556e-41,
          5.9428e-40,  8.4680e-42],
        [ 1.1040e-40, -2.6473e-40, -1.2022e-02,  ..., -7.8781e-42,
          1.6604e-41,  1.4632e-40],
        ...,
        [-2.4200e-42, -4.0201e-40,  5.5450e-40,  ..., -2.7802e-42,
          5.5573e-40, -3.6271e-41],
        [ 3.0371e-40,  6.6618e-42,  1.5924e-41,  ...,  3.3669e-41,
          1.4127e-40, -5.1618e-40],
        [-3.1059e-02, -1.2277e-03,  3.6285e-02,  ...,  2.3400e-02,
         -3.6186e-03,  2.3114e-02]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-7.0558e-03, -3.7172e-02, -1.5672e-03, -5.2793e-02,  9.2622e-02,
        -8.2150e-41,  7.9341e-02, -5.4480e-03,  5.7943e-02,  1.7039e-02,
        -4.8017e-03,  1.6520e-01,  1.1019e-01, -8.5359e-03, -4.3051e-02,
         8.5420e-04, -6.8003e-04, -4.1748e-05,  1.1192e-02,  1.1579e-41,
         1.3449e-03,  3.9255e-02,  8.6002e-02,  7.2070e-02, -1.3669e-01,
         9.2575e-33, -1.6916e-02, -1.7293e-06, -3.5280e-04,  5.8227e-02,
        -1.1718e-03, -7.0940e-03, -8.1112e-03, -1.5031e-02, -4.4343e-03,
         2.4024e-02,  1.8876e-02, -1.5845e-11, -2.9342e-03,  5.8880e-03,
         8.7249e-02, -3.7619e-02,  4.9758e-02,  1.2958e-01,  1.4208e-01,
        -9.8703e-03,  8.9723e-02, -4.0753e-02, -1.9507e-07, -2.5060e-05,
         8.4177e-02, -2.4827e-10, -4.0714e-05, -8.2422e-03,  3.3287e-37,
        -3.2568e-04, -3.1067e-02, -1.4407e-03,  6.6557e-02,  1.8456e-02,
         1.6037e-02,  3.5478e-02, -5.7802e-05, -3.7000e-02, -2.3314e-03,
        -8.0476e-02, -1.9293e-02,  4.8976e-04, -1.0913e-40,  7.5455e-02,
         3.0446e-02, -4.2212e-02,  1.0817e-01, -7.8565e-03, -7.9331e-02,
        -4.8987e-03, -4.7379e-03,  7.3637e-02, -2.3352e-01, -7.9667e-02,
        -6.5121e-08,  8.9361e-42, -2.3973e-02, -1.9573e-02, -1.4679e-02,
         2.2382e-02,  7.6200e-02, -6.2239e-03,  7.3505e-41, -4.1212e-02,
         7.9253e-17,  9.3991e-02,  4.4873e-02, -7.2854e-41,  2.2043e-02,
        -2.9636e-03, -1.3258e-02, -2.0913e-02,  9.8960e-42, -2.2906e-08,
        -4.7245e-03, -2.1521e-03,  7.9862e-02, -6.4000e-14,  8.1361e-02,
        -6.3534e-05, -9.5118e-18, -6.6331e-04,  2.7794e-02, -1.3347e-10,
         4.8545e-02,  9.4646e-02, -2.1744e-03, -1.2362e-02, -1.9245e-04,
        -1.5246e-03,  8.3107e-03,  7.9864e-03, -2.8022e-03,  2.2391e-02,
        -2.8753e-03, -8.3380e-03, -8.3185e-02, -3.4925e-22, -1.9513e-14,
        -1.1075e-03,  6.7693e-33, -3.1611e-02], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[ 6.6600e-03,  5.3371e-02, -4.8077e-02,  ..., -6.6092e-03,
          2.0959e-10, -1.3230e-01],
        [ 1.4298e-02, -2.9888e-02,  4.4467e-02,  ...,  4.2098e-03,
         -4.4483e-41, -1.6730e-01],
        [ 1.9743e-02,  5.1366e-02, -3.1678e-02,  ...,  2.9230e-03,
          4.0837e-41,  1.5629e-01],
        ...,
        [-5.8339e-41, -2.6854e-41,  2.9447e-41,  ...,  3.2090e-43,
          5.9366e-40, -9.7327e-03],
        [ 2.2001e-03,  2.2239e-02,  4.6495e-02,  ...,  4.8957e-03,
         -1.6717e-40, -8.2583e-02],
        [ 5.7593e-41, -1.2613e-41,  4.3642e-04,  ..., -4.6389e-41,
         -7.8052e-43, -3.1468e-02]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 5.1326e-02,  3.5244e-02, -3.2115e-02, -1.7422e-02, -7.3016e-03,
        -4.2838e-03,  1.3857e-01, -5.0883e-02,  6.0639e-09, -1.4742e-02,
        -5.0366e-02, -3.5836e-03, -4.9479e-02, -3.5526e-03, -7.7315e-09,
         5.5176e-03, -2.9379e-03,  1.4709e-02, -2.9775e-02, -3.0803e-02,
        -2.0356e-04, -1.3030e-02,  2.8359e-02, -1.3239e-03, -5.1900e-02,
        -3.3534e-02, -1.8046e-02,  6.0551e-02,  5.9333e-02, -5.0766e-41,
        -7.1739e-02, -6.2407e-02,  6.2005e-02, -4.6102e-02, -6.3576e-03,
        -3.4751e-02,  1.9840e-02, -2.1838e-41,  6.9235e-02, -8.5390e-02,
         1.2318e-02,  2.2565e-02, -1.8288e-03,  2.1844e-02,  6.5679e-02,
         1.3088e-01, -4.1326e-02,  1.6390e-01,  7.0078e-03, -1.2194e-01,
         8.9929e-02, -4.5609e-04,  1.3150e-01,  6.2382e-03,  9.2773e-02,
         4.1883e-02, -7.8277e-02,  2.1447e-02, -8.0149e-02, -1.8002e-02,
        -2.2873e-04, -1.8196e-02, -6.9984e-02, -2.7040e-02], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[-3.7214e-03, -1.8846e-02,  4.6815e-02,  ...,  1.0241e-05,
          4.9115e-02,  1.7847e-02],
        [-8.4936e-03, -8.9964e-02,  6.7896e-02,  ...,  2.9275e-03,
          1.0649e-01, -3.7718e-03],
        [ 3.1673e-02, -7.2237e-02, -8.5903e-02,  ..., -1.3801e-03,
          2.0279e-02, -1.1352e-02],
        ...,
        [ 1.4604e-02, -5.1263e-02,  8.7237e-02,  ...,  1.6451e-42,
          4.7792e-02, -9.6828e-03],
        [-1.5482e-05,  1.3640e-41,  1.5714e-40,  ..., -7.0220e-41,
          7.9008e-41,  1.7871e-41],
        [-1.7178e-04, -6.7289e-41,  2.3023e-42,  ...,  1.5470e-42,
         -2.3897e-02, -1.6510e-41]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 1.0039e-01, -1.9635e-02,  4.3405e-03,  ..., -3.1129e-02,
         2.2415e-18, -1.1404e-02], device='cuda:0', requires_grad=True)], 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}]
epoch: 0 batch 0.0 event: 0 loss: tensor(171.8142, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 10.0 event: 300 loss: tensor(1490.0286, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 20.0 event: 600 loss: tensor(1856.6996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 30.0 event: 900 loss: tensor(1781.9418, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 40.0 event: 1200 loss: tensor(1882.0481, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 50.0 event: 1500 loss: tensor(1907.9274, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 60.0 event: 1800 loss: tensor(1692.4141, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 70.0 event: 2100 loss: tensor(1730.1508, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 80.0 event: 2400 loss: tensor(1641.5165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 90.0 event: 2700 loss: tensor(1751.8733, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 100.0 event: 3000 loss: tensor(1701.7513, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 110.0 event: 3300 loss: tensor(1931.6321, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 120.0 event: 3600 loss: tensor(1797.7086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 130.0 event: 3900 loss: tensor(1679.0889, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 140.0 event: 4200 loss: tensor(1482.7284, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 150.0 event: 4500 loss: tensor(1894.6975, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 160.0 event: 4800 loss: tensor(1489.5692, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 170.0 event: 5100 loss: tensor(1695.7118, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 180.0 event: 5400 loss: tensor(1943.3232, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 190.0 event: 5700 loss: tensor(1902.6776, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 200.0 event: 6000 loss: tensor(2019.3759, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 210.0 event: 6300 loss: tensor(1822.5883, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 220.0 event: 6600 loss: tensor(1951.3466, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 230.0 event: 6900 loss: tensor(1917.1133, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 240.0 event: 7200 loss: tensor(1807.0133, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 250.0 event: 7500 loss: tensor(1948.9749, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 260.0 event: 7800 loss: tensor(1890.8606, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 270.0 event: 8100 loss: tensor(1475.5331, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 280.0 event: 8400 loss: tensor(1899.7311, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 290.0 event: 8700 loss: tensor(1826.4492, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 300.0 event: 9000 loss: tensor(1724.7352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 310.0 event: 9300 loss: tensor(1674.7321, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 320.0 event: 9600 loss: tensor(1815.6727, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 330.0 event: 9900 loss: tensor(1753.2809, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:00:27.002465
evaluation loss: 1848.2633056640625
epoch: 0 mean loss: 1787.7742919921875
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 1 batch 0.0 event: 0 loss: tensor(169.2424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 10.0 event: 300 loss: tensor(1474.5701, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 20.0 event: 600 loss: tensor(1840.7655, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 30.0 event: 900 loss: tensor(1769.7500, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 40.0 event: 1200 loss: tensor(1870.5537, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 50.0 event: 1500 loss: tensor(1898.5953, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 60.0 event: 1800 loss: tensor(1682.9330, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 70.0 event: 2100 loss: tensor(1721.0956, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 80.0 event: 2400 loss: tensor(1633.2787, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 90.0 event: 2700 loss: tensor(1745.1200, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 100.0 event: 3000 loss: tensor(1692.5312, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 110.0 event: 3300 loss: tensor(1924.3961, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 120.0 event: 3600 loss: tensor(1791.1176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 130.0 event: 3900 loss: tensor(1673.8604, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 140.0 event: 4200 loss: tensor(1475.8983, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 150.0 event: 4500 loss: tensor(1887.8613, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 160.0 event: 4800 loss: tensor(1485.6200, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 170.0 event: 5100 loss: tensor(1690.4072, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 180.0 event: 5400 loss: tensor(1937.0555, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 190.0 event: 5700 loss: tensor(1892.3684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 200.0 event: 6000 loss: tensor(2011.6924, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 210.0 event: 6300 loss: tensor(1814.5830, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 220.0 event: 6600 loss: tensor(1945.0090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 230.0 event: 6900 loss: tensor(1912.1312, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 240.0 event: 7200 loss: tensor(1802.5500, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 250.0 event: 7500 loss: tensor(1944.3495, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 260.0 event: 7800 loss: tensor(1885.3965, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 270.0 event: 8100 loss: tensor(1470.1166, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 280.0 event: 8400 loss: tensor(1895.7148, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 290.0 event: 8700 loss: tensor(1821.8440, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 300.0 event: 9000 loss: tensor(1720.3619, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 310.0 event: 9300 loss: tensor(1670.9561, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 320.0 event: 9600 loss: tensor(1812.4791, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 330.0 event: 9900 loss: tensor(1748.2229, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:13.188867
evaluation loss: 1847.227783203125
epoch: 1 mean loss: 1780.512939453125
epoch: 2 batch 0.0 event: 0 loss: tensor(169.0138, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 10.0 event: 300 loss: tensor(1473.0907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 20.0 event: 600 loss: tensor(1841.4811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 30.0 event: 900 loss: tensor(1768.5410, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 40.0 event: 1200 loss: tensor(1867.6022, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 50.0 event: 1500 loss: tensor(1895.5306, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 60.0 event: 1800 loss: tensor(1681.0768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 70.0 event: 2100 loss: tensor(1720.7567, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 80.0 event: 2400 loss: tensor(1631.2422, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 90.0 event: 2700 loss: tensor(1742.7617, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 100.0 event: 3000 loss: tensor(1690.6650, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 110.0 event: 3300 loss: tensor(1923.2289, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 120.0 event: 3600 loss: tensor(1786.8059, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 130.0 event: 3900 loss: tensor(1672.7294, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 140.0 event: 4200 loss: tensor(1475.4807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 150.0 event: 4500 loss: tensor(1888.2386, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 160.0 event: 4800 loss: tensor(1482.9462, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 170.0 event: 5100 loss: tensor(1686.6215, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 180.0 event: 5400 loss: tensor(1935.3558, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 190.0 event: 5700 loss: tensor(1891.7225, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 200.0 event: 6000 loss: tensor(2008.7356, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 210.0 event: 6300 loss: tensor(1811.9401, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 220.0 event: 6600 loss: tensor(1944.6249, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 230.0 event: 6900 loss: tensor(1910.8436, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 240.0 event: 7200 loss: tensor(1801.0117, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 250.0 event: 7500 loss: tensor(1944.4100, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 260.0 event: 7800 loss: tensor(1885.2352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 270.0 event: 8100 loss: tensor(1468.5912, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 280.0 event: 8400 loss: tensor(1891.7692, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 290.0 event: 8700 loss: tensor(1815.7783, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 300.0 event: 9000 loss: tensor(1717.7313, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 310.0 event: 9300 loss: tensor(1670.5276, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 320.0 event: 9600 loss: tensor(1812.1670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 330.0 event: 9900 loss: tensor(1748.5748, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:47.445018
evaluation loss: 1848.4798583984375
epoch: 2 mean loss: 1778.857421875
epoch: 3 batch 0.0 event: 0 loss: tensor(169.0779, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 10.0 event: 300 loss: tensor(1470.9774, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 20.0 event: 600 loss: tensor(1837.9716, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 30.0 event: 900 loss: tensor(1767.9895, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 40.0 event: 1200 loss: tensor(1865.3168, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 50.0 event: 1500 loss: tensor(1892.5596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 60.0 event: 1800 loss: tensor(1678.3773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 70.0 event: 2100 loss: tensor(1716.6859, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 80.0 event: 2400 loss: tensor(1627.3214, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 90.0 event: 2700 loss: tensor(1739.5479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 100.0 event: 3000 loss: tensor(1688.1940, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 110.0 event: 3300 loss: tensor(1919.0302, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 120.0 event: 3600 loss: tensor(1782.8723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 130.0 event: 3900 loss: tensor(1667.0996, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 140.0 event: 4200 loss: tensor(1474.4778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 150.0 event: 4500 loss: tensor(1886.3737, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 160.0 event: 4800 loss: tensor(1481.5074, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 170.0 event: 5100 loss: tensor(1684.6361, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 180.0 event: 5400 loss: tensor(1930.9447, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 190.0 event: 5700 loss: tensor(1888.9541, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 200.0 event: 6000 loss: tensor(2006.6305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 210.0 event: 6300 loss: tensor(1809.0250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 220.0 event: 6600 loss: tensor(1938.0588, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 230.0 event: 6900 loss: tensor(1904.3617, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 240.0 event: 7200 loss: tensor(1795.8223, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 250.0 event: 7500 loss: tensor(1938.9642, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 260.0 event: 7800 loss: tensor(1881.9286, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 270.0 event: 8100 loss: tensor(1468.9579, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 280.0 event: 8400 loss: tensor(1891.2434, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 290.0 event: 8700 loss: tensor(1813.7034, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 300.0 event: 9000 loss: tensor(1716.4192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 310.0 event: 9300 loss: tensor(1667.5518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 320.0 event: 9600 loss: tensor(1808.7795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 330.0 event: 9900 loss: tensor(1744.3964, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:21.681156
evaluation loss: 1847.3629150390625
epoch: 3 mean loss: 1775.7694091796875
epoch: 4 batch 0.0 event: 0 loss: tensor(168.5952, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 10.0 event: 300 loss: tensor(1466.2842, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 20.0 event: 600 loss: tensor(1832.9407, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 30.0 event: 900 loss: tensor(1764.2975, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 40.0 event: 1200 loss: tensor(1863.8691, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 50.0 event: 1500 loss: tensor(1892.7098, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 60.0 event: 1800 loss: tensor(1676.4510, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 70.0 event: 2100 loss: tensor(1715.6731, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 80.0 event: 2400 loss: tensor(1627.0363, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 90.0 event: 2700 loss: tensor(1737.6526, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 100.0 event: 3000 loss: tensor(1686.2506, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 110.0 event: 3300 loss: tensor(1916.0941, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 120.0 event: 3600 loss: tensor(1780.7451, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 130.0 event: 3900 loss: tensor(1667.0029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 140.0 event: 4200 loss: tensor(1469.7666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 150.0 event: 4500 loss: tensor(1882.0869, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 160.0 event: 4800 loss: tensor(1478.1954, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 170.0 event: 5100 loss: tensor(1681.7200, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 180.0 event: 5400 loss: tensor(1928.5647, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 190.0 event: 5700 loss: tensor(1886.0938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 200.0 event: 6000 loss: tensor(2005.2606, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 210.0 event: 6300 loss: tensor(1811.5156, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 220.0 event: 6600 loss: tensor(1938.9023, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 230.0 event: 6900 loss: tensor(1905.5625, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 240.0 event: 7200 loss: tensor(1795.2040, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 250.0 event: 7500 loss: tensor(1936.1992, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 260.0 event: 7800 loss: tensor(1876.8567, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 270.0 event: 8100 loss: tensor(1465.5428, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 280.0 event: 8400 loss: tensor(1887.7864, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 290.0 event: 8700 loss: tensor(1810.4172, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 300.0 event: 9000 loss: tensor(1714.1611, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 310.0 event: 9300 loss: tensor(1666.3688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 320.0 event: 9600 loss: tensor(1805.8584, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 330.0 event: 9900 loss: tensor(1746.8528, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:55.936455
evaluation loss: 1846.8236083984375
epoch: 4 mean loss: 1773.7513427734375
epoch: 5 batch 0.0 event: 0 loss: tensor(168.8398, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 10.0 event: 300 loss: tensor(1468.5638, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 20.0 event: 600 loss: tensor(1831.6176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 30.0 event: 900 loss: tensor(1763.1038, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 40.0 event: 1200 loss: tensor(1864.4371, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 50.0 event: 1500 loss: tensor(1888.9042, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 60.0 event: 1800 loss: tensor(1674.3320, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 70.0 event: 2100 loss: tensor(1712.8524, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 80.0 event: 2400 loss: tensor(1623.7246, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 90.0 event: 2700 loss: tensor(1735.4932, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 100.0 event: 3000 loss: tensor(1684.5715, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 110.0 event: 3300 loss: tensor(1914.5006, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 120.0 event: 3600 loss: tensor(1779.0911, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 130.0 event: 3900 loss: tensor(1664.5487, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 140.0 event: 4200 loss: tensor(1468.5925, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 150.0 event: 4500 loss: tensor(1879.2067, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 160.0 event: 4800 loss: tensor(1475.2076, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 170.0 event: 5100 loss: tensor(1680.0052, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 180.0 event: 5400 loss: tensor(1926.5563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 190.0 event: 5700 loss: tensor(1884.4281, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 200.0 event: 6000 loss: tensor(2003.0563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 210.0 event: 6300 loss: tensor(1807.3160, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 220.0 event: 6600 loss: tensor(1937.5250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 230.0 event: 6900 loss: tensor(1904.9091, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 240.0 event: 7200 loss: tensor(1795.1012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 250.0 event: 7500 loss: tensor(1939.9739, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 260.0 event: 7800 loss: tensor(1878.6992, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 270.0 event: 8100 loss: tensor(1464.3538, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 280.0 event: 8400 loss: tensor(1885.1703, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 290.0 event: 8700 loss: tensor(1808.6947, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 300.0 event: 9000 loss: tensor(1710.4462, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 310.0 event: 9300 loss: tensor(1663.9554, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 320.0 event: 9600 loss: tensor(1804.1846, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 330.0 event: 9900 loss: tensor(1743.0715, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:30.195520
evaluation loss: 1847.6112060546875
epoch: 5 mean loss: 1772.121337890625
=> saveing checkpoint at epoch 5
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 6 batch 0.0 event: 0 loss: tensor(168.1622, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 10.0 event: 300 loss: tensor(1464.9912, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 20.0 event: 600 loss: tensor(1827.2256, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 30.0 event: 900 loss: tensor(1763.1484, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 40.0 event: 1200 loss: tensor(1865.9061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 50.0 event: 1500 loss: tensor(1892.3817, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 60.0 event: 1800 loss: tensor(1674.5941, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 70.0 event: 2100 loss: tensor(1713.0928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 80.0 event: 2400 loss: tensor(1623.7838, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 90.0 event: 2700 loss: tensor(1733.4436, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 100.0 event: 3000 loss: tensor(1683.4244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 110.0 event: 3300 loss: tensor(1913.9797, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 120.0 event: 3600 loss: tensor(1778.3479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 130.0 event: 3900 loss: tensor(1662.4149, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 140.0 event: 4200 loss: tensor(1467.2129, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 150.0 event: 4500 loss: tensor(1877.9720, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 160.0 event: 4800 loss: tensor(1473.9751, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 170.0 event: 5100 loss: tensor(1678.7545, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 180.0 event: 5400 loss: tensor(1925.1801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 190.0 event: 5700 loss: tensor(1883.4723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 200.0 event: 6000 loss: tensor(2001.4495, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 210.0 event: 6300 loss: tensor(1805.9977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 220.0 event: 6600 loss: tensor(1939.4512, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 230.0 event: 6900 loss: tensor(1906.2783, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 240.0 event: 7200 loss: tensor(1795.3743, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 250.0 event: 7500 loss: tensor(1939.4156, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 260.0 event: 7800 loss: tensor(1880.1084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 270.0 event: 8100 loss: tensor(1465.5529, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 280.0 event: 8400 loss: tensor(1887.7318, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 290.0 event: 8700 loss: tensor(1809.0739, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 300.0 event: 9000 loss: tensor(1711.2802, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 310.0 event: 9300 loss: tensor(1663.5684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 320.0 event: 9600 loss: tensor(1802.0061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 330.0 event: 9900 loss: tensor(1742.0394, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:09.347433
evaluation loss: 1848.5869140625
epoch: 6 mean loss: 1771.696533203125
epoch: 7 batch 0.0 event: 0 loss: tensor(168.4768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 10.0 event: 300 loss: tensor(1465.2856, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 20.0 event: 600 loss: tensor(1828.3680, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 30.0 event: 900 loss: tensor(1762.0873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 40.0 event: 1200 loss: tensor(1862.4908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 50.0 event: 1500 loss: tensor(1889.3684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 60.0 event: 1800 loss: tensor(1674.2229, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 70.0 event: 2100 loss: tensor(1712.7438, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 80.0 event: 2400 loss: tensor(1621.3347, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 90.0 event: 2700 loss: tensor(1732.5458, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 100.0 event: 3000 loss: tensor(1681.0205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 110.0 event: 3300 loss: tensor(1911.2250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 120.0 event: 3600 loss: tensor(1775.8561, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 130.0 event: 3900 loss: tensor(1662.8300, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 140.0 event: 4200 loss: tensor(1466.5865, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 150.0 event: 4500 loss: tensor(1878.7297, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 160.0 event: 4800 loss: tensor(1474.7128, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 170.0 event: 5100 loss: tensor(1678.3678, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 180.0 event: 5400 loss: tensor(1923.9808, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 190.0 event: 5700 loss: tensor(1881.5061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 200.0 event: 6000 loss: tensor(1997.2135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 210.0 event: 6300 loss: tensor(1802.7069, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 220.0 event: 6600 loss: tensor(1936.9854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 230.0 event: 6900 loss: tensor(1902.9794, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 240.0 event: 7200 loss: tensor(1795.9244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 250.0 event: 7500 loss: tensor(1938.0966, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 260.0 event: 7800 loss: tensor(1878.8290, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 270.0 event: 8100 loss: tensor(1465.8656, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 280.0 event: 8400 loss: tensor(1885.4619, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 290.0 event: 8700 loss: tensor(1806.1400, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 300.0 event: 9000 loss: tensor(1709.1842, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 310.0 event: 9300 loss: tensor(1661.4252, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 320.0 event: 9600 loss: tensor(1801.5565, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 330.0 event: 9900 loss: tensor(1740.1744, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:43.706230
evaluation loss: 1847.9619140625
epoch: 7 mean loss: 1770.298095703125
epoch: 8 batch 0.0 event: 0 loss: tensor(168.4286, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 10.0 event: 300 loss: tensor(1464.7389, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 20.0 event: 600 loss: tensor(1828.0188, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 30.0 event: 900 loss: tensor(1763.3280, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 40.0 event: 1200 loss: tensor(1861.2001, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 50.0 event: 1500 loss: tensor(1889.5145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 60.0 event: 1800 loss: tensor(1674.9286, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 70.0 event: 2100 loss: tensor(1711.2955, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 80.0 event: 2400 loss: tensor(1620.8207, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 90.0 event: 2700 loss: tensor(1731.3414, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 100.0 event: 3000 loss: tensor(1680.1888, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 110.0 event: 3300 loss: tensor(1909.8652, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 120.0 event: 3600 loss: tensor(1775.6078, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 130.0 event: 3900 loss: tensor(1660.7633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 140.0 event: 4200 loss: tensor(1464.7437, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 150.0 event: 4500 loss: tensor(1876.8057, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 160.0 event: 4800 loss: tensor(1472.5342, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 170.0 event: 5100 loss: tensor(1676.8446, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 180.0 event: 5400 loss: tensor(1922.7018, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 190.0 event: 5700 loss: tensor(1882.7172, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 200.0 event: 6000 loss: tensor(2000.3486, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 210.0 event: 6300 loss: tensor(1801.9174, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 220.0 event: 6600 loss: tensor(1932.6926, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 230.0 event: 6900 loss: tensor(1899.6908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 240.0 event: 7200 loss: tensor(1793.4700, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 250.0 event: 7500 loss: tensor(1934.4573, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 260.0 event: 7800 loss: tensor(1876.5531, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 270.0 event: 8100 loss: tensor(1461.6973, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 280.0 event: 8400 loss: tensor(1886.6068, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 290.0 event: 8700 loss: tensor(1807.5555, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 300.0 event: 9000 loss: tensor(1708.9778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 310.0 event: 9300 loss: tensor(1659.9016, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 320.0 event: 9600 loss: tensor(1800.2242, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 330.0 event: 9900 loss: tensor(1738.7484, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:18.034558
evaluation loss: 1847.283447265625
epoch: 8 mean loss: 1769.2091064453125
epoch: 9 batch 0.0 event: 0 loss: tensor(168.1303, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 10.0 event: 300 loss: tensor(1462.2871, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 20.0 event: 600 loss: tensor(1827.2604, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 30.0 event: 900 loss: tensor(1759.2184, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 40.0 event: 1200 loss: tensor(1856.4573, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 50.0 event: 1500 loss: tensor(1883.8734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 60.0 event: 1800 loss: tensor(1669.7799, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 70.0 event: 2100 loss: tensor(1707.4963, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 80.0 event: 2400 loss: tensor(1618.5697, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 90.0 event: 2700 loss: tensor(1730.0614, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 100.0 event: 3000 loss: tensor(1678.1063, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 110.0 event: 3300 loss: tensor(1909.1293, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 120.0 event: 3600 loss: tensor(1772.6545, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 130.0 event: 3900 loss: tensor(1658.0354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 140.0 event: 4200 loss: tensor(1464.9349, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 150.0 event: 4500 loss: tensor(1874.1331, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 160.0 event: 4800 loss: tensor(1471.8811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 170.0 event: 5100 loss: tensor(1674.8459, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 180.0 event: 5400 loss: tensor(1922.1869, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 190.0 event: 5700 loss: tensor(1879.9124, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 200.0 event: 6000 loss: tensor(1998.7981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 210.0 event: 6300 loss: tensor(1801.0803, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 220.0 event: 6600 loss: tensor(1937.8584, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 230.0 event: 6900 loss: tensor(1900.5365, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 240.0 event: 7200 loss: tensor(1793.5137, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 250.0 event: 7500 loss: tensor(1933.9658, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 260.0 event: 7800 loss: tensor(1869.7604, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 270.0 event: 8100 loss: tensor(1458.0336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 280.0 event: 8400 loss: tensor(1879.2650, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 290.0 event: 8700 loss: tensor(1802.5205, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 300.0 event: 9000 loss: tensor(1705.9076, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 310.0 event: 9300 loss: tensor(1657.3616, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 320.0 event: 9600 loss: tensor(1796.9081, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 330.0 event: 9900 loss: tensor(1735.9489, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:13.247255
evaluation loss: 1846.9139404296875
epoch: 9 mean loss: 1766.829833984375
=> saveing checkpoint at epoch 9
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2

outi tensor([[0.0000, 0.4115, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [2.1715, 1.4172, 0.0000,  ..., 0.4933, 0.7121, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0452, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 1.4173, 0.1928,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
 torch.Size([30, 6796]) 
 tensor(70796.5469, device='cuda:0', grad_fn=<SumBackward0>) 
 tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0') 
 tensor(203880, device='cuda:0')



training loss:
 [1787.77429199 1780.51293945 1778.85742188 1775.76940918 1773.75134277
 1772.12133789 1771.6965332  1770.2980957  1769.20910645 1766.82983398] 

\evaluation loss:
 [1848.26330566 1847.2277832  1848.4798584  1847.36291504 1846.8236084
 1847.61120605 1848.58691406 1847.96191406 1847.28344727 1846.91394043]



eval_efficiency:
 [0.6556747  0.65508637 0.65457915 0.65400385 0.65341425 0.65279552
 0.65217542 0.65146185 0.6508797  0.65023728 0.64961597 0.64892927
 0.64831892 0.64764155 0.647057   0.64639938 0.64581307 0.6453113
 0.64454175 0.64370021 0.64302253 0.64227032 0.6416007  0.64097244
 0.64019334 0.63941705 0.63865931 0.6379187  0.63720399 0.63641182
 0.63566414 0.63490527 0.63390135 0.63311428 0.63218742 0.6315242
 0.63083974 0.62992107 0.62899399 0.62815051 0.62720806 0.62635686
 0.62538863 0.62457144 0.62360689 0.62265223 0.62187406 0.62095099
 0.62000872 0.61901427 0.61803511 0.61723184 0.61627523 0.61510246
 0.61401849 0.61302046 0.61195111 0.61111682 0.60993878 0.60900239
 0.60787481 0.60684412 0.60584303 0.60488152 0.60377778 0.60269423
 0.60161652 0.60036987 0.59935781 0.59830957 0.59719134 0.5959718
 0.59483779 0.59363431 0.59239074 0.5910165  0.58983676 0.58867931
 0.58755513 0.58636845 0.5850267  0.58374865 0.58261906 0.58144201
 0.58013434 0.57891797 0.57773378 0.5764733  0.57515966 0.57385518
 0.57247795 0.57106734 0.56963173 0.56809555 0.56658059 0.56525427
 0.56376496 0.56213805 0.56078425 0.55939415] 


eval_purity:
 [0.90119029 0.90135241 0.90151456 0.90170123 0.90192643 0.90217185
 0.90238715 0.90260575 0.90283208 0.90302985 0.90326119 0.90352443
 0.90376936 0.90396896 0.90411995 0.90431652 0.90449013 0.90470679
 0.90485019 0.90499572 0.9051488  0.90536871 0.9055778  0.90589015
 0.90610896 0.90631753 0.90645353 0.90677254 0.9070338  0.90731943
 0.90756764 0.90781841 0.90804533 0.90819888 0.90844993 0.90860393
 0.90879284 0.90888711 0.90909859 0.9093088  0.90939972 0.90957626
 0.90983845 0.90999199 0.91011867 0.91041083 0.91053342 0.91074929
 0.91083609 0.91097275 0.91127666 0.9116906  0.91183475 0.91207948
 0.91228977 0.91249909 0.91269576 0.91285834 0.91302502 0.91325752
 0.9134712  0.91373337 0.91395085 0.91416558 0.91437084 0.9146359
 0.91479606 0.91503735 0.91521172 0.91548167 0.91575223 0.91583961
 0.91591912 0.91604584 0.91627387 0.91636245 0.91659626 0.91674826
 0.9169574  0.91713762 0.91742839 0.91771306 0.91789831 0.91836062
 0.91850659 0.91882052 0.91902502 0.91921418 0.91937326 0.9195315
 0.91973855 0.9198718  0.91998846 0.92011038 0.92024473 0.92045459
 0.92068014 0.92080634 0.92105072 0.92121978]

Passing event 10003 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0000, 0.0931, 0.0000,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10003 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0000, 0.1199, 0.1535,  ..., 0.0092, 0.0533, 0.1152],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network before training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0.1774, 2.3929, 2.7131,  ..., 0.2430, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network after training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([0.0000, 0.1200, 0.1535,  ..., 0.0093, 0.0531, 0.1151],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.5915, 2.4218, 1.7385,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([0.0000, 0.1200, 0.1537,  ..., 0.0092, 0.0532, 0.1153],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

real	9m4.504s
user	8m47.712s
sys	4m7.563s
