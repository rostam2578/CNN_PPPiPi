0: gpu021.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ac352fa0-e553-4a4b-9138-f546b3cbd7bb)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        C2:44:16:3E:F4:B2:32:61:B4:43:86:F6:64:80:CC:44:95:DA:BA:12
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Thu Sep  1 05:31:14 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1D:00.0 Off |                    0 |
| N/A   37C    P0    44W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b59f21c38e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	1m37.037s
user	0m3.665s
sys	0m2.216s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2/./Trainings0.py:126: RuntimeWarning: invalid value encountered in true_divide
  effres = efficiency.sum(axis = 0) / (efficiency!=0).sum(axis = 0)
/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2/./Trainings0.py:128: RuntimeWarning: invalid value encountered in true_divide
  eval_effres = eval_efficiency.sum(axis = 0) / (eval_efficiency!=0).sum(axis = 0)




 Training ... 






 The Network ... 







 Loading data ... 



training set shape (20000, 43, 288) 
sum 5279207

target set shape (20000, 6796) 
sum 4575851
Net(
  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=667776, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=6796, bias=True)
)

number of the free parameters: 171805196
parameters of the network conv1.weight 
 torch.Size([256, 1, 3, 3]) 
 True 
 tensor([[[[ 0.3129, -0.2885,  0.0656],
          [ 0.2580, -0.1279, -0.2082],
          [ 0.1556,  0.2825,  0.3051]]],


        [[[ 0.1487,  0.1102,  0.2609],
          [-0.2534,  0.0374,  0.0210],
          [ 0.0970, -0.1092,  0.2126]]],


        [[[-0.2969,  0.2453, -0.1986],
          [ 0.2558, -0.2782,  0.3274],
          [-0.0891,  0.1049, -0.0472]]],


        ...,


        [[[-0.1653, -0.2331,  0.2812],
          [-0.1462, -0.2053, -0.1415],
          [-0.1826,  0.3090,  0.0105]]],


        [[[-0.0824,  0.0784, -0.1888],
          [-0.2260,  0.0503, -0.2077],
          [ 0.0791, -0.2147,  0.1157]]],


        [[[-0.2646, -0.1032, -0.2132],
          [-0.2699, -0.0290, -0.1747],
          [-0.3030,  0.1307,  0.3131]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 0.3129, -0.2885,  0.0656],
          [ 0.2580, -0.1279, -0.2082],
          [ 0.1556,  0.2825,  0.3051]]],


        [[[ 0.1487,  0.1102,  0.2609],
          [-0.2534,  0.0374,  0.0210],
          [ 0.0970, -0.1092,  0.2126]]],


        [[[-0.2969,  0.2453, -0.1986],
          [ 0.2558, -0.2782,  0.3274],
          [-0.0891,  0.1049, -0.0472]]],


        ...,


        [[[-0.1653, -0.2331,  0.2812],
          [-0.1462, -0.2053, -0.1415],
          [-0.1826,  0.3090,  0.0105]]],


        [[[-0.0824,  0.0784, -0.1888],
          [-0.2260,  0.0503, -0.2077],
          [ 0.0791, -0.2147,  0.1157]]],


        [[[-0.2646, -0.1032, -0.2132],
          [-0.2699, -0.0290, -0.1747],
          [-0.3030,  0.1307,  0.3131]]]], device='cuda:0', requires_grad=True)
parameters of the network conv1.bias 
 torch.Size([256]) 
 True 
 tensor([-0.1767,  0.0627, -0.2130,  0.1982,  0.2295, -0.3250,  0.2442,  0.2183,
        -0.3247, -0.1058,  0.2110,  0.1045, -0.1193,  0.0822,  0.3307, -0.0602,
        -0.0071, -0.1507,  0.1902, -0.1241,  0.2717, -0.1302,  0.3318,  0.1037,
         0.1725,  0.2832, -0.0190,  0.3273,  0.1878, -0.0177,  0.0146,  0.0872,
        -0.1978,  0.2526, -0.2097, -0.1758,  0.1084,  0.0066,  0.0280,  0.0689,
        -0.2242, -0.0169,  0.2568,  0.2065,  0.1934, -0.2311,  0.0915, -0.0853,
        -0.1976,  0.0650,  0.0974,  0.1705, -0.3265, -0.0615,  0.3036,  0.1969,
        -0.3254, -0.2068,  0.1048,  0.1944, -0.0796,  0.2937, -0.1855, -0.0446,
         0.1111,  0.0417,  0.1960, -0.0456,  0.2097, -0.1589,  0.3202,  0.0360,
         0.0105,  0.2339, -0.3325, -0.2906,  0.2491,  0.2044, -0.3289,  0.0269,
         0.2542,  0.2114,  0.3295,  0.1740,  0.3210,  0.1454, -0.3320, -0.3272,
         0.1603, -0.1385, -0.3003,  0.1479, -0.1769,  0.0190, -0.0914,  0.3157,
        -0.2243, -0.2674,  0.2012,  0.2529, -0.0296, -0.1451,  0.1487, -0.1288,
         0.1947,  0.3015,  0.0238, -0.1244, -0.0541, -0.0189,  0.1240, -0.2449,
         0.1848,  0.0652,  0.2821, -0.2178,  0.1717,  0.0665, -0.2911, -0.1870,
         0.0756, -0.2837, -0.1105, -0.1341, -0.0914, -0.0148, -0.1856, -0.0801,
         0.2814, -0.3121,  0.3143, -0.1410, -0.2391,  0.0885,  0.1062,  0.2465,
        -0.2077,  0.0361,  0.3162, -0.2295, -0.1674, -0.2464, -0.3218,  0.1236,
        -0.0837,  0.2134, -0.2885,  0.2510,  0.3257, -0.0952, -0.0549,  0.0538,
        -0.1342,  0.1417,  0.1939, -0.2808,  0.0738, -0.1913, -0.0641, -0.1219,
        -0.1733,  0.2684, -0.1113, -0.1254, -0.1180, -0.2393, -0.0529, -0.2386,
        -0.3033,  0.1657,  0.0151, -0.2090, -0.1358, -0.1437, -0.1299,  0.0049,
        -0.0690,  0.2334, -0.1828, -0.2622, -0.2328,  0.1214,  0.2600,  0.1397,
         0.0819,  0.0100,  0.0092,  0.0139, -0.0584,  0.3070,  0.2886,  0.1482,
        -0.0636, -0.2537, -0.2193,  0.2425,  0.0939, -0.1055, -0.0766, -0.2937,
         0.2135, -0.2276, -0.0413,  0.1901, -0.0517,  0.0738,  0.2327,  0.0050,
         0.0780, -0.1210, -0.2051,  0.0286,  0.2760, -0.0618, -0.2447,  0.0894,
         0.2388, -0.2524,  0.0351,  0.1228, -0.3313, -0.1054, -0.3091, -0.1851,
        -0.0284, -0.2792, -0.2071, -0.1339, -0.2733, -0.3152,  0.1137, -0.1305,
        -0.0851,  0.2541, -0.0962,  0.0607,  0.2723, -0.3296, -0.2892,  0.2117,
         0.1254,  0.0772,  0.0410, -0.1825,  0.0620, -0.2212,  0.0965,  0.2243,
         0.2195, -0.2346, -0.2423, -0.1405, -0.2053,  0.0567,  0.1308,  0.1242],
       device='cuda:0') 
 Parameter containing:
tensor([-0.1767,  0.0627, -0.2130,  0.1982,  0.2295, -0.3250,  0.2442,  0.2183,
        -0.3247, -0.1058,  0.2110,  0.1045, -0.1193,  0.0822,  0.3307, -0.0602,
        -0.0071, -0.1507,  0.1902, -0.1241,  0.2717, -0.1302,  0.3318,  0.1037,
         0.1725,  0.2832, -0.0190,  0.3273,  0.1878, -0.0177,  0.0146,  0.0872,
        -0.1978,  0.2526, -0.2097, -0.1758,  0.1084,  0.0066,  0.0280,  0.0689,
        -0.2242, -0.0169,  0.2568,  0.2065,  0.1934, -0.2311,  0.0915, -0.0853,
        -0.1976,  0.0650,  0.0974,  0.1705, -0.3265, -0.0615,  0.3036,  0.1969,
        -0.3254, -0.2068,  0.1048,  0.1944, -0.0796,  0.2937, -0.1855, -0.0446,
         0.1111,  0.0417,  0.1960, -0.0456,  0.2097, -0.1589,  0.3202,  0.0360,
         0.0105,  0.2339, -0.3325, -0.2906,  0.2491,  0.2044, -0.3289,  0.0269,
         0.2542,  0.2114,  0.3295,  0.1740,  0.3210,  0.1454, -0.3320, -0.3272,
         0.1603, -0.1385, -0.3003,  0.1479, -0.1769,  0.0190, -0.0914,  0.3157,
        -0.2243, -0.2674,  0.2012,  0.2529, -0.0296, -0.1451,  0.1487, -0.1288,
         0.1947,  0.3015,  0.0238, -0.1244, -0.0541, -0.0189,  0.1240, -0.2449,
         0.1848,  0.0652,  0.2821, -0.2178,  0.1717,  0.0665, -0.2911, -0.1870,
         0.0756, -0.2837, -0.1105, -0.1341, -0.0914, -0.0148, -0.1856, -0.0801,
         0.2814, -0.3121,  0.3143, -0.1410, -0.2391,  0.0885,  0.1062,  0.2465,
        -0.2077,  0.0361,  0.3162, -0.2295, -0.1674, -0.2464, -0.3218,  0.1236,
        -0.0837,  0.2134, -0.2885,  0.2510,  0.3257, -0.0952, -0.0549,  0.0538,
        -0.1342,  0.1417,  0.1939, -0.2808,  0.0738, -0.1913, -0.0641, -0.1219,
        -0.1733,  0.2684, -0.1113, -0.1254, -0.1180, -0.2393, -0.0529, -0.2386,
        -0.3033,  0.1657,  0.0151, -0.2090, -0.1358, -0.1437, -0.1299,  0.0049,
        -0.0690,  0.2334, -0.1828, -0.2622, -0.2328,  0.1214,  0.2600,  0.1397,
         0.0819,  0.0100,  0.0092,  0.0139, -0.0584,  0.3070,  0.2886,  0.1482,
        -0.0636, -0.2537, -0.2193,  0.2425,  0.0939, -0.1055, -0.0766, -0.2937,
         0.2135, -0.2276, -0.0413,  0.1901, -0.0517,  0.0738,  0.2327,  0.0050,
         0.0780, -0.1210, -0.2051,  0.0286,  0.2760, -0.0618, -0.2447,  0.0894,
         0.2388, -0.2524,  0.0351,  0.1228, -0.3313, -0.1054, -0.3091, -0.1851,
        -0.0284, -0.2792, -0.2071, -0.1339, -0.2733, -0.3152,  0.1137, -0.1305,
        -0.0851,  0.2541, -0.0962,  0.0607,  0.2723, -0.3296, -0.2892,  0.2117,
         0.1254,  0.0772,  0.0410, -0.1825,  0.0620, -0.2212,  0.0965,  0.2243,
         0.2195, -0.2346, -0.2423, -0.1405, -0.2053,  0.0567,  0.1308,  0.1242],
       device='cuda:0', requires_grad=True)
parameters of the network conv2.weight 
 torch.Size([128, 256, 3, 3]) 
 True 
 tensor([[[[ 5.6303e-03,  3.5354e-03,  5.7323e-03],
          [ 1.6418e-02, -6.4130e-03, -1.4426e-02],
          [ 1.4839e-02,  1.4297e-02,  2.0228e-05]],

         [[-1.9752e-02,  7.7885e-03,  1.7548e-02],
          [-2.0621e-02,  1.6617e-02, -2.3232e-03],
          [ 1.8688e-02,  1.6164e-02,  8.7311e-03]],

         [[-1.5555e-02, -1.7436e-02, -6.0463e-04],
          [ 1.7197e-02, -1.6258e-02,  1.2700e-02],
          [ 2.0646e-02, -3.0825e-03,  1.5890e-03]],

         ...,

         [[ 1.4617e-02, -9.5248e-03, -1.9759e-03],
          [ 7.3266e-03,  9.0351e-03, -1.3683e-02],
          [ 1.4651e-02,  1.1025e-02, -7.0569e-03]],

         [[ 3.1352e-03, -1.5400e-02,  3.5097e-03],
          [ 1.5712e-02, -1.1509e-02,  1.9968e-02],
          [ 1.2902e-02,  1.9542e-02, -4.0946e-03]],

         [[-1.4172e-02,  5.6560e-03, -2.0739e-02],
          [-2.0198e-02,  2.0439e-02,  6.5740e-03],
          [-1.5758e-03,  1.6841e-02,  1.8854e-02]]],


        [[[ 1.3540e-03, -3.3472e-03,  1.4615e-02],
          [-2.0364e-02,  4.6075e-03, -1.3804e-02],
          [-4.4612e-03,  1.8322e-02,  1.9669e-02]],

         [[-1.9898e-02,  1.8913e-03,  1.9455e-02],
          [-1.9898e-02,  1.5815e-02,  3.9913e-03],
          [ 7.5213e-03, -8.0218e-03, -6.0923e-03]],

         [[ 6.8261e-03, -8.4190e-03, -1.3921e-02],
          [-8.1240e-03,  1.5488e-02, -7.2429e-03],
          [-1.8481e-03,  9.1329e-03, -1.8603e-02]],

         ...,

         [[-2.8494e-03,  8.5613e-03,  8.8518e-03],
          [-7.0075e-03,  1.2683e-02, -1.4643e-02],
          [-1.5749e-02, -2.9623e-03, -2.0428e-02]],

         [[-1.5620e-02,  9.0172e-03, -6.2789e-03],
          [ 1.3451e-02,  1.5227e-02,  1.6359e-02],
          [ 1.0850e-02, -1.3990e-02,  6.5632e-03]],

         [[-4.9801e-03, -1.2397e-02, -1.8239e-02],
          [ 1.4276e-02,  8.6565e-03,  1.0555e-02],
          [-2.3118e-03,  8.1796e-03, -1.4146e-03]]],


        [[[ 2.0490e-02, -2.2547e-03,  7.3374e-03],
          [-1.7445e-02,  7.8550e-03, -8.8512e-03],
          [-9.1433e-03,  2.5977e-03, -1.3290e-02]],

         [[-1.5516e-02,  2.5586e-04, -5.7135e-03],
          [-1.6320e-02, -1.5780e-02, -1.9644e-02],
          [-1.0518e-02,  7.0403e-03, -1.1263e-02]],

         [[ 2.0590e-02, -9.5940e-03, -1.7574e-02],
          [ 1.6599e-02,  7.0224e-03, -8.0341e-03],
          [ 3.5135e-03, -1.3966e-03, -3.3470e-04]],

         ...,

         [[ 8.7496e-03,  1.9801e-03,  1.2289e-02],
          [-1.4465e-02, -5.8790e-03, -1.6913e-02],
          [ 5.6468e-04, -1.9806e-02, -5.4762e-03]],

         [[-1.4564e-03,  1.9271e-02,  1.9554e-03],
          [ 9.6824e-03, -1.3347e-02,  1.6524e-03],
          [ 1.4491e-02,  1.3251e-02,  1.5668e-02]],

         [[ 6.4438e-03,  1.1861e-03,  1.7804e-02],
          [-1.7333e-02,  8.1064e-03, -8.5991e-03],
          [ 1.4474e-02, -2.0812e-02,  8.5236e-03]]],


        ...,


        [[[-1.7177e-02,  5.2304e-03,  1.1418e-02],
          [ 1.1249e-02,  8.9096e-03,  1.4745e-03],
          [ 1.6902e-03,  9.8755e-03, -1.4320e-02]],

         [[ 1.1407e-03, -8.2634e-03, -1.0860e-02],
          [ 1.9013e-02,  2.0283e-02, -1.4225e-02],
          [-2.5249e-03, -1.1592e-02,  1.5500e-02]],

         [[ 2.0822e-02,  2.0287e-02,  7.2269e-03],
          [ 1.1749e-02,  1.3769e-02, -4.9773e-03],
          [ 1.3071e-02, -9.2361e-03, -8.3839e-03]],

         ...,

         [[ 1.8720e-02,  2.5220e-04, -1.6399e-02],
          [ 1.2159e-02,  1.0991e-03,  6.1120e-03],
          [-1.7150e-02,  4.7642e-03,  1.2067e-02]],

         [[ 1.8120e-02, -4.7455e-03,  1.5362e-02],
          [ 3.6156e-03,  1.5223e-02, -1.5470e-02],
          [ 1.1558e-02,  1.4388e-02, -1.4604e-02]],

         [[-1.0203e-02, -2.0505e-03, -1.8828e-02],
          [ 5.0696e-03,  1.8876e-02, -1.0560e-02],
          [-9.9183e-04, -1.0989e-03,  3.6235e-04]]],


        [[[ 2.6896e-03, -3.8696e-03,  6.5818e-03],
          [-1.1843e-02,  1.8020e-02, -6.1127e-04],
          [ 1.9572e-02,  8.2735e-03,  1.4990e-02]],

         [[-2.0390e-04,  1.2978e-02, -9.7646e-03],
          [-1.1748e-02,  8.6689e-03,  8.9062e-03],
          [-3.4595e-03, -1.0561e-02,  6.9155e-03]],

         [[ 1.5320e-02, -1.1527e-02, -7.9798e-03],
          [ 7.8623e-03, -1.2457e-02, -1.0651e-02],
          [ 7.4512e-03, -8.4165e-03, -1.3482e-02]],

         ...,

         [[-1.2215e-03,  2.1670e-03,  9.8158e-03],
          [ 3.8258e-03, -8.1640e-03,  4.7181e-03],
          [-5.6130e-03,  8.0696e-03, -1.9440e-02]],

         [[-1.3208e-02, -8.1883e-03,  2.0979e-03],
          [ 1.9636e-02,  3.7386e-03,  1.9061e-02],
          [-2.0421e-02, -1.0976e-03,  1.3090e-02]],

         [[ 1.2750e-02,  4.1809e-03,  1.6264e-02],
          [ 5.0563e-03,  1.2823e-02, -1.3153e-02],
          [ 1.8328e-02, -1.6222e-02, -1.4266e-02]]],


        [[[ 1.2117e-02, -7.9300e-03,  2.0046e-02],
          [-1.5920e-02, -1.2682e-02, -6.8356e-03],
          [-1.4756e-02, -1.5922e-02,  1.5526e-02]],

         [[-7.6641e-03,  9.0006e-05, -1.2120e-02],
          [ 1.6956e-02,  5.2447e-03, -1.3075e-02],
          [-8.0757e-03, -9.3682e-03, -2.3438e-03]],

         [[-1.2846e-02,  6.2280e-03, -2.0528e-02],
          [-8.1270e-03, -2.0381e-03, -1.2743e-02],
          [ 1.3536e-02, -1.5415e-02,  5.4172e-03]],

         ...,

         [[ 1.9611e-02, -5.5070e-03,  3.0335e-03],
          [ 1.0419e-02, -6.8077e-03, -1.3399e-02],
          [ 1.1735e-02, -1.1150e-02, -1.3266e-02]],

         [[ 1.9204e-02, -1.3937e-02,  1.9788e-02],
          [-1.8052e-02,  1.0332e-02,  5.0269e-03],
          [ 7.4378e-03, -1.6509e-02,  1.4473e-02]],

         [[ 7.2617e-03,  9.2860e-03,  9.8883e-04],
          [-1.3246e-02,  1.9339e-02, -1.3767e-02],
          [ 1.7816e-02,  5.1444e-03, -7.5935e-03]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 5.6303e-03,  3.5354e-03,  5.7323e-03],
          [ 1.6418e-02, -6.4130e-03, -1.4426e-02],
          [ 1.4839e-02,  1.4297e-02,  2.0228e-05]],

         [[-1.9752e-02,  7.7885e-03,  1.7548e-02],
          [-2.0621e-02,  1.6617e-02, -2.3232e-03],
          [ 1.8688e-02,  1.6164e-02,  8.7311e-03]],

         [[-1.5555e-02, -1.7436e-02, -6.0463e-04],
          [ 1.7197e-02, -1.6258e-02,  1.2700e-02],
          [ 2.0646e-02, -3.0825e-03,  1.5890e-03]],

         ...,

         [[ 1.4617e-02, -9.5248e-03, -1.9759e-03],
          [ 7.3266e-03,  9.0351e-03, -1.3683e-02],
          [ 1.4651e-02,  1.1025e-02, -7.0569e-03]],

         [[ 3.1352e-03, -1.5400e-02,  3.5097e-03],
          [ 1.5712e-02, -1.1509e-02,  1.9968e-02],
          [ 1.2902e-02,  1.9542e-02, -4.0946e-03]],

         [[-1.4172e-02,  5.6560e-03, -2.0739e-02],
          [-2.0198e-02,  2.0439e-02,  6.5740e-03],
          [-1.5758e-03,  1.6841e-02,  1.8854e-02]]],


        [[[ 1.3540e-03, -3.3472e-03,  1.4615e-02],
          [-2.0364e-02,  4.6075e-03, -1.3804e-02],
          [-4.4612e-03,  1.8322e-02,  1.9669e-02]],

         [[-1.9898e-02,  1.8913e-03,  1.9455e-02],
          [-1.9898e-02,  1.5815e-02,  3.9913e-03],
          [ 7.5213e-03, -8.0218e-03, -6.0923e-03]],

         [[ 6.8261e-03, -8.4190e-03, -1.3921e-02],
          [-8.1240e-03,  1.5488e-02, -7.2429e-03],
          [-1.8481e-03,  9.1329e-03, -1.8603e-02]],

         ...,

         [[-2.8494e-03,  8.5613e-03,  8.8518e-03],
          [-7.0075e-03,  1.2683e-02, -1.4643e-02],
          [-1.5749e-02, -2.9623e-03, -2.0428e-02]],

         [[-1.5620e-02,  9.0172e-03, -6.2789e-03],
          [ 1.3451e-02,  1.5227e-02,  1.6359e-02],
          [ 1.0850e-02, -1.3990e-02,  6.5632e-03]],

         [[-4.9801e-03, -1.2397e-02, -1.8239e-02],
          [ 1.4276e-02,  8.6565e-03,  1.0555e-02],
          [-2.3118e-03,  8.1796e-03, -1.4146e-03]]],


        [[[ 2.0490e-02, -2.2547e-03,  7.3374e-03],
          [-1.7445e-02,  7.8550e-03, -8.8512e-03],
          [-9.1433e-03,  2.5977e-03, -1.3290e-02]],

         [[-1.5516e-02,  2.5586e-04, -5.7135e-03],
          [-1.6320e-02, -1.5780e-02, -1.9644e-02],
          [-1.0518e-02,  7.0403e-03, -1.1263e-02]],

         [[ 2.0590e-02, -9.5940e-03, -1.7574e-02],
          [ 1.6599e-02,  7.0224e-03, -8.0341e-03],
          [ 3.5135e-03, -1.3966e-03, -3.3470e-04]],

         ...,

         [[ 8.7496e-03,  1.9801e-03,  1.2289e-02],
          [-1.4465e-02, -5.8790e-03, -1.6913e-02],
          [ 5.6468e-04, -1.9806e-02, -5.4762e-03]],

         [[-1.4564e-03,  1.9271e-02,  1.9554e-03],
          [ 9.6824e-03, -1.3347e-02,  1.6524e-03],
          [ 1.4491e-02,  1.3251e-02,  1.5668e-02]],

         [[ 6.4438e-03,  1.1861e-03,  1.7804e-02],
          [-1.7333e-02,  8.1064e-03, -8.5991e-03],
          [ 1.4474e-02, -2.0812e-02,  8.5236e-03]]],


        ...,


        [[[-1.7177e-02,  5.2304e-03,  1.1418e-02],
          [ 1.1249e-02,  8.9096e-03,  1.4745e-03],
          [ 1.6902e-03,  9.8755e-03, -1.4320e-02]],

         [[ 1.1407e-03, -8.2634e-03, -1.0860e-02],
          [ 1.9013e-02,  2.0283e-02, -1.4225e-02],
          [-2.5249e-03, -1.1592e-02,  1.5500e-02]],

         [[ 2.0822e-02,  2.0287e-02,  7.2269e-03],
          [ 1.1749e-02,  1.3769e-02, -4.9773e-03],
          [ 1.3071e-02, -9.2361e-03, -8.3839e-03]],

         ...,

         [[ 1.8720e-02,  2.5220e-04, -1.6399e-02],
          [ 1.2159e-02,  1.0991e-03,  6.1120e-03],
          [-1.7150e-02,  4.7642e-03,  1.2067e-02]],

         [[ 1.8120e-02, -4.7455e-03,  1.5362e-02],
          [ 3.6156e-03,  1.5223e-02, -1.5470e-02],
          [ 1.1558e-02,  1.4388e-02, -1.4604e-02]],

         [[-1.0203e-02, -2.0505e-03, -1.8828e-02],
          [ 5.0696e-03,  1.8876e-02, -1.0560e-02],
          [-9.9183e-04, -1.0989e-03,  3.6235e-04]]],


        [[[ 2.6896e-03, -3.8696e-03,  6.5818e-03],
          [-1.1843e-02,  1.8020e-02, -6.1127e-04],
          [ 1.9572e-02,  8.2735e-03,  1.4990e-02]],

         [[-2.0390e-04,  1.2978e-02, -9.7646e-03],
          [-1.1748e-02,  8.6689e-03,  8.9062e-03],
          [-3.4595e-03, -1.0561e-02,  6.9155e-03]],

         [[ 1.5320e-02, -1.1527e-02, -7.9798e-03],
          [ 7.8623e-03, -1.2457e-02, -1.0651e-02],
          [ 7.4512e-03, -8.4165e-03, -1.3482e-02]],

         ...,

         [[-1.2215e-03,  2.1670e-03,  9.8158e-03],
          [ 3.8258e-03, -8.1640e-03,  4.7181e-03],
          [-5.6130e-03,  8.0696e-03, -1.9440e-02]],

         [[-1.3208e-02, -8.1883e-03,  2.0979e-03],
          [ 1.9636e-02,  3.7386e-03,  1.9061e-02],
          [-2.0421e-02, -1.0976e-03,  1.3090e-02]],

         [[ 1.2750e-02,  4.1809e-03,  1.6264e-02],
          [ 5.0563e-03,  1.2823e-02, -1.3153e-02],
          [ 1.8328e-02, -1.6222e-02, -1.4266e-02]]],


        [[[ 1.2117e-02, -7.9300e-03,  2.0046e-02],
          [-1.5920e-02, -1.2682e-02, -6.8356e-03],
          [-1.4756e-02, -1.5922e-02,  1.5526e-02]],

         [[-7.6641e-03,  9.0006e-05, -1.2120e-02],
          [ 1.6956e-02,  5.2447e-03, -1.3075e-02],
          [-8.0757e-03, -9.3682e-03, -2.3438e-03]],

         [[-1.2846e-02,  6.2280e-03, -2.0528e-02],
          [-8.1270e-03, -2.0381e-03, -1.2743e-02],
          [ 1.3536e-02, -1.5415e-02,  5.4172e-03]],

         ...,

         [[ 1.9611e-02, -5.5070e-03,  3.0335e-03],
          [ 1.0419e-02, -6.8077e-03, -1.3399e-02],
          [ 1.1735e-02, -1.1150e-02, -1.3266e-02]],

         [[ 1.9204e-02, -1.3937e-02,  1.9788e-02],
          [-1.8052e-02,  1.0332e-02,  5.0269e-03],
          [ 7.4378e-03, -1.6509e-02,  1.4473e-02]],

         [[ 7.2617e-03,  9.2860e-03,  9.8883e-04],
          [-1.3246e-02,  1.9339e-02, -1.3767e-02],
          [ 1.7816e-02,  5.1444e-03, -7.5935e-03]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv2.bias 
 torch.Size([128]) 
 True 
 tensor([ 8.1115e-03,  1.8515e-02, -1.4618e-03,  1.4796e-02, -1.0113e-02,
        -1.2103e-02,  1.2086e-02, -1.7365e-03, -1.0299e-03, -1.8343e-02,
         6.0407e-04, -2.0399e-02, -1.6576e-02, -3.3806e-03,  1.2277e-02,
        -1.4746e-02,  1.9115e-02, -1.5854e-02,  7.0682e-03,  1.7003e-02,
         1.6486e-02,  3.6418e-03,  1.2305e-02,  1.8542e-02,  4.4404e-03,
        -1.7533e-02,  3.7615e-03,  8.7416e-03, -1.1948e-02,  5.8874e-03,
        -1.3342e-02, -6.9386e-03,  4.4313e-03,  1.6345e-02,  1.7104e-02,
        -8.6520e-03, -5.9965e-03,  1.4802e-02, -1.1230e-02, -1.2628e-02,
         1.9291e-02, -1.1672e-02,  1.2193e-02,  1.1439e-03, -4.4692e-04,
         1.1806e-02,  1.4172e-02,  3.3166e-03,  4.6098e-03,  1.6863e-02,
         1.3679e-02, -2.0576e-03,  7.4542e-04, -9.1319e-04,  1.0864e-04,
         8.3799e-04, -7.3396e-03, -9.1375e-03,  1.7259e-02,  1.1018e-02,
         5.5725e-03, -3.8412e-03,  1.0486e-02, -1.1778e-02,  1.1492e-02,
        -2.3041e-03,  1.0176e-02,  1.8861e-02, -1.2498e-02,  8.1997e-03,
         1.8269e-02,  1.7416e-02,  3.8098e-04,  8.3362e-03,  1.5670e-02,
        -8.6106e-03,  2.0148e-02,  1.2096e-02,  1.9227e-03,  1.2011e-02,
         1.0292e-02, -1.2383e-02,  1.8003e-02,  1.6280e-02,  1.6002e-03,
         1.0521e-02, -1.3559e-02, -7.9527e-03,  1.8492e-02, -1.2035e-03,
        -8.4903e-03, -1.9103e-02,  1.9198e-02, -2.0975e-03, -1.6507e-03,
         7.6283e-03, -3.4503e-03,  5.0924e-03,  1.6698e-02, -2.7426e-03,
         4.3503e-03,  6.1627e-03,  5.0217e-05,  1.5545e-02, -1.8023e-02,
        -4.0500e-03,  1.4399e-02, -4.8925e-03,  6.2630e-03, -1.7338e-02,
         2.7936e-04, -1.3428e-02, -4.8556e-03,  1.8882e-02, -5.6148e-04,
         5.4209e-03,  1.4877e-02, -5.5442e-03,  1.9790e-02,  9.5492e-03,
         1.3459e-02, -1.4578e-03, -1.8035e-02,  5.7673e-03, -1.5587e-03,
        -1.9816e-03,  7.6983e-04,  2.0333e-02], device='cuda:0') 
 Parameter containing:
tensor([ 8.1115e-03,  1.8515e-02, -1.4618e-03,  1.4796e-02, -1.0113e-02,
        -1.2103e-02,  1.2086e-02, -1.7365e-03, -1.0299e-03, -1.8343e-02,
         6.0407e-04, -2.0399e-02, -1.6576e-02, -3.3806e-03,  1.2277e-02,
        -1.4746e-02,  1.9115e-02, -1.5854e-02,  7.0682e-03,  1.7003e-02,
         1.6486e-02,  3.6418e-03,  1.2305e-02,  1.8542e-02,  4.4404e-03,
        -1.7533e-02,  3.7615e-03,  8.7416e-03, -1.1948e-02,  5.8874e-03,
        -1.3342e-02, -6.9386e-03,  4.4313e-03,  1.6345e-02,  1.7104e-02,
        -8.6520e-03, -5.9965e-03,  1.4802e-02, -1.1230e-02, -1.2628e-02,
         1.9291e-02, -1.1672e-02,  1.2193e-02,  1.1439e-03, -4.4692e-04,
         1.1806e-02,  1.4172e-02,  3.3166e-03,  4.6098e-03,  1.6863e-02,
         1.3679e-02, -2.0576e-03,  7.4542e-04, -9.1319e-04,  1.0864e-04,
         8.3799e-04, -7.3396e-03, -9.1375e-03,  1.7259e-02,  1.1018e-02,
         5.5725e-03, -3.8412e-03,  1.0486e-02, -1.1778e-02,  1.1492e-02,
        -2.3041e-03,  1.0176e-02,  1.8861e-02, -1.2498e-02,  8.1997e-03,
         1.8269e-02,  1.7416e-02,  3.8098e-04,  8.3362e-03,  1.5670e-02,
        -8.6106e-03,  2.0148e-02,  1.2096e-02,  1.9227e-03,  1.2011e-02,
         1.0292e-02, -1.2383e-02,  1.8003e-02,  1.6280e-02,  1.6002e-03,
         1.0521e-02, -1.3559e-02, -7.9527e-03,  1.8492e-02, -1.2035e-03,
        -8.4903e-03, -1.9103e-02,  1.9198e-02, -2.0975e-03, -1.6507e-03,
         7.6283e-03, -3.4503e-03,  5.0924e-03,  1.6698e-02, -2.7426e-03,
         4.3503e-03,  6.1627e-03,  5.0217e-05,  1.5545e-02, -1.8023e-02,
        -4.0500e-03,  1.4399e-02, -4.8925e-03,  6.2630e-03, -1.7338e-02,
         2.7936e-04, -1.3428e-02, -4.8556e-03,  1.8882e-02, -5.6148e-04,
         5.4209e-03,  1.4877e-02, -5.5442e-03,  1.9790e-02,  9.5492e-03,
         1.3459e-02, -1.4578e-03, -1.8035e-02,  5.7673e-03, -1.5587e-03,
        -1.9816e-03,  7.6983e-04,  2.0333e-02], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.weight 
 torch.Size([64, 128, 3, 3]) 
 True 
 tensor([[[[-2.4920e-02, -8.3494e-03,  2.6304e-02],
          [ 8.9767e-03, -2.8502e-02, -1.5565e-03],
          [-2.1893e-02,  8.0243e-04, -4.0647e-03]],

         [[ 2.4816e-02, -2.2081e-02, -1.5463e-02],
          [-2.5172e-02,  7.2438e-03,  2.9052e-02],
          [-1.0746e-02,  6.4857e-03, -4.6564e-03]],

         [[-6.5855e-03, -1.4794e-02, -7.6443e-03],
          [-3.5495e-03,  2.4543e-02,  3.4315e-03],
          [ 9.1402e-03, -1.6658e-02,  1.0003e-02]],

         ...,

         [[ 2.0640e-03, -2.6199e-02,  2.2306e-02],
          [ 2.3520e-02, -7.0268e-03,  1.2953e-02],
          [ 1.1984e-02, -1.5149e-02,  2.2729e-02]],

         [[-1.7215e-02,  5.3358e-03, -8.6513e-03],
          [-2.8366e-02, -2.4052e-02, -7.4373e-03],
          [ 2.6679e-02, -1.3849e-03, -2.8949e-02]],

         [[-1.7981e-02,  2.3839e-03,  2.7123e-02],
          [-4.9312e-03,  1.3224e-02, -1.3717e-02],
          [ 2.9041e-02, -6.8743e-03,  2.6992e-02]]],


        [[[-3.5097e-03,  2.5516e-02,  1.2979e-02],
          [-1.0213e-02, -4.4809e-03, -5.1935e-03],
          [ 2.9381e-02,  3.4079e-03,  2.3098e-02]],

         [[ 3.7397e-03, -1.4303e-02,  1.4708e-02],
          [-2.5776e-02,  2.7027e-03, -1.7492e-03],
          [-1.1808e-02, -2.7581e-02,  1.3922e-02]],

         [[ 8.0677e-03, -2.0276e-02, -2.8033e-02],
          [ 2.0285e-02, -1.4815e-02,  1.7570e-03],
          [ 1.9621e-02, -2.5453e-02, -5.4602e-03]],

         ...,

         [[ 2.1823e-02, -1.5105e-02, -1.4767e-02],
          [-2.4071e-02, -7.8013e-03, -1.1597e-02],
          [-9.0623e-03, -9.7497e-04, -2.8447e-03]],

         [[-2.4373e-02,  1.5872e-02, -1.8536e-02],
          [ 1.2310e-02,  1.8794e-02,  2.4844e-02],
          [-1.3369e-02, -2.2506e-02, -2.2743e-02]],

         [[-2.0090e-03,  5.1476e-03,  3.5750e-03],
          [ 1.4271e-02,  1.2384e-02,  7.1031e-03],
          [-1.4733e-03,  1.9467e-03,  2.5509e-02]]],


        [[[-1.2411e-02, -2.7071e-02,  2.4918e-02],
          [ 2.4782e-02,  2.6313e-02, -2.8324e-02],
          [-9.7078e-06, -1.4561e-02,  5.3616e-03]],

         [[ 9.0409e-03,  2.8524e-02, -2.2636e-02],
          [-2.7890e-02, -1.1642e-02, -1.1588e-03],
          [-1.7491e-02, -2.8665e-02,  3.4639e-03]],

         [[ 7.2966e-03, -2.2500e-02,  1.7863e-02],
          [ 2.1882e-02, -3.8861e-03, -1.0746e-02],
          [ 9.8841e-03,  2.7151e-02, -6.6589e-03]],

         ...,

         [[ 7.5755e-03,  1.3006e-02, -2.0798e-02],
          [-1.5046e-02,  8.5001e-03,  3.3313e-04],
          [-2.0268e-02, -1.6086e-02, -1.7531e-03]],

         [[-1.7518e-02, -2.6873e-02,  2.9340e-02],
          [ 2.5602e-02,  2.9389e-02,  2.8872e-03],
          [-6.3584e-03, -2.7602e-02, -1.1252e-02]],

         [[ 2.2651e-02,  1.2308e-02, -2.6038e-02],
          [-8.5869e-03, -5.0105e-03,  1.9114e-02],
          [-2.9123e-02, -2.6504e-03, -2.4416e-02]]],


        ...,


        [[[ 1.1775e-02,  1.9122e-02,  2.8011e-02],
          [ 5.8104e-03, -2.1902e-02, -2.6422e-02],
          [ 2.6523e-02, -2.2277e-02,  2.3245e-02]],

         [[ 1.4312e-02,  1.8152e-02,  2.9162e-02],
          [-2.1804e-02, -1.2945e-02, -1.5047e-02],
          [-1.2972e-03,  1.7683e-02,  2.4115e-02]],

         [[ 2.1204e-03, -5.3647e-03, -1.6902e-02],
          [-8.1336e-03,  1.7296e-02,  2.3786e-02],
          [ 1.8862e-02,  1.3455e-02, -1.4665e-02]],

         ...,

         [[ 3.4951e-03, -5.6755e-03,  1.8545e-02],
          [ 2.7958e-02,  1.4488e-02, -9.5361e-03],
          [ 7.1615e-03, -4.5180e-03,  1.1090e-02]],

         [[ 1.1351e-02, -1.3737e-02,  2.3967e-02],
          [-3.8123e-03,  1.7016e-02, -4.6126e-03],
          [ 9.3697e-03, -9.8776e-03, -1.2629e-02]],

         [[-2.9353e-02, -2.4369e-02,  1.7385e-02],
          [ 6.1357e-03, -2.5430e-02,  3.4712e-03],
          [-5.9187e-03,  2.7827e-02,  6.4239e-03]]],


        [[[ 2.9224e-02, -1.8481e-02,  1.7762e-02],
          [ 4.8882e-03,  2.1918e-03, -5.4927e-03],
          [-1.1432e-02, -2.1387e-03, -2.5244e-03]],

         [[ 7.5577e-03, -2.4533e-03,  2.0422e-02],
          [-1.8961e-02,  2.6530e-02,  2.0998e-02],
          [-2.9217e-02,  7.7334e-03,  3.9284e-03]],

         [[ 8.4735e-03,  1.6426e-02, -1.3015e-02],
          [-2.6150e-03,  2.4259e-02,  2.9042e-02],
          [-2.6126e-02,  2.8892e-02,  2.4876e-03]],

         ...,

         [[-8.4156e-03, -1.9732e-02,  1.0396e-02],
          [-1.9039e-02,  1.2717e-02,  1.3854e-02],
          [ 2.7850e-02,  8.4072e-03, -1.8700e-02]],

         [[ 1.5330e-02, -2.8341e-03, -1.0034e-02],
          [-2.6899e-02, -2.8799e-02, -2.5962e-02],
          [-8.3609e-03,  2.1420e-02, -1.6651e-02]],

         [[-2.5213e-02, -2.1274e-02,  7.7778e-03],
          [-1.2425e-02,  5.0532e-03, -2.4222e-02],
          [ 1.1426e-02, -2.3393e-02,  1.6802e-02]]],


        [[[-1.1031e-02,  1.2506e-02, -2.5240e-02],
          [-1.5513e-02,  4.0995e-03, -1.7241e-02],
          [-2.4374e-02, -2.5310e-02, -3.0288e-03]],

         [[-1.3222e-02,  5.6685e-03,  1.3540e-02],
          [-1.5127e-02, -1.4086e-02,  1.3937e-02],
          [ 7.0224e-03,  1.1128e-02, -1.3478e-02]],

         [[-3.3983e-03,  9.8271e-03, -1.5246e-02],
          [ 2.6623e-02, -1.3041e-02,  1.2640e-02],
          [-5.6076e-03,  1.1469e-02,  2.4637e-02]],

         ...,

         [[-7.0413e-03, -2.8961e-02,  2.5619e-02],
          [ 2.1936e-02, -4.3300e-03, -1.9980e-02],
          [ 1.5612e-02, -3.3640e-03,  2.8432e-02]],

         [[ 2.5615e-02,  1.1388e-03, -1.8629e-02],
          [-3.3786e-03,  2.4850e-02,  2.6624e-02],
          [ 2.6544e-02, -2.7811e-02, -2.6018e-02]],

         [[-2.2589e-02,  1.1243e-02, -1.7334e-02],
          [-1.0106e-02, -1.4192e-02,  7.7515e-03],
          [-6.5047e-03,  2.8586e-02, -2.8278e-02]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[-2.4920e-02, -8.3494e-03,  2.6304e-02],
          [ 8.9767e-03, -2.8502e-02, -1.5565e-03],
          [-2.1893e-02,  8.0243e-04, -4.0647e-03]],

         [[ 2.4816e-02, -2.2081e-02, -1.5463e-02],
          [-2.5172e-02,  7.2438e-03,  2.9052e-02],
          [-1.0746e-02,  6.4857e-03, -4.6564e-03]],

         [[-6.5855e-03, -1.4794e-02, -7.6443e-03],
          [-3.5495e-03,  2.4543e-02,  3.4315e-03],
          [ 9.1402e-03, -1.6658e-02,  1.0003e-02]],

         ...,

         [[ 2.0640e-03, -2.6199e-02,  2.2306e-02],
          [ 2.3520e-02, -7.0268e-03,  1.2953e-02],
          [ 1.1984e-02, -1.5149e-02,  2.2729e-02]],

         [[-1.7215e-02,  5.3358e-03, -8.6513e-03],
          [-2.8366e-02, -2.4052e-02, -7.4373e-03],
          [ 2.6679e-02, -1.3849e-03, -2.8949e-02]],

         [[-1.7981e-02,  2.3839e-03,  2.7123e-02],
          [-4.9312e-03,  1.3224e-02, -1.3717e-02],
          [ 2.9041e-02, -6.8743e-03,  2.6992e-02]]],


        [[[-3.5097e-03,  2.5516e-02,  1.2979e-02],
          [-1.0213e-02, -4.4809e-03, -5.1935e-03],
          [ 2.9381e-02,  3.4079e-03,  2.3098e-02]],

         [[ 3.7397e-03, -1.4303e-02,  1.4708e-02],
          [-2.5776e-02,  2.7027e-03, -1.7492e-03],
          [-1.1808e-02, -2.7581e-02,  1.3922e-02]],

         [[ 8.0677e-03, -2.0276e-02, -2.8033e-02],
          [ 2.0285e-02, -1.4815e-02,  1.7570e-03],
          [ 1.9621e-02, -2.5453e-02, -5.4602e-03]],

         ...,

         [[ 2.1823e-02, -1.5105e-02, -1.4767e-02],
          [-2.4071e-02, -7.8013e-03, -1.1597e-02],
          [-9.0623e-03, -9.7497e-04, -2.8447e-03]],

         [[-2.4373e-02,  1.5872e-02, -1.8536e-02],
          [ 1.2310e-02,  1.8794e-02,  2.4844e-02],
          [-1.3369e-02, -2.2506e-02, -2.2743e-02]],

         [[-2.0090e-03,  5.1476e-03,  3.5750e-03],
          [ 1.4271e-02,  1.2384e-02,  7.1031e-03],
          [-1.4733e-03,  1.9467e-03,  2.5509e-02]]],


        [[[-1.2411e-02, -2.7071e-02,  2.4918e-02],
          [ 2.4782e-02,  2.6313e-02, -2.8324e-02],
          [-9.7078e-06, -1.4561e-02,  5.3616e-03]],

         [[ 9.0409e-03,  2.8524e-02, -2.2636e-02],
          [-2.7890e-02, -1.1642e-02, -1.1588e-03],
          [-1.7491e-02, -2.8665e-02,  3.4639e-03]],

         [[ 7.2966e-03, -2.2500e-02,  1.7863e-02],
          [ 2.1882e-02, -3.8861e-03, -1.0746e-02],
          [ 9.8841e-03,  2.7151e-02, -6.6589e-03]],

         ...,

         [[ 7.5755e-03,  1.3006e-02, -2.0798e-02],
          [-1.5046e-02,  8.5001e-03,  3.3313e-04],
          [-2.0268e-02, -1.6086e-02, -1.7531e-03]],

         [[-1.7518e-02, -2.6873e-02,  2.9340e-02],
          [ 2.5602e-02,  2.9389e-02,  2.8872e-03],
          [-6.3584e-03, -2.7602e-02, -1.1252e-02]],

         [[ 2.2651e-02,  1.2308e-02, -2.6038e-02],
          [-8.5869e-03, -5.0105e-03,  1.9114e-02],
          [-2.9123e-02, -2.6504e-03, -2.4416e-02]]],


        ...,


        [[[ 1.1775e-02,  1.9122e-02,  2.8011e-02],
          [ 5.8104e-03, -2.1902e-02, -2.6422e-02],
          [ 2.6523e-02, -2.2277e-02,  2.3245e-02]],

         [[ 1.4312e-02,  1.8152e-02,  2.9162e-02],
          [-2.1804e-02, -1.2945e-02, -1.5047e-02],
          [-1.2972e-03,  1.7683e-02,  2.4115e-02]],

         [[ 2.1204e-03, -5.3647e-03, -1.6902e-02],
          [-8.1336e-03,  1.7296e-02,  2.3786e-02],
          [ 1.8862e-02,  1.3455e-02, -1.4665e-02]],

         ...,

         [[ 3.4951e-03, -5.6755e-03,  1.8545e-02],
          [ 2.7958e-02,  1.4488e-02, -9.5361e-03],
          [ 7.1615e-03, -4.5180e-03,  1.1090e-02]],

         [[ 1.1351e-02, -1.3737e-02,  2.3967e-02],
          [-3.8123e-03,  1.7016e-02, -4.6126e-03],
          [ 9.3697e-03, -9.8776e-03, -1.2629e-02]],

         [[-2.9353e-02, -2.4369e-02,  1.7385e-02],
          [ 6.1357e-03, -2.5430e-02,  3.4712e-03],
          [-5.9187e-03,  2.7827e-02,  6.4239e-03]]],


        [[[ 2.9224e-02, -1.8481e-02,  1.7762e-02],
          [ 4.8882e-03,  2.1918e-03, -5.4927e-03],
          [-1.1432e-02, -2.1387e-03, -2.5244e-03]],

         [[ 7.5577e-03, -2.4533e-03,  2.0422e-02],
          [-1.8961e-02,  2.6530e-02,  2.0998e-02],
          [-2.9217e-02,  7.7334e-03,  3.9284e-03]],

         [[ 8.4735e-03,  1.6426e-02, -1.3015e-02],
          [-2.6150e-03,  2.4259e-02,  2.9042e-02],
          [-2.6126e-02,  2.8892e-02,  2.4876e-03]],

         ...,

         [[-8.4156e-03, -1.9732e-02,  1.0396e-02],
          [-1.9039e-02,  1.2717e-02,  1.3854e-02],
          [ 2.7850e-02,  8.4072e-03, -1.8700e-02]],

         [[ 1.5330e-02, -2.8341e-03, -1.0034e-02],
          [-2.6899e-02, -2.8799e-02, -2.5962e-02],
          [-8.3609e-03,  2.1420e-02, -1.6651e-02]],

         [[-2.5213e-02, -2.1274e-02,  7.7778e-03],
          [-1.2425e-02,  5.0532e-03, -2.4222e-02],
          [ 1.1426e-02, -2.3393e-02,  1.6802e-02]]],


        [[[-1.1031e-02,  1.2506e-02, -2.5240e-02],
          [-1.5513e-02,  4.0995e-03, -1.7241e-02],
          [-2.4374e-02, -2.5310e-02, -3.0288e-03]],

         [[-1.3222e-02,  5.6685e-03,  1.3540e-02],
          [-1.5127e-02, -1.4086e-02,  1.3937e-02],
          [ 7.0224e-03,  1.1128e-02, -1.3478e-02]],

         [[-3.3983e-03,  9.8271e-03, -1.5246e-02],
          [ 2.6623e-02, -1.3041e-02,  1.2640e-02],
          [-5.6076e-03,  1.1469e-02,  2.4637e-02]],

         ...,

         [[-7.0413e-03, -2.8961e-02,  2.5619e-02],
          [ 2.1936e-02, -4.3300e-03, -1.9980e-02],
          [ 1.5612e-02, -3.3640e-03,  2.8432e-02]],

         [[ 2.5615e-02,  1.1388e-03, -1.8629e-02],
          [-3.3786e-03,  2.4850e-02,  2.6624e-02],
          [ 2.6544e-02, -2.7811e-02, -2.6018e-02]],

         [[-2.2589e-02,  1.1243e-02, -1.7334e-02],
          [-1.0106e-02, -1.4192e-02,  7.7515e-03],
          [-6.5047e-03,  2.8586e-02, -2.8278e-02]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.bias 
 torch.Size([64]) 
 True 
 tensor([-0.0175,  0.0102, -0.0230, -0.0219, -0.0202, -0.0016, -0.0052, -0.0155,
        -0.0164, -0.0197, -0.0158,  0.0049,  0.0204, -0.0196,  0.0045,  0.0009,
        -0.0005,  0.0066, -0.0253,  0.0249,  0.0016,  0.0165, -0.0138, -0.0124,
         0.0171, -0.0154,  0.0067,  0.0088, -0.0172,  0.0160,  0.0194, -0.0264,
        -0.0204, -0.0234, -0.0200, -0.0134, -0.0261,  0.0252, -0.0146, -0.0083,
         0.0027, -0.0047, -0.0162,  0.0082, -0.0206,  0.0083,  0.0023,  0.0113,
        -0.0133, -0.0257,  0.0113,  0.0070,  0.0032,  0.0149, -0.0168,  0.0068,
        -0.0169, -0.0119,  0.0080,  0.0014, -0.0185,  0.0020, -0.0254, -0.0071],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0175,  0.0102, -0.0230, -0.0219, -0.0202, -0.0016, -0.0052, -0.0155,
        -0.0164, -0.0197, -0.0158,  0.0049,  0.0204, -0.0196,  0.0045,  0.0009,
        -0.0005,  0.0066, -0.0253,  0.0249,  0.0016,  0.0165, -0.0138, -0.0124,
         0.0171, -0.0154,  0.0067,  0.0088, -0.0172,  0.0160,  0.0194, -0.0264,
        -0.0204, -0.0234, -0.0200, -0.0134, -0.0261,  0.0252, -0.0146, -0.0083,
         0.0027, -0.0047, -0.0162,  0.0082, -0.0206,  0.0083,  0.0023,  0.0113,
        -0.0133, -0.0257,  0.0113,  0.0070,  0.0032,  0.0149, -0.0168,  0.0068,
        -0.0169, -0.0119,  0.0080,  0.0014, -0.0185,  0.0020, -0.0254, -0.0071],
       device='cuda:0', requires_grad=True)
parameters of the network fc1.weight 
 torch.Size([256, 667776]) 
 True 
 tensor([[-2.7981e-04,  4.6222e-04,  8.2343e-04,  ...,  9.5716e-04,
         -6.5943e-04, -7.1785e-04],
        [-7.7615e-04,  4.1314e-04,  3.7770e-04,  ..., -1.0324e-03,
         -9.2519e-04, -7.3603e-04],
        [ 3.3259e-04,  1.1810e-03,  3.8961e-04,  ...,  3.5367e-04,
          4.2199e-04,  2.8923e-04],
        ...,
        [ 6.6711e-04, -6.6501e-04,  3.1118e-04,  ..., -5.4418e-05,
          8.6085e-04,  1.5973e-04],
        [ 2.2807e-04, -9.5957e-04,  6.5461e-04,  ...,  1.0684e-03,
          1.0859e-03,  2.0802e-04],
        [ 3.4264e-04,  7.7734e-05,  6.1534e-04,  ..., -6.2139e-04,
          4.8889e-04,  7.4162e-04]], device='cuda:0') 
 Parameter containing:
tensor([[-2.7981e-04,  4.6222e-04,  8.2343e-04,  ...,  9.5716e-04,
         -6.5943e-04, -7.1785e-04],
        [-7.7615e-04,  4.1314e-04,  3.7770e-04,  ..., -1.0324e-03,
         -9.2519e-04, -7.3603e-04],
        [ 3.3259e-04,  1.1810e-03,  3.8961e-04,  ...,  3.5367e-04,
          4.2199e-04,  2.8923e-04],
        ...,
        [ 6.6711e-04, -6.6501e-04,  3.1118e-04,  ..., -5.4418e-05,
          8.6085e-04,  1.5973e-04],
        [ 2.2807e-04, -9.5957e-04,  6.5461e-04,  ...,  1.0684e-03,
          1.0859e-03,  2.0802e-04],
        [ 3.4264e-04,  7.7734e-05,  6.1534e-04,  ..., -6.2139e-04,
          4.8889e-04,  7.4162e-04]], device='cuda:0', requires_grad=True)
parameters of the network fc1.bias 
 torch.Size([256]) 
 True 
 tensor([ 6.1713e-04,  4.0125e-05,  4.6840e-04,  1.1606e-03, -4.1270e-04,
        -4.7591e-04,  1.6289e-04,  1.1189e-03, -7.0155e-04,  2.2801e-04,
        -4.5823e-04,  1.0545e-03, -1.0656e-03, -3.2905e-04, -8.8246e-04,
         1.0456e-03, -5.7185e-04, -4.9010e-04,  7.0999e-04, -1.1417e-03,
        -4.2988e-04,  3.0236e-04, -1.0862e-03, -7.3601e-04,  7.6377e-05,
        -6.9017e-04,  5.0288e-05, -7.9682e-04, -7.2137e-04, -7.5212e-04,
        -1.6198e-04, -1.8708e-04,  1.0306e-04,  2.2651e-04,  6.6503e-04,
        -1.0319e-03,  5.4800e-04,  1.1789e-03,  5.6878e-04, -5.4766e-04,
        -4.0980e-04, -7.6540e-04,  1.0249e-03,  1.2202e-03, -3.8059e-04,
         1.0179e-03,  1.0240e-03, -9.3503e-04,  1.1228e-03, -1.3382e-04,
        -4.3287e-04,  1.1728e-03,  1.1229e-03,  5.6693e-04, -6.7496e-04,
         7.6357e-04, -1.0564e-03,  3.0238e-04, -1.0735e-03, -1.1635e-03,
        -1.4915e-05, -1.1050e-03, -4.6053e-04,  8.8657e-04,  1.0341e-03,
        -9.9754e-04,  1.1750e-03, -4.9411e-04, -2.3729e-04, -6.5839e-04,
        -7.6845e-04,  5.2486e-04,  8.7116e-04,  1.1589e-03,  3.0834e-04,
         6.7564e-04, -8.4507e-04,  1.1731e-03, -1.1112e-03, -1.9520e-04,
         5.6330e-04, -3.4269e-04, -1.2103e-03,  1.1773e-03,  4.5802e-04,
         1.1819e-03, -8.5054e-05,  2.5718e-04, -4.9266e-04,  1.2211e-03,
        -5.6536e-04, -5.4450e-04, -8.8106e-04, -7.4396e-04,  9.3117e-04,
         9.8117e-04, -7.5614e-04, -1.1400e-03, -7.0875e-04,  1.1051e-03,
         7.6298e-04, -6.9962e-04, -1.2943e-04, -3.1101e-04,  1.0851e-03,
        -7.4113e-04, -9.8252e-04, -5.6361e-04,  1.1026e-03, -8.6428e-04,
         3.1314e-04,  2.0051e-04,  2.4336e-04,  7.7853e-04,  2.3284e-04,
         1.2012e-03,  8.8414e-04,  1.2005e-03,  6.8631e-05,  1.1787e-03,
        -2.2033e-04,  1.1223e-03, -7.7019e-05,  9.9474e-04, -1.1668e-03,
         8.9306e-04, -1.2032e-04, -4.3413e-04,  1.0235e-03, -9.0695e-04,
        -6.9845e-04,  6.8354e-04, -1.0166e-03, -1.1419e-03,  8.0369e-04,
         3.8502e-04,  6.6019e-05,  1.0296e-03, -4.7034e-04, -1.2036e-05,
         5.5529e-04,  8.6512e-04, -1.0809e-03,  8.2455e-05, -2.5442e-04,
         4.0823e-04,  7.0103e-04,  2.3142e-04,  4.0364e-04,  9.9712e-04,
         1.0552e-03,  4.6721e-04, -4.9858e-04, -8.4691e-04,  1.0949e-03,
         5.7322e-04,  1.0284e-03,  1.0236e-03,  1.0788e-03, -5.1646e-04,
         8.2082e-04,  1.1430e-03,  3.5254e-04, -3.2243e-05, -1.0033e-03,
         8.9920e-04, -1.0568e-03, -7.9076e-04, -9.3401e-04, -1.1554e-03,
        -4.7509e-04, -1.0109e-03, -3.3463e-04, -5.5433e-04,  2.1944e-04,
        -6.3119e-04, -1.1915e-03,  2.7447e-04, -8.8979e-04, -4.6563e-05,
         1.1308e-03,  8.8969e-04,  1.1509e-03, -9.1260e-04, -1.0380e-03,
        -1.1582e-03, -6.9249e-04, -7.2969e-04, -1.8594e-04, -1.0232e-03,
         4.8221e-04, -1.1394e-03, -4.4475e-04, -7.7697e-04,  3.6370e-04,
        -4.8560e-04, -5.5504e-04,  8.1375e-06, -5.1043e-04,  5.1089e-04,
        -4.1389e-04, -7.8442e-05,  8.8911e-04,  1.0197e-03,  8.2519e-04,
         1.9840e-04,  1.9980e-04,  9.3644e-04, -8.7316e-04,  1.0644e-03,
        -8.7671e-04,  1.0646e-03,  1.7299e-04,  9.6933e-04, -9.7397e-04,
         2.5256e-04,  3.1187e-04, -9.8159e-04,  1.1745e-03,  1.0009e-03,
         2.1245e-04, -7.8727e-04, -8.9921e-04, -1.1956e-04, -7.4747e-04,
        -6.0271e-04,  2.9568e-04, -1.2047e-03,  6.9909e-04,  8.4887e-04,
         5.9657e-05,  2.5524e-04, -3.5093e-04, -6.0787e-04, -2.6802e-04,
        -1.0992e-03, -1.0385e-03, -3.4905e-04, -9.3953e-04, -9.4002e-04,
        -2.0154e-04, -7.0210e-05,  4.7178e-05,  1.1294e-03,  6.5122e-04,
        -6.7561e-04,  1.1107e-03, -6.5898e-04, -1.0690e-03, -3.5504e-04,
         4.0603e-04, -3.2846e-04,  9.5819e-04, -5.1690e-04, -4.1640e-04,
        -1.1214e-03], device='cuda:0') 
 Parameter containing:
tensor([ 6.1713e-04,  4.0125e-05,  4.6840e-04,  1.1606e-03, -4.1270e-04,
        -4.7591e-04,  1.6289e-04,  1.1189e-03, -7.0155e-04,  2.2801e-04,
        -4.5823e-04,  1.0545e-03, -1.0656e-03, -3.2905e-04, -8.8246e-04,
         1.0456e-03, -5.7185e-04, -4.9010e-04,  7.0999e-04, -1.1417e-03,
        -4.2988e-04,  3.0236e-04, -1.0862e-03, -7.3601e-04,  7.6377e-05,
        -6.9017e-04,  5.0288e-05, -7.9682e-04, -7.2137e-04, -7.5212e-04,
        -1.6198e-04, -1.8708e-04,  1.0306e-04,  2.2651e-04,  6.6503e-04,
        -1.0319e-03,  5.4800e-04,  1.1789e-03,  5.6878e-04, -5.4766e-04,
        -4.0980e-04, -7.6540e-04,  1.0249e-03,  1.2202e-03, -3.8059e-04,
         1.0179e-03,  1.0240e-03, -9.3503e-04,  1.1228e-03, -1.3382e-04,
        -4.3287e-04,  1.1728e-03,  1.1229e-03,  5.6693e-04, -6.7496e-04,
         7.6357e-04, -1.0564e-03,  3.0238e-04, -1.0735e-03, -1.1635e-03,
        -1.4915e-05, -1.1050e-03, -4.6053e-04,  8.8657e-04,  1.0341e-03,
        -9.9754e-04,  1.1750e-03, -4.9411e-04, -2.3729e-04, -6.5839e-04,
        -7.6845e-04,  5.2486e-04,  8.7116e-04,  1.1589e-03,  3.0834e-04,
         6.7564e-04, -8.4507e-04,  1.1731e-03, -1.1112e-03, -1.9520e-04,
         5.6330e-04, -3.4269e-04, -1.2103e-03,  1.1773e-03,  4.5802e-04,
         1.1819e-03, -8.5054e-05,  2.5718e-04, -4.9266e-04,  1.2211e-03,
        -5.6536e-04, -5.4450e-04, -8.8106e-04, -7.4396e-04,  9.3117e-04,
         9.8117e-04, -7.5614e-04, -1.1400e-03, -7.0875e-04,  1.1051e-03,
         7.6298e-04, -6.9962e-04, -1.2943e-04, -3.1101e-04,  1.0851e-03,
        -7.4113e-04, -9.8252e-04, -5.6361e-04,  1.1026e-03, -8.6428e-04,
         3.1314e-04,  2.0051e-04,  2.4336e-04,  7.7853e-04,  2.3284e-04,
         1.2012e-03,  8.8414e-04,  1.2005e-03,  6.8631e-05,  1.1787e-03,
        -2.2033e-04,  1.1223e-03, -7.7019e-05,  9.9474e-04, -1.1668e-03,
         8.9306e-04, -1.2032e-04, -4.3413e-04,  1.0235e-03, -9.0695e-04,
        -6.9845e-04,  6.8354e-04, -1.0166e-03, -1.1419e-03,  8.0369e-04,
         3.8502e-04,  6.6019e-05,  1.0296e-03, -4.7034e-04, -1.2036e-05,
         5.5529e-04,  8.6512e-04, -1.0809e-03,  8.2455e-05, -2.5442e-04,
         4.0823e-04,  7.0103e-04,  2.3142e-04,  4.0364e-04,  9.9712e-04,
         1.0552e-03,  4.6721e-04, -4.9858e-04, -8.4691e-04,  1.0949e-03,
         5.7322e-04,  1.0284e-03,  1.0236e-03,  1.0788e-03, -5.1646e-04,
         8.2082e-04,  1.1430e-03,  3.5254e-04, -3.2243e-05, -1.0033e-03,
         8.9920e-04, -1.0568e-03, -7.9076e-04, -9.3401e-04, -1.1554e-03,
        -4.7509e-04, -1.0109e-03, -3.3463e-04, -5.5433e-04,  2.1944e-04,
        -6.3119e-04, -1.1915e-03,  2.7447e-04, -8.8979e-04, -4.6563e-05,
         1.1308e-03,  8.8969e-04,  1.1509e-03, -9.1260e-04, -1.0380e-03,
        -1.1582e-03, -6.9249e-04, -7.2969e-04, -1.8594e-04, -1.0232e-03,
         4.8221e-04, -1.1394e-03, -4.4475e-04, -7.7697e-04,  3.6370e-04,
        -4.8560e-04, -5.5504e-04,  8.1375e-06, -5.1043e-04,  5.1089e-04,
        -4.1389e-04, -7.8442e-05,  8.8911e-04,  1.0197e-03,  8.2519e-04,
         1.9840e-04,  1.9980e-04,  9.3644e-04, -8.7316e-04,  1.0644e-03,
        -8.7671e-04,  1.0646e-03,  1.7299e-04,  9.6933e-04, -9.7397e-04,
         2.5256e-04,  3.1187e-04, -9.8159e-04,  1.1745e-03,  1.0009e-03,
         2.1245e-04, -7.8727e-04, -8.9921e-04, -1.1956e-04, -7.4747e-04,
        -6.0271e-04,  2.9568e-04, -1.2047e-03,  6.9909e-04,  8.4887e-04,
         5.9657e-05,  2.5524e-04, -3.5093e-04, -6.0787e-04, -2.6802e-04,
        -1.0992e-03, -1.0385e-03, -3.4905e-04, -9.3953e-04, -9.4002e-04,
        -2.0154e-04, -7.0210e-05,  4.7178e-05,  1.1294e-03,  6.5122e-04,
        -6.7561e-04,  1.1107e-03, -6.5898e-04, -1.0690e-03, -3.5504e-04,
         4.0603e-04, -3.2846e-04,  9.5819e-04, -5.1690e-04, -4.1640e-04,
        -1.1214e-03], device='cuda:0', requires_grad=True)
parameters of the network fc2.weight 
 torch.Size([128, 256]) 
 True 
 tensor([[-0.0216, -0.0165,  0.0545,  ...,  0.0192, -0.0132,  0.0258],
        [ 0.0429,  0.0013,  0.0495,  ...,  0.0437,  0.0500,  0.0610],
        [ 0.0246,  0.0377,  0.0403,  ...,  0.0464,  0.0463, -0.0586],
        ...,
        [ 0.0035,  0.0506,  0.0036,  ...,  0.0079, -0.0468,  0.0426],
        [ 0.0049,  0.0422, -0.0514,  ..., -0.0029, -0.0035, -0.0556],
        [ 0.0455, -0.0344, -0.0108,  ..., -0.0012,  0.0041, -0.0430]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0216, -0.0165,  0.0545,  ...,  0.0192, -0.0132,  0.0258],
        [ 0.0429,  0.0013,  0.0495,  ...,  0.0437,  0.0500,  0.0610],
        [ 0.0246,  0.0377,  0.0403,  ...,  0.0464,  0.0463, -0.0586],
        ...,
        [ 0.0035,  0.0506,  0.0036,  ...,  0.0079, -0.0468,  0.0426],
        [ 0.0049,  0.0422, -0.0514,  ..., -0.0029, -0.0035, -0.0556],
        [ 0.0455, -0.0344, -0.0108,  ..., -0.0012,  0.0041, -0.0430]],
       device='cuda:0', requires_grad=True)
parameters of the network fc2.bias 
 torch.Size([128]) 
 True 
 tensor([-0.0372, -0.0291,  0.0101, -0.0418,  0.0604,  0.0161, -0.0318,  0.0329,
         0.0361,  0.0189,  0.0144,  0.0541,  0.0097,  0.0199,  0.0487,  0.0506,
        -0.0082, -0.0191,  0.0337,  0.0431, -0.0220, -0.0010,  0.0600,  0.0311,
        -0.0334,  0.0329, -0.0590, -0.0066,  0.0359,  0.0115,  0.0530, -0.0358,
         0.0321,  0.0462,  0.0414,  0.0425, -0.0173,  0.0070,  0.0431, -0.0457,
         0.0020,  0.0104,  0.0062,  0.0191, -0.0196, -0.0060, -0.0443,  0.0012,
        -0.0451,  0.0126,  0.0470,  0.0374, -0.0309, -0.0290,  0.0064, -0.0281,
         0.0504, -0.0423, -0.0169,  0.0456, -0.0371, -0.0098,  0.0464, -0.0228,
        -0.0480,  0.0447, -0.0326, -0.0145,  0.0285, -0.0314,  0.0065,  0.0426,
        -0.0154,  0.0578, -0.0415, -0.0091, -0.0259, -0.0582,  0.0604, -0.0080,
        -0.0475,  0.0615,  0.0499,  0.0606, -0.0038, -0.0165,  0.0154,  0.0204,
         0.0400, -0.0345,  0.0572,  0.0444, -0.0529,  0.0551,  0.0180,  0.0127,
        -0.0089,  0.0268, -0.0312, -0.0243,  0.0315,  0.0322, -0.0407,  0.0057,
        -0.0349,  0.0384, -0.0390,  0.0284,  0.0502, -0.0123,  0.0273,  0.0150,
         0.0544,  0.0462, -0.0536,  0.0430, -0.0579, -0.0148,  0.0494,  0.0119,
         0.0511,  0.0272,  0.0022, -0.0105,  0.0509, -0.0479, -0.0204, -0.0007],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0372, -0.0291,  0.0101, -0.0418,  0.0604,  0.0161, -0.0318,  0.0329,
         0.0361,  0.0189,  0.0144,  0.0541,  0.0097,  0.0199,  0.0487,  0.0506,
        -0.0082, -0.0191,  0.0337,  0.0431, -0.0220, -0.0010,  0.0600,  0.0311,
        -0.0334,  0.0329, -0.0590, -0.0066,  0.0359,  0.0115,  0.0530, -0.0358,
         0.0321,  0.0462,  0.0414,  0.0425, -0.0173,  0.0070,  0.0431, -0.0457,
         0.0020,  0.0104,  0.0062,  0.0191, -0.0196, -0.0060, -0.0443,  0.0012,
        -0.0451,  0.0126,  0.0470,  0.0374, -0.0309, -0.0290,  0.0064, -0.0281,
         0.0504, -0.0423, -0.0169,  0.0456, -0.0371, -0.0098,  0.0464, -0.0228,
        -0.0480,  0.0447, -0.0326, -0.0145,  0.0285, -0.0314,  0.0065,  0.0426,
        -0.0154,  0.0578, -0.0415, -0.0091, -0.0259, -0.0582,  0.0604, -0.0080,
        -0.0475,  0.0615,  0.0499,  0.0606, -0.0038, -0.0165,  0.0154,  0.0204,
         0.0400, -0.0345,  0.0572,  0.0444, -0.0529,  0.0551,  0.0180,  0.0127,
        -0.0089,  0.0268, -0.0312, -0.0243,  0.0315,  0.0322, -0.0407,  0.0057,
        -0.0349,  0.0384, -0.0390,  0.0284,  0.0502, -0.0123,  0.0273,  0.0150,
         0.0544,  0.0462, -0.0536,  0.0430, -0.0579, -0.0148,  0.0494,  0.0119,
         0.0511,  0.0272,  0.0022, -0.0105,  0.0509, -0.0479, -0.0204, -0.0007],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.weight 
 torch.Size([64, 128]) 
 True 
 tensor([[-0.0321, -0.0327, -0.0368,  ..., -0.0814, -0.0055,  0.0428],
        [ 0.0533, -0.0522,  0.0685,  ..., -0.0384,  0.0846,  0.0743],
        [ 0.0276, -0.0697, -0.0388,  ..., -0.0191,  0.0596,  0.0847],
        ...,
        [-0.0175, -0.0713, -0.0725,  ...,  0.0650, -0.0764, -0.0110],
        [ 0.0623, -0.0229, -0.0244,  ..., -0.0629,  0.0759,  0.0252],
        [ 0.0303,  0.0860, -0.0487,  ...,  0.0227, -0.0071,  0.0189]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0321, -0.0327, -0.0368,  ..., -0.0814, -0.0055,  0.0428],
        [ 0.0533, -0.0522,  0.0685,  ..., -0.0384,  0.0846,  0.0743],
        [ 0.0276, -0.0697, -0.0388,  ..., -0.0191,  0.0596,  0.0847],
        ...,
        [-0.0175, -0.0713, -0.0725,  ...,  0.0650, -0.0764, -0.0110],
        [ 0.0623, -0.0229, -0.0244,  ..., -0.0629,  0.0759,  0.0252],
        [ 0.0303,  0.0860, -0.0487,  ...,  0.0227, -0.0071,  0.0189]],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.bias 
 torch.Size([64]) 
 True 
 tensor([ 0.0162, -0.0749,  0.0525,  0.0361, -0.0835,  0.0028, -0.0596, -0.0409,
         0.0608,  0.0340,  0.0255, -0.0167, -0.0064, -0.0743, -0.0595,  0.0378,
         0.0824, -0.0324, -0.0155,  0.0149, -0.0502,  0.0291, -0.0730,  0.0686,
        -0.0260,  0.0734,  0.0666,  0.0291,  0.0542, -0.0329,  0.0651, -0.0817,
        -0.0374, -0.0613, -0.0522, -0.0575, -0.0020, -0.0532,  0.0303,  0.0803,
         0.0764,  0.0567, -0.0237,  0.0488,  0.0055, -0.0319,  0.0339, -0.0295,
         0.0378,  0.0188,  0.0117, -0.0845, -0.0458, -0.0868, -0.0733,  0.0205,
        -0.0624, -0.0014, -0.0692, -0.0696, -0.0860, -0.0012, -0.0206,  0.0413],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0162, -0.0749,  0.0525,  0.0361, -0.0835,  0.0028, -0.0596, -0.0409,
         0.0608,  0.0340,  0.0255, -0.0167, -0.0064, -0.0743, -0.0595,  0.0378,
         0.0824, -0.0324, -0.0155,  0.0149, -0.0502,  0.0291, -0.0730,  0.0686,
        -0.0260,  0.0734,  0.0666,  0.0291,  0.0542, -0.0329,  0.0651, -0.0817,
        -0.0374, -0.0613, -0.0522, -0.0575, -0.0020, -0.0532,  0.0303,  0.0803,
         0.0764,  0.0567, -0.0237,  0.0488,  0.0055, -0.0319,  0.0339, -0.0295,
         0.0378,  0.0188,  0.0117, -0.0845, -0.0458, -0.0868, -0.0733,  0.0205,
        -0.0624, -0.0014, -0.0692, -0.0696, -0.0860, -0.0012, -0.0206,  0.0413],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.weight 
 torch.Size([6796, 64]) 
 True 
 tensor([[ 0.0161, -0.1100,  0.1234,  ..., -0.0591,  0.0389, -0.0647],
        [-0.0096, -0.0092, -0.1096,  ...,  0.0762,  0.0037, -0.0914],
        [ 0.0910, -0.0686,  0.0947,  ...,  0.0038, -0.0075, -0.0077],
        ...,
        [ 0.0648, -0.1238, -0.1052,  ...,  0.0567, -0.0704,  0.0340],
        [-0.0905, -0.0440, -0.1197,  ...,  0.0837, -0.0190, -0.0217],
        [ 0.0119, -0.0097, -0.0601,  ...,  0.0579, -0.1100, -0.0269]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0161, -0.1100,  0.1234,  ..., -0.0591,  0.0389, -0.0647],
        [-0.0096, -0.0092, -0.1096,  ...,  0.0762,  0.0037, -0.0914],
        [ 0.0910, -0.0686,  0.0947,  ...,  0.0038, -0.0075, -0.0077],
        ...,
        [ 0.0648, -0.1238, -0.1052,  ...,  0.0567, -0.0704,  0.0340],
        [-0.0905, -0.0440, -0.1197,  ...,  0.0837, -0.0190, -0.0217],
        [ 0.0119, -0.0097, -0.0601,  ...,  0.0579, -0.1100, -0.0269]],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.bias 
 torch.Size([6796]) 
 True 
 tensor([ 0.0387,  0.0304,  0.0152,  ..., -0.1057,  0.0169, -0.0226],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0387,  0.0304,  0.0152,  ..., -0.1057,  0.0169, -0.0226],
       device='cuda:0', requires_grad=True)

Passing event 1007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([[ 0.0525,  0.0278,  0.0312,  ..., -0.1299,  0.0307, -0.0053],
        [ 0.0526,  0.0276,  0.0313,  ..., -0.1299,  0.0307, -0.0052],
        [ 0.0525,  0.0277,  0.0313,  ..., -0.1299,  0.0307, -0.0051],
        ...,
        [ 0.0526,  0.0277,  0.0314,  ..., -0.1300,  0.0307, -0.0053],
        [ 0.0527,  0.0274,  0.0314,  ..., -0.1299,  0.0307, -0.0054],
        [ 0.0523,  0.0278,  0.0315,  ..., -0.1296,  0.0309, -0.0053]],
       device='cuda:0', grad_fn=<AddmmBackward0>) 
result1.shape: torch.Size([20, 6796])

Passing two random events from the network before training 
result1: tensor([[ 0.0525,  0.0278,  0.0312,  ..., -0.1299,  0.0307, -0.0053],
        [ 0.0526,  0.0276,  0.0313,  ..., -0.1299,  0.0307, -0.0052],
        [ 0.0525,  0.0277,  0.0313,  ..., -0.1299,  0.0307, -0.0051],
        ...,
        [ 0.0526,  0.0277,  0.0314,  ..., -0.1300,  0.0307, -0.0053],
        [ 0.0527,  0.0274,  0.0314,  ..., -0.1299,  0.0307, -0.0054],
        [ 0.0523,  0.0278,  0.0315,  ..., -0.1296,  0.0309, -0.0053]],
       device='cuda:0', grad_fn=<AddmmBackward0>) 
result1.shape: torch.Size([20, 6796]) 
input: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]



load_model False 
TraEvN 10008 
BatchSize 30 
EpochNum 30 
epoch_save 5 
LrVal 0.001 
weight_decay 0.0001 
startmesh 305 
endmesh 306 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[[[ 0.3129, -0.2885,  0.0656],
          [ 0.2580, -0.1279, -0.2082],
          [ 0.1556,  0.2825,  0.3051]]],


        [[[ 0.1487,  0.1102,  0.2609],
          [-0.2534,  0.0374,  0.0210],
          [ 0.0970, -0.1092,  0.2126]]],


        [[[-0.2969,  0.2453, -0.1986],
          [ 0.2558, -0.2782,  0.3274],
          [-0.0891,  0.1049, -0.0472]]],


        ...,


        [[[-0.1653, -0.2331,  0.2812],
          [-0.1462, -0.2053, -0.1415],
          [-0.1826,  0.3090,  0.0105]]],


        [[[-0.0824,  0.0784, -0.1888],
          [-0.2260,  0.0503, -0.2077],
          [ 0.0791, -0.2147,  0.1157]]],


        [[[-0.2646, -0.1032, -0.2132],
          [-0.2699, -0.0290, -0.1747],
          [-0.3030,  0.1307,  0.3131]]]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.1767,  0.0627, -0.2130,  0.1982,  0.2295, -0.3250,  0.2442,  0.2183,
        -0.3247, -0.1058,  0.2110,  0.1045, -0.1193,  0.0822,  0.3307, -0.0602,
        -0.0071, -0.1507,  0.1902, -0.1241,  0.2717, -0.1302,  0.3318,  0.1037,
         0.1725,  0.2832, -0.0190,  0.3273,  0.1878, -0.0177,  0.0146,  0.0872,
        -0.1978,  0.2526, -0.2097, -0.1758,  0.1084,  0.0066,  0.0280,  0.0689,
        -0.2242, -0.0169,  0.2568,  0.2065,  0.1934, -0.2311,  0.0915, -0.0853,
        -0.1976,  0.0650,  0.0974,  0.1705, -0.3265, -0.0615,  0.3036,  0.1969,
        -0.3254, -0.2068,  0.1048,  0.1944, -0.0796,  0.2937, -0.1855, -0.0446,
         0.1111,  0.0417,  0.1960, -0.0456,  0.2097, -0.1589,  0.3202,  0.0360,
         0.0105,  0.2339, -0.3325, -0.2906,  0.2491,  0.2044, -0.3289,  0.0269,
         0.2542,  0.2114,  0.3295,  0.1740,  0.3210,  0.1454, -0.3320, -0.3272,
         0.1603, -0.1385, -0.3003,  0.1479, -0.1769,  0.0190, -0.0914,  0.3157,
        -0.2243, -0.2674,  0.2012,  0.2529, -0.0296, -0.1451,  0.1487, -0.1288,
         0.1947,  0.3015,  0.0238, -0.1244, -0.0541, -0.0189,  0.1240, -0.2449,
         0.1848,  0.0652,  0.2821, -0.2178,  0.1717,  0.0665, -0.2911, -0.1870,
         0.0756, -0.2837, -0.1105, -0.1341, -0.0914, -0.0148, -0.1856, -0.0801,
         0.2814, -0.3121,  0.3143, -0.1410, -0.2391,  0.0885,  0.1062,  0.2465,
        -0.2077,  0.0361,  0.3162, -0.2295, -0.1674, -0.2464, -0.3218,  0.1236,
        -0.0837,  0.2134, -0.2885,  0.2510,  0.3257, -0.0952, -0.0549,  0.0538,
        -0.1342,  0.1417,  0.1939, -0.2808,  0.0738, -0.1913, -0.0641, -0.1219,
        -0.1733,  0.2684, -0.1113, -0.1254, -0.1180, -0.2393, -0.0529, -0.2386,
        -0.3033,  0.1657,  0.0151, -0.2090, -0.1358, -0.1437, -0.1299,  0.0049,
        -0.0690,  0.2334, -0.1828, -0.2622, -0.2328,  0.1214,  0.2600,  0.1397,
         0.0819,  0.0100,  0.0092,  0.0139, -0.0584,  0.3070,  0.2886,  0.1482,
        -0.0636, -0.2537, -0.2193,  0.2425,  0.0939, -0.1055, -0.0766, -0.2937,
         0.2135, -0.2276, -0.0413,  0.1901, -0.0517,  0.0738,  0.2327,  0.0050,
         0.0780, -0.1210, -0.2051,  0.0286,  0.2760, -0.0618, -0.2447,  0.0894,
         0.2388, -0.2524,  0.0351,  0.1228, -0.3313, -0.1054, -0.3091, -0.1851,
        -0.0284, -0.2792, -0.2071, -0.1339, -0.2733, -0.3152,  0.1137, -0.1305,
        -0.0851,  0.2541, -0.0962,  0.0607,  0.2723, -0.3296, -0.2892,  0.2117,
         0.1254,  0.0772,  0.0410, -0.1825,  0.0620, -0.2212,  0.0965,  0.2243,
         0.2195, -0.2346, -0.2423, -0.1405, -0.2053,  0.0567,  0.1308,  0.1242],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[ 5.6303e-03,  3.5354e-03,  5.7323e-03],
          [ 1.6418e-02, -6.4130e-03, -1.4426e-02],
          [ 1.4839e-02,  1.4297e-02,  2.0228e-05]],

         [[-1.9752e-02,  7.7885e-03,  1.7548e-02],
          [-2.0621e-02,  1.6617e-02, -2.3232e-03],
          [ 1.8688e-02,  1.6164e-02,  8.7311e-03]],

         [[-1.5555e-02, -1.7436e-02, -6.0463e-04],
          [ 1.7197e-02, -1.6258e-02,  1.2700e-02],
          [ 2.0646e-02, -3.0825e-03,  1.5890e-03]],

         ...,

         [[ 1.4617e-02, -9.5248e-03, -1.9759e-03],
          [ 7.3266e-03,  9.0351e-03, -1.3683e-02],
          [ 1.4651e-02,  1.1025e-02, -7.0569e-03]],

         [[ 3.1352e-03, -1.5400e-02,  3.5097e-03],
          [ 1.5712e-02, -1.1509e-02,  1.9968e-02],
          [ 1.2902e-02,  1.9542e-02, -4.0946e-03]],

         [[-1.4172e-02,  5.6560e-03, -2.0739e-02],
          [-2.0198e-02,  2.0439e-02,  6.5740e-03],
          [-1.5758e-03,  1.6841e-02,  1.8854e-02]]],


        [[[ 1.3540e-03, -3.3472e-03,  1.4615e-02],
          [-2.0364e-02,  4.6075e-03, -1.3804e-02],
          [-4.4612e-03,  1.8322e-02,  1.9669e-02]],

         [[-1.9898e-02,  1.8913e-03,  1.9455e-02],
          [-1.9898e-02,  1.5815e-02,  3.9913e-03],
          [ 7.5213e-03, -8.0218e-03, -6.0923e-03]],

         [[ 6.8261e-03, -8.4190e-03, -1.3921e-02],
          [-8.1240e-03,  1.5488e-02, -7.2429e-03],
          [-1.8481e-03,  9.1329e-03, -1.8603e-02]],

         ...,

         [[-2.8494e-03,  8.5613e-03,  8.8518e-03],
          [-7.0075e-03,  1.2683e-02, -1.4643e-02],
          [-1.5749e-02, -2.9623e-03, -2.0428e-02]],

         [[-1.5620e-02,  9.0172e-03, -6.2789e-03],
          [ 1.3451e-02,  1.5227e-02,  1.6359e-02],
          [ 1.0850e-02, -1.3990e-02,  6.5632e-03]],

         [[-4.9801e-03, -1.2397e-02, -1.8239e-02],
          [ 1.4276e-02,  8.6565e-03,  1.0555e-02],
          [-2.3118e-03,  8.1796e-03, -1.4146e-03]]],


        [[[ 2.0490e-02, -2.2547e-03,  7.3374e-03],
          [-1.7445e-02,  7.8550e-03, -8.8512e-03],
          [-9.1433e-03,  2.5977e-03, -1.3290e-02]],

         [[-1.5516e-02,  2.5586e-04, -5.7135e-03],
          [-1.6320e-02, -1.5780e-02, -1.9644e-02],
          [-1.0518e-02,  7.0403e-03, -1.1263e-02]],

         [[ 2.0590e-02, -9.5940e-03, -1.7574e-02],
          [ 1.6599e-02,  7.0224e-03, -8.0341e-03],
          [ 3.5135e-03, -1.3966e-03, -3.3470e-04]],

         ...,

         [[ 8.7496e-03,  1.9801e-03,  1.2289e-02],
          [-1.4465e-02, -5.8790e-03, -1.6913e-02],
          [ 5.6468e-04, -1.9806e-02, -5.4762e-03]],

         [[-1.4564e-03,  1.9271e-02,  1.9554e-03],
          [ 9.6824e-03, -1.3347e-02,  1.6524e-03],
          [ 1.4491e-02,  1.3251e-02,  1.5668e-02]],

         [[ 6.4438e-03,  1.1861e-03,  1.7804e-02],
          [-1.7333e-02,  8.1064e-03, -8.5991e-03],
          [ 1.4474e-02, -2.0812e-02,  8.5236e-03]]],


        ...,


        [[[-1.7177e-02,  5.2304e-03,  1.1418e-02],
          [ 1.1249e-02,  8.9096e-03,  1.4745e-03],
          [ 1.6902e-03,  9.8755e-03, -1.4320e-02]],

         [[ 1.1407e-03, -8.2634e-03, -1.0860e-02],
          [ 1.9013e-02,  2.0283e-02, -1.4225e-02],
          [-2.5249e-03, -1.1592e-02,  1.5500e-02]],

         [[ 2.0822e-02,  2.0287e-02,  7.2269e-03],
          [ 1.1749e-02,  1.3769e-02, -4.9773e-03],
          [ 1.3071e-02, -9.2361e-03, -8.3839e-03]],

         ...,

         [[ 1.8720e-02,  2.5220e-04, -1.6399e-02],
          [ 1.2159e-02,  1.0991e-03,  6.1120e-03],
          [-1.7150e-02,  4.7642e-03,  1.2067e-02]],

         [[ 1.8120e-02, -4.7455e-03,  1.5362e-02],
          [ 3.6156e-03,  1.5223e-02, -1.5470e-02],
          [ 1.1558e-02,  1.4388e-02, -1.4604e-02]],

         [[-1.0203e-02, -2.0505e-03, -1.8828e-02],
          [ 5.0696e-03,  1.8876e-02, -1.0560e-02],
          [-9.9183e-04, -1.0989e-03,  3.6235e-04]]],


        [[[ 2.6896e-03, -3.8696e-03,  6.5818e-03],
          [-1.1843e-02,  1.8020e-02, -6.1127e-04],
          [ 1.9572e-02,  8.2735e-03,  1.4990e-02]],

         [[-2.0390e-04,  1.2978e-02, -9.7646e-03],
          [-1.1748e-02,  8.6689e-03,  8.9062e-03],
          [-3.4595e-03, -1.0561e-02,  6.9155e-03]],

         [[ 1.5320e-02, -1.1527e-02, -7.9798e-03],
          [ 7.8623e-03, -1.2457e-02, -1.0651e-02],
          [ 7.4512e-03, -8.4165e-03, -1.3482e-02]],

         ...,

         [[-1.2215e-03,  2.1670e-03,  9.8158e-03],
          [ 3.8258e-03, -8.1640e-03,  4.7181e-03],
          [-5.6130e-03,  8.0696e-03, -1.9440e-02]],

         [[-1.3208e-02, -8.1883e-03,  2.0979e-03],
          [ 1.9636e-02,  3.7386e-03,  1.9061e-02],
          [-2.0421e-02, -1.0976e-03,  1.3090e-02]],

         [[ 1.2750e-02,  4.1809e-03,  1.6264e-02],
          [ 5.0563e-03,  1.2823e-02, -1.3153e-02],
          [ 1.8328e-02, -1.6222e-02, -1.4266e-02]]],


        [[[ 1.2117e-02, -7.9300e-03,  2.0046e-02],
          [-1.5920e-02, -1.2682e-02, -6.8356e-03],
          [-1.4756e-02, -1.5922e-02,  1.5526e-02]],

         [[-7.6641e-03,  9.0006e-05, -1.2120e-02],
          [ 1.6956e-02,  5.2447e-03, -1.3075e-02],
          [-8.0757e-03, -9.3682e-03, -2.3438e-03]],

         [[-1.2846e-02,  6.2280e-03, -2.0528e-02],
          [-8.1270e-03, -2.0381e-03, -1.2743e-02],
          [ 1.3536e-02, -1.5415e-02,  5.4172e-03]],

         ...,

         [[ 1.9611e-02, -5.5070e-03,  3.0335e-03],
          [ 1.0419e-02, -6.8077e-03, -1.3399e-02],
          [ 1.1735e-02, -1.1150e-02, -1.3266e-02]],

         [[ 1.9204e-02, -1.3937e-02,  1.9788e-02],
          [-1.8052e-02,  1.0332e-02,  5.0269e-03],
          [ 7.4378e-03, -1.6509e-02,  1.4473e-02]],

         [[ 7.2617e-03,  9.2860e-03,  9.8883e-04],
          [-1.3246e-02,  1.9339e-02, -1.3767e-02],
          [ 1.7816e-02,  5.1444e-03, -7.5935e-03]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([ 8.1115e-03,  1.8515e-02, -1.4618e-03,  1.4796e-02, -1.0113e-02,
        -1.2103e-02,  1.2086e-02, -1.7365e-03, -1.0299e-03, -1.8343e-02,
         6.0407e-04, -2.0399e-02, -1.6576e-02, -3.3806e-03,  1.2277e-02,
        -1.4746e-02,  1.9115e-02, -1.5854e-02,  7.0682e-03,  1.7003e-02,
         1.6486e-02,  3.6418e-03,  1.2305e-02,  1.8542e-02,  4.4404e-03,
        -1.7533e-02,  3.7615e-03,  8.7416e-03, -1.1948e-02,  5.8874e-03,
        -1.3342e-02, -6.9386e-03,  4.4313e-03,  1.6345e-02,  1.7104e-02,
        -8.6520e-03, -5.9965e-03,  1.4802e-02, -1.1230e-02, -1.2628e-02,
         1.9291e-02, -1.1672e-02,  1.2193e-02,  1.1439e-03, -4.4692e-04,
         1.1806e-02,  1.4172e-02,  3.3166e-03,  4.6098e-03,  1.6863e-02,
         1.3679e-02, -2.0576e-03,  7.4542e-04, -9.1319e-04,  1.0864e-04,
         8.3799e-04, -7.3396e-03, -9.1375e-03,  1.7259e-02,  1.1018e-02,
         5.5725e-03, -3.8412e-03,  1.0486e-02, -1.1778e-02,  1.1492e-02,
        -2.3041e-03,  1.0176e-02,  1.8861e-02, -1.2498e-02,  8.1997e-03,
         1.8269e-02,  1.7416e-02,  3.8098e-04,  8.3362e-03,  1.5670e-02,
        -8.6106e-03,  2.0148e-02,  1.2096e-02,  1.9227e-03,  1.2011e-02,
         1.0292e-02, -1.2383e-02,  1.8003e-02,  1.6280e-02,  1.6002e-03,
         1.0521e-02, -1.3559e-02, -7.9527e-03,  1.8492e-02, -1.2035e-03,
        -8.4903e-03, -1.9103e-02,  1.9198e-02, -2.0975e-03, -1.6507e-03,
         7.6283e-03, -3.4503e-03,  5.0924e-03,  1.6698e-02, -2.7426e-03,
         4.3503e-03,  6.1627e-03,  5.0217e-05,  1.5545e-02, -1.8023e-02,
        -4.0500e-03,  1.4399e-02, -4.8925e-03,  6.2630e-03, -1.7338e-02,
         2.7936e-04, -1.3428e-02, -4.8556e-03,  1.8882e-02, -5.6148e-04,
         5.4209e-03,  1.4877e-02, -5.5442e-03,  1.9790e-02,  9.5492e-03,
         1.3459e-02, -1.4578e-03, -1.8035e-02,  5.7673e-03, -1.5587e-03,
        -1.9816e-03,  7.6983e-04,  2.0333e-02], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[[[-2.4920e-02, -8.3494e-03,  2.6304e-02],
          [ 8.9767e-03, -2.8502e-02, -1.5565e-03],
          [-2.1893e-02,  8.0243e-04, -4.0647e-03]],

         [[ 2.4816e-02, -2.2081e-02, -1.5463e-02],
          [-2.5172e-02,  7.2438e-03,  2.9052e-02],
          [-1.0746e-02,  6.4857e-03, -4.6564e-03]],

         [[-6.5855e-03, -1.4794e-02, -7.6443e-03],
          [-3.5495e-03,  2.4543e-02,  3.4315e-03],
          [ 9.1402e-03, -1.6658e-02,  1.0003e-02]],

         ...,

         [[ 2.0640e-03, -2.6199e-02,  2.2306e-02],
          [ 2.3520e-02, -7.0268e-03,  1.2953e-02],
          [ 1.1984e-02, -1.5149e-02,  2.2729e-02]],

         [[-1.7215e-02,  5.3358e-03, -8.6513e-03],
          [-2.8366e-02, -2.4052e-02, -7.4373e-03],
          [ 2.6679e-02, -1.3849e-03, -2.8949e-02]],

         [[-1.7981e-02,  2.3839e-03,  2.7123e-02],
          [-4.9312e-03,  1.3224e-02, -1.3717e-02],
          [ 2.9041e-02, -6.8743e-03,  2.6992e-02]]],


        [[[-3.5097e-03,  2.5516e-02,  1.2979e-02],
          [-1.0213e-02, -4.4809e-03, -5.1935e-03],
          [ 2.9381e-02,  3.4079e-03,  2.3098e-02]],

         [[ 3.7397e-03, -1.4303e-02,  1.4708e-02],
          [-2.5776e-02,  2.7027e-03, -1.7492e-03],
          [-1.1808e-02, -2.7581e-02,  1.3922e-02]],

         [[ 8.0677e-03, -2.0276e-02, -2.8033e-02],
          [ 2.0285e-02, -1.4815e-02,  1.7570e-03],
          [ 1.9621e-02, -2.5453e-02, -5.4602e-03]],

         ...,

         [[ 2.1823e-02, -1.5105e-02, -1.4767e-02],
          [-2.4071e-02, -7.8013e-03, -1.1597e-02],
          [-9.0623e-03, -9.7497e-04, -2.8447e-03]],

         [[-2.4373e-02,  1.5872e-02, -1.8536e-02],
          [ 1.2310e-02,  1.8794e-02,  2.4844e-02],
          [-1.3369e-02, -2.2506e-02, -2.2743e-02]],

         [[-2.0090e-03,  5.1476e-03,  3.5750e-03],
          [ 1.4271e-02,  1.2384e-02,  7.1031e-03],
          [-1.4733e-03,  1.9467e-03,  2.5509e-02]]],


        [[[-1.2411e-02, -2.7071e-02,  2.4918e-02],
          [ 2.4782e-02,  2.6313e-02, -2.8324e-02],
          [-9.7078e-06, -1.4561e-02,  5.3616e-03]],

         [[ 9.0409e-03,  2.8524e-02, -2.2636e-02],
          [-2.7890e-02, -1.1642e-02, -1.1588e-03],
          [-1.7491e-02, -2.8665e-02,  3.4639e-03]],

         [[ 7.2966e-03, -2.2500e-02,  1.7863e-02],
          [ 2.1882e-02, -3.8861e-03, -1.0746e-02],
          [ 9.8841e-03,  2.7151e-02, -6.6589e-03]],

         ...,

         [[ 7.5755e-03,  1.3006e-02, -2.0798e-02],
          [-1.5046e-02,  8.5001e-03,  3.3313e-04],
          [-2.0268e-02, -1.6086e-02, -1.7531e-03]],

         [[-1.7518e-02, -2.6873e-02,  2.9340e-02],
          [ 2.5602e-02,  2.9389e-02,  2.8872e-03],
          [-6.3584e-03, -2.7602e-02, -1.1252e-02]],

         [[ 2.2651e-02,  1.2308e-02, -2.6038e-02],
          [-8.5869e-03, -5.0105e-03,  1.9114e-02],
          [-2.9123e-02, -2.6504e-03, -2.4416e-02]]],


        ...,


        [[[ 1.1775e-02,  1.9122e-02,  2.8011e-02],
          [ 5.8104e-03, -2.1902e-02, -2.6422e-02],
          [ 2.6523e-02, -2.2277e-02,  2.3245e-02]],

         [[ 1.4312e-02,  1.8152e-02,  2.9162e-02],
          [-2.1804e-02, -1.2945e-02, -1.5047e-02],
          [-1.2972e-03,  1.7683e-02,  2.4115e-02]],

         [[ 2.1204e-03, -5.3647e-03, -1.6902e-02],
          [-8.1336e-03,  1.7296e-02,  2.3786e-02],
          [ 1.8862e-02,  1.3455e-02, -1.4665e-02]],

         ...,

         [[ 3.4951e-03, -5.6755e-03,  1.8545e-02],
          [ 2.7958e-02,  1.4488e-02, -9.5361e-03],
          [ 7.1615e-03, -4.5180e-03,  1.1090e-02]],

         [[ 1.1351e-02, -1.3737e-02,  2.3967e-02],
          [-3.8123e-03,  1.7016e-02, -4.6126e-03],
          [ 9.3697e-03, -9.8776e-03, -1.2629e-02]],

         [[-2.9353e-02, -2.4369e-02,  1.7385e-02],
          [ 6.1357e-03, -2.5430e-02,  3.4712e-03],
          [-5.9187e-03,  2.7827e-02,  6.4239e-03]]],


        [[[ 2.9224e-02, -1.8481e-02,  1.7762e-02],
          [ 4.8882e-03,  2.1918e-03, -5.4927e-03],
          [-1.1432e-02, -2.1387e-03, -2.5244e-03]],

         [[ 7.5577e-03, -2.4533e-03,  2.0422e-02],
          [-1.8961e-02,  2.6530e-02,  2.0998e-02],
          [-2.9217e-02,  7.7334e-03,  3.9284e-03]],

         [[ 8.4735e-03,  1.6426e-02, -1.3015e-02],
          [-2.6150e-03,  2.4259e-02,  2.9042e-02],
          [-2.6126e-02,  2.8892e-02,  2.4876e-03]],

         ...,

         [[-8.4156e-03, -1.9732e-02,  1.0396e-02],
          [-1.9039e-02,  1.2717e-02,  1.3854e-02],
          [ 2.7850e-02,  8.4072e-03, -1.8700e-02]],

         [[ 1.5330e-02, -2.8341e-03, -1.0034e-02],
          [-2.6899e-02, -2.8799e-02, -2.5962e-02],
          [-8.3609e-03,  2.1420e-02, -1.6651e-02]],

         [[-2.5213e-02, -2.1274e-02,  7.7778e-03],
          [-1.2425e-02,  5.0532e-03, -2.4222e-02],
          [ 1.1426e-02, -2.3393e-02,  1.6802e-02]]],


        [[[-1.1031e-02,  1.2506e-02, -2.5240e-02],
          [-1.5513e-02,  4.0995e-03, -1.7241e-02],
          [-2.4374e-02, -2.5310e-02, -3.0288e-03]],

         [[-1.3222e-02,  5.6685e-03,  1.3540e-02],
          [-1.5127e-02, -1.4086e-02,  1.3937e-02],
          [ 7.0224e-03,  1.1128e-02, -1.3478e-02]],

         [[-3.3983e-03,  9.8271e-03, -1.5246e-02],
          [ 2.6623e-02, -1.3041e-02,  1.2640e-02],
          [-5.6076e-03,  1.1469e-02,  2.4637e-02]],

         ...,

         [[-7.0413e-03, -2.8961e-02,  2.5619e-02],
          [ 2.1936e-02, -4.3300e-03, -1.9980e-02],
          [ 1.5612e-02, -3.3640e-03,  2.8432e-02]],

         [[ 2.5615e-02,  1.1388e-03, -1.8629e-02],
          [-3.3786e-03,  2.4850e-02,  2.6624e-02],
          [ 2.6544e-02, -2.7811e-02, -2.6018e-02]],

         [[-2.2589e-02,  1.1243e-02, -1.7334e-02],
          [-1.0106e-02, -1.4192e-02,  7.7515e-03],
          [-6.5047e-03,  2.8586e-02, -2.8278e-02]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([-0.0175,  0.0102, -0.0230, -0.0219, -0.0202, -0.0016, -0.0052, -0.0155,
        -0.0164, -0.0197, -0.0158,  0.0049,  0.0204, -0.0196,  0.0045,  0.0009,
        -0.0005,  0.0066, -0.0253,  0.0249,  0.0016,  0.0165, -0.0138, -0.0124,
         0.0171, -0.0154,  0.0067,  0.0088, -0.0172,  0.0160,  0.0194, -0.0264,
        -0.0204, -0.0234, -0.0200, -0.0134, -0.0261,  0.0252, -0.0146, -0.0083,
         0.0027, -0.0047, -0.0162,  0.0082, -0.0206,  0.0083,  0.0023,  0.0113,
        -0.0133, -0.0257,  0.0113,  0.0070,  0.0032,  0.0149, -0.0168,  0.0068,
        -0.0169, -0.0119,  0.0080,  0.0014, -0.0185,  0.0020, -0.0254, -0.0071],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-2.7981e-04,  4.6222e-04,  8.2343e-04,  ...,  9.5716e-04,
         -6.5943e-04, -7.1785e-04],
        [-7.7615e-04,  4.1314e-04,  3.7770e-04,  ..., -1.0324e-03,
         -9.2519e-04, -7.3603e-04],
        [ 3.3259e-04,  1.1810e-03,  3.8961e-04,  ...,  3.5367e-04,
          4.2199e-04,  2.8923e-04],
        ...,
        [ 6.6711e-04, -6.6501e-04,  3.1118e-04,  ..., -5.4418e-05,
          8.6085e-04,  1.5973e-04],
        [ 2.2807e-04, -9.5957e-04,  6.5461e-04,  ...,  1.0684e-03,
          1.0859e-03,  2.0802e-04],
        [ 3.4264e-04,  7.7734e-05,  6.1534e-04,  ..., -6.2139e-04,
          4.8889e-04,  7.4162e-04]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 6.1713e-04,  4.0125e-05,  4.6840e-04,  1.1606e-03, -4.1270e-04,
        -4.7591e-04,  1.6289e-04,  1.1189e-03, -7.0155e-04,  2.2801e-04,
        -4.5823e-04,  1.0545e-03, -1.0656e-03, -3.2905e-04, -8.8246e-04,
         1.0456e-03, -5.7185e-04, -4.9010e-04,  7.0999e-04, -1.1417e-03,
        -4.2988e-04,  3.0236e-04, -1.0862e-03, -7.3601e-04,  7.6377e-05,
        -6.9017e-04,  5.0288e-05, -7.9682e-04, -7.2137e-04, -7.5212e-04,
        -1.6198e-04, -1.8708e-04,  1.0306e-04,  2.2651e-04,  6.6503e-04,
        -1.0319e-03,  5.4800e-04,  1.1789e-03,  5.6878e-04, -5.4766e-04,
        -4.0980e-04, -7.6540e-04,  1.0249e-03,  1.2202e-03, -3.8059e-04,
         1.0179e-03,  1.0240e-03, -9.3503e-04,  1.1228e-03, -1.3382e-04,
        -4.3287e-04,  1.1728e-03,  1.1229e-03,  5.6693e-04, -6.7496e-04,
         7.6357e-04, -1.0564e-03,  3.0238e-04, -1.0735e-03, -1.1635e-03,
        -1.4915e-05, -1.1050e-03, -4.6053e-04,  8.8657e-04,  1.0341e-03,
        -9.9754e-04,  1.1750e-03, -4.9411e-04, -2.3729e-04, -6.5839e-04,
        -7.6845e-04,  5.2486e-04,  8.7116e-04,  1.1589e-03,  3.0834e-04,
         6.7564e-04, -8.4507e-04,  1.1731e-03, -1.1112e-03, -1.9520e-04,
         5.6330e-04, -3.4269e-04, -1.2103e-03,  1.1773e-03,  4.5802e-04,
         1.1819e-03, -8.5054e-05,  2.5718e-04, -4.9266e-04,  1.2211e-03,
        -5.6536e-04, -5.4450e-04, -8.8106e-04, -7.4396e-04,  9.3117e-04,
         9.8117e-04, -7.5614e-04, -1.1400e-03, -7.0875e-04,  1.1051e-03,
         7.6298e-04, -6.9962e-04, -1.2943e-04, -3.1101e-04,  1.0851e-03,
        -7.4113e-04, -9.8252e-04, -5.6361e-04,  1.1026e-03, -8.6428e-04,
         3.1314e-04,  2.0051e-04,  2.4336e-04,  7.7853e-04,  2.3284e-04,
         1.2012e-03,  8.8414e-04,  1.2005e-03,  6.8631e-05,  1.1787e-03,
        -2.2033e-04,  1.1223e-03, -7.7019e-05,  9.9474e-04, -1.1668e-03,
         8.9306e-04, -1.2032e-04, -4.3413e-04,  1.0235e-03, -9.0695e-04,
        -6.9845e-04,  6.8354e-04, -1.0166e-03, -1.1419e-03,  8.0369e-04,
         3.8502e-04,  6.6019e-05,  1.0296e-03, -4.7034e-04, -1.2036e-05,
         5.5529e-04,  8.6512e-04, -1.0809e-03,  8.2455e-05, -2.5442e-04,
         4.0823e-04,  7.0103e-04,  2.3142e-04,  4.0364e-04,  9.9712e-04,
         1.0552e-03,  4.6721e-04, -4.9858e-04, -8.4691e-04,  1.0949e-03,
         5.7322e-04,  1.0284e-03,  1.0236e-03,  1.0788e-03, -5.1646e-04,
         8.2082e-04,  1.1430e-03,  3.5254e-04, -3.2243e-05, -1.0033e-03,
         8.9920e-04, -1.0568e-03, -7.9076e-04, -9.3401e-04, -1.1554e-03,
        -4.7509e-04, -1.0109e-03, -3.3463e-04, -5.5433e-04,  2.1944e-04,
        -6.3119e-04, -1.1915e-03,  2.7447e-04, -8.8979e-04, -4.6563e-05,
         1.1308e-03,  8.8969e-04,  1.1509e-03, -9.1260e-04, -1.0380e-03,
        -1.1582e-03, -6.9249e-04, -7.2969e-04, -1.8594e-04, -1.0232e-03,
         4.8221e-04, -1.1394e-03, -4.4475e-04, -7.7697e-04,  3.6370e-04,
        -4.8560e-04, -5.5504e-04,  8.1375e-06, -5.1043e-04,  5.1089e-04,
        -4.1389e-04, -7.8442e-05,  8.8911e-04,  1.0197e-03,  8.2519e-04,
         1.9840e-04,  1.9980e-04,  9.3644e-04, -8.7316e-04,  1.0644e-03,
        -8.7671e-04,  1.0646e-03,  1.7299e-04,  9.6933e-04, -9.7397e-04,
         2.5256e-04,  3.1187e-04, -9.8159e-04,  1.1745e-03,  1.0009e-03,
         2.1245e-04, -7.8727e-04, -8.9921e-04, -1.1956e-04, -7.4747e-04,
        -6.0271e-04,  2.9568e-04, -1.2047e-03,  6.9909e-04,  8.4887e-04,
         5.9657e-05,  2.5524e-04, -3.5093e-04, -6.0787e-04, -2.6802e-04,
        -1.0992e-03, -1.0385e-03, -3.4905e-04, -9.3953e-04, -9.4002e-04,
        -2.0154e-04, -7.0210e-05,  4.7178e-05,  1.1294e-03,  6.5122e-04,
        -6.7561e-04,  1.1107e-03, -6.5898e-04, -1.0690e-03, -3.5504e-04,
         4.0603e-04, -3.2846e-04,  9.5819e-04, -5.1690e-04, -4.1640e-04,
        -1.1214e-03], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0216, -0.0165,  0.0545,  ...,  0.0192, -0.0132,  0.0258],
        [ 0.0429,  0.0013,  0.0495,  ...,  0.0437,  0.0500,  0.0610],
        [ 0.0246,  0.0377,  0.0403,  ...,  0.0464,  0.0463, -0.0586],
        ...,
        [ 0.0035,  0.0506,  0.0036,  ...,  0.0079, -0.0468,  0.0426],
        [ 0.0049,  0.0422, -0.0514,  ..., -0.0029, -0.0035, -0.0556],
        [ 0.0455, -0.0344, -0.0108,  ..., -0.0012,  0.0041, -0.0430]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0372, -0.0291,  0.0101, -0.0418,  0.0604,  0.0161, -0.0318,  0.0329,
         0.0361,  0.0189,  0.0144,  0.0541,  0.0097,  0.0199,  0.0487,  0.0506,
        -0.0082, -0.0191,  0.0337,  0.0431, -0.0220, -0.0010,  0.0600,  0.0311,
        -0.0334,  0.0329, -0.0590, -0.0066,  0.0359,  0.0115,  0.0530, -0.0358,
         0.0321,  0.0462,  0.0414,  0.0425, -0.0173,  0.0070,  0.0431, -0.0457,
         0.0020,  0.0104,  0.0062,  0.0191, -0.0196, -0.0060, -0.0443,  0.0012,
        -0.0451,  0.0126,  0.0470,  0.0374, -0.0309, -0.0290,  0.0064, -0.0281,
         0.0504, -0.0423, -0.0169,  0.0456, -0.0371, -0.0098,  0.0464, -0.0228,
        -0.0480,  0.0447, -0.0326, -0.0145,  0.0285, -0.0314,  0.0065,  0.0426,
        -0.0154,  0.0578, -0.0415, -0.0091, -0.0259, -0.0582,  0.0604, -0.0080,
        -0.0475,  0.0615,  0.0499,  0.0606, -0.0038, -0.0165,  0.0154,  0.0204,
         0.0400, -0.0345,  0.0572,  0.0444, -0.0529,  0.0551,  0.0180,  0.0127,
        -0.0089,  0.0268, -0.0312, -0.0243,  0.0315,  0.0322, -0.0407,  0.0057,
        -0.0349,  0.0384, -0.0390,  0.0284,  0.0502, -0.0123,  0.0273,  0.0150,
         0.0544,  0.0462, -0.0536,  0.0430, -0.0579, -0.0148,  0.0494,  0.0119,
         0.0511,  0.0272,  0.0022, -0.0105,  0.0509, -0.0479, -0.0204, -0.0007],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0321, -0.0327, -0.0368,  ..., -0.0814, -0.0055,  0.0428],
        [ 0.0533, -0.0522,  0.0685,  ..., -0.0384,  0.0846,  0.0743],
        [ 0.0276, -0.0697, -0.0388,  ..., -0.0191,  0.0596,  0.0847],
        ...,
        [-0.0175, -0.0713, -0.0725,  ...,  0.0650, -0.0764, -0.0110],
        [ 0.0623, -0.0229, -0.0244,  ..., -0.0629,  0.0759,  0.0252],
        [ 0.0303,  0.0860, -0.0487,  ...,  0.0227, -0.0071,  0.0189]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0162, -0.0749,  0.0525,  0.0361, -0.0835,  0.0028, -0.0596, -0.0409,
         0.0608,  0.0340,  0.0255, -0.0167, -0.0064, -0.0743, -0.0595,  0.0378,
         0.0824, -0.0324, -0.0155,  0.0149, -0.0502,  0.0291, -0.0730,  0.0686,
        -0.0260,  0.0734,  0.0666,  0.0291,  0.0542, -0.0329,  0.0651, -0.0817,
        -0.0374, -0.0613, -0.0522, -0.0575, -0.0020, -0.0532,  0.0303,  0.0803,
         0.0764,  0.0567, -0.0237,  0.0488,  0.0055, -0.0319,  0.0339, -0.0295,
         0.0378,  0.0188,  0.0117, -0.0845, -0.0458, -0.0868, -0.0733,  0.0205,
        -0.0624, -0.0014, -0.0692, -0.0696, -0.0860, -0.0012, -0.0206,  0.0413],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0161, -0.1100,  0.1234,  ..., -0.0591,  0.0389, -0.0647],
        [-0.0096, -0.0092, -0.1096,  ...,  0.0762,  0.0037, -0.0914],
        [ 0.0910, -0.0686,  0.0947,  ...,  0.0038, -0.0075, -0.0077],
        ...,
        [ 0.0648, -0.1238, -0.1052,  ...,  0.0567, -0.0704,  0.0340],
        [-0.0905, -0.0440, -0.1197,  ...,  0.0837, -0.0190, -0.0217],
        [ 0.0119, -0.0097, -0.0601,  ...,  0.0579, -0.1100, -0.0269]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0387,  0.0304,  0.0152,  ..., -0.1057,  0.0169, -0.0226],
       device='cuda:0', requires_grad=True)], 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}]
epoch: 0 batch 0.0 event: 0 loss: tensor(184.4087, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 10.0 event: 300 loss: tensor(2101.3899, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 20.0 event: 600 loss: tensor(1978.3939, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 30.0 event: 900 loss: tensor(1894.4905, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 40.0 event: 1200 loss: tensor(1800.9541, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 50.0 event: 1500 loss: tensor(2039.4580, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 60.0 event: 1800 loss: tensor(1991.9518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 70.0 event: 2100 loss: tensor(2025.2773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 80.0 event: 2400 loss: tensor(2043.8090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 100.0 event: 3000 loss: tensor(3858.9211, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 110.0 event: 3300 loss: tensor(1663.2805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 120.0 event: 3600 loss: tensor(1915.4261, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 130.0 event: 3900 loss: tensor(1568.3096, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 140.0 event: 4200 loss: tensor(1975.4313, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 150.0 event: 4500 loss: tensor(1793.4506, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 160.0 event: 4800 loss: tensor(1776.2323, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 170.0 event: 5100 loss: tensor(1997.3649, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 180.0 event: 5400 loss: tensor(2058.7722, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 190.0 event: 5700 loss: tensor(2021.8473, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 200.0 event: 6000 loss: tensor(1902.8563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 210.0 event: 6300 loss: tensor(1577.6317, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 220.0 event: 6600 loss: tensor(2066.6445, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 230.0 event: 6900 loss: tensor(1824.2100, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 240.0 event: 7200 loss: tensor(2095.7458, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 250.0 event: 7500 loss: tensor(1885.6467, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 260.0 event: 7800 loss: tensor(2014.4462, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 270.0 event: 8100 loss: tensor(1986.2965, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 280.0 event: 8400 loss: tensor(2019.9928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 290.0 event: 8700 loss: tensor(1731.2157, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 300.0 event: 9000 loss: tensor(2051.3901, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 310.0 event: 9300 loss: tensor(1796.3558, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 320.0 event: 9600 loss: tensor(1937.1074, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 330.0 event: 9900 loss: tensor(1843.8385, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:00:22.600901
evaluation loss: 1704.5721435546875
epoch: 0 mean loss: 1923.0819091796875
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 1 batch 0.0 event: 0 loss: tensor(183.2735, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 10.0 event: 300 loss: tensor(1997.0101, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 20.0 event: 600 loss: tensor(1966.4883, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 30.0 event: 900 loss: tensor(1881.6112, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 40.0 event: 1200 loss: tensor(1790.1301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 50.0 event: 1500 loss: tensor(2029.0878, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 60.0 event: 1800 loss: tensor(1983.6390, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 70.0 event: 2100 loss: tensor(2018.7885, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 80.0 event: 2400 loss: tensor(1970.6180, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 100.0 event: 3000 loss: tensor(3878.7664, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 110.0 event: 3300 loss: tensor(1663.4369, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 120.0 event: 3600 loss: tensor(1916.1637, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 130.0 event: 3900 loss: tensor(1568.5907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 140.0 event: 4200 loss: tensor(1975.3987, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 150.0 event: 4500 loss: tensor(1793.3785, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 160.0 event: 4800 loss: tensor(1776.1227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 170.0 event: 5100 loss: tensor(1997.2523, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 180.0 event: 5400 loss: tensor(2075.1130, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 190.0 event: 5700 loss: tensor(2022.1956, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 200.0 event: 6000 loss: tensor(1903.3314, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 210.0 event: 6300 loss: tensor(1578.0006, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 220.0 event: 6600 loss: tensor(2067.1165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 230.0 event: 6900 loss: tensor(1824.2780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 240.0 event: 7200 loss: tensor(2095.5122, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 250.0 event: 7500 loss: tensor(1885.5809, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 260.0 event: 7800 loss: tensor(2014.4749, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 270.0 event: 8100 loss: tensor(1986.1982, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 280.0 event: 8400 loss: tensor(2019.8561, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 290.0 event: 8700 loss: tensor(1731.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 300.0 event: 9000 loss: tensor(2051.3181, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 310.0 event: 9300 loss: tensor(1796.2750, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 320.0 event: 9600 loss: tensor(1937.0344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 330.0 event: 9900 loss: tensor(1843.7170, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:02.360074
evaluation loss: 1703.5009765625
epoch: 1 mean loss: 1917.022216796875
epoch: 2 batch 0.0 event: 0 loss: tensor(183.3005, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 10.0 event: 300 loss: tensor(1996.9807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 20.0 event: 600 loss: tensor(1966.3942, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 30.0 event: 900 loss: tensor(1881.5527, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 40.0 event: 1200 loss: tensor(1790.1897, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 50.0 event: 1500 loss: tensor(2029.1200, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 60.0 event: 1800 loss: tensor(1983.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 70.0 event: 2100 loss: tensor(2018.8602, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 80.0 event: 2400 loss: tensor(1942.1116, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 100.0 event: 3000 loss: tensor(3851.2058, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 110.0 event: 3300 loss: tensor(1660.9965, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 120.0 event: 3600 loss: tensor(1912.5657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 130.0 event: 3900 loss: tensor(1566.2135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 140.0 event: 4200 loss: tensor(1973.6217, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 150.0 event: 4500 loss: tensor(1791.8733, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 160.0 event: 4800 loss: tensor(1774.8092, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 170.0 event: 5100 loss: tensor(1996.0670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 180.0 event: 5400 loss: tensor(2057.8477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 190.0 event: 5700 loss: tensor(2021.1194, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 200.0 event: 6000 loss: tensor(1902.2424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 210.0 event: 6300 loss: tensor(1577.0463, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 220.0 event: 6600 loss: tensor(2066.0972, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 230.0 event: 6900 loss: tensor(1823.7864, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 240.0 event: 7200 loss: tensor(2095.2847, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 250.0 event: 7500 loss: tensor(1885.2240, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 260.0 event: 7800 loss: tensor(2014.0654, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 270.0 event: 8100 loss: tensor(1985.9346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 280.0 event: 8400 loss: tensor(2019.6469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 290.0 event: 8700 loss: tensor(1730.9276, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 300.0 event: 9000 loss: tensor(2051.1016, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 310.0 event: 9300 loss: tensor(1796.1598, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 320.0 event: 9600 loss: tensor(1936.8438, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 330.0 event: 9900 loss: tensor(1843.5957, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:37.579403
evaluation loss: 1702.5640869140625
epoch: 2 mean loss: 1914.169921875
epoch: 3 batch 0.0 event: 0 loss: tensor(183.2806, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 10.0 event: 300 loss: tensor(1996.8600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 20.0 event: 600 loss: tensor(1966.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 30.0 event: 900 loss: tensor(1881.4862, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 40.0 event: 1200 loss: tensor(1790.1155, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 50.0 event: 1500 loss: tensor(2029.0670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 60.0 event: 1800 loss: tensor(1982.9521, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 70.0 event: 2100 loss: tensor(2018.7727, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 80.0 event: 2400 loss: tensor(1942.0850, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 100.0 event: 3000 loss: tensor(3851.0586, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 110.0 event: 3300 loss: tensor(1660.9016, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 120.0 event: 3600 loss: tensor(1912.4570, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 130.0 event: 3900 loss: tensor(1566.1489, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 140.0 event: 4200 loss: tensor(1973.5380, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 150.0 event: 4500 loss: tensor(1791.8063, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 160.0 event: 4800 loss: tensor(1774.7133, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 170.0 event: 5100 loss: tensor(1995.9803, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 180.0 event: 5400 loss: tensor(2057.8018, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 190.0 event: 5700 loss: tensor(2021.0061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 200.0 event: 6000 loss: tensor(1902.1699, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 210.0 event: 6300 loss: tensor(1576.9639, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 220.0 event: 6600 loss: tensor(2066.0271, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 230.0 event: 6900 loss: tensor(1823.7151, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 240.0 event: 7200 loss: tensor(2095.2266, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 250.0 event: 7500 loss: tensor(1885.1542, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 260.0 event: 7800 loss: tensor(2013.9879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 270.0 event: 8100 loss: tensor(1985.8715, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 280.0 event: 8400 loss: tensor(2019.5696, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 290.0 event: 8700 loss: tensor(1730.8805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 300.0 event: 9000 loss: tensor(2051.0305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 310.0 event: 9300 loss: tensor(1796.1135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 320.0 event: 9600 loss: tensor(1936.7699, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 330.0 event: 9900 loss: tensor(1843.5352, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:12.768398
evaluation loss: 1702.4996337890625
epoch: 3 mean loss: 1914.0965576171875
epoch: 4 batch 0.0 event: 0 loss: tensor(183.2722, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 10.0 event: 300 loss: tensor(1996.8086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 20.0 event: 600 loss: tensor(1966.3098, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 30.0 event: 900 loss: tensor(1881.4344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 40.0 event: 1200 loss: tensor(1790.0667, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 50.0 event: 1500 loss: tensor(2029.0309, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 60.0 event: 1800 loss: tensor(1982.8848, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 70.0 event: 2100 loss: tensor(2018.7178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 80.0 event: 2400 loss: tensor(1942.0433, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 100.0 event: 3000 loss: tensor(3850.9512, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 110.0 event: 3300 loss: tensor(1660.8436, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 120.0 event: 3600 loss: tensor(1912.3955, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 130.0 event: 3900 loss: tensor(1566.1141, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 140.0 event: 4200 loss: tensor(1973.4879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 150.0 event: 4500 loss: tensor(1791.7574, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 160.0 event: 4800 loss: tensor(1774.6556, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 170.0 event: 5100 loss: tensor(1995.9277, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 180.0 event: 5400 loss: tensor(2058.1411, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 190.0 event: 5700 loss: tensor(2020.9414, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 200.0 event: 6000 loss: tensor(1902.1309, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 210.0 event: 6300 loss: tensor(1576.9114, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 220.0 event: 6600 loss: tensor(2065.9805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 230.0 event: 6900 loss: tensor(1823.6663, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 240.0 event: 7200 loss: tensor(2095.1917, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 250.0 event: 7500 loss: tensor(1885.1006, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 260.0 event: 7800 loss: tensor(2013.9330, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 270.0 event: 8100 loss: tensor(1985.8232, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 280.0 event: 8400 loss: tensor(2019.5051, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 290.0 event: 8700 loss: tensor(1730.8408, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 300.0 event: 9000 loss: tensor(2050.9719, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 310.0 event: 9300 loss: tensor(1796.0764, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 320.0 event: 9600 loss: tensor(1936.7122, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 330.0 event: 9900 loss: tensor(1843.4828, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:47.955090
evaluation loss: 1702.4671630859375
epoch: 4 mean loss: 1914.0565185546875
epoch: 5 batch 0.0 event: 0 loss: tensor(183.2653, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 10.0 event: 300 loss: tensor(1996.7631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 20.0 event: 600 loss: tensor(1966.2666, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 30.0 event: 900 loss: tensor(1881.3936, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 40.0 event: 1200 loss: tensor(1790.0267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 50.0 event: 1500 loss: tensor(2029.0049, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 60.0 event: 1800 loss: tensor(1982.8353, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 70.0 event: 2100 loss: tensor(2018.6722, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 80.0 event: 2400 loss: tensor(1942.0096, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 100.0 event: 3000 loss: tensor(3850.8633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 110.0 event: 3300 loss: tensor(1660.7971, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 120.0 event: 3600 loss: tensor(1912.3434, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 130.0 event: 3900 loss: tensor(1566.0836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 140.0 event: 4200 loss: tensor(1973.4469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 150.0 event: 4500 loss: tensor(1791.7145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 160.0 event: 4800 loss: tensor(1774.6097, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 170.0 event: 5100 loss: tensor(1995.8856, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 180.0 event: 5400 loss: tensor(2057.7173, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 190.0 event: 5700 loss: tensor(2020.8879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 200.0 event: 6000 loss: tensor(1902.0865, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 210.0 event: 6300 loss: tensor(1576.8795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 220.0 event: 6600 loss: tensor(2065.9504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 230.0 event: 6900 loss: tensor(1823.6295, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 240.0 event: 7200 loss: tensor(2095.1494, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 250.0 event: 7500 loss: tensor(1885.0631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 260.0 event: 7800 loss: tensor(2013.8909, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 270.0 event: 8100 loss: tensor(1985.7919, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 280.0 event: 8400 loss: tensor(2019.4706, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 290.0 event: 8700 loss: tensor(1730.8145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 300.0 event: 9000 loss: tensor(2050.9385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 310.0 event: 9300 loss: tensor(1796.0540, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 320.0 event: 9600 loss: tensor(1936.6742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 330.0 event: 9900 loss: tensor(1843.4471, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:23.093232
evaluation loss: 1702.4462890625
epoch: 5 mean loss: 1914.0045166015625
=> saveing checkpoint at epoch 5
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 6 batch 0.0 event: 0 loss: tensor(183.2607, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 10.0 event: 300 loss: tensor(1996.7401, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 20.0 event: 600 loss: tensor(1966.2213, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 30.0 event: 900 loss: tensor(1881.3557, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 40.0 event: 1200 loss: tensor(1789.9932, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 50.0 event: 1500 loss: tensor(2028.9807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 60.0 event: 1800 loss: tensor(1982.8024, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 70.0 event: 2100 loss: tensor(2018.6429, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 80.0 event: 2400 loss: tensor(1941.9867, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 100.0 event: 3000 loss: tensor(3850.7949, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 110.0 event: 3300 loss: tensor(1660.7551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 120.0 event: 3600 loss: tensor(1912.3026, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 130.0 event: 3900 loss: tensor(1566.0599, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 140.0 event: 4200 loss: tensor(1973.4125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 150.0 event: 4500 loss: tensor(1791.6797, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 160.0 event: 4800 loss: tensor(1774.5725, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 170.0 event: 5100 loss: tensor(1995.8470, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 180.0 event: 5400 loss: tensor(2057.6812, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 190.0 event: 5700 loss: tensor(2020.8469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 200.0 event: 6000 loss: tensor(1902.0570, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 210.0 event: 6300 loss: tensor(1576.8558, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 220.0 event: 6600 loss: tensor(2065.9209, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 230.0 event: 6900 loss: tensor(1823.5999, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 240.0 event: 7200 loss: tensor(2095.1255, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 250.0 event: 7500 loss: tensor(1885.0267, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 260.0 event: 7800 loss: tensor(2013.8567, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 270.0 event: 8100 loss: tensor(1985.7610, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 280.0 event: 8400 loss: tensor(2019.4291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 290.0 event: 8700 loss: tensor(1730.7871, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 300.0 event: 9000 loss: tensor(2050.8955, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 310.0 event: 9300 loss: tensor(1796.0253, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 320.0 event: 9600 loss: tensor(1936.6327, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 330.0 event: 9900 loss: tensor(1843.4120, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:03.816412
evaluation loss: 1702.42578125
epoch: 6 mean loss: 1913.9715576171875
epoch: 7 batch 0.0 event: 0 loss: tensor(183.2559, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 10.0 event: 300 loss: tensor(1996.7076, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 20.0 event: 600 loss: tensor(1966.1805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 30.0 event: 900 loss: tensor(1881.3236, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 40.0 event: 1200 loss: tensor(1789.9592, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 50.0 event: 1500 loss: tensor(2028.9567, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 60.0 event: 1800 loss: tensor(1982.7721, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 70.0 event: 2100 loss: tensor(2018.6200, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 80.0 event: 2400 loss: tensor(1941.9696, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 100.0 event: 3000 loss: tensor(3850.7466, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 110.0 event: 3300 loss: tensor(1660.7268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 120.0 event: 3600 loss: tensor(1912.2639, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 130.0 event: 3900 loss: tensor(1566.0415, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 140.0 event: 4200 loss: tensor(1973.3876, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 150.0 event: 4500 loss: tensor(1791.6522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 160.0 event: 4800 loss: tensor(1774.5387, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 170.0 event: 5100 loss: tensor(1995.8206, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 180.0 event: 5400 loss: tensor(2057.6492, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 190.0 event: 5700 loss: tensor(2020.8098, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 200.0 event: 6000 loss: tensor(1902.0336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 210.0 event: 6300 loss: tensor(1576.8337, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 220.0 event: 6600 loss: tensor(2065.8958, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 230.0 event: 6900 loss: tensor(1823.5723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 240.0 event: 7200 loss: tensor(2095.1028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 250.0 event: 7500 loss: tensor(1884.9983, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 260.0 event: 7800 loss: tensor(2013.8334, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 270.0 event: 8100 loss: tensor(1985.7375, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 280.0 event: 8400 loss: tensor(2019.4030, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 290.0 event: 8700 loss: tensor(1730.7688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 300.0 event: 9000 loss: tensor(2050.8672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 310.0 event: 9300 loss: tensor(1796.0062, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 320.0 event: 9600 loss: tensor(1936.6057, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 330.0 event: 9900 loss: tensor(1843.3850, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:39.034569
evaluation loss: 1702.4110107421875
epoch: 7 mean loss: 1913.9444580078125
epoch: 8 batch 0.0 event: 0 loss: tensor(183.2509, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 10.0 event: 300 loss: tensor(1996.6766, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 20.0 event: 600 loss: tensor(1966.1473, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 30.0 event: 900 loss: tensor(1881.2933, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 40.0 event: 1200 loss: tensor(1789.9277, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 50.0 event: 1500 loss: tensor(2028.9338, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 60.0 event: 1800 loss: tensor(1982.7461, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 70.0 event: 2100 loss: tensor(2018.5986, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 80.0 event: 2400 loss: tensor(1941.9545, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 100.0 event: 3000 loss: tensor(3850.7039, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 110.0 event: 3300 loss: tensor(1660.6991, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 120.0 event: 3600 loss: tensor(1912.2170, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 130.0 event: 3900 loss: tensor(1566.0233, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 140.0 event: 4200 loss: tensor(1973.3557, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 150.0 event: 4500 loss: tensor(1791.6262, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 160.0 event: 4800 loss: tensor(1774.5104, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 170.0 event: 5100 loss: tensor(1995.7887, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 180.0 event: 5400 loss: tensor(2057.6248, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 190.0 event: 5700 loss: tensor(2020.7733, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 200.0 event: 6000 loss: tensor(1902.0068, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 210.0 event: 6300 loss: tensor(1576.8119, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 220.0 event: 6600 loss: tensor(2065.8677, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 230.0 event: 6900 loss: tensor(1823.5510, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 240.0 event: 7200 loss: tensor(2095.0854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 250.0 event: 7500 loss: tensor(1884.9768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 260.0 event: 7800 loss: tensor(2013.8124, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 270.0 event: 8100 loss: tensor(1985.7158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 280.0 event: 8400 loss: tensor(2019.3770, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 290.0 event: 8700 loss: tensor(1730.7543, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 300.0 event: 9000 loss: tensor(2050.8350, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 310.0 event: 9300 loss: tensor(1795.9834, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 320.0 event: 9600 loss: tensor(1936.5725, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 330.0 event: 9900 loss: tensor(1843.3588, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:14.248670
evaluation loss: 1702.3970947265625
epoch: 8 mean loss: 1913.9178466796875
epoch: 9 batch 0.0 event: 0 loss: tensor(183.2485, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 10.0 event: 300 loss: tensor(1996.6361, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 20.0 event: 600 loss: tensor(1966.1200, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 30.0 event: 900 loss: tensor(1881.2721, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 40.0 event: 1200 loss: tensor(1789.9026, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 50.0 event: 1500 loss: tensor(2028.9102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 60.0 event: 1800 loss: tensor(1982.7152, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 70.0 event: 2100 loss: tensor(2018.5762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 80.0 event: 2400 loss: tensor(1941.9346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 100.0 event: 3000 loss: tensor(3850.6672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 110.0 event: 3300 loss: tensor(1660.6766, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 120.0 event: 3600 loss: tensor(1912.1930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 130.0 event: 3900 loss: tensor(1566.0009, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 140.0 event: 4200 loss: tensor(1973.3381, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 150.0 event: 4500 loss: tensor(1791.5959, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 160.0 event: 4800 loss: tensor(1774.4813, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 170.0 event: 5100 loss: tensor(1995.7670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 180.0 event: 5400 loss: tensor(2057.5994, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 190.0 event: 5700 loss: tensor(2020.7461, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 200.0 event: 6000 loss: tensor(1901.9895, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 210.0 event: 6300 loss: tensor(1576.7963, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 220.0 event: 6600 loss: tensor(2065.8511, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 230.0 event: 6900 loss: tensor(1823.5315, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 240.0 event: 7200 loss: tensor(2095.0642, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 250.0 event: 7500 loss: tensor(1884.9547, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 260.0 event: 7800 loss: tensor(2013.7903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 270.0 event: 8100 loss: tensor(1985.6998, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 280.0 event: 8400 loss: tensor(2019.3633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 290.0 event: 8700 loss: tensor(1730.7415, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 300.0 event: 9000 loss: tensor(2050.8247, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 310.0 event: 9300 loss: tensor(1795.9814, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 320.0 event: 9600 loss: tensor(1936.5668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 330.0 event: 9900 loss: tensor(1843.3889, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:49.470641
evaluation loss: 1702.3941650390625
epoch: 9 mean loss: 1913.8990478515625
epoch: 10 batch 0.0 event: 0 loss: tensor(183.2459, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 10.0 event: 300 loss: tensor(1996.6434, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 20.0 event: 600 loss: tensor(1966.0928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 30.0 event: 900 loss: tensor(1881.2542, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 40.0 event: 1200 loss: tensor(1789.8668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 50.0 event: 1500 loss: tensor(2028.8864, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 60.0 event: 1800 loss: tensor(1982.6956, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 70.0 event: 2100 loss: tensor(2018.5643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 80.0 event: 2400 loss: tensor(1941.9310, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 100.0 event: 3000 loss: tensor(3850.6536, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 110.0 event: 3300 loss: tensor(1660.6594, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 120.0 event: 3600 loss: tensor(1912.1741, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 130.0 event: 3900 loss: tensor(1565.9855, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 140.0 event: 4200 loss: tensor(1973.3207, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 150.0 event: 4500 loss: tensor(1791.5803, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 160.0 event: 4800 loss: tensor(1774.4637, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 170.0 event: 5100 loss: tensor(1995.7444, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 180.0 event: 5400 loss: tensor(2057.5808, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 190.0 event: 5700 loss: tensor(2020.7190, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 200.0 event: 6000 loss: tensor(1901.9730, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 210.0 event: 6300 loss: tensor(1576.7822, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 220.0 event: 6600 loss: tensor(2065.8308, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 230.0 event: 6900 loss: tensor(1823.5143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 240.0 event: 7200 loss: tensor(2095.0454, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 250.0 event: 7500 loss: tensor(1884.9332, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 260.0 event: 7800 loss: tensor(2013.7688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 270.0 event: 8100 loss: tensor(1985.6796, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 280.0 event: 8400 loss: tensor(2019.3436, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 290.0 event: 8700 loss: tensor(1730.7268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 300.0 event: 9000 loss: tensor(2050.8035, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 310.0 event: 9300 loss: tensor(1795.9684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 320.0 event: 9600 loss: tensor(1936.5500, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 330.0 event: 9900 loss: tensor(1843.3363, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:06:24.694170
evaluation loss: 1702.3853759765625
epoch: 10 mean loss: 1913.8804931640625
=> saveing checkpoint at epoch 10
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 11 batch 0.0 event: 0 loss: tensor(183.2419, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 10.0 event: 300 loss: tensor(1996.6102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 20.0 event: 600 loss: tensor(1966.0703, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 30.0 event: 900 loss: tensor(1881.2249, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 40.0 event: 1200 loss: tensor(1789.8383, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 50.0 event: 1500 loss: tensor(2028.8596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 60.0 event: 1800 loss: tensor(1982.6641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 70.0 event: 2100 loss: tensor(2018.5375, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 80.0 event: 2400 loss: tensor(1941.9144, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 100.0 event: 3000 loss: tensor(3850.6250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 110.0 event: 3300 loss: tensor(1660.6445, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 120.0 event: 3600 loss: tensor(1912.1510, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 130.0 event: 3900 loss: tensor(1565.9681, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 140.0 event: 4200 loss: tensor(1973.3024, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 150.0 event: 4500 loss: tensor(1791.5605, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 160.0 event: 4800 loss: tensor(1774.4424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 170.0 event: 5100 loss: tensor(1995.7197, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 180.0 event: 5400 loss: tensor(2057.5586, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 190.0 event: 5700 loss: tensor(2020.6926, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 200.0 event: 6000 loss: tensor(1901.9574, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 210.0 event: 6300 loss: tensor(1576.7672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 220.0 event: 6600 loss: tensor(2065.8123, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 230.0 event: 6900 loss: tensor(1823.4990, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 240.0 event: 7200 loss: tensor(2095.0305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 250.0 event: 7500 loss: tensor(1884.9215, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 260.0 event: 7800 loss: tensor(2013.7529, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 270.0 event: 8100 loss: tensor(1985.6656, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 280.0 event: 8400 loss: tensor(2019.3209, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 290.0 event: 8700 loss: tensor(1730.7122, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 300.0 event: 9000 loss: tensor(2050.7820, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 310.0 event: 9300 loss: tensor(1795.9504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 320.0 event: 9600 loss: tensor(1936.5273, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 330.0 event: 9900 loss: tensor(1843.3141, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:04.731930
evaluation loss: 1702.3822021484375
epoch: 11 mean loss: 1913.8603515625
epoch: 12 batch 0.0 event: 0 loss: tensor(183.2396, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 10.0 event: 300 loss: tensor(1996.5881, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 20.0 event: 600 loss: tensor(1966.0563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 30.0 event: 900 loss: tensor(1881.2067, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 40.0 event: 1200 loss: tensor(1789.8215, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 50.0 event: 1500 loss: tensor(2028.8447, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 60.0 event: 1800 loss: tensor(1982.6497, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 70.0 event: 2100 loss: tensor(2018.5179, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 80.0 event: 2400 loss: tensor(1941.8998, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 100.0 event: 3000 loss: tensor(3850.5903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 110.0 event: 3300 loss: tensor(1660.6227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 120.0 event: 3600 loss: tensor(1912.1174, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 130.0 event: 3900 loss: tensor(1565.9462, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 140.0 event: 4200 loss: tensor(1973.2772, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 150.0 event: 4500 loss: tensor(1791.5391, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 160.0 event: 4800 loss: tensor(1774.4297, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 170.0 event: 5100 loss: tensor(1995.7109, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 180.0 event: 5400 loss: tensor(2057.5479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 190.0 event: 5700 loss: tensor(2020.6865, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 200.0 event: 6000 loss: tensor(1901.9554, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 210.0 event: 6300 loss: tensor(1576.7518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 220.0 event: 6600 loss: tensor(2065.7925, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 230.0 event: 6900 loss: tensor(1823.4762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 240.0 event: 7200 loss: tensor(2095.0042, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 250.0 event: 7500 loss: tensor(1884.8939, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 260.0 event: 7800 loss: tensor(2013.7285, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 270.0 event: 8100 loss: tensor(1985.6547, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 280.0 event: 8400 loss: tensor(2019.3112, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 290.0 event: 8700 loss: tensor(1730.7242, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 300.0 event: 9000 loss: tensor(2050.7954, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 310.0 event: 9300 loss: tensor(1795.9745, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 320.0 event: 9600 loss: tensor(1936.5438, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 330.0 event: 9900 loss: tensor(1843.3412, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:39.971052
evaluation loss: 1702.3785400390625
epoch: 12 mean loss: 1913.8480224609375
epoch: 13 batch 0.0 event: 0 loss: tensor(183.2388, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 10.0 event: 300 loss: tensor(1996.5902, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 20.0 event: 600 loss: tensor(1966.0502, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 30.0 event: 900 loss: tensor(1881.1967, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 40.0 event: 1200 loss: tensor(1789.8008, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 50.0 event: 1500 loss: tensor(2028.8226, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 60.0 event: 1800 loss: tensor(1982.6055, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 70.0 event: 2100 loss: tensor(2018.4674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 80.0 event: 2400 loss: tensor(1941.8665, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 100.0 event: 3000 loss: tensor(3850.5645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 110.0 event: 3300 loss: tensor(1660.6162, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 120.0 event: 3600 loss: tensor(1912.1180, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 130.0 event: 3900 loss: tensor(1565.9506, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 140.0 event: 4200 loss: tensor(1973.2637, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 150.0 event: 4500 loss: tensor(1791.5406, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 160.0 event: 4800 loss: tensor(1774.4196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 170.0 event: 5100 loss: tensor(1995.6985, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 180.0 event: 5400 loss: tensor(2057.5352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 190.0 event: 5700 loss: tensor(2020.6643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 200.0 event: 6000 loss: tensor(1901.9365, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 210.0 event: 6300 loss: tensor(1576.7460, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 220.0 event: 6600 loss: tensor(2067.8430, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 230.0 event: 6900 loss: tensor(1823.4821, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 240.0 event: 7200 loss: tensor(2095.0120, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 250.0 event: 7500 loss: tensor(1884.9036, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 260.0 event: 7800 loss: tensor(2013.7288, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 270.0 event: 8100 loss: tensor(1985.6276, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 280.0 event: 8400 loss: tensor(2019.2855, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 290.0 event: 8700 loss: tensor(1730.7018, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 300.0 event: 9000 loss: tensor(2050.7778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 310.0 event: 9300 loss: tensor(1795.9364, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 320.0 event: 9600 loss: tensor(1936.5254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 330.0 event: 9900 loss: tensor(1843.3011, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:15.184143
evaluation loss: 1702.3785400390625
epoch: 13 mean loss: 1913.89404296875
epoch: 14 batch 0.0 event: 0 loss: tensor(183.2357, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 10.0 event: 300 loss: tensor(1996.5479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 20.0 event: 600 loss: tensor(1966.0111, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 30.0 event: 900 loss: tensor(1881.1854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 40.0 event: 1200 loss: tensor(1789.7780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 50.0 event: 1500 loss: tensor(2028.7913, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 60.0 event: 1800 loss: tensor(1982.6068, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 70.0 event: 2100 loss: tensor(2018.4769, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 80.0 event: 2400 loss: tensor(1941.8625, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 100.0 event: 3000 loss: tensor(3850.5488, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 110.0 event: 3300 loss: tensor(1660.5879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 120.0 event: 3600 loss: tensor(1912.0787, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 130.0 event: 3900 loss: tensor(1565.9218, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 140.0 event: 4200 loss: tensor(1973.2402, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 150.0 event: 4500 loss: tensor(1791.5051, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 160.0 event: 4800 loss: tensor(1774.3851, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 170.0 event: 5100 loss: tensor(1995.6698, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 180.0 event: 5400 loss: tensor(2057.5078, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 190.0 event: 5700 loss: tensor(2020.6451, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 200.0 event: 6000 loss: tensor(1901.9182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 210.0 event: 6300 loss: tensor(1576.7336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 220.0 event: 6600 loss: tensor(2065.8115, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 230.0 event: 6900 loss: tensor(1823.4524, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 240.0 event: 7200 loss: tensor(2094.9868, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 250.0 event: 7500 loss: tensor(1884.8711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 260.0 event: 7800 loss: tensor(2013.7083, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 270.0 event: 8100 loss: tensor(1985.6195, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 280.0 event: 8400 loss: tensor(2019.2643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 290.0 event: 8700 loss: tensor(1730.6908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 300.0 event: 9000 loss: tensor(2050.7437, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 310.0 event: 9300 loss: tensor(1795.9387, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 320.0 event: 9600 loss: tensor(1936.5166, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 330.0 event: 9900 loss: tensor(1843.3256, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:50.434997
evaluation loss: 1702.3717041015625
epoch: 14 mean loss: 1913.8157958984375
epoch: 15 batch 0.0 event: 0 loss: tensor(183.2347, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 10.0 event: 300 loss: tensor(1996.5605, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 20.0 event: 600 loss: tensor(1966.0381, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 30.0 event: 900 loss: tensor(1881.1777, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 40.0 event: 1200 loss: tensor(1789.7855, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 50.0 event: 1500 loss: tensor(2028.8051, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 60.0 event: 1800 loss: tensor(1982.5956, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 70.0 event: 2100 loss: tensor(2018.4550, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 80.0 event: 2400 loss: tensor(1941.8522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 100.0 event: 3000 loss: tensor(3850.5442, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 110.0 event: 3300 loss: tensor(1660.5875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 120.0 event: 3600 loss: tensor(1912.0881, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 130.0 event: 3900 loss: tensor(1565.9307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 140.0 event: 4200 loss: tensor(1973.2275, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 150.0 event: 4500 loss: tensor(1791.4977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 160.0 event: 4800 loss: tensor(1774.3688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 170.0 event: 5100 loss: tensor(1995.6644, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 180.0 event: 5400 loss: tensor(2057.4958, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 190.0 event: 5700 loss: tensor(2020.6393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 200.0 event: 6000 loss: tensor(1901.9086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 210.0 event: 6300 loss: tensor(1576.7318, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 220.0 event: 6600 loss: tensor(2065.7744, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 230.0 event: 6900 loss: tensor(1823.4462, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 240.0 event: 7200 loss: tensor(2094.9888, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 250.0 event: 7500 loss: tensor(1884.8691, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 260.0 event: 7800 loss: tensor(2013.7037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 270.0 event: 8100 loss: tensor(1985.6283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 280.0 event: 8400 loss: tensor(2019.2621, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 290.0 event: 8700 loss: tensor(1730.6956, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 300.0 event: 9000 loss: tensor(2050.7266, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 310.0 event: 9300 loss: tensor(1795.9232, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 320.0 event: 9600 loss: tensor(1936.4957, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 330.0 event: 9900 loss: tensor(1843.2852, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:09:25.664726
evaluation loss: 1702.3668212890625
epoch: 15 mean loss: 1913.81005859375
=> saveing checkpoint at epoch 15
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 16 batch 0.0 event: 0 loss: tensor(183.2254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 10.0 event: 300 loss: tensor(1996.4862, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 20.0 event: 600 loss: tensor(1965.9479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 30.0 event: 900 loss: tensor(1881.0839, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 40.0 event: 1200 loss: tensor(1789.6934, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 50.0 event: 1500 loss: tensor(2028.7103, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 60.0 event: 1800 loss: tensor(1982.5803, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 70.0 event: 2100 loss: tensor(2018.4580, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 80.0 event: 2400 loss: tensor(1941.8590, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 100.0 event: 3000 loss: tensor(3850.6328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 110.0 event: 3300 loss: tensor(1660.6080, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 120.0 event: 3600 loss: tensor(1912.0918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 130.0 event: 3900 loss: tensor(1565.9069, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 140.0 event: 4200 loss: tensor(1973.1766, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 150.0 event: 4500 loss: tensor(1791.4432, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 160.0 event: 4800 loss: tensor(1774.3251, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 170.0 event: 5100 loss: tensor(1995.6176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 180.0 event: 5400 loss: tensor(2057.4507, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 190.0 event: 5700 loss: tensor(2020.5961, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 200.0 event: 6000 loss: tensor(1901.8827, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 210.0 event: 6300 loss: tensor(1576.7074, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 220.0 event: 6600 loss: tensor(2065.7449, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 230.0 event: 6900 loss: tensor(1823.4159, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 240.0 event: 7200 loss: tensor(2094.9519, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 250.0 event: 7500 loss: tensor(1884.8362, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 260.0 event: 7800 loss: tensor(2013.6752, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 270.0 event: 8100 loss: tensor(1985.6005, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 280.0 event: 8400 loss: tensor(2019.2367, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 290.0 event: 8700 loss: tensor(1730.6940, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 300.0 event: 9000 loss: tensor(2050.7183, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 310.0 event: 9300 loss: tensor(1795.9326, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 320.0 event: 9600 loss: tensor(1936.5194, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 330.0 event: 9900 loss: tensor(1843.3401, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:10:05.624829
evaluation loss: 1702.373291015625
epoch: 16 mean loss: 1913.78515625
epoch: 17 batch 0.0 event: 0 loss: tensor(183.2335, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 10.0 event: 300 loss: tensor(1996.5879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 20.0 event: 600 loss: tensor(1966.0477, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 30.0 event: 900 loss: tensor(1881.1805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 40.0 event: 1200 loss: tensor(1789.7812, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 50.0 event: 1500 loss: tensor(2028.8040, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 60.0 event: 1800 loss: tensor(1982.5670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 70.0 event: 2100 loss: tensor(2018.4309, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 80.0 event: 2400 loss: tensor(1941.8303, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 100.0 event: 3000 loss: tensor(3850.5349, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 110.0 event: 3300 loss: tensor(1660.5790, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 120.0 event: 3600 loss: tensor(1912.0813, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 130.0 event: 3900 loss: tensor(1565.9159, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 140.0 event: 4200 loss: tensor(1973.2089, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 150.0 event: 4500 loss: tensor(1791.4684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 160.0 event: 4800 loss: tensor(1774.3401, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 170.0 event: 5100 loss: tensor(1995.6383, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 180.0 event: 5400 loss: tensor(2057.4626, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 190.0 event: 5700 loss: tensor(2020.5938, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 200.0 event: 6000 loss: tensor(1901.8783, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 210.0 event: 6300 loss: tensor(1576.7029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 220.0 event: 6600 loss: tensor(2065.8538, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 230.0 event: 6900 loss: tensor(1823.4104, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 240.0 event: 7200 loss: tensor(2094.9451, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 250.0 event: 7500 loss: tensor(1884.8196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 260.0 event: 7800 loss: tensor(2013.6656, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 270.0 event: 8100 loss: tensor(2003.8041, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 280.0 event: 8400 loss: tensor(2019.8213, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 290.0 event: 8700 loss: tensor(1731.0123, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 300.0 event: 9000 loss: tensor(2050.7346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 310.0 event: 9300 loss: tensor(1795.9047, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 320.0 event: 9600 loss: tensor(1936.4971, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 330.0 event: 9900 loss: tensor(1843.2428, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:10:40.881443
evaluation loss: 1702.4017333984375
epoch: 17 mean loss: 1914.3690185546875
epoch: 18 batch 0.0 event: 0 loss: tensor(183.2335, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 10.0 event: 300 loss: tensor(1996.4437, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 20.0 event: 600 loss: tensor(1966.0540, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 30.0 event: 900 loss: tensor(1881.1591, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 40.0 event: 1200 loss: tensor(1789.7675, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 50.0 event: 1500 loss: tensor(2028.7881, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 60.0 event: 1800 loss: tensor(1982.6243, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 70.0 event: 2100 loss: tensor(2018.4633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 80.0 event: 2400 loss: tensor(1941.8369, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 100.0 event: 3000 loss: tensor(3850.5916, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 110.0 event: 3300 loss: tensor(1660.5908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 120.0 event: 3600 loss: tensor(1912.1514, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 130.0 event: 3900 loss: tensor(1565.9169, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 140.0 event: 4200 loss: tensor(1973.1842, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 150.0 event: 4500 loss: tensor(1791.4352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 160.0 event: 4800 loss: tensor(1774.2936, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 170.0 event: 5100 loss: tensor(1995.5657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 180.0 event: 5400 loss: tensor(2057.4080, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 190.0 event: 5700 loss: tensor(2020.5677, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 200.0 event: 6000 loss: tensor(1901.8258, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 210.0 event: 6300 loss: tensor(1576.6610, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 220.0 event: 6600 loss: tensor(2065.6926, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 230.0 event: 6900 loss: tensor(1823.3838, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 240.0 event: 7200 loss: tensor(2094.8972, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 250.0 event: 7500 loss: tensor(1884.7776, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 260.0 event: 7800 loss: tensor(2013.6448, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 270.0 event: 8100 loss: tensor(1985.5276, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 280.0 event: 8400 loss: tensor(2019.3102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 290.0 event: 8700 loss: tensor(1730.7281, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 300.0 event: 9000 loss: tensor(2050.7849, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 310.0 event: 9300 loss: tensor(1795.9608, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 320.0 event: 9600 loss: tensor(1936.5325, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 330.0 event: 9900 loss: tensor(1843.3096, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:11:16.110356
evaluation loss: 1702.3876953125
epoch: 18 mean loss: 1913.7833251953125
epoch: 19 batch 0.0 event: 0 loss: tensor(183.2284, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 10.0 event: 300 loss: tensor(1996.5631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 20.0 event: 600 loss: tensor(1966.0111, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 30.0 event: 900 loss: tensor(1881.1005, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 40.0 event: 1200 loss: tensor(1789.7275, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 50.0 event: 1500 loss: tensor(2028.7539, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 60.0 event: 1800 loss: tensor(1982.5201, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 70.0 event: 2100 loss: tensor(2018.3864, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 80.0 event: 2400 loss: tensor(1941.7928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 100.0 event: 3000 loss: tensor(3850.5254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 110.0 event: 3300 loss: tensor(1660.5742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 120.0 event: 3600 loss: tensor(1912.1346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 130.0 event: 3900 loss: tensor(1565.9250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 140.0 event: 4200 loss: tensor(1973.2343, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 150.0 event: 4500 loss: tensor(1791.4821, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 160.0 event: 4800 loss: tensor(1774.3320, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 170.0 event: 5100 loss: tensor(1995.6113, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 180.0 event: 5400 loss: tensor(2057.4382, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 190.0 event: 5700 loss: tensor(2020.5579, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 200.0 event: 6000 loss: tensor(1901.8219, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 210.0 event: 6300 loss: tensor(1576.6450, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 220.0 event: 6600 loss: tensor(2065.6897, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 230.0 event: 6900 loss: tensor(1823.3629, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 240.0 event: 7200 loss: tensor(2094.8728, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 250.0 event: 7500 loss: tensor(1884.7372, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 260.0 event: 7800 loss: tensor(2013.6151, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 270.0 event: 8100 loss: tensor(1985.5342, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 280.0 event: 8400 loss: tensor(2019.2526, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 290.0 event: 8700 loss: tensor(1730.6875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 300.0 event: 9000 loss: tensor(2050.7661, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 310.0 event: 9300 loss: tensor(1795.9664, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 320.0 event: 9600 loss: tensor(1936.5641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 330.0 event: 9900 loss: tensor(1843.3815, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:11:51.347419
evaluation loss: 1702.3707275390625
epoch: 19 mean loss: 1913.7750244140625
epoch: 20 batch 0.0 event: 0 loss: tensor(183.2346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 10.0 event: 300 loss: tensor(1996.6764, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 20.0 event: 600 loss: tensor(1966.1090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 30.0 event: 900 loss: tensor(1881.2291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 40.0 event: 1200 loss: tensor(1789.8427, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 50.0 event: 1500 loss: tensor(2028.8710, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 60.0 event: 1800 loss: tensor(1982.5668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 70.0 event: 2100 loss: tensor(2018.4528, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 80.0 event: 2400 loss: tensor(1941.8549, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 100.0 event: 3000 loss: tensor(3850.4851, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 110.0 event: 3300 loss: tensor(1660.5707, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 120.0 event: 3600 loss: tensor(1912.0801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 130.0 event: 3900 loss: tensor(1565.9122, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 140.0 event: 4200 loss: tensor(1973.2061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 150.0 event: 4500 loss: tensor(1791.4677, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 160.0 event: 4800 loss: tensor(1774.3307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 170.0 event: 5100 loss: tensor(1995.6233, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 180.0 event: 5400 loss: tensor(2057.4612, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 190.0 event: 5700 loss: tensor(2020.5852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 200.0 event: 6000 loss: tensor(1901.8490, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 210.0 event: 6300 loss: tensor(1576.6643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 220.0 event: 6600 loss: tensor(2065.7239, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 230.0 event: 6900 loss: tensor(1823.3857, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 240.0 event: 7200 loss: tensor(2094.9233, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 250.0 event: 7500 loss: tensor(1884.7711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 260.0 event: 7800 loss: tensor(2013.6311, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 270.0 event: 8100 loss: tensor(1985.5638, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 280.0 event: 8400 loss: tensor(2019.2090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 290.0 event: 8700 loss: tensor(1730.6458, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 300.0 event: 9000 loss: tensor(2050.7009, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 310.0 event: 9300 loss: tensor(1795.9059, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 320.0 event: 9600 loss: tensor(1936.4847, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 330.0 event: 9900 loss: tensor(1843.3026, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:12:26.572101
evaluation loss: 1702.3541259765625
epoch: 20 mean loss: 1913.7896728515625
=> saveing checkpoint at epoch 20
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 21 batch 0.0 event: 0 loss: tensor(183.2256, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 10.0 event: 300 loss: tensor(1996.5814, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 20.0 event: 600 loss: tensor(1966.0319, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 30.0 event: 900 loss: tensor(1881.1864, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 40.0 event: 1200 loss: tensor(1789.7748, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 50.0 event: 1500 loss: tensor(2028.8082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 60.0 event: 1800 loss: tensor(1982.5227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 70.0 event: 2100 loss: tensor(2018.4027, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 80.0 event: 2400 loss: tensor(1941.8109, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 100.0 event: 3000 loss: tensor(3850.4512, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 110.0 event: 3300 loss: tensor(1660.5569, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 120.0 event: 3600 loss: tensor(1912.0811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 130.0 event: 3900 loss: tensor(1565.9193, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 140.0 event: 4200 loss: tensor(1973.2014, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 150.0 event: 4500 loss: tensor(1791.4681, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 160.0 event: 4800 loss: tensor(1774.3275, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 170.0 event: 5100 loss: tensor(1995.6195, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 180.0 event: 5400 loss: tensor(2057.4587, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 190.0 event: 5700 loss: tensor(2020.5902, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 200.0 event: 6000 loss: tensor(1901.8583, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 210.0 event: 6300 loss: tensor(1576.6724, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 220.0 event: 6600 loss: tensor(2065.7388, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 230.0 event: 6900 loss: tensor(1823.3929, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 240.0 event: 7200 loss: tensor(2094.9373, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 250.0 event: 7500 loss: tensor(1884.7864, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 260.0 event: 7800 loss: tensor(2013.6376, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 270.0 event: 8100 loss: tensor(1985.5736, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 280.0 event: 8400 loss: tensor(2019.1965, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 290.0 event: 8700 loss: tensor(1730.6356, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 300.0 event: 9000 loss: tensor(2050.6804, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 310.0 event: 9300 loss: tensor(1795.8870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 320.0 event: 9600 loss: tensor(1936.4561, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 330.0 event: 9900 loss: tensor(1843.2760, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:13:06.572603
evaluation loss: 1702.347900390625
epoch: 21 mean loss: 1913.7725830078125
epoch: 22 batch 0.0 event: 0 loss: tensor(183.2216, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 10.0 event: 300 loss: tensor(1996.5481, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 20.0 event: 600 loss: tensor(1966.0012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 30.0 event: 900 loss: tensor(1881.1244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 40.0 event: 1200 loss: tensor(1789.7460, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 50.0 event: 1500 loss: tensor(2028.7822, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 60.0 event: 1800 loss: tensor(1982.5039, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 70.0 event: 2100 loss: tensor(2018.3822, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 80.0 event: 2400 loss: tensor(1941.7942, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 100.0 event: 3000 loss: tensor(3850.4324, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 110.0 event: 3300 loss: tensor(1660.5475, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 120.0 event: 3600 loss: tensor(1912.0726, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 130.0 event: 3900 loss: tensor(1565.9117, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 140.0 event: 4200 loss: tensor(1973.1926, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 150.0 event: 4500 loss: tensor(1791.4602, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 160.0 event: 4800 loss: tensor(1774.3176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 170.0 event: 5100 loss: tensor(1995.6080, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 180.0 event: 5400 loss: tensor(2057.4490, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 190.0 event: 5700 loss: tensor(2020.5771, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 200.0 event: 6000 loss: tensor(1901.8479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 210.0 event: 6300 loss: tensor(1576.6648, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 220.0 event: 6600 loss: tensor(2065.7341, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 230.0 event: 6900 loss: tensor(1823.3861, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 240.0 event: 7200 loss: tensor(2094.9343, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 250.0 event: 7500 loss: tensor(1884.7836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 260.0 event: 7800 loss: tensor(2013.6344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 270.0 event: 8100 loss: tensor(1985.5706, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 280.0 event: 8400 loss: tensor(2019.1881, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 290.0 event: 8700 loss: tensor(1730.6307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 300.0 event: 9000 loss: tensor(2050.6707, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 310.0 event: 9300 loss: tensor(1795.8795, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 320.0 event: 9600 loss: tensor(1936.4424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 330.0 event: 9900 loss: tensor(1843.2621, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:13:41.839266
evaluation loss: 1702.3450927734375
epoch: 22 mean loss: 1913.75927734375
epoch: 23 batch 0.0 event: 0 loss: tensor(183.2193, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 10.0 event: 300 loss: tensor(1996.5336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 20.0 event: 600 loss: tensor(1965.9823, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 30.0 event: 900 loss: tensor(1881.1057, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 40.0 event: 1200 loss: tensor(1789.7294, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 50.0 event: 1500 loss: tensor(2028.7684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 60.0 event: 1800 loss: tensor(1982.4893, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 70.0 event: 2100 loss: tensor(2018.3688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 80.0 event: 2400 loss: tensor(1941.7848, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 100.0 event: 3000 loss: tensor(3850.4192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 110.0 event: 3300 loss: tensor(1660.5420, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 120.0 event: 3600 loss: tensor(1912.0676, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 130.0 event: 3900 loss: tensor(1565.9082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 140.0 event: 4200 loss: tensor(1973.1868, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 150.0 event: 4500 loss: tensor(1791.4541, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 160.0 event: 4800 loss: tensor(1774.3088, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 170.0 event: 5100 loss: tensor(1995.5979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 180.0 event: 5400 loss: tensor(2057.4395, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 190.0 event: 5700 loss: tensor(2020.5621, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 200.0 event: 6000 loss: tensor(1901.8353, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 210.0 event: 6300 loss: tensor(1576.6539, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 220.0 event: 6600 loss: tensor(2065.7246, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 230.0 event: 6900 loss: tensor(1823.3749, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 240.0 event: 7200 loss: tensor(2094.9253, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 250.0 event: 7500 loss: tensor(1884.7766, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 260.0 event: 7800 loss: tensor(2013.6279, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 270.0 event: 8100 loss: tensor(1985.5645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 280.0 event: 8400 loss: tensor(2019.1810, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 290.0 event: 8700 loss: tensor(1730.6279, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 300.0 event: 9000 loss: tensor(2050.6650, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 310.0 event: 9300 loss: tensor(1795.8762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 320.0 event: 9600 loss: tensor(1936.4344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 330.0 event: 9900 loss: tensor(1843.2535, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:14:17.061989
evaluation loss: 1702.3426513671875
epoch: 23 mean loss: 1913.7484130859375
epoch: 24 batch 0.0 event: 0 loss: tensor(183.2177, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 10.0 event: 300 loss: tensor(1996.5254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 20.0 event: 600 loss: tensor(1965.9667, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 30.0 event: 900 loss: tensor(1881.0902, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 40.0 event: 1200 loss: tensor(1789.7137, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 50.0 event: 1500 loss: tensor(2028.7559, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 60.0 event: 1800 loss: tensor(1982.4749, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 70.0 event: 2100 loss: tensor(2018.3551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 80.0 event: 2400 loss: tensor(1941.7756, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 100.0 event: 3000 loss: tensor(3850.4067, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 110.0 event: 3300 loss: tensor(1660.5375, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 120.0 event: 3600 loss: tensor(1912.0637, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 130.0 event: 3900 loss: tensor(1565.9056, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 140.0 event: 4200 loss: tensor(1973.1826, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 150.0 event: 4500 loss: tensor(1791.4495, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 160.0 event: 4800 loss: tensor(1774.3020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 170.0 event: 5100 loss: tensor(1995.5895, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 180.0 event: 5400 loss: tensor(2057.4316, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 190.0 event: 5700 loss: tensor(2020.5485, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 200.0 event: 6000 loss: tensor(1901.8235, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 210.0 event: 6300 loss: tensor(1576.6431, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 220.0 event: 6600 loss: tensor(2065.7144, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 230.0 event: 6900 loss: tensor(1823.3623, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 240.0 event: 7200 loss: tensor(2094.9136, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 250.0 event: 7500 loss: tensor(1884.7659, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 260.0 event: 7800 loss: tensor(2013.6200, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 270.0 event: 8100 loss: tensor(1985.5563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 280.0 event: 8400 loss: tensor(2019.1748, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 290.0 event: 8700 loss: tensor(1730.6260, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 300.0 event: 9000 loss: tensor(2050.6628, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 310.0 event: 9300 loss: tensor(1795.8768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 320.0 event: 9600 loss: tensor(1936.4305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 330.0 event: 9900 loss: tensor(1843.2496, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:14:52.319403
evaluation loss: 1702.3406982421875
epoch: 24 mean loss: 1913.7408447265625
epoch: 25 batch 0.0 event: 0 loss: tensor(183.2168, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 10.0 event: 300 loss: tensor(1996.5228, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 20.0 event: 600 loss: tensor(1965.9554, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 30.0 event: 900 loss: tensor(1881.0774, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 40.0 event: 1200 loss: tensor(1789.7004, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 50.0 event: 1500 loss: tensor(2028.7430, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 60.0 event: 1800 loss: tensor(1982.4586, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 70.0 event: 2100 loss: tensor(2018.3387, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 80.0 event: 2400 loss: tensor(1941.7649, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 100.0 event: 3000 loss: tensor(3850.3933, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 110.0 event: 3300 loss: tensor(1660.5328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 120.0 event: 3600 loss: tensor(1912.0609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 130.0 event: 3900 loss: tensor(1565.9037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 140.0 event: 4200 loss: tensor(1973.1801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 150.0 event: 4500 loss: tensor(1791.4479, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 160.0 event: 4800 loss: tensor(1774.2987, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 170.0 event: 5100 loss: tensor(1995.5852, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 180.0 event: 5400 loss: tensor(2057.4275, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 190.0 event: 5700 loss: tensor(2020.5375, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 200.0 event: 6000 loss: tensor(1901.8145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 210.0 event: 6300 loss: tensor(1576.6328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 220.0 event: 6600 loss: tensor(2065.7046, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 230.0 event: 6900 loss: tensor(1823.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 240.0 event: 7200 loss: tensor(2094.8999, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 250.0 event: 7500 loss: tensor(1884.7520, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 260.0 event: 7800 loss: tensor(2013.6100, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 270.0 event: 8100 loss: tensor(1985.5455, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 280.0 event: 8400 loss: tensor(2019.1664, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 290.0 event: 8700 loss: tensor(1730.6230, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 300.0 event: 9000 loss: tensor(2050.6599, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 310.0 event: 9300 loss: tensor(1795.8785, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 320.0 event: 9600 loss: tensor(1936.4291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 330.0 event: 9900 loss: tensor(1843.2490, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:15:27.566732
evaluation loss: 1702.3387451171875
epoch: 25 mean loss: 1913.73388671875
=> saveing checkpoint at epoch 25
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 26 batch 0.0 event: 0 loss: tensor(183.2165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 10.0 event: 300 loss: tensor(1996.5247, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 20.0 event: 600 loss: tensor(1965.9482, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 30.0 event: 900 loss: tensor(1881.0670, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 40.0 event: 1200 loss: tensor(1789.6884, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 50.0 event: 1500 loss: tensor(2028.7317, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 60.0 event: 1800 loss: tensor(1982.4359, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 70.0 event: 2100 loss: tensor(2018.3049, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 80.0 event: 2400 loss: tensor(1941.7135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 100.0 event: 3000 loss: tensor(3850.3696, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 110.0 event: 3300 loss: tensor(1660.5159, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 120.0 event: 3600 loss: tensor(1912.0748, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 130.0 event: 3900 loss: tensor(1565.8865, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 140.0 event: 4200 loss: tensor(1973.1924, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 150.0 event: 4500 loss: tensor(1791.4635, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 160.0 event: 4800 loss: tensor(1774.3105, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 170.0 event: 5100 loss: tensor(1995.5914, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 180.0 event: 5400 loss: tensor(2057.4297, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 190.0 event: 5700 loss: tensor(2020.5117, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 200.0 event: 6000 loss: tensor(1901.7913, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 210.0 event: 6300 loss: tensor(1576.6035, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 220.0 event: 6600 loss: tensor(2065.6697, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 230.0 event: 6900 loss: tensor(1823.3207, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 240.0 event: 7200 loss: tensor(2094.8630, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 250.0 event: 7500 loss: tensor(1884.7073, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 260.0 event: 7800 loss: tensor(2013.5793, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 270.0 event: 8100 loss: tensor(1985.5165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 280.0 event: 8400 loss: tensor(2019.1442, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 290.0 event: 8700 loss: tensor(1730.6074, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 300.0 event: 9000 loss: tensor(2050.6501, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 310.0 event: 9300 loss: tensor(1795.8746, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 320.0 event: 9600 loss: tensor(1936.4283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 330.0 event: 9900 loss: tensor(1843.2477, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:16:07.982522
evaluation loss: 1702.347900390625
epoch: 26 mean loss: 1913.71875
epoch: 27 batch 0.0 event: 0 loss: tensor(183.2167, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 10.0 event: 300 loss: tensor(1996.5367, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 20.0 event: 600 loss: tensor(1965.9467, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 30.0 event: 900 loss: tensor(1881.0712, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 40.0 event: 1200 loss: tensor(1789.6842, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 50.0 event: 1500 loss: tensor(2028.7258, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 60.0 event: 1800 loss: tensor(1982.4291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 70.0 event: 2100 loss: tensor(2018.3086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 80.0 event: 2400 loss: tensor(1941.7480, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 100.0 event: 3000 loss: tensor(3850.3767, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 110.0 event: 3300 loss: tensor(1660.5312, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 120.0 event: 3600 loss: tensor(1912.0605, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 130.0 event: 3900 loss: tensor(1565.9042, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 140.0 event: 4200 loss: tensor(1973.1838, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 150.0 event: 4500 loss: tensor(1791.4489, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 160.0 event: 4800 loss: tensor(1774.2981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 170.0 event: 5100 loss: tensor(1995.5823, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 180.0 event: 5400 loss: tensor(2057.4233, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 190.0 event: 5700 loss: tensor(2020.5201, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 200.0 event: 6000 loss: tensor(1901.7977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 210.0 event: 6300 loss: tensor(1576.6105, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 220.0 event: 6600 loss: tensor(2065.6804, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 230.0 event: 6900 loss: tensor(1823.3202, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 240.0 event: 7200 loss: tensor(2094.8645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 250.0 event: 7500 loss: tensor(1884.7102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 260.0 event: 7800 loss: tensor(2013.5780, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 270.0 event: 8100 loss: tensor(1985.5131, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 280.0 event: 8400 loss: tensor(2019.1385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 290.0 event: 8700 loss: tensor(1730.6071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 300.0 event: 9000 loss: tensor(2050.6492, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 310.0 event: 9300 loss: tensor(1795.8792, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 320.0 event: 9600 loss: tensor(1936.4296, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 330.0 event: 9900 loss: tensor(1843.2523, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:16:43.251127
evaluation loss: 1702.339111328125
epoch: 27 mean loss: 1913.7203369140625
epoch: 28 batch 0.0 event: 0 loss: tensor(183.2180, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 10.0 event: 300 loss: tensor(1996.5458, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 20.0 event: 600 loss: tensor(1965.9534, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 30.0 event: 900 loss: tensor(1881.0668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 40.0 event: 1200 loss: tensor(1789.6848, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 50.0 event: 1500 loss: tensor(2028.7246, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 60.0 event: 1800 loss: tensor(1982.4102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 70.0 event: 2100 loss: tensor(2018.2831, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 80.0 event: 2400 loss: tensor(1941.7217, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 100.0 event: 3000 loss: tensor(3850.3301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 110.0 event: 3300 loss: tensor(1660.5045, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 120.0 event: 3600 loss: tensor(1912.0438, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 130.0 event: 3900 loss: tensor(1565.8875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 140.0 event: 4200 loss: tensor(1973.1669, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 150.0 event: 4500 loss: tensor(1791.4424, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 160.0 event: 4800 loss: tensor(1774.2977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 170.0 event: 5100 loss: tensor(1995.5834, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 180.0 event: 5400 loss: tensor(2057.4343, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 190.0 event: 5700 loss: tensor(2020.5331, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 200.0 event: 6000 loss: tensor(1901.8108, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 210.0 event: 6300 loss: tensor(1576.6194, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 220.0 event: 6600 loss: tensor(2065.6917, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 230.0 event: 6900 loss: tensor(1823.3268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 240.0 event: 7200 loss: tensor(2094.8638, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 250.0 event: 7500 loss: tensor(1884.7045, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 260.0 event: 7800 loss: tensor(2013.5674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 270.0 event: 8100 loss: tensor(1985.5016, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 280.0 event: 8400 loss: tensor(2019.1188, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 290.0 event: 8700 loss: tensor(1730.5908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 300.0 event: 9000 loss: tensor(2050.6321, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 310.0 event: 9300 loss: tensor(1795.8680, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 320.0 event: 9600 loss: tensor(1936.4196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 330.0 event: 9900 loss: tensor(1843.2463, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:17:18.532728
evaluation loss: 1702.3363037109375
epoch: 28 mean loss: 1913.712646484375
epoch: 29 batch 0.0 event: 0 loss: tensor(183.2181, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 10.0 event: 300 loss: tensor(1996.5492, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 20.0 event: 600 loss: tensor(1965.9561, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 30.0 event: 900 loss: tensor(1881.0712, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 40.0 event: 1200 loss: tensor(1789.6914, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 50.0 event: 1500 loss: tensor(2028.7307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 60.0 event: 1800 loss: tensor(1982.4039, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 70.0 event: 2100 loss: tensor(2018.2731, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 80.0 event: 2400 loss: tensor(1941.7090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 100.0 event: 3000 loss: tensor(3850.2986, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 110.0 event: 3300 loss: tensor(1660.4879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 120.0 event: 3600 loss: tensor(1912.0273, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 130.0 event: 3900 loss: tensor(1565.8723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 140.0 event: 4200 loss: tensor(1973.1516, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 150.0 event: 4500 loss: tensor(1791.4291, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 160.0 event: 4800 loss: tensor(1774.2893, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 170.0 event: 5100 loss: tensor(1995.5774, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 180.0 event: 5400 loss: tensor(2057.4360, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 190.0 event: 5700 loss: tensor(2020.5400, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 200.0 event: 6000 loss: tensor(1901.8173, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 210.0 event: 6300 loss: tensor(1576.6251, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 220.0 event: 6600 loss: tensor(2065.6987, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 230.0 event: 6900 loss: tensor(1823.3323, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 240.0 event: 7200 loss: tensor(2094.8650, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 250.0 event: 7500 loss: tensor(1884.7014, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 260.0 event: 7800 loss: tensor(2013.5602, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 270.0 event: 8100 loss: tensor(1985.4926, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 280.0 event: 8400 loss: tensor(2019.1012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 290.0 event: 8700 loss: tensor(1730.5745, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 300.0 event: 9000 loss: tensor(2050.6150, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 310.0 event: 9300 loss: tensor(1795.8549, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 320.0 event: 9600 loss: tensor(1936.4065, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 330.0 event: 9900 loss: tensor(1843.2354, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:19:12.764591
evaluation loss: 1702.3365478515625
epoch: 29 mean loss: 1913.706298828125
=> saveing checkpoint at epoch 29
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2

outi tensor([[ 0.6888,  0.6581,  0.6610,  ..., -0.4018, -0.3875, -0.3903],
        [ 0.6888,  0.6581,  0.6610,  ..., -0.4018, -0.3875, -0.3903],
        [ 0.6888,  0.6581,  0.6610,  ..., -0.4018, -0.3875, -0.3903],
        ...,
        [ 0.6888,  0.6581,  0.6610,  ..., -0.4018, -0.3875, -0.3903],
        [ 0.6888,  0.6581,  0.6610,  ..., -0.4018, -0.3875, -0.3903],
        [ 0.6888,  0.6581,  0.6610,  ..., -0.4018, -0.3875, -0.3903]],
       device='cuda:0', grad_fn=<AddmmBackward0>) 
 torch.Size([30, 6796]) 
 tensor(-13794.9297, device='cuda:0', grad_fn=<SumBackward0>) 
 tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0') 
 tensor(203880, device='cuda:0')



training loss:
 [1923.08190918 1917.0222168  1914.16992188 1914.09655762 1914.05651855
 1914.0045166  1913.97155762 1913.94445801 1913.91784668 1913.89904785
 1913.88049316 1913.86035156 1913.84802246 1913.89404297 1913.8157959
 1913.81005859 1913.78515625 1914.36901855 1913.7833252  1913.77502441
 1913.78967285 1913.77258301 1913.75927734 1913.74841309 1913.74084473
 1913.73388672 1913.71875    1913.72033691 1913.71264648 1913.70629883] 

\evaluation loss:
 [1704.57214355 1703.50097656 1702.56408691 1702.49963379 1702.46716309
 1702.44628906 1702.42578125 1702.41101074 1702.39709473 1702.39416504
 1702.38537598 1702.38220215 1702.37854004 1702.37854004 1702.3717041
 1702.36682129 1702.37329102 1702.4017334  1702.38769531 1702.37072754
 1702.35412598 1702.34790039 1702.34509277 1702.34265137 1702.34069824
 1702.33874512 1702.34790039 1702.33911133 1702.33630371 1702.33654785]



eval_efficiency:
 [5.04894476e-01 4.92201625e-01 4.79378514e-01 4.65671818e-01
 4.53037130e-01 4.40115794e-01 4.27304243e-01 4.14500612e-01
 4.01932005e-01 3.90614629e-01 3.80291406e-01 3.71409465e-01
 3.61729731e-01 3.52079469e-01 3.44074903e-01 3.36880905e-01
 3.29721805e-01 3.21656257e-01 3.14348188e-01 3.07630360e-01
 3.01881184e-01 2.96036538e-01 2.90825667e-01 2.85730071e-01
 2.80384330e-01 2.75038979e-01 2.69797579e-01 2.64642226e-01
 2.59816193e-01 2.54500161e-01 2.49551523e-01 2.44407957e-01
 2.39382944e-01 2.34584468e-01 2.29068777e-01 2.23929160e-01
 2.18174451e-01 2.12441701e-01 2.06997430e-01 2.01525276e-01
 1.95712099e-01 1.89899568e-01 1.83855976e-01 1.77427342e-01
 1.71125298e-01 1.64813134e-01 1.57988880e-01 1.51194083e-01
 1.44602883e-01 1.38354331e-01 1.31889015e-01 1.25360480e-01
 1.19216040e-01 1.13053329e-01 1.06795239e-01 1.01792857e-01
 9.64232162e-02 9.16569316e-02 8.70547444e-02 8.38296606e-02
 8.04276791e-02 7.72688617e-02 7.38819949e-02 7.10246116e-02
 6.82894680e-02 6.54811561e-02 6.29611973e-02 5.95082529e-02
 5.63546597e-02 5.32454259e-02 5.03346269e-02 4.71771316e-02
 4.41263355e-02 4.12385658e-02 3.84565895e-02 3.58980806e-02
 3.27756848e-02 2.95783785e-02 2.60414764e-02 2.24020866e-02
 1.99307333e-02 1.65699033e-02 1.37466969e-02 1.13569999e-02
 9.60936723e-03 7.84534693e-03 5.98288207e-03 4.69248703e-03
 3.49076547e-03 2.70663166e-03 2.00617481e-03 1.82041255e-03
 1.09372786e-03 6.73209361e-04 6.93465299e-04 7.01364528e-04
 1.55884642e-04 1.55884642e-04            nan            nan] 


eval_purity:
 [0.77494749 0.77299194 0.77086524 0.76855839 0.76654424 0.76435333
 0.76153263 0.75921244 0.75645113 0.75414283 0.75223151 0.75013737
 0.74813004 0.74564913 0.74342698 0.74170277 0.73987487 0.73745944
 0.73529324 0.73301241 0.73093761 0.7287133  0.72631334 0.7244689
 0.72255759 0.72005485 0.71788883 0.71519819 0.71248324 0.70982641
 0.70708673 0.70405486 0.70129206 0.69852081 0.69500656 0.69160344
 0.68803076 0.68476902 0.68125156 0.67744786 0.67380647 0.66974621
 0.66568128 0.66077129 0.65659816 0.65191289 0.64601284 0.6398927
 0.63406291 0.62784934 0.62084817 0.61392095 0.60693451 0.59975046
 0.59163542 0.58483865 0.57731256 0.57016898 0.56365272 0.5592599
 0.5547803  0.55221829 0.54790376 0.5461176  0.54559666 0.54434619
 0.5438013  0.54158882 0.54129172 0.54066123 0.54351174 0.54170948
 0.53906843 0.5377903  0.5381396  0.53934519 0.5396545  0.53713711
 0.53630767 0.53630622 0.53897719 0.54258737 0.5376531  0.54000647
 0.5519449  0.55953403 0.56581882 0.57631429 0.58128254 0.57806895
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan]

Passing event 10003 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([ 0.6898,  0.6592,  0.6634,  ..., -0.4035, -0.3889, -0.3918],
       device='cuda:0', grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10003 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([ 0.0839,  0.0419,  0.0845,  ..., -0.0906,  0.0721, -0.0222],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network before training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([ 0.6898,  0.6592,  0.6634,  ..., -0.4035, -0.3889, -0.3918],
       device='cuda:0', grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network after training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([ 0.0836,  0.0418,  0.0843,  ..., -0.0908,  0.0721, -0.0218],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([ 0.6898,  0.6592,  0.6634,  ..., -0.4035, -0.3889, -0.3918],
       device='cuda:0', grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([ 0.0838,  0.0416,  0.0843,  ..., -0.0906,  0.0719, -0.0219],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

real	21m15.610s
user	21m58.643s
sys	10m33.310s
