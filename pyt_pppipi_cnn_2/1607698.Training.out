0: gpu021.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ac352fa0-e553-4a4b-9138-f546b3cbd7bb)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        C2:44:16:3E:F4:B2:32:61:B4:43:86:F6:64:80:CC:44:95:DA:BA:12
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Thu Sep  1 06:30:16 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1D:00.0 Off |                    0 |
| N/A   33C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b0bc7f0a8e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m4.668s
user	0m2.681s
sys	0m0.831s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")




 Training ... 






 The Network ... 







 Loading data ... 



training set shape (20000, 43, 288) 
sum 5279207

target set shape (20000, 6796) 
sum 4575851
Net(
  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=667776, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=64, bias=True)
  (fc4): Linear(in_features=64, out_features=6796, bias=True)
)

number of the free parameters: 171805196
parameters of the network conv1.weight 
 torch.Size([256, 1, 3, 3]) 
 True 
 tensor([[[[ 0.1365,  0.0634,  0.1282],
          [ 0.3034,  0.0424,  0.2197],
          [-0.0846, -0.2672,  0.3159]]],


        [[[-0.0439, -0.3265, -0.0232],
          [ 0.0054, -0.1233, -0.3020],
          [ 0.3055,  0.0485,  0.2305]]],


        [[[ 0.1208, -0.1645,  0.1958],
          [-0.1214, -0.3283, -0.2164],
          [-0.1885,  0.1984,  0.2014]]],


        ...,


        [[[ 0.2418, -0.1105,  0.3108],
          [-0.2589,  0.0633,  0.0737],
          [ 0.1762,  0.2413,  0.1364]]],


        [[[ 0.0935, -0.0680, -0.2618],
          [-0.2221, -0.3325,  0.3108],
          [ 0.1375,  0.3238, -0.1645]]],


        [[[ 0.0966, -0.0138,  0.2438],
          [ 0.3302, -0.0782,  0.2465],
          [-0.1160,  0.2738,  0.3322]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 0.1365,  0.0634,  0.1282],
          [ 0.3034,  0.0424,  0.2197],
          [-0.0846, -0.2672,  0.3159]]],


        [[[-0.0439, -0.3265, -0.0232],
          [ 0.0054, -0.1233, -0.3020],
          [ 0.3055,  0.0485,  0.2305]]],


        [[[ 0.1208, -0.1645,  0.1958],
          [-0.1214, -0.3283, -0.2164],
          [-0.1885,  0.1984,  0.2014]]],


        ...,


        [[[ 0.2418, -0.1105,  0.3108],
          [-0.2589,  0.0633,  0.0737],
          [ 0.1762,  0.2413,  0.1364]]],


        [[[ 0.0935, -0.0680, -0.2618],
          [-0.2221, -0.3325,  0.3108],
          [ 0.1375,  0.3238, -0.1645]]],


        [[[ 0.0966, -0.0138,  0.2438],
          [ 0.3302, -0.0782,  0.2465],
          [-0.1160,  0.2738,  0.3322]]]], device='cuda:0', requires_grad=True)
parameters of the network conv1.bias 
 torch.Size([256]) 
 True 
 tensor([-0.3301, -0.3143,  0.2596, -0.3016,  0.1467,  0.2979,  0.2536, -0.1292,
         0.0624, -0.0516, -0.2673,  0.0853, -0.0952, -0.2302,  0.2147,  0.3253,
        -0.0070,  0.3164,  0.1630,  0.1089, -0.3141, -0.0496,  0.2092, -0.1959,
         0.1782, -0.2139,  0.0236,  0.1976, -0.0577, -0.2597,  0.0951,  0.3085,
         0.3036, -0.2008, -0.1623, -0.0144, -0.1473, -0.2016, -0.2512, -0.2220,
         0.2696,  0.0052, -0.3310,  0.1075, -0.2521, -0.2412,  0.1229,  0.0225,
         0.0737,  0.0350,  0.2876, -0.0177, -0.0573, -0.0254,  0.0398, -0.3219,
        -0.1076,  0.2699, -0.1188, -0.1774,  0.1873, -0.1937, -0.2190,  0.1176,
        -0.1862, -0.1306,  0.0842,  0.2177, -0.1512, -0.0774, -0.1403, -0.1685,
        -0.1377,  0.3057,  0.0493, -0.0768, -0.1334, -0.0216,  0.1364, -0.2795,
        -0.0167, -0.1339,  0.1355,  0.2275, -0.0481, -0.1562, -0.0718,  0.3317,
        -0.2993, -0.2353, -0.1190, -0.0309,  0.2908,  0.0827, -0.2634, -0.2757,
         0.1856, -0.0504, -0.2445, -0.0327,  0.1610, -0.0007, -0.1320, -0.0150,
        -0.1859, -0.1199,  0.1585, -0.2144,  0.1808,  0.2527, -0.1557,  0.0171,
        -0.0340,  0.0066,  0.1837, -0.1571, -0.2975, -0.2493, -0.2703, -0.2163,
        -0.2250, -0.0351, -0.0228, -0.0496, -0.0884, -0.0466,  0.0157, -0.1300,
         0.3034,  0.0009, -0.0608, -0.0918,  0.1466,  0.1433, -0.2690, -0.2057,
         0.3204,  0.3295,  0.0164,  0.3201,  0.2074, -0.1526, -0.2757, -0.2446,
         0.1179,  0.1245,  0.2031,  0.0709, -0.2448,  0.2108, -0.1685,  0.1096,
         0.0674, -0.2637, -0.0805,  0.3018, -0.1218,  0.0566,  0.2822,  0.0613,
        -0.0407, -0.0025, -0.2585, -0.2118,  0.3061,  0.2972, -0.2987, -0.0646,
         0.0259,  0.2497, -0.2157,  0.0733,  0.2167,  0.1202,  0.0034, -0.2196,
         0.1668, -0.2597,  0.2115,  0.3191, -0.0229, -0.1223, -0.1098, -0.0931,
        -0.1908,  0.0660,  0.1668, -0.0974,  0.0235,  0.0641, -0.1592, -0.0794,
         0.0712,  0.1607,  0.2750, -0.1182, -0.2408,  0.2274,  0.0237,  0.0886,
        -0.0940,  0.1444,  0.1362, -0.2689,  0.2667,  0.2062, -0.0928, -0.0380,
        -0.3322, -0.0050,  0.1441, -0.0733, -0.1347,  0.0500,  0.0429, -0.0491,
        -0.3169, -0.1599, -0.0736,  0.0871, -0.3276,  0.1705, -0.2864,  0.2323,
        -0.3301, -0.1291,  0.2886,  0.2735, -0.0632, -0.1541, -0.2002,  0.2158,
        -0.0064,  0.0635, -0.0363,  0.0048, -0.2354,  0.1227,  0.0618,  0.3218,
        -0.3227,  0.0427, -0.1370, -0.0772,  0.0139,  0.0041, -0.1122,  0.0891,
         0.0354, -0.0595, -0.1697,  0.0046,  0.1868,  0.0263,  0.2966, -0.1496],
       device='cuda:0') 
 Parameter containing:
tensor([-0.3301, -0.3143,  0.2596, -0.3016,  0.1467,  0.2979,  0.2536, -0.1292,
         0.0624, -0.0516, -0.2673,  0.0853, -0.0952, -0.2302,  0.2147,  0.3253,
        -0.0070,  0.3164,  0.1630,  0.1089, -0.3141, -0.0496,  0.2092, -0.1959,
         0.1782, -0.2139,  0.0236,  0.1976, -0.0577, -0.2597,  0.0951,  0.3085,
         0.3036, -0.2008, -0.1623, -0.0144, -0.1473, -0.2016, -0.2512, -0.2220,
         0.2696,  0.0052, -0.3310,  0.1075, -0.2521, -0.2412,  0.1229,  0.0225,
         0.0737,  0.0350,  0.2876, -0.0177, -0.0573, -0.0254,  0.0398, -0.3219,
        -0.1076,  0.2699, -0.1188, -0.1774,  0.1873, -0.1937, -0.2190,  0.1176,
        -0.1862, -0.1306,  0.0842,  0.2177, -0.1512, -0.0774, -0.1403, -0.1685,
        -0.1377,  0.3057,  0.0493, -0.0768, -0.1334, -0.0216,  0.1364, -0.2795,
        -0.0167, -0.1339,  0.1355,  0.2275, -0.0481, -0.1562, -0.0718,  0.3317,
        -0.2993, -0.2353, -0.1190, -0.0309,  0.2908,  0.0827, -0.2634, -0.2757,
         0.1856, -0.0504, -0.2445, -0.0327,  0.1610, -0.0007, -0.1320, -0.0150,
        -0.1859, -0.1199,  0.1585, -0.2144,  0.1808,  0.2527, -0.1557,  0.0171,
        -0.0340,  0.0066,  0.1837, -0.1571, -0.2975, -0.2493, -0.2703, -0.2163,
        -0.2250, -0.0351, -0.0228, -0.0496, -0.0884, -0.0466,  0.0157, -0.1300,
         0.3034,  0.0009, -0.0608, -0.0918,  0.1466,  0.1433, -0.2690, -0.2057,
         0.3204,  0.3295,  0.0164,  0.3201,  0.2074, -0.1526, -0.2757, -0.2446,
         0.1179,  0.1245,  0.2031,  0.0709, -0.2448,  0.2108, -0.1685,  0.1096,
         0.0674, -0.2637, -0.0805,  0.3018, -0.1218,  0.0566,  0.2822,  0.0613,
        -0.0407, -0.0025, -0.2585, -0.2118,  0.3061,  0.2972, -0.2987, -0.0646,
         0.0259,  0.2497, -0.2157,  0.0733,  0.2167,  0.1202,  0.0034, -0.2196,
         0.1668, -0.2597,  0.2115,  0.3191, -0.0229, -0.1223, -0.1098, -0.0931,
        -0.1908,  0.0660,  0.1668, -0.0974,  0.0235,  0.0641, -0.1592, -0.0794,
         0.0712,  0.1607,  0.2750, -0.1182, -0.2408,  0.2274,  0.0237,  0.0886,
        -0.0940,  0.1444,  0.1362, -0.2689,  0.2667,  0.2062, -0.0928, -0.0380,
        -0.3322, -0.0050,  0.1441, -0.0733, -0.1347,  0.0500,  0.0429, -0.0491,
        -0.3169, -0.1599, -0.0736,  0.0871, -0.3276,  0.1705, -0.2864,  0.2323,
        -0.3301, -0.1291,  0.2886,  0.2735, -0.0632, -0.1541, -0.2002,  0.2158,
        -0.0064,  0.0635, -0.0363,  0.0048, -0.2354,  0.1227,  0.0618,  0.3218,
        -0.3227,  0.0427, -0.1370, -0.0772,  0.0139,  0.0041, -0.1122,  0.0891,
         0.0354, -0.0595, -0.1697,  0.0046,  0.1868,  0.0263,  0.2966, -0.1496],
       device='cuda:0', requires_grad=True)
parameters of the network conv2.weight 
 torch.Size([128, 256, 3, 3]) 
 True 
 tensor([[[[ 9.6523e-03,  1.8857e-02, -2.0635e-02],
          [ 5.3270e-03,  1.4328e-02, -1.4185e-02],
          [-1.7151e-02,  1.6000e-02,  1.0798e-02]],

         [[-1.5245e-02, -1.8752e-02, -4.4059e-03],
          [-8.8792e-03, -2.0131e-02, -1.9737e-02],
          [-1.5439e-02, -9.4015e-03, -1.8323e-02]],

         [[ 1.7097e-02,  2.0794e-02, -3.0245e-03],
          [ 1.3821e-02,  1.1073e-02, -1.8223e-02],
          [-3.8369e-03,  1.5777e-02,  1.4149e-02]],

         ...,

         [[ 8.6842e-03,  1.6215e-03,  1.3569e-02],
          [ 2.0711e-02, -2.0922e-03, -1.1631e-02],
          [-1.3673e-03, -1.1257e-02,  6.7959e-03]],

         [[ 3.7557e-03, -1.8036e-02, -5.3567e-03],
          [ 1.3854e-02, -1.7324e-02, -2.0774e-02],
          [-3.0345e-03, -8.0616e-04,  1.4631e-02]],

         [[ 2.0734e-02,  2.8000e-03,  1.0670e-02],
          [-1.1762e-02,  1.0680e-03, -1.7131e-02],
          [-4.7164e-03,  6.4863e-03, -1.1764e-02]]],


        [[[-1.7094e-02, -1.0081e-02, -7.0719e-03],
          [-2.0763e-02, -9.9568e-03, -1.4303e-02],
          [-1.5592e-02,  1.8146e-02,  2.9996e-03]],

         [[-1.9040e-02, -1.9274e-02, -7.3387e-03],
          [ 7.6573e-03, -7.8644e-03,  9.2295e-03],
          [ 1.3356e-02,  1.7302e-03, -4.3014e-03]],

         [[-1.0173e-02,  6.7769e-03,  1.2203e-02],
          [-2.8143e-03, -2.7564e-03,  1.1230e-02],
          [ 3.0779e-03, -1.0137e-02, -8.8210e-03]],

         ...,

         [[-1.8023e-02, -1.5240e-02, -1.2748e-02],
          [ 1.6826e-02, -3.0385e-03, -5.9470e-03],
          [-1.2211e-02, -1.9214e-02,  1.9738e-02]],

         [[ 8.7187e-03, -1.2111e-02,  1.1724e-02],
          [ 2.0109e-02,  1.4926e-02,  7.4265e-04],
          [ 1.8214e-02,  3.0723e-03,  1.7641e-02]],

         [[ 1.8506e-02,  1.1961e-02, -1.2326e-02],
          [ 2.7330e-03,  4.6137e-03, -6.8403e-03],
          [-1.1702e-02,  7.0226e-03,  1.0684e-02]]],


        [[[-2.0489e-02,  3.2249e-04, -1.3531e-02],
          [-1.0409e-02, -1.6456e-02,  1.5809e-02],
          [-1.7256e-02,  9.4350e-03, -7.4618e-03]],

         [[-8.1340e-03, -1.6273e-02, -9.5159e-03],
          [ 5.0177e-03,  1.7476e-04,  1.6053e-02],
          [-1.2659e-02, -1.2499e-02, -1.6123e-03]],

         [[ 1.1089e-02, -1.9049e-02,  1.7875e-02],
          [-1.8377e-02, -1.9802e-02,  1.5109e-02],
          [ 3.4052e-04,  9.5141e-03,  1.5208e-02]],

         ...,

         [[ 1.0274e-02, -1.0860e-02,  8.4504e-03],
          [-8.0987e-03,  6.6583e-03, -8.6819e-03],
          [ 2.0542e-02,  1.9885e-02, -1.4371e-02]],

         [[-2.6663e-03,  1.3536e-02, -9.1108e-04],
          [ 4.9406e-03, -1.5664e-02, -4.0086e-04],
          [ 1.9432e-02,  1.9640e-02, -1.6323e-02]],

         [[-2.0997e-03, -6.9756e-03,  1.8689e-02],
          [-1.4351e-02, -1.8876e-04, -7.3234e-03],
          [ 1.6859e-02,  4.1876e-03,  3.4434e-03]]],


        ...,


        [[[ 6.5481e-04, -1.0955e-02,  9.0845e-03],
          [-2.0453e-02, -1.3297e-02, -3.0511e-03],
          [ 2.8653e-03,  1.8174e-02,  1.0993e-02]],

         [[ 5.3097e-03,  1.2497e-02, -1.3083e-02],
          [-7.2331e-03, -1.1013e-02,  4.2739e-03],
          [ 2.5044e-03,  1.1624e-02,  1.6807e-02]],

         [[-2.4365e-03,  5.5354e-04, -1.5423e-03],
          [ 1.4944e-03, -4.7100e-03, -1.4307e-02],
          [-1.6624e-03, -1.9849e-02,  3.6362e-03]],

         ...,

         [[-2.0385e-03, -3.7616e-03,  3.8099e-03],
          [ 7.2245e-04,  1.8433e-02,  1.7452e-02],
          [-1.3441e-02,  1.7067e-03,  1.3826e-04]],

         [[-5.3270e-03,  2.6133e-03,  1.9654e-02],
          [ 1.1702e-02, -7.2242e-03, -1.8410e-02],
          [ 1.9709e-02,  1.0237e-02, -1.8945e-02]],

         [[-1.1785e-02, -8.1971e-03, -1.8714e-02],
          [-2.8370e-03, -4.1563e-03,  9.1840e-03],
          [ 3.4422e-03,  2.0151e-02, -1.5898e-02]]],


        [[[-1.7399e-02,  6.9736e-03,  1.2958e-02],
          [-1.3594e-02, -1.6910e-02, -4.7962e-03],
          [-3.2362e-03,  1.2976e-02,  6.1702e-03]],

         [[ 1.6628e-02,  9.9445e-03, -1.4950e-02],
          [-1.6286e-02, -2.0126e-02,  1.3142e-02],
          [ 1.4414e-02,  8.8897e-03,  1.4451e-02]],

         [[-1.2380e-02, -6.2399e-03, -2.2666e-03],
          [ 1.6831e-02, -9.6647e-03, -1.8286e-02],
          [ 1.2819e-02, -1.9449e-02,  3.9639e-03]],

         ...,

         [[ 5.6157e-03,  1.5936e-02,  1.7576e-02],
          [ 9.2463e-03, -1.9075e-02, -9.4090e-03],
          [-1.9510e-02, -1.2765e-02, -2.7594e-03]],

         [[ 1.1712e-02, -6.6999e-03, -7.4531e-03],
          [ 1.2634e-02,  8.7416e-03,  1.0879e-02],
          [-5.1442e-03,  1.6151e-02, -6.1956e-03]],

         [[-1.8044e-02, -1.2836e-02,  1.6444e-02],
          [ 7.0460e-03, -8.7291e-04,  1.9111e-02],
          [ 1.3073e-02, -5.6643e-03,  3.9583e-03]]],


        [[[ 2.6260e-03, -4.8641e-03, -1.8978e-02],
          [ 6.1085e-03,  6.6349e-03, -1.9355e-02],
          [-1.8983e-02, -5.1619e-03, -1.6886e-02]],

         [[ 1.9689e-02, -4.8627e-03,  1.3331e-03],
          [-1.2137e-02, -2.5957e-03,  2.1985e-03],
          [-6.5756e-03,  1.6766e-02,  5.4637e-03]],

         [[ 1.2748e-05,  1.3803e-02,  1.0038e-02],
          [ 3.0737e-03, -9.5890e-03,  1.8569e-02],
          [ 1.4484e-02,  1.3513e-02, -1.9683e-02]],

         ...,

         [[-1.9354e-02, -1.8656e-03, -9.9481e-03],
          [ 1.7063e-02, -1.2662e-02,  2.4464e-03],
          [ 4.2848e-03, -8.0842e-03,  1.6858e-03]],

         [[ 4.8825e-03, -7.9121e-03,  1.4763e-02],
          [ 1.6768e-02,  6.3914e-03, -1.7228e-02],
          [-1.3600e-02, -1.9079e-02,  1.5404e-02]],

         [[ 1.1446e-02,  3.6312e-03, -8.7406e-03],
          [ 2.6022e-03, -1.8315e-02, -4.8054e-03],
          [ 1.5778e-02, -1.0965e-02,  1.0203e-02]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[ 9.6523e-03,  1.8857e-02, -2.0635e-02],
          [ 5.3270e-03,  1.4328e-02, -1.4185e-02],
          [-1.7151e-02,  1.6000e-02,  1.0798e-02]],

         [[-1.5245e-02, -1.8752e-02, -4.4059e-03],
          [-8.8792e-03, -2.0131e-02, -1.9737e-02],
          [-1.5439e-02, -9.4015e-03, -1.8323e-02]],

         [[ 1.7097e-02,  2.0794e-02, -3.0245e-03],
          [ 1.3821e-02,  1.1073e-02, -1.8223e-02],
          [-3.8369e-03,  1.5777e-02,  1.4149e-02]],

         ...,

         [[ 8.6842e-03,  1.6215e-03,  1.3569e-02],
          [ 2.0711e-02, -2.0922e-03, -1.1631e-02],
          [-1.3673e-03, -1.1257e-02,  6.7959e-03]],

         [[ 3.7557e-03, -1.8036e-02, -5.3567e-03],
          [ 1.3854e-02, -1.7324e-02, -2.0774e-02],
          [-3.0345e-03, -8.0616e-04,  1.4631e-02]],

         [[ 2.0734e-02,  2.8000e-03,  1.0670e-02],
          [-1.1762e-02,  1.0680e-03, -1.7131e-02],
          [-4.7164e-03,  6.4863e-03, -1.1764e-02]]],


        [[[-1.7094e-02, -1.0081e-02, -7.0719e-03],
          [-2.0763e-02, -9.9568e-03, -1.4303e-02],
          [-1.5592e-02,  1.8146e-02,  2.9996e-03]],

         [[-1.9040e-02, -1.9274e-02, -7.3387e-03],
          [ 7.6573e-03, -7.8644e-03,  9.2295e-03],
          [ 1.3356e-02,  1.7302e-03, -4.3014e-03]],

         [[-1.0173e-02,  6.7769e-03,  1.2203e-02],
          [-2.8143e-03, -2.7564e-03,  1.1230e-02],
          [ 3.0779e-03, -1.0137e-02, -8.8210e-03]],

         ...,

         [[-1.8023e-02, -1.5240e-02, -1.2748e-02],
          [ 1.6826e-02, -3.0385e-03, -5.9470e-03],
          [-1.2211e-02, -1.9214e-02,  1.9738e-02]],

         [[ 8.7187e-03, -1.2111e-02,  1.1724e-02],
          [ 2.0109e-02,  1.4926e-02,  7.4265e-04],
          [ 1.8214e-02,  3.0723e-03,  1.7641e-02]],

         [[ 1.8506e-02,  1.1961e-02, -1.2326e-02],
          [ 2.7330e-03,  4.6137e-03, -6.8403e-03],
          [-1.1702e-02,  7.0226e-03,  1.0684e-02]]],


        [[[-2.0489e-02,  3.2249e-04, -1.3531e-02],
          [-1.0409e-02, -1.6456e-02,  1.5809e-02],
          [-1.7256e-02,  9.4350e-03, -7.4618e-03]],

         [[-8.1340e-03, -1.6273e-02, -9.5159e-03],
          [ 5.0177e-03,  1.7476e-04,  1.6053e-02],
          [-1.2659e-02, -1.2499e-02, -1.6123e-03]],

         [[ 1.1089e-02, -1.9049e-02,  1.7875e-02],
          [-1.8377e-02, -1.9802e-02,  1.5109e-02],
          [ 3.4052e-04,  9.5141e-03,  1.5208e-02]],

         ...,

         [[ 1.0274e-02, -1.0860e-02,  8.4504e-03],
          [-8.0987e-03,  6.6583e-03, -8.6819e-03],
          [ 2.0542e-02,  1.9885e-02, -1.4371e-02]],

         [[-2.6663e-03,  1.3536e-02, -9.1108e-04],
          [ 4.9406e-03, -1.5664e-02, -4.0086e-04],
          [ 1.9432e-02,  1.9640e-02, -1.6323e-02]],

         [[-2.0997e-03, -6.9756e-03,  1.8689e-02],
          [-1.4351e-02, -1.8876e-04, -7.3234e-03],
          [ 1.6859e-02,  4.1876e-03,  3.4434e-03]]],


        ...,


        [[[ 6.5481e-04, -1.0955e-02,  9.0845e-03],
          [-2.0453e-02, -1.3297e-02, -3.0511e-03],
          [ 2.8653e-03,  1.8174e-02,  1.0993e-02]],

         [[ 5.3097e-03,  1.2497e-02, -1.3083e-02],
          [-7.2331e-03, -1.1013e-02,  4.2739e-03],
          [ 2.5044e-03,  1.1624e-02,  1.6807e-02]],

         [[-2.4365e-03,  5.5354e-04, -1.5423e-03],
          [ 1.4944e-03, -4.7100e-03, -1.4307e-02],
          [-1.6624e-03, -1.9849e-02,  3.6362e-03]],

         ...,

         [[-2.0385e-03, -3.7616e-03,  3.8099e-03],
          [ 7.2245e-04,  1.8433e-02,  1.7452e-02],
          [-1.3441e-02,  1.7067e-03,  1.3826e-04]],

         [[-5.3270e-03,  2.6133e-03,  1.9654e-02],
          [ 1.1702e-02, -7.2242e-03, -1.8410e-02],
          [ 1.9709e-02,  1.0237e-02, -1.8945e-02]],

         [[-1.1785e-02, -8.1971e-03, -1.8714e-02],
          [-2.8370e-03, -4.1563e-03,  9.1840e-03],
          [ 3.4422e-03,  2.0151e-02, -1.5898e-02]]],


        [[[-1.7399e-02,  6.9736e-03,  1.2958e-02],
          [-1.3594e-02, -1.6910e-02, -4.7962e-03],
          [-3.2362e-03,  1.2976e-02,  6.1702e-03]],

         [[ 1.6628e-02,  9.9445e-03, -1.4950e-02],
          [-1.6286e-02, -2.0126e-02,  1.3142e-02],
          [ 1.4414e-02,  8.8897e-03,  1.4451e-02]],

         [[-1.2380e-02, -6.2399e-03, -2.2666e-03],
          [ 1.6831e-02, -9.6647e-03, -1.8286e-02],
          [ 1.2819e-02, -1.9449e-02,  3.9639e-03]],

         ...,

         [[ 5.6157e-03,  1.5936e-02,  1.7576e-02],
          [ 9.2463e-03, -1.9075e-02, -9.4090e-03],
          [-1.9510e-02, -1.2765e-02, -2.7594e-03]],

         [[ 1.1712e-02, -6.6999e-03, -7.4531e-03],
          [ 1.2634e-02,  8.7416e-03,  1.0879e-02],
          [-5.1442e-03,  1.6151e-02, -6.1956e-03]],

         [[-1.8044e-02, -1.2836e-02,  1.6444e-02],
          [ 7.0460e-03, -8.7291e-04,  1.9111e-02],
          [ 1.3073e-02, -5.6643e-03,  3.9583e-03]]],


        [[[ 2.6260e-03, -4.8641e-03, -1.8978e-02],
          [ 6.1085e-03,  6.6349e-03, -1.9355e-02],
          [-1.8983e-02, -5.1619e-03, -1.6886e-02]],

         [[ 1.9689e-02, -4.8627e-03,  1.3331e-03],
          [-1.2137e-02, -2.5957e-03,  2.1985e-03],
          [-6.5756e-03,  1.6766e-02,  5.4637e-03]],

         [[ 1.2748e-05,  1.3803e-02,  1.0038e-02],
          [ 3.0737e-03, -9.5890e-03,  1.8569e-02],
          [ 1.4484e-02,  1.3513e-02, -1.9683e-02]],

         ...,

         [[-1.9354e-02, -1.8656e-03, -9.9481e-03],
          [ 1.7063e-02, -1.2662e-02,  2.4464e-03],
          [ 4.2848e-03, -8.0842e-03,  1.6858e-03]],

         [[ 4.8825e-03, -7.9121e-03,  1.4763e-02],
          [ 1.6768e-02,  6.3914e-03, -1.7228e-02],
          [-1.3600e-02, -1.9079e-02,  1.5404e-02]],

         [[ 1.1446e-02,  3.6312e-03, -8.7406e-03],
          [ 2.6022e-03, -1.8315e-02, -4.8054e-03],
          [ 1.5778e-02, -1.0965e-02,  1.0203e-02]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv2.bias 
 torch.Size([128]) 
 True 
 tensor([-0.0184,  0.0065,  0.0085,  0.0114, -0.0056, -0.0185, -0.0206, -0.0010,
         0.0137,  0.0037, -0.0029,  0.0196, -0.0114,  0.0140, -0.0207, -0.0201,
         0.0116,  0.0004, -0.0147,  0.0012,  0.0140, -0.0027,  0.0160, -0.0065,
         0.0045,  0.0186,  0.0204, -0.0148, -0.0071,  0.0124, -0.0155,  0.0185,
        -0.0060, -0.0090, -0.0118,  0.0094,  0.0053,  0.0070, -0.0029,  0.0207,
         0.0173, -0.0064, -0.0099, -0.0137,  0.0142,  0.0176, -0.0099, -0.0169,
         0.0032, -0.0133,  0.0174,  0.0145, -0.0093,  0.0070,  0.0181, -0.0118,
        -0.0034, -0.0018, -0.0152, -0.0049, -0.0134,  0.0046, -0.0062,  0.0066,
         0.0169,  0.0104, -0.0035,  0.0036, -0.0147,  0.0170,  0.0160,  0.0172,
         0.0072, -0.0178, -0.0197,  0.0151,  0.0002, -0.0113, -0.0181, -0.0052,
        -0.0166,  0.0092,  0.0075,  0.0027,  0.0098,  0.0180,  0.0203,  0.0140,
        -0.0050, -0.0093,  0.0170, -0.0057, -0.0076,  0.0012, -0.0100,  0.0077,
        -0.0144, -0.0061, -0.0076,  0.0152,  0.0018, -0.0095, -0.0097,  0.0085,
        -0.0052,  0.0148, -0.0205, -0.0073,  0.0194, -0.0018, -0.0079, -0.0114,
         0.0187, -0.0150,  0.0104, -0.0099,  0.0146,  0.0122,  0.0118, -0.0030,
         0.0011, -0.0029, -0.0003, -0.0135, -0.0086,  0.0169,  0.0078,  0.0132],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0184,  0.0065,  0.0085,  0.0114, -0.0056, -0.0185, -0.0206, -0.0010,
         0.0137,  0.0037, -0.0029,  0.0196, -0.0114,  0.0140, -0.0207, -0.0201,
         0.0116,  0.0004, -0.0147,  0.0012,  0.0140, -0.0027,  0.0160, -0.0065,
         0.0045,  0.0186,  0.0204, -0.0148, -0.0071,  0.0124, -0.0155,  0.0185,
        -0.0060, -0.0090, -0.0118,  0.0094,  0.0053,  0.0070, -0.0029,  0.0207,
         0.0173, -0.0064, -0.0099, -0.0137,  0.0142,  0.0176, -0.0099, -0.0169,
         0.0032, -0.0133,  0.0174,  0.0145, -0.0093,  0.0070,  0.0181, -0.0118,
        -0.0034, -0.0018, -0.0152, -0.0049, -0.0134,  0.0046, -0.0062,  0.0066,
         0.0169,  0.0104, -0.0035,  0.0036, -0.0147,  0.0170,  0.0160,  0.0172,
         0.0072, -0.0178, -0.0197,  0.0151,  0.0002, -0.0113, -0.0181, -0.0052,
        -0.0166,  0.0092,  0.0075,  0.0027,  0.0098,  0.0180,  0.0203,  0.0140,
        -0.0050, -0.0093,  0.0170, -0.0057, -0.0076,  0.0012, -0.0100,  0.0077,
        -0.0144, -0.0061, -0.0076,  0.0152,  0.0018, -0.0095, -0.0097,  0.0085,
        -0.0052,  0.0148, -0.0205, -0.0073,  0.0194, -0.0018, -0.0079, -0.0114,
         0.0187, -0.0150,  0.0104, -0.0099,  0.0146,  0.0122,  0.0118, -0.0030,
         0.0011, -0.0029, -0.0003, -0.0135, -0.0086,  0.0169,  0.0078,  0.0132],
       device='cuda:0', requires_grad=True)
parameters of the network conv3.weight 
 torch.Size([64, 128, 3, 3]) 
 True 
 tensor([[[[-1.7198e-02,  2.7940e-02, -2.9067e-02],
          [ 1.7867e-02, -7.2168e-03,  1.9256e-02],
          [ 1.1685e-02, -1.7754e-02, -1.8437e-02]],

         [[ 9.3728e-03, -2.0525e-02, -2.8353e-02],
          [-6.1900e-05, -2.0254e-04,  1.6545e-02],
          [-1.3548e-02,  1.0159e-02, -2.9324e-04]],

         [[ 1.5207e-02,  1.4826e-02, -4.1385e-03],
          [ 1.5501e-03,  2.3402e-02, -1.8457e-03],
          [-2.8626e-02,  1.0163e-02,  1.7968e-02]],

         ...,

         [[ 2.7437e-02, -2.2868e-02, -7.5602e-03],
          [-8.3196e-04, -1.6114e-02,  9.3629e-03],
          [-1.7033e-02,  2.2063e-02, -2.6407e-02]],

         [[-8.8413e-03,  2.2718e-02, -1.4401e-02],
          [-1.8941e-02,  5.3310e-03, -1.1081e-02],
          [ 7.8783e-03, -1.1862e-02, -1.4230e-03]],

         [[ 2.3462e-02, -6.1988e-03,  1.5973e-02],
          [-9.8774e-03,  1.8872e-02,  6.1011e-03],
          [-1.5521e-02,  7.4547e-03,  1.8579e-02]]],


        [[[-9.9322e-03, -6.5645e-03,  2.3656e-02],
          [-1.2047e-02, -5.5653e-03, -4.4935e-03],
          [ 2.0162e-02,  2.5708e-03,  9.0420e-03]],

         [[ 3.0725e-03, -2.3605e-02,  1.9630e-02],
          [ 1.5096e-02, -1.4991e-02,  3.7327e-03],
          [ 9.6004e-03, -3.9864e-03,  1.4348e-02]],

         [[-1.1324e-02, -2.3489e-02,  6.9235e-03],
          [-2.7482e-02,  1.3754e-02,  2.3643e-02],
          [-9.4603e-03, -8.7204e-03, -1.5461e-02]],

         ...,

         [[ 1.2399e-02, -5.1459e-04, -2.5198e-02],
          [-5.2935e-03, -1.2930e-02,  1.0714e-02],
          [-1.2636e-02,  2.5730e-02,  1.9515e-02]],

         [[-2.6639e-02,  5.8851e-03, -5.1466e-03],
          [-3.8981e-03, -2.3580e-02,  1.1012e-02],
          [-2.1279e-03,  7.6229e-03,  2.0463e-03]],

         [[ 9.1271e-03,  2.8227e-02,  2.6484e-02],
          [ 1.0395e-02, -2.5879e-02,  1.2176e-02],
          [ 2.8968e-02,  1.2082e-03, -2.3320e-02]]],


        [[[-2.9440e-02,  1.3247e-02,  1.6973e-03],
          [-6.5303e-03,  1.2279e-02,  2.7685e-02],
          [ 2.6135e-02, -1.1678e-02,  1.9401e-02]],

         [[-7.3120e-03,  1.8502e-02,  1.2751e-02],
          [-2.5114e-02, -9.1101e-03, -1.7970e-02],
          [-4.8128e-03,  1.8424e-02, -2.8991e-02]],

         [[-1.0829e-02,  2.9034e-02, -3.9104e-03],
          [-8.3583e-03,  1.3562e-03,  8.2053e-03],
          [-1.4869e-02, -1.6514e-03,  1.1357e-02]],

         ...,

         [[ 2.1696e-02, -5.6982e-03,  1.8312e-02],
          [-1.3858e-03,  1.6157e-02,  2.4770e-02],
          [-1.5052e-02,  2.6057e-02,  2.8267e-02]],

         [[ 2.2596e-02, -1.7286e-02, -9.4499e-03],
          [ 1.7039e-02,  2.5748e-02,  2.0841e-02],
          [ 1.0816e-02,  1.4807e-02, -2.4615e-02]],

         [[-3.8938e-03,  2.3334e-02,  2.1775e-02],
          [-1.2300e-02, -3.2544e-03, -1.3446e-02],
          [ 1.6880e-02, -1.3765e-02,  1.2109e-02]]],


        ...,


        [[[-2.4724e-02,  2.2631e-03, -2.7342e-02],
          [ 9.4691e-03, -2.3411e-02, -1.3608e-02],
          [-2.3599e-02,  1.6276e-02,  4.8593e-03]],

         [[ 1.9975e-02,  1.9886e-02,  2.4194e-02],
          [ 6.7931e-03, -8.3723e-03,  2.6893e-04],
          [ 1.3391e-02,  2.6894e-02,  1.4727e-02]],

         [[-8.4196e-03,  2.4458e-02,  8.2713e-03],
          [ 1.5602e-02, -1.5368e-02,  1.7659e-02],
          [-1.2612e-02, -1.6600e-02, -2.8419e-02]],

         ...,

         [[ 1.2234e-02, -1.2439e-02, -4.2199e-03],
          [-2.6552e-02, -1.1327e-02,  1.5551e-02],
          [ 3.8368e-03, -1.4043e-02, -2.3361e-02]],

         [[ 7.6830e-03, -2.8771e-02, -2.6860e-02],
          [ 4.4224e-03, -1.9232e-02, -1.8536e-02],
          [ 2.3377e-02, -2.4900e-02,  2.9274e-02]],

         [[-1.6658e-03, -1.8553e-03, -2.0682e-02],
          [ 4.7011e-03,  2.1108e-02, -1.6459e-02],
          [-5.5520e-03, -1.8805e-05, -1.6018e-02]]],


        [[[ 1.2336e-02, -8.1696e-03,  6.9215e-03],
          [-5.5210e-03,  6.8099e-04,  3.8969e-03],
          [ 3.3525e-03, -2.1812e-02, -1.5952e-02]],

         [[-1.7374e-02, -3.1130e-03, -9.3640e-03],
          [ 9.5154e-03, -7.2519e-03,  6.8179e-03],
          [-2.1229e-02, -3.4450e-03,  2.0826e-02]],

         [[ 1.6290e-02, -2.4972e-02,  4.5296e-03],
          [-1.2615e-02,  1.4047e-02, -1.2479e-02],
          [-9.4185e-03,  1.1403e-02, -9.7915e-03]],

         ...,

         [[-1.1446e-03, -5.7107e-03, -2.6393e-02],
          [ 1.5612e-02,  2.2528e-02,  1.8396e-02],
          [ 2.0905e-02, -7.4124e-03, -2.3069e-02]],

         [[-2.5040e-02, -7.8777e-03,  1.1636e-02],
          [-1.0198e-02, -2.2445e-02,  9.1419e-04],
          [-1.0400e-02,  2.8372e-02, -1.0903e-02]],

         [[-2.9094e-04, -1.2736e-02,  2.2513e-02],
          [-3.0297e-03,  2.6086e-02, -3.2669e-03],
          [-2.3886e-02, -1.2524e-02,  2.3304e-02]]],


        [[[-3.5636e-03, -1.2934e-02, -2.3888e-02],
          [ 1.4170e-02,  2.3284e-02, -1.5566e-02],
          [ 1.8602e-02,  2.7389e-02,  1.5756e-02]],

         [[-1.2817e-02, -6.2735e-03,  4.2991e-03],
          [ 3.2025e-03,  2.9356e-02, -9.0245e-03],
          [-2.0173e-02,  4.5353e-03, -2.4210e-02]],

         [[ 1.4677e-02, -9.4783e-04,  4.0573e-03],
          [-6.6413e-03,  1.7009e-02,  7.6570e-04],
          [-1.1370e-02, -2.0277e-02, -1.1386e-02]],

         ...,

         [[-2.9276e-02,  9.1124e-03,  3.9844e-03],
          [ 6.1416e-03, -8.6654e-03,  8.3142e-03],
          [-3.1780e-03, -3.1551e-03,  2.4916e-02]],

         [[ 2.8426e-02, -6.4266e-03, -1.5769e-02],
          [-1.9493e-02, -3.5080e-03,  2.5468e-02],
          [ 1.1843e-02, -2.3012e-02,  1.2617e-02]],

         [[-8.9353e-03, -1.3834e-02, -1.5740e-02],
          [ 3.0274e-03, -2.3203e-02, -2.9812e-03],
          [ 2.4825e-02,  2.4326e-02,  3.7773e-03]]]], device='cuda:0') 
 Parameter containing:
tensor([[[[-1.7198e-02,  2.7940e-02, -2.9067e-02],
          [ 1.7867e-02, -7.2168e-03,  1.9256e-02],
          [ 1.1685e-02, -1.7754e-02, -1.8437e-02]],

         [[ 9.3728e-03, -2.0525e-02, -2.8353e-02],
          [-6.1900e-05, -2.0254e-04,  1.6545e-02],
          [-1.3548e-02,  1.0159e-02, -2.9324e-04]],

         [[ 1.5207e-02,  1.4826e-02, -4.1385e-03],
          [ 1.5501e-03,  2.3402e-02, -1.8457e-03],
          [-2.8626e-02,  1.0163e-02,  1.7968e-02]],

         ...,

         [[ 2.7437e-02, -2.2868e-02, -7.5602e-03],
          [-8.3196e-04, -1.6114e-02,  9.3629e-03],
          [-1.7033e-02,  2.2063e-02, -2.6407e-02]],

         [[-8.8413e-03,  2.2718e-02, -1.4401e-02],
          [-1.8941e-02,  5.3310e-03, -1.1081e-02],
          [ 7.8783e-03, -1.1862e-02, -1.4230e-03]],

         [[ 2.3462e-02, -6.1988e-03,  1.5973e-02],
          [-9.8774e-03,  1.8872e-02,  6.1011e-03],
          [-1.5521e-02,  7.4547e-03,  1.8579e-02]]],


        [[[-9.9322e-03, -6.5645e-03,  2.3656e-02],
          [-1.2047e-02, -5.5653e-03, -4.4935e-03],
          [ 2.0162e-02,  2.5708e-03,  9.0420e-03]],

         [[ 3.0725e-03, -2.3605e-02,  1.9630e-02],
          [ 1.5096e-02, -1.4991e-02,  3.7327e-03],
          [ 9.6004e-03, -3.9864e-03,  1.4348e-02]],

         [[-1.1324e-02, -2.3489e-02,  6.9235e-03],
          [-2.7482e-02,  1.3754e-02,  2.3643e-02],
          [-9.4603e-03, -8.7204e-03, -1.5461e-02]],

         ...,

         [[ 1.2399e-02, -5.1459e-04, -2.5198e-02],
          [-5.2935e-03, -1.2930e-02,  1.0714e-02],
          [-1.2636e-02,  2.5730e-02,  1.9515e-02]],

         [[-2.6639e-02,  5.8851e-03, -5.1466e-03],
          [-3.8981e-03, -2.3580e-02,  1.1012e-02],
          [-2.1279e-03,  7.6229e-03,  2.0463e-03]],

         [[ 9.1271e-03,  2.8227e-02,  2.6484e-02],
          [ 1.0395e-02, -2.5879e-02,  1.2176e-02],
          [ 2.8968e-02,  1.2082e-03, -2.3320e-02]]],


        [[[-2.9440e-02,  1.3247e-02,  1.6973e-03],
          [-6.5303e-03,  1.2279e-02,  2.7685e-02],
          [ 2.6135e-02, -1.1678e-02,  1.9401e-02]],

         [[-7.3120e-03,  1.8502e-02,  1.2751e-02],
          [-2.5114e-02, -9.1101e-03, -1.7970e-02],
          [-4.8128e-03,  1.8424e-02, -2.8991e-02]],

         [[-1.0829e-02,  2.9034e-02, -3.9104e-03],
          [-8.3583e-03,  1.3562e-03,  8.2053e-03],
          [-1.4869e-02, -1.6514e-03,  1.1357e-02]],

         ...,

         [[ 2.1696e-02, -5.6982e-03,  1.8312e-02],
          [-1.3858e-03,  1.6157e-02,  2.4770e-02],
          [-1.5052e-02,  2.6057e-02,  2.8267e-02]],

         [[ 2.2596e-02, -1.7286e-02, -9.4499e-03],
          [ 1.7039e-02,  2.5748e-02,  2.0841e-02],
          [ 1.0816e-02,  1.4807e-02, -2.4615e-02]],

         [[-3.8938e-03,  2.3334e-02,  2.1775e-02],
          [-1.2300e-02, -3.2544e-03, -1.3446e-02],
          [ 1.6880e-02, -1.3765e-02,  1.2109e-02]]],


        ...,


        [[[-2.4724e-02,  2.2631e-03, -2.7342e-02],
          [ 9.4691e-03, -2.3411e-02, -1.3608e-02],
          [-2.3599e-02,  1.6276e-02,  4.8593e-03]],

         [[ 1.9975e-02,  1.9886e-02,  2.4194e-02],
          [ 6.7931e-03, -8.3723e-03,  2.6893e-04],
          [ 1.3391e-02,  2.6894e-02,  1.4727e-02]],

         [[-8.4196e-03,  2.4458e-02,  8.2713e-03],
          [ 1.5602e-02, -1.5368e-02,  1.7659e-02],
          [-1.2612e-02, -1.6600e-02, -2.8419e-02]],

         ...,

         [[ 1.2234e-02, -1.2439e-02, -4.2199e-03],
          [-2.6552e-02, -1.1327e-02,  1.5551e-02],
          [ 3.8368e-03, -1.4043e-02, -2.3361e-02]],

         [[ 7.6830e-03, -2.8771e-02, -2.6860e-02],
          [ 4.4224e-03, -1.9232e-02, -1.8536e-02],
          [ 2.3377e-02, -2.4900e-02,  2.9274e-02]],

         [[-1.6658e-03, -1.8553e-03, -2.0682e-02],
          [ 4.7011e-03,  2.1108e-02, -1.6459e-02],
          [-5.5520e-03, -1.8805e-05, -1.6018e-02]]],


        [[[ 1.2336e-02, -8.1696e-03,  6.9215e-03],
          [-5.5210e-03,  6.8099e-04,  3.8969e-03],
          [ 3.3525e-03, -2.1812e-02, -1.5952e-02]],

         [[-1.7374e-02, -3.1130e-03, -9.3640e-03],
          [ 9.5154e-03, -7.2519e-03,  6.8179e-03],
          [-2.1229e-02, -3.4450e-03,  2.0826e-02]],

         [[ 1.6290e-02, -2.4972e-02,  4.5296e-03],
          [-1.2615e-02,  1.4047e-02, -1.2479e-02],
          [-9.4185e-03,  1.1403e-02, -9.7915e-03]],

         ...,

         [[-1.1446e-03, -5.7107e-03, -2.6393e-02],
          [ 1.5612e-02,  2.2528e-02,  1.8396e-02],
          [ 2.0905e-02, -7.4124e-03, -2.3069e-02]],

         [[-2.5040e-02, -7.8777e-03,  1.1636e-02],
          [-1.0198e-02, -2.2445e-02,  9.1419e-04],
          [-1.0400e-02,  2.8372e-02, -1.0903e-02]],

         [[-2.9094e-04, -1.2736e-02,  2.2513e-02],
          [-3.0297e-03,  2.6086e-02, -3.2669e-03],
          [-2.3886e-02, -1.2524e-02,  2.3304e-02]]],


        [[[-3.5636e-03, -1.2934e-02, -2.3888e-02],
          [ 1.4170e-02,  2.3284e-02, -1.5566e-02],
          [ 1.8602e-02,  2.7389e-02,  1.5756e-02]],

         [[-1.2817e-02, -6.2735e-03,  4.2991e-03],
          [ 3.2025e-03,  2.9356e-02, -9.0245e-03],
          [-2.0173e-02,  4.5353e-03, -2.4210e-02]],

         [[ 1.4677e-02, -9.4783e-04,  4.0573e-03],
          [-6.6413e-03,  1.7009e-02,  7.6570e-04],
          [-1.1370e-02, -2.0277e-02, -1.1386e-02]],

         ...,

         [[-2.9276e-02,  9.1124e-03,  3.9844e-03],
          [ 6.1416e-03, -8.6654e-03,  8.3142e-03],
          [-3.1780e-03, -3.1551e-03,  2.4916e-02]],

         [[ 2.8426e-02, -6.4266e-03, -1.5769e-02],
          [-1.9493e-02, -3.5080e-03,  2.5468e-02],
          [ 1.1843e-02, -2.3012e-02,  1.2617e-02]],

         [[-8.9353e-03, -1.3834e-02, -1.5740e-02],
          [ 3.0274e-03, -2.3203e-02, -2.9812e-03],
          [ 2.4825e-02,  2.4326e-02,  3.7773e-03]]]], device='cuda:0',
       requires_grad=True)
parameters of the network conv3.bias 
 torch.Size([64]) 
 True 
 tensor([ 1.2925e-02, -2.8340e-02, -2.2119e-02,  1.7973e-02, -2.5629e-02,
         1.6713e-03, -4.5494e-04,  7.3140e-03, -1.1474e-02, -2.4245e-02,
        -2.4731e-02, -1.7754e-02, -1.0132e-02, -1.4753e-02, -1.7116e-03,
        -2.1424e-02,  1.8921e-02,  2.5732e-03, -2.1065e-03,  1.8724e-02,
        -2.6229e-02, -1.2588e-02,  1.8256e-02, -2.1994e-02,  1.2928e-03,
        -1.3472e-02,  5.5339e-03, -6.3103e-03,  1.3384e-02,  2.4037e-02,
         5.8723e-03, -6.3647e-03, -2.0924e-02,  1.0217e-02,  2.8223e-02,
         2.0527e-03,  5.4846e-03, -1.2194e-02, -6.0574e-03,  2.6820e-02,
        -1.5106e-02, -2.4590e-02, -2.3627e-02, -1.6032e-02,  7.1653e-05,
         2.4337e-02,  8.6639e-04, -5.8384e-03,  7.9358e-03,  2.0289e-02,
        -1.3435e-02,  6.3464e-03,  1.3167e-02,  5.7539e-04,  1.1267e-02,
         2.5924e-02, -7.2255e-03,  5.1039e-04,  2.2475e-02,  1.4289e-03,
         2.5346e-02,  2.9852e-03,  7.2466e-03, -2.2359e-03], device='cuda:0') 
 Parameter containing:
tensor([ 1.2925e-02, -2.8340e-02, -2.2119e-02,  1.7973e-02, -2.5629e-02,
         1.6713e-03, -4.5494e-04,  7.3140e-03, -1.1474e-02, -2.4245e-02,
        -2.4731e-02, -1.7754e-02, -1.0132e-02, -1.4753e-02, -1.7116e-03,
        -2.1424e-02,  1.8921e-02,  2.5732e-03, -2.1065e-03,  1.8724e-02,
        -2.6229e-02, -1.2588e-02,  1.8256e-02, -2.1994e-02,  1.2928e-03,
        -1.3472e-02,  5.5339e-03, -6.3103e-03,  1.3384e-02,  2.4037e-02,
         5.8723e-03, -6.3647e-03, -2.0924e-02,  1.0217e-02,  2.8223e-02,
         2.0527e-03,  5.4846e-03, -1.2194e-02, -6.0574e-03,  2.6820e-02,
        -1.5106e-02, -2.4590e-02, -2.3627e-02, -1.6032e-02,  7.1653e-05,
         2.4337e-02,  8.6639e-04, -5.8384e-03,  7.9358e-03,  2.0289e-02,
        -1.3435e-02,  6.3464e-03,  1.3167e-02,  5.7539e-04,  1.1267e-02,
         2.5924e-02, -7.2255e-03,  5.1039e-04,  2.2475e-02,  1.4289e-03,
         2.5346e-02,  2.9852e-03,  7.2466e-03, -2.2359e-03], device='cuda:0',
       requires_grad=True)
parameters of the network fc1.weight 
 torch.Size([256, 667776]) 
 True 
 tensor([[-1.0167e-03, -7.9711e-04, -6.1652e-04,  ..., -1.2207e-03,
          9.1585e-04, -1.3481e-04],
        [ 1.0409e-03, -4.7957e-04,  3.7023e-04,  ..., -4.1433e-04,
          5.4535e-04,  4.4666e-05],
        [-1.0489e-03, -5.6772e-04, -5.4059e-04,  ...,  4.6646e-04,
          4.5091e-04, -1.9330e-04],
        ...,
        [ 5.6396e-04, -4.5875e-04, -7.7641e-04,  ..., -1.0306e-03,
          9.4737e-05, -9.8452e-04],
        [-2.2380e-04,  3.8886e-04, -4.3662e-04,  ...,  4.9510e-04,
          8.0998e-04,  8.0477e-04],
        [-1.1275e-03, -8.5918e-04,  1.2136e-03,  ..., -1.0646e-04,
          3.6420e-04, -1.0462e-03]], device='cuda:0') 
 Parameter containing:
tensor([[-1.0167e-03, -7.9711e-04, -6.1652e-04,  ..., -1.2207e-03,
          9.1585e-04, -1.3481e-04],
        [ 1.0409e-03, -4.7957e-04,  3.7023e-04,  ..., -4.1433e-04,
          5.4535e-04,  4.4666e-05],
        [-1.0489e-03, -5.6772e-04, -5.4059e-04,  ...,  4.6646e-04,
          4.5091e-04, -1.9330e-04],
        ...,
        [ 5.6396e-04, -4.5875e-04, -7.7641e-04,  ..., -1.0306e-03,
          9.4737e-05, -9.8452e-04],
        [-2.2380e-04,  3.8886e-04, -4.3662e-04,  ...,  4.9510e-04,
          8.0998e-04,  8.0477e-04],
        [-1.1275e-03, -8.5918e-04,  1.2136e-03,  ..., -1.0646e-04,
          3.6420e-04, -1.0462e-03]], device='cuda:0', requires_grad=True)
parameters of the network fc1.bias 
 torch.Size([256]) 
 True 
 tensor([ 8.2490e-05,  7.9214e-04, -4.6564e-04, -1.0110e-03, -9.6571e-04,
         7.4078e-04,  1.1145e-03, -2.6957e-04,  1.1915e-03,  1.1747e-03,
        -5.8867e-04,  7.2217e-04,  3.8313e-05,  9.6535e-04, -1.1793e-03,
         7.1274e-04, -6.2603e-04,  6.9898e-04, -2.6961e-05, -1.1569e-03,
         2.9337e-04,  4.1618e-04,  9.8982e-04,  8.2820e-04,  3.5958e-04,
        -1.0010e-03,  1.6920e-04, -2.3556e-04,  1.1794e-03,  4.0641e-04,
         9.0323e-04,  1.6744e-04,  8.7198e-05,  9.4663e-04,  1.5950e-04,
        -5.4904e-05, -1.0279e-03, -1.8942e-04,  6.6067e-04, -1.4668e-04,
         1.1107e-03,  2.5380e-04,  1.1150e-03, -5.6788e-04, -1.1781e-03,
         7.3234e-04,  5.2115e-04, -9.4535e-04,  3.5736e-04,  1.0765e-03,
        -4.8418e-04, -8.8663e-04, -1.1302e-03,  1.0342e-03, -6.8624e-04,
        -9.3784e-04,  1.1971e-03, -2.8124e-04, -6.4876e-04,  7.3768e-04,
        -1.3691e-04, -5.2910e-05,  1.0802e-03,  7.2598e-05,  3.7359e-04,
        -7.4984e-04,  3.4124e-04, -4.4581e-04, -1.3135e-04, -1.1280e-03,
         8.2058e-04, -4.7856e-04,  2.4444e-04, -5.9814e-04,  5.0440e-04,
         2.3484e-04, -7.1410e-04, -6.1887e-04,  1.0223e-03, -2.6023e-05,
        -1.1177e-03, -9.9812e-04,  7.4757e-04,  4.1047e-04,  9.8998e-04,
        -1.5070e-04, -1.0127e-03, -5.5961e-04, -1.2132e-03,  1.1563e-03,
         6.1132e-04,  3.5548e-04,  8.2525e-05,  3.5655e-04,  7.9925e-04,
        -9.8057e-04,  6.4325e-04,  1.0989e-03,  8.7143e-04, -4.5986e-04,
         5.7024e-04,  1.0072e-03,  1.0436e-03, -1.1720e-03, -1.1004e-03,
        -1.0363e-03, -4.4857e-05,  5.5693e-04, -8.2361e-04, -2.8400e-04,
        -5.4471e-04, -5.1889e-04,  2.5192e-04,  7.3594e-05,  4.0026e-04,
        -1.0342e-03, -2.5211e-04,  1.3573e-05,  1.0586e-03,  6.9255e-04,
        -9.1473e-04,  9.8570e-04,  1.0302e-03,  1.1541e-03, -9.5821e-04,
        -7.9774e-04,  9.0594e-04, -1.0331e-03,  1.4645e-05,  8.2563e-04,
        -4.8806e-04, -9.2835e-04, -8.0500e-05,  1.1810e-03,  1.4080e-04,
        -1.3869e-04, -6.9341e-04, -9.9163e-04,  6.2961e-04, -3.3478e-04,
        -6.5256e-04, -7.6679e-04, -1.1920e-03,  9.4395e-04, -5.0802e-04,
         1.1457e-03,  7.0343e-04,  7.8325e-04, -6.4942e-04,  1.1788e-03,
        -7.2126e-04, -3.5105e-04,  3.8601e-04, -1.0603e-03,  7.4049e-04,
        -5.2252e-04,  9.5582e-04, -9.3071e-04,  1.9794e-04,  1.0190e-03,
        -4.7878e-04, -1.0513e-03, -4.5800e-05, -1.4807e-04, -1.1599e-03,
         1.0344e-03, -6.3925e-04, -1.0943e-03,  5.8245e-04,  1.0895e-03,
        -8.4961e-04,  5.5546e-05,  2.0741e-04, -2.2007e-04, -3.6700e-04,
        -9.7091e-04,  9.9772e-04, -8.0280e-04,  6.0113e-04, -6.1427e-05,
        -6.7603e-04,  7.2016e-04, -3.6544e-04, -1.2526e-05,  8.5646e-04,
         2.5470e-04, -9.9230e-04, -8.8535e-05,  7.1564e-04, -6.1584e-04,
         3.9028e-04, -8.2282e-04,  1.0631e-03,  1.0438e-04, -6.0402e-04,
         8.1669e-04,  1.2002e-03, -8.8434e-04, -8.1060e-04,  8.5121e-05,
        -5.9289e-04, -3.2750e-04,  2.7762e-04,  1.1664e-03,  3.1957e-04,
        -2.3027e-04,  3.9996e-04,  6.2040e-04,  7.2916e-04,  2.5134e-05,
         2.2891e-04, -2.0518e-04,  1.1346e-03,  4.1367e-04, -3.1525e-04,
        -1.0020e-04,  3.9422e-04, -4.0628e-04,  2.5092e-04, -3.0448e-04,
        -5.3575e-04, -3.7205e-05,  1.0253e-03, -4.6911e-04,  6.7080e-04,
         1.1481e-03, -5.4737e-04, -4.8293e-04,  8.5930e-04, -4.6021e-05,
         8.7356e-04, -8.2400e-04,  7.0621e-04,  4.0010e-04, -9.2210e-05,
        -3.0186e-04,  4.8250e-04, -1.7573e-04,  1.1657e-03,  1.1834e-03,
        -1.3861e-04, -7.4215e-04,  2.5374e-06,  1.0761e-03, -4.5970e-04,
         2.8531e-04, -1.0594e-03, -5.1552e-05,  5.2889e-04, -8.6710e-04,
         4.6757e-04,  3.0927e-04,  8.5147e-04, -9.1277e-04,  9.6686e-04,
         4.4460e-04], device='cuda:0') 
 Parameter containing:
tensor([ 8.2490e-05,  7.9214e-04, -4.6564e-04, -1.0110e-03, -9.6571e-04,
         7.4078e-04,  1.1145e-03, -2.6957e-04,  1.1915e-03,  1.1747e-03,
        -5.8867e-04,  7.2217e-04,  3.8313e-05,  9.6535e-04, -1.1793e-03,
         7.1274e-04, -6.2603e-04,  6.9898e-04, -2.6961e-05, -1.1569e-03,
         2.9337e-04,  4.1618e-04,  9.8982e-04,  8.2820e-04,  3.5958e-04,
        -1.0010e-03,  1.6920e-04, -2.3556e-04,  1.1794e-03,  4.0641e-04,
         9.0323e-04,  1.6744e-04,  8.7198e-05,  9.4663e-04,  1.5950e-04,
        -5.4904e-05, -1.0279e-03, -1.8942e-04,  6.6067e-04, -1.4668e-04,
         1.1107e-03,  2.5380e-04,  1.1150e-03, -5.6788e-04, -1.1781e-03,
         7.3234e-04,  5.2115e-04, -9.4535e-04,  3.5736e-04,  1.0765e-03,
        -4.8418e-04, -8.8663e-04, -1.1302e-03,  1.0342e-03, -6.8624e-04,
        -9.3784e-04,  1.1971e-03, -2.8124e-04, -6.4876e-04,  7.3768e-04,
        -1.3691e-04, -5.2910e-05,  1.0802e-03,  7.2598e-05,  3.7359e-04,
        -7.4984e-04,  3.4124e-04, -4.4581e-04, -1.3135e-04, -1.1280e-03,
         8.2058e-04, -4.7856e-04,  2.4444e-04, -5.9814e-04,  5.0440e-04,
         2.3484e-04, -7.1410e-04, -6.1887e-04,  1.0223e-03, -2.6023e-05,
        -1.1177e-03, -9.9812e-04,  7.4757e-04,  4.1047e-04,  9.8998e-04,
        -1.5070e-04, -1.0127e-03, -5.5961e-04, -1.2132e-03,  1.1563e-03,
         6.1132e-04,  3.5548e-04,  8.2525e-05,  3.5655e-04,  7.9925e-04,
        -9.8057e-04,  6.4325e-04,  1.0989e-03,  8.7143e-04, -4.5986e-04,
         5.7024e-04,  1.0072e-03,  1.0436e-03, -1.1720e-03, -1.1004e-03,
        -1.0363e-03, -4.4857e-05,  5.5693e-04, -8.2361e-04, -2.8400e-04,
        -5.4471e-04, -5.1889e-04,  2.5192e-04,  7.3594e-05,  4.0026e-04,
        -1.0342e-03, -2.5211e-04,  1.3573e-05,  1.0586e-03,  6.9255e-04,
        -9.1473e-04,  9.8570e-04,  1.0302e-03,  1.1541e-03, -9.5821e-04,
        -7.9774e-04,  9.0594e-04, -1.0331e-03,  1.4645e-05,  8.2563e-04,
        -4.8806e-04, -9.2835e-04, -8.0500e-05,  1.1810e-03,  1.4080e-04,
        -1.3869e-04, -6.9341e-04, -9.9163e-04,  6.2961e-04, -3.3478e-04,
        -6.5256e-04, -7.6679e-04, -1.1920e-03,  9.4395e-04, -5.0802e-04,
         1.1457e-03,  7.0343e-04,  7.8325e-04, -6.4942e-04,  1.1788e-03,
        -7.2126e-04, -3.5105e-04,  3.8601e-04, -1.0603e-03,  7.4049e-04,
        -5.2252e-04,  9.5582e-04, -9.3071e-04,  1.9794e-04,  1.0190e-03,
        -4.7878e-04, -1.0513e-03, -4.5800e-05, -1.4807e-04, -1.1599e-03,
         1.0344e-03, -6.3925e-04, -1.0943e-03,  5.8245e-04,  1.0895e-03,
        -8.4961e-04,  5.5546e-05,  2.0741e-04, -2.2007e-04, -3.6700e-04,
        -9.7091e-04,  9.9772e-04, -8.0280e-04,  6.0113e-04, -6.1427e-05,
        -6.7603e-04,  7.2016e-04, -3.6544e-04, -1.2526e-05,  8.5646e-04,
         2.5470e-04, -9.9230e-04, -8.8535e-05,  7.1564e-04, -6.1584e-04,
         3.9028e-04, -8.2282e-04,  1.0631e-03,  1.0438e-04, -6.0402e-04,
         8.1669e-04,  1.2002e-03, -8.8434e-04, -8.1060e-04,  8.5121e-05,
        -5.9289e-04, -3.2750e-04,  2.7762e-04,  1.1664e-03,  3.1957e-04,
        -2.3027e-04,  3.9996e-04,  6.2040e-04,  7.2916e-04,  2.5134e-05,
         2.2891e-04, -2.0518e-04,  1.1346e-03,  4.1367e-04, -3.1525e-04,
        -1.0020e-04,  3.9422e-04, -4.0628e-04,  2.5092e-04, -3.0448e-04,
        -5.3575e-04, -3.7205e-05,  1.0253e-03, -4.6911e-04,  6.7080e-04,
         1.1481e-03, -5.4737e-04, -4.8293e-04,  8.5930e-04, -4.6021e-05,
         8.7356e-04, -8.2400e-04,  7.0621e-04,  4.0010e-04, -9.2210e-05,
        -3.0186e-04,  4.8250e-04, -1.7573e-04,  1.1657e-03,  1.1834e-03,
        -1.3861e-04, -7.4215e-04,  2.5374e-06,  1.0761e-03, -4.5970e-04,
         2.8531e-04, -1.0594e-03, -5.1552e-05,  5.2889e-04, -8.6710e-04,
         4.6757e-04,  3.0927e-04,  8.5147e-04, -9.1277e-04,  9.6686e-04,
         4.4460e-04], device='cuda:0', requires_grad=True)
parameters of the network fc2.weight 
 torch.Size([128, 256]) 
 True 
 tensor([[-0.0174, -0.0114,  0.0484,  ...,  0.0023, -0.0041,  0.0069],
        [ 0.0006,  0.0028,  0.0379,  ...,  0.0272,  0.0568, -0.0385],
        [ 0.0090, -0.0161,  0.0416,  ..., -0.0535,  0.0581, -0.0574],
        ...,
        [-0.0110, -0.0366, -0.0179,  ..., -0.0119, -0.0015, -0.0489],
        [ 0.0097,  0.0624,  0.0618,  ...,  0.0016,  0.0272, -0.0114],
        [-0.0509,  0.0286, -0.0018,  ...,  0.0613, -0.0220, -0.0525]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0174, -0.0114,  0.0484,  ...,  0.0023, -0.0041,  0.0069],
        [ 0.0006,  0.0028,  0.0379,  ...,  0.0272,  0.0568, -0.0385],
        [ 0.0090, -0.0161,  0.0416,  ..., -0.0535,  0.0581, -0.0574],
        ...,
        [-0.0110, -0.0366, -0.0179,  ..., -0.0119, -0.0015, -0.0489],
        [ 0.0097,  0.0624,  0.0618,  ...,  0.0016,  0.0272, -0.0114],
        [-0.0509,  0.0286, -0.0018,  ...,  0.0613, -0.0220, -0.0525]],
       device='cuda:0', requires_grad=True)
parameters of the network fc2.bias 
 torch.Size([128]) 
 True 
 tensor([ 0.0146, -0.0255, -0.0035,  0.0116,  0.0262,  0.0490, -0.0265, -0.0298,
         0.0304,  0.0131,  0.0304, -0.0583,  0.0556,  0.0331, -0.0496, -0.0300,
         0.0285,  0.0110, -0.0443, -0.0515, -0.0447,  0.0083, -0.0401, -0.0439,
         0.0560,  0.0112, -0.0206, -0.0049,  0.0125,  0.0295, -0.0109,  0.0379,
        -0.0457,  0.0523, -0.0167,  0.0120, -0.0301, -0.0025, -0.0617, -0.0137,
         0.0336,  0.0352,  0.0573, -0.0338,  0.0138,  0.0069,  0.0388,  0.0233,
        -0.0438, -0.0114,  0.0073,  0.0145, -0.0341, -0.0573,  0.0318, -0.0018,
        -0.0015, -0.0185,  0.0061, -0.0070, -0.0239, -0.0605, -0.0247, -0.0112,
        -0.0431, -0.0434,  0.0572,  0.0047,  0.0226, -0.0168,  0.0048, -0.0488,
        -0.0538, -0.0327,  0.0354, -0.0497, -0.0275,  0.0412, -0.0167, -0.0325,
        -0.0186, -0.0263, -0.0028,  0.0366, -0.0302,  0.0548, -0.0248,  0.0608,
         0.0355,  0.0157, -0.0331,  0.0613,  0.0537, -0.0169, -0.0456,  0.0502,
         0.0016,  0.0152, -0.0617,  0.0005,  0.0432,  0.0243,  0.0214,  0.0243,
        -0.0077, -0.0219, -0.0179, -0.0496, -0.0456,  0.0166,  0.0181, -0.0505,
        -0.0181,  0.0214, -0.0028,  0.0527, -0.0079,  0.0250,  0.0403, -0.0255,
        -0.0343, -0.0321,  0.0369, -0.0493, -0.0239, -0.0538, -0.0260,  0.0067],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0146, -0.0255, -0.0035,  0.0116,  0.0262,  0.0490, -0.0265, -0.0298,
         0.0304,  0.0131,  0.0304, -0.0583,  0.0556,  0.0331, -0.0496, -0.0300,
         0.0285,  0.0110, -0.0443, -0.0515, -0.0447,  0.0083, -0.0401, -0.0439,
         0.0560,  0.0112, -0.0206, -0.0049,  0.0125,  0.0295, -0.0109,  0.0379,
        -0.0457,  0.0523, -0.0167,  0.0120, -0.0301, -0.0025, -0.0617, -0.0137,
         0.0336,  0.0352,  0.0573, -0.0338,  0.0138,  0.0069,  0.0388,  0.0233,
        -0.0438, -0.0114,  0.0073,  0.0145, -0.0341, -0.0573,  0.0318, -0.0018,
        -0.0015, -0.0185,  0.0061, -0.0070, -0.0239, -0.0605, -0.0247, -0.0112,
        -0.0431, -0.0434,  0.0572,  0.0047,  0.0226, -0.0168,  0.0048, -0.0488,
        -0.0538, -0.0327,  0.0354, -0.0497, -0.0275,  0.0412, -0.0167, -0.0325,
        -0.0186, -0.0263, -0.0028,  0.0366, -0.0302,  0.0548, -0.0248,  0.0608,
         0.0355,  0.0157, -0.0331,  0.0613,  0.0537, -0.0169, -0.0456,  0.0502,
         0.0016,  0.0152, -0.0617,  0.0005,  0.0432,  0.0243,  0.0214,  0.0243,
        -0.0077, -0.0219, -0.0179, -0.0496, -0.0456,  0.0166,  0.0181, -0.0505,
        -0.0181,  0.0214, -0.0028,  0.0527, -0.0079,  0.0250,  0.0403, -0.0255,
        -0.0343, -0.0321,  0.0369, -0.0493, -0.0239, -0.0538, -0.0260,  0.0067],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.weight 
 torch.Size([64, 128]) 
 True 
 tensor([[ 0.0308, -0.0784, -0.0195,  ..., -0.0858,  0.0618,  0.0718],
        [-0.0188,  0.0541, -0.0324,  ..., -0.0372,  0.0684, -0.0490],
        [ 0.0392, -0.0595, -0.0700,  ...,  0.0688,  0.0409,  0.0560],
        ...,
        [-0.0331, -0.0172, -0.0060,  ...,  0.0520,  0.0295,  0.0678],
        [-0.0135,  0.0073,  0.0119,  ..., -0.0285,  0.0584, -0.0192],
        [ 0.0478,  0.0660,  0.0831,  ..., -0.0137, -0.0551, -0.0205]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0308, -0.0784, -0.0195,  ..., -0.0858,  0.0618,  0.0718],
        [-0.0188,  0.0541, -0.0324,  ..., -0.0372,  0.0684, -0.0490],
        [ 0.0392, -0.0595, -0.0700,  ...,  0.0688,  0.0409,  0.0560],
        ...,
        [-0.0331, -0.0172, -0.0060,  ...,  0.0520,  0.0295,  0.0678],
        [-0.0135,  0.0073,  0.0119,  ..., -0.0285,  0.0584, -0.0192],
        [ 0.0478,  0.0660,  0.0831,  ..., -0.0137, -0.0551, -0.0205]],
       device='cuda:0', requires_grad=True)
parameters of the network fc3.bias 
 torch.Size([64]) 
 True 
 tensor([ 0.0866, -0.0298,  0.0598, -0.0754, -0.0837,  0.0276,  0.0182, -0.0629,
         0.0237,  0.0291,  0.0177,  0.0620,  0.0639,  0.0761,  0.0273, -0.0169,
        -0.0571,  0.0191,  0.0694,  0.0624, -0.0009,  0.0840,  0.0391, -0.0394,
        -0.0169,  0.0391,  0.0152,  0.0530, -0.0176,  0.0094, -0.0695,  0.0481,
         0.0383, -0.0255, -0.0239, -0.0393,  0.0083,  0.0096,  0.0514,  0.0233,
        -0.0260,  0.0068,  0.0627, -0.0509, -0.0287, -0.0096,  0.0213,  0.0489,
        -0.0347,  0.0811,  0.0490, -0.0506,  0.0134,  0.0409,  0.0332,  0.0638,
        -0.0529, -0.0671,  0.0365,  0.0422, -0.0766, -0.0548,  0.0291, -0.0850],
       device='cuda:0') 
 Parameter containing:
tensor([ 0.0866, -0.0298,  0.0598, -0.0754, -0.0837,  0.0276,  0.0182, -0.0629,
         0.0237,  0.0291,  0.0177,  0.0620,  0.0639,  0.0761,  0.0273, -0.0169,
        -0.0571,  0.0191,  0.0694,  0.0624, -0.0009,  0.0840,  0.0391, -0.0394,
        -0.0169,  0.0391,  0.0152,  0.0530, -0.0176,  0.0094, -0.0695,  0.0481,
         0.0383, -0.0255, -0.0239, -0.0393,  0.0083,  0.0096,  0.0514,  0.0233,
        -0.0260,  0.0068,  0.0627, -0.0509, -0.0287, -0.0096,  0.0213,  0.0489,
        -0.0347,  0.0811,  0.0490, -0.0506,  0.0134,  0.0409,  0.0332,  0.0638,
        -0.0529, -0.0671,  0.0365,  0.0422, -0.0766, -0.0548,  0.0291, -0.0850],
       device='cuda:0', requires_grad=True)
parameters of the network fc4.weight 
 torch.Size([6796, 64]) 
 True 
 tensor([[-2.4949e-02, -1.0006e-01, -1.0102e-01,  ..., -1.0864e-01,
         -4.1625e-02,  1.1924e-01],
        [ 1.0515e-01,  4.4813e-02,  9.0565e-02,  ..., -7.4679e-02,
         -6.1702e-02,  5.3593e-02],
        [-1.0389e-02,  1.1763e-01, -3.0448e-02,  ...,  1.2344e-01,
         -4.3430e-02,  4.7424e-02],
        ...,
        [ 1.1695e-01, -9.3734e-02, -1.0180e-01,  ...,  8.0784e-02,
         -1.1053e-01,  3.4320e-02],
        [ 9.5114e-05, -6.9015e-02,  5.5913e-02,  ..., -1.6636e-02,
          7.2829e-02,  1.1890e-01],
        [ 6.5126e-02, -7.8668e-02, -1.1826e-01,  ...,  3.8232e-02,
          1.6224e-02,  4.5751e-02]], device='cuda:0') 
 Parameter containing:
tensor([[-2.4949e-02, -1.0006e-01, -1.0102e-01,  ..., -1.0864e-01,
         -4.1625e-02,  1.1924e-01],
        [ 1.0515e-01,  4.4813e-02,  9.0565e-02,  ..., -7.4679e-02,
         -6.1702e-02,  5.3593e-02],
        [-1.0389e-02,  1.1763e-01, -3.0448e-02,  ...,  1.2344e-01,
         -4.3430e-02,  4.7424e-02],
        ...,
        [ 1.1695e-01, -9.3734e-02, -1.0180e-01,  ...,  8.0784e-02,
         -1.1053e-01,  3.4320e-02],
        [ 9.5114e-05, -6.9015e-02,  5.5913e-02,  ..., -1.6636e-02,
          7.2829e-02,  1.1890e-01],
        [ 6.5126e-02, -7.8668e-02, -1.1826e-01,  ...,  3.8232e-02,
          1.6224e-02,  4.5751e-02]], device='cuda:0', requires_grad=True)
parameters of the network fc4.bias 
 torch.Size([6796]) 
 True 
 tensor([-0.0931, -0.0141,  0.0605,  ...,  0.0113, -0.0671,  0.0225],
       device='cuda:0') 
 Parameter containing:
tensor([-0.0931, -0.0141,  0.0605,  ...,  0.0113, -0.0671,  0.0225],
       device='cuda:0', requires_grad=True)

Passing event 1007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([[-0.1233,  0.0113,  0.0277,  ...,  0.0092, -0.0801,  0.0174],
        [-0.1233,  0.0113,  0.0275,  ...,  0.0093, -0.0800,  0.0178],
        [-0.1233,  0.0113,  0.0275,  ...,  0.0094, -0.0799,  0.0177],
        ...,
        [-0.1233,  0.0113,  0.0276,  ...,  0.0094, -0.0800,  0.0176],
        [-0.1232,  0.0113,  0.0273,  ...,  0.0091, -0.0800,  0.0177],
        [-0.1234,  0.0114,  0.0274,  ...,  0.0089, -0.0801,  0.0175]],
       device='cuda:0', grad_fn=<TanhBackward0>) 
result1.shape: torch.Size([20, 6796])

Passing two random events from the network before training 
result1: tensor([[-0.1233,  0.0113,  0.0277,  ...,  0.0092, -0.0801,  0.0174],
        [-0.1233,  0.0113,  0.0275,  ...,  0.0093, -0.0800,  0.0178],
        [-0.1233,  0.0113,  0.0275,  ...,  0.0094, -0.0799,  0.0177],
        ...,
        [-0.1233,  0.0113,  0.0276,  ...,  0.0094, -0.0800,  0.0176],
        [-0.1232,  0.0113,  0.0273,  ...,  0.0091, -0.0800,  0.0177],
        [-0.1234,  0.0114,  0.0274,  ...,  0.0089, -0.0801,  0.0175]],
       device='cuda:0', grad_fn=<TanhBackward0>) 
result1.shape: torch.Size([20, 6796]) 
input: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]



load_model False 
TraEvN 10008 
BatchSize 30 
EpochNum 30 
epoch_save 5 
LrVal 0.001 
weight_decay 0.0001 
startmesh 305 
endmesh 306 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[[[ 0.1365,  0.0634,  0.1282],
          [ 0.3034,  0.0424,  0.2197],
          [-0.0846, -0.2672,  0.3159]]],


        [[[-0.0439, -0.3265, -0.0232],
          [ 0.0054, -0.1233, -0.3020],
          [ 0.3055,  0.0485,  0.2305]]],


        [[[ 0.1208, -0.1645,  0.1958],
          [-0.1214, -0.3283, -0.2164],
          [-0.1885,  0.1984,  0.2014]]],


        ...,


        [[[ 0.2418, -0.1105,  0.3108],
          [-0.2589,  0.0633,  0.0737],
          [ 0.1762,  0.2413,  0.1364]]],


        [[[ 0.0935, -0.0680, -0.2618],
          [-0.2221, -0.3325,  0.3108],
          [ 0.1375,  0.3238, -0.1645]]],


        [[[ 0.0966, -0.0138,  0.2438],
          [ 0.3302, -0.0782,  0.2465],
          [-0.1160,  0.2738,  0.3322]]]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.3301, -0.3143,  0.2596, -0.3016,  0.1467,  0.2979,  0.2536, -0.1292,
         0.0624, -0.0516, -0.2673,  0.0853, -0.0952, -0.2302,  0.2147,  0.3253,
        -0.0070,  0.3164,  0.1630,  0.1089, -0.3141, -0.0496,  0.2092, -0.1959,
         0.1782, -0.2139,  0.0236,  0.1976, -0.0577, -0.2597,  0.0951,  0.3085,
         0.3036, -0.2008, -0.1623, -0.0144, -0.1473, -0.2016, -0.2512, -0.2220,
         0.2696,  0.0052, -0.3310,  0.1075, -0.2521, -0.2412,  0.1229,  0.0225,
         0.0737,  0.0350,  0.2876, -0.0177, -0.0573, -0.0254,  0.0398, -0.3219,
        -0.1076,  0.2699, -0.1188, -0.1774,  0.1873, -0.1937, -0.2190,  0.1176,
        -0.1862, -0.1306,  0.0842,  0.2177, -0.1512, -0.0774, -0.1403, -0.1685,
        -0.1377,  0.3057,  0.0493, -0.0768, -0.1334, -0.0216,  0.1364, -0.2795,
        -0.0167, -0.1339,  0.1355,  0.2275, -0.0481, -0.1562, -0.0718,  0.3317,
        -0.2993, -0.2353, -0.1190, -0.0309,  0.2908,  0.0827, -0.2634, -0.2757,
         0.1856, -0.0504, -0.2445, -0.0327,  0.1610, -0.0007, -0.1320, -0.0150,
        -0.1859, -0.1199,  0.1585, -0.2144,  0.1808,  0.2527, -0.1557,  0.0171,
        -0.0340,  0.0066,  0.1837, -0.1571, -0.2975, -0.2493, -0.2703, -0.2163,
        -0.2250, -0.0351, -0.0228, -0.0496, -0.0884, -0.0466,  0.0157, -0.1300,
         0.3034,  0.0009, -0.0608, -0.0918,  0.1466,  0.1433, -0.2690, -0.2057,
         0.3204,  0.3295,  0.0164,  0.3201,  0.2074, -0.1526, -0.2757, -0.2446,
         0.1179,  0.1245,  0.2031,  0.0709, -0.2448,  0.2108, -0.1685,  0.1096,
         0.0674, -0.2637, -0.0805,  0.3018, -0.1218,  0.0566,  0.2822,  0.0613,
        -0.0407, -0.0025, -0.2585, -0.2118,  0.3061,  0.2972, -0.2987, -0.0646,
         0.0259,  0.2497, -0.2157,  0.0733,  0.2167,  0.1202,  0.0034, -0.2196,
         0.1668, -0.2597,  0.2115,  0.3191, -0.0229, -0.1223, -0.1098, -0.0931,
        -0.1908,  0.0660,  0.1668, -0.0974,  0.0235,  0.0641, -0.1592, -0.0794,
         0.0712,  0.1607,  0.2750, -0.1182, -0.2408,  0.2274,  0.0237,  0.0886,
        -0.0940,  0.1444,  0.1362, -0.2689,  0.2667,  0.2062, -0.0928, -0.0380,
        -0.3322, -0.0050,  0.1441, -0.0733, -0.1347,  0.0500,  0.0429, -0.0491,
        -0.3169, -0.1599, -0.0736,  0.0871, -0.3276,  0.1705, -0.2864,  0.2323,
        -0.3301, -0.1291,  0.2886,  0.2735, -0.0632, -0.1541, -0.2002,  0.2158,
        -0.0064,  0.0635, -0.0363,  0.0048, -0.2354,  0.1227,  0.0618,  0.3218,
        -0.3227,  0.0427, -0.1370, -0.0772,  0.0139,  0.0041, -0.1122,  0.0891,
         0.0354, -0.0595, -0.1697,  0.0046,  0.1868,  0.0263,  0.2966, -0.1496],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[ 9.6523e-03,  1.8857e-02, -2.0635e-02],
          [ 5.3270e-03,  1.4328e-02, -1.4185e-02],
          [-1.7151e-02,  1.6000e-02,  1.0798e-02]],

         [[-1.5245e-02, -1.8752e-02, -4.4059e-03],
          [-8.8792e-03, -2.0131e-02, -1.9737e-02],
          [-1.5439e-02, -9.4015e-03, -1.8323e-02]],

         [[ 1.7097e-02,  2.0794e-02, -3.0245e-03],
          [ 1.3821e-02,  1.1073e-02, -1.8223e-02],
          [-3.8369e-03,  1.5777e-02,  1.4149e-02]],

         ...,

         [[ 8.6842e-03,  1.6215e-03,  1.3569e-02],
          [ 2.0711e-02, -2.0922e-03, -1.1631e-02],
          [-1.3673e-03, -1.1257e-02,  6.7959e-03]],

         [[ 3.7557e-03, -1.8036e-02, -5.3567e-03],
          [ 1.3854e-02, -1.7324e-02, -2.0774e-02],
          [-3.0345e-03, -8.0616e-04,  1.4631e-02]],

         [[ 2.0734e-02,  2.8000e-03,  1.0670e-02],
          [-1.1762e-02,  1.0680e-03, -1.7131e-02],
          [-4.7164e-03,  6.4863e-03, -1.1764e-02]]],


        [[[-1.7094e-02, -1.0081e-02, -7.0719e-03],
          [-2.0763e-02, -9.9568e-03, -1.4303e-02],
          [-1.5592e-02,  1.8146e-02,  2.9996e-03]],

         [[-1.9040e-02, -1.9274e-02, -7.3387e-03],
          [ 7.6573e-03, -7.8644e-03,  9.2295e-03],
          [ 1.3356e-02,  1.7302e-03, -4.3014e-03]],

         [[-1.0173e-02,  6.7769e-03,  1.2203e-02],
          [-2.8143e-03, -2.7564e-03,  1.1230e-02],
          [ 3.0779e-03, -1.0137e-02, -8.8210e-03]],

         ...,

         [[-1.8023e-02, -1.5240e-02, -1.2748e-02],
          [ 1.6826e-02, -3.0385e-03, -5.9470e-03],
          [-1.2211e-02, -1.9214e-02,  1.9738e-02]],

         [[ 8.7187e-03, -1.2111e-02,  1.1724e-02],
          [ 2.0109e-02,  1.4926e-02,  7.4265e-04],
          [ 1.8214e-02,  3.0723e-03,  1.7641e-02]],

         [[ 1.8506e-02,  1.1961e-02, -1.2326e-02],
          [ 2.7330e-03,  4.6137e-03, -6.8403e-03],
          [-1.1702e-02,  7.0226e-03,  1.0684e-02]]],


        [[[-2.0489e-02,  3.2249e-04, -1.3531e-02],
          [-1.0409e-02, -1.6456e-02,  1.5809e-02],
          [-1.7256e-02,  9.4350e-03, -7.4618e-03]],

         [[-8.1340e-03, -1.6273e-02, -9.5159e-03],
          [ 5.0177e-03,  1.7476e-04,  1.6053e-02],
          [-1.2659e-02, -1.2499e-02, -1.6123e-03]],

         [[ 1.1089e-02, -1.9049e-02,  1.7875e-02],
          [-1.8377e-02, -1.9802e-02,  1.5109e-02],
          [ 3.4052e-04,  9.5141e-03,  1.5208e-02]],

         ...,

         [[ 1.0274e-02, -1.0860e-02,  8.4504e-03],
          [-8.0987e-03,  6.6583e-03, -8.6819e-03],
          [ 2.0542e-02,  1.9885e-02, -1.4371e-02]],

         [[-2.6663e-03,  1.3536e-02, -9.1108e-04],
          [ 4.9406e-03, -1.5664e-02, -4.0086e-04],
          [ 1.9432e-02,  1.9640e-02, -1.6323e-02]],

         [[-2.0997e-03, -6.9756e-03,  1.8689e-02],
          [-1.4351e-02, -1.8876e-04, -7.3234e-03],
          [ 1.6859e-02,  4.1876e-03,  3.4434e-03]]],


        ...,


        [[[ 6.5481e-04, -1.0955e-02,  9.0845e-03],
          [-2.0453e-02, -1.3297e-02, -3.0511e-03],
          [ 2.8653e-03,  1.8174e-02,  1.0993e-02]],

         [[ 5.3097e-03,  1.2497e-02, -1.3083e-02],
          [-7.2331e-03, -1.1013e-02,  4.2739e-03],
          [ 2.5044e-03,  1.1624e-02,  1.6807e-02]],

         [[-2.4365e-03,  5.5354e-04, -1.5423e-03],
          [ 1.4944e-03, -4.7100e-03, -1.4307e-02],
          [-1.6624e-03, -1.9849e-02,  3.6362e-03]],

         ...,

         [[-2.0385e-03, -3.7616e-03,  3.8099e-03],
          [ 7.2245e-04,  1.8433e-02,  1.7452e-02],
          [-1.3441e-02,  1.7067e-03,  1.3826e-04]],

         [[-5.3270e-03,  2.6133e-03,  1.9654e-02],
          [ 1.1702e-02, -7.2242e-03, -1.8410e-02],
          [ 1.9709e-02,  1.0237e-02, -1.8945e-02]],

         [[-1.1785e-02, -8.1971e-03, -1.8714e-02],
          [-2.8370e-03, -4.1563e-03,  9.1840e-03],
          [ 3.4422e-03,  2.0151e-02, -1.5898e-02]]],


        [[[-1.7399e-02,  6.9736e-03,  1.2958e-02],
          [-1.3594e-02, -1.6910e-02, -4.7962e-03],
          [-3.2362e-03,  1.2976e-02,  6.1702e-03]],

         [[ 1.6628e-02,  9.9445e-03, -1.4950e-02],
          [-1.6286e-02, -2.0126e-02,  1.3142e-02],
          [ 1.4414e-02,  8.8897e-03,  1.4451e-02]],

         [[-1.2380e-02, -6.2399e-03, -2.2666e-03],
          [ 1.6831e-02, -9.6647e-03, -1.8286e-02],
          [ 1.2819e-02, -1.9449e-02,  3.9639e-03]],

         ...,

         [[ 5.6157e-03,  1.5936e-02,  1.7576e-02],
          [ 9.2463e-03, -1.9075e-02, -9.4090e-03],
          [-1.9510e-02, -1.2765e-02, -2.7594e-03]],

         [[ 1.1712e-02, -6.6999e-03, -7.4531e-03],
          [ 1.2634e-02,  8.7416e-03,  1.0879e-02],
          [-5.1442e-03,  1.6151e-02, -6.1956e-03]],

         [[-1.8044e-02, -1.2836e-02,  1.6444e-02],
          [ 7.0460e-03, -8.7291e-04,  1.9111e-02],
          [ 1.3073e-02, -5.6643e-03,  3.9583e-03]]],


        [[[ 2.6260e-03, -4.8641e-03, -1.8978e-02],
          [ 6.1085e-03,  6.6349e-03, -1.9355e-02],
          [-1.8983e-02, -5.1619e-03, -1.6886e-02]],

         [[ 1.9689e-02, -4.8627e-03,  1.3331e-03],
          [-1.2137e-02, -2.5957e-03,  2.1985e-03],
          [-6.5756e-03,  1.6766e-02,  5.4637e-03]],

         [[ 1.2748e-05,  1.3803e-02,  1.0038e-02],
          [ 3.0737e-03, -9.5890e-03,  1.8569e-02],
          [ 1.4484e-02,  1.3513e-02, -1.9683e-02]],

         ...,

         [[-1.9354e-02, -1.8656e-03, -9.9481e-03],
          [ 1.7063e-02, -1.2662e-02,  2.4464e-03],
          [ 4.2848e-03, -8.0842e-03,  1.6858e-03]],

         [[ 4.8825e-03, -7.9121e-03,  1.4763e-02],
          [ 1.6768e-02,  6.3914e-03, -1.7228e-02],
          [-1.3600e-02, -1.9079e-02,  1.5404e-02]],

         [[ 1.1446e-02,  3.6312e-03, -8.7406e-03],
          [ 2.6022e-03, -1.8315e-02, -4.8054e-03],
          [ 1.5778e-02, -1.0965e-02,  1.0203e-02]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([-0.0184,  0.0065,  0.0085,  0.0114, -0.0056, -0.0185, -0.0206, -0.0010,
         0.0137,  0.0037, -0.0029,  0.0196, -0.0114,  0.0140, -0.0207, -0.0201,
         0.0116,  0.0004, -0.0147,  0.0012,  0.0140, -0.0027,  0.0160, -0.0065,
         0.0045,  0.0186,  0.0204, -0.0148, -0.0071,  0.0124, -0.0155,  0.0185,
        -0.0060, -0.0090, -0.0118,  0.0094,  0.0053,  0.0070, -0.0029,  0.0207,
         0.0173, -0.0064, -0.0099, -0.0137,  0.0142,  0.0176, -0.0099, -0.0169,
         0.0032, -0.0133,  0.0174,  0.0145, -0.0093,  0.0070,  0.0181, -0.0118,
        -0.0034, -0.0018, -0.0152, -0.0049, -0.0134,  0.0046, -0.0062,  0.0066,
         0.0169,  0.0104, -0.0035,  0.0036, -0.0147,  0.0170,  0.0160,  0.0172,
         0.0072, -0.0178, -0.0197,  0.0151,  0.0002, -0.0113, -0.0181, -0.0052,
        -0.0166,  0.0092,  0.0075,  0.0027,  0.0098,  0.0180,  0.0203,  0.0140,
        -0.0050, -0.0093,  0.0170, -0.0057, -0.0076,  0.0012, -0.0100,  0.0077,
        -0.0144, -0.0061, -0.0076,  0.0152,  0.0018, -0.0095, -0.0097,  0.0085,
        -0.0052,  0.0148, -0.0205, -0.0073,  0.0194, -0.0018, -0.0079, -0.0114,
         0.0187, -0.0150,  0.0104, -0.0099,  0.0146,  0.0122,  0.0118, -0.0030,
         0.0011, -0.0029, -0.0003, -0.0135, -0.0086,  0.0169,  0.0078,  0.0132],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[[[-1.7198e-02,  2.7940e-02, -2.9067e-02],
          [ 1.7867e-02, -7.2168e-03,  1.9256e-02],
          [ 1.1685e-02, -1.7754e-02, -1.8437e-02]],

         [[ 9.3728e-03, -2.0525e-02, -2.8353e-02],
          [-6.1900e-05, -2.0254e-04,  1.6545e-02],
          [-1.3548e-02,  1.0159e-02, -2.9324e-04]],

         [[ 1.5207e-02,  1.4826e-02, -4.1385e-03],
          [ 1.5501e-03,  2.3402e-02, -1.8457e-03],
          [-2.8626e-02,  1.0163e-02,  1.7968e-02]],

         ...,

         [[ 2.7437e-02, -2.2868e-02, -7.5602e-03],
          [-8.3196e-04, -1.6114e-02,  9.3629e-03],
          [-1.7033e-02,  2.2063e-02, -2.6407e-02]],

         [[-8.8413e-03,  2.2718e-02, -1.4401e-02],
          [-1.8941e-02,  5.3310e-03, -1.1081e-02],
          [ 7.8783e-03, -1.1862e-02, -1.4230e-03]],

         [[ 2.3462e-02, -6.1988e-03,  1.5973e-02],
          [-9.8774e-03,  1.8872e-02,  6.1011e-03],
          [-1.5521e-02,  7.4547e-03,  1.8579e-02]]],


        [[[-9.9322e-03, -6.5645e-03,  2.3656e-02],
          [-1.2047e-02, -5.5653e-03, -4.4935e-03],
          [ 2.0162e-02,  2.5708e-03,  9.0420e-03]],

         [[ 3.0725e-03, -2.3605e-02,  1.9630e-02],
          [ 1.5096e-02, -1.4991e-02,  3.7327e-03],
          [ 9.6004e-03, -3.9864e-03,  1.4348e-02]],

         [[-1.1324e-02, -2.3489e-02,  6.9235e-03],
          [-2.7482e-02,  1.3754e-02,  2.3643e-02],
          [-9.4603e-03, -8.7204e-03, -1.5461e-02]],

         ...,

         [[ 1.2399e-02, -5.1459e-04, -2.5198e-02],
          [-5.2935e-03, -1.2930e-02,  1.0714e-02],
          [-1.2636e-02,  2.5730e-02,  1.9515e-02]],

         [[-2.6639e-02,  5.8851e-03, -5.1466e-03],
          [-3.8981e-03, -2.3580e-02,  1.1012e-02],
          [-2.1279e-03,  7.6229e-03,  2.0463e-03]],

         [[ 9.1271e-03,  2.8227e-02,  2.6484e-02],
          [ 1.0395e-02, -2.5879e-02,  1.2176e-02],
          [ 2.8968e-02,  1.2082e-03, -2.3320e-02]]],


        [[[-2.9440e-02,  1.3247e-02,  1.6973e-03],
          [-6.5303e-03,  1.2279e-02,  2.7685e-02],
          [ 2.6135e-02, -1.1678e-02,  1.9401e-02]],

         [[-7.3120e-03,  1.8502e-02,  1.2751e-02],
          [-2.5114e-02, -9.1101e-03, -1.7970e-02],
          [-4.8128e-03,  1.8424e-02, -2.8991e-02]],

         [[-1.0829e-02,  2.9034e-02, -3.9104e-03],
          [-8.3583e-03,  1.3562e-03,  8.2053e-03],
          [-1.4869e-02, -1.6514e-03,  1.1357e-02]],

         ...,

         [[ 2.1696e-02, -5.6982e-03,  1.8312e-02],
          [-1.3858e-03,  1.6157e-02,  2.4770e-02],
          [-1.5052e-02,  2.6057e-02,  2.8267e-02]],

         [[ 2.2596e-02, -1.7286e-02, -9.4499e-03],
          [ 1.7039e-02,  2.5748e-02,  2.0841e-02],
          [ 1.0816e-02,  1.4807e-02, -2.4615e-02]],

         [[-3.8938e-03,  2.3334e-02,  2.1775e-02],
          [-1.2300e-02, -3.2544e-03, -1.3446e-02],
          [ 1.6880e-02, -1.3765e-02,  1.2109e-02]]],


        ...,


        [[[-2.4724e-02,  2.2631e-03, -2.7342e-02],
          [ 9.4691e-03, -2.3411e-02, -1.3608e-02],
          [-2.3599e-02,  1.6276e-02,  4.8593e-03]],

         [[ 1.9975e-02,  1.9886e-02,  2.4194e-02],
          [ 6.7931e-03, -8.3723e-03,  2.6893e-04],
          [ 1.3391e-02,  2.6894e-02,  1.4727e-02]],

         [[-8.4196e-03,  2.4458e-02,  8.2713e-03],
          [ 1.5602e-02, -1.5368e-02,  1.7659e-02],
          [-1.2612e-02, -1.6600e-02, -2.8419e-02]],

         ...,

         [[ 1.2234e-02, -1.2439e-02, -4.2199e-03],
          [-2.6552e-02, -1.1327e-02,  1.5551e-02],
          [ 3.8368e-03, -1.4043e-02, -2.3361e-02]],

         [[ 7.6830e-03, -2.8771e-02, -2.6860e-02],
          [ 4.4224e-03, -1.9232e-02, -1.8536e-02],
          [ 2.3377e-02, -2.4900e-02,  2.9274e-02]],

         [[-1.6658e-03, -1.8553e-03, -2.0682e-02],
          [ 4.7011e-03,  2.1108e-02, -1.6459e-02],
          [-5.5520e-03, -1.8805e-05, -1.6018e-02]]],


        [[[ 1.2336e-02, -8.1696e-03,  6.9215e-03],
          [-5.5210e-03,  6.8099e-04,  3.8969e-03],
          [ 3.3525e-03, -2.1812e-02, -1.5952e-02]],

         [[-1.7374e-02, -3.1130e-03, -9.3640e-03],
          [ 9.5154e-03, -7.2519e-03,  6.8179e-03],
          [-2.1229e-02, -3.4450e-03,  2.0826e-02]],

         [[ 1.6290e-02, -2.4972e-02,  4.5296e-03],
          [-1.2615e-02,  1.4047e-02, -1.2479e-02],
          [-9.4185e-03,  1.1403e-02, -9.7915e-03]],

         ...,

         [[-1.1446e-03, -5.7107e-03, -2.6393e-02],
          [ 1.5612e-02,  2.2528e-02,  1.8396e-02],
          [ 2.0905e-02, -7.4124e-03, -2.3069e-02]],

         [[-2.5040e-02, -7.8777e-03,  1.1636e-02],
          [-1.0198e-02, -2.2445e-02,  9.1419e-04],
          [-1.0400e-02,  2.8372e-02, -1.0903e-02]],

         [[-2.9094e-04, -1.2736e-02,  2.2513e-02],
          [-3.0297e-03,  2.6086e-02, -3.2669e-03],
          [-2.3886e-02, -1.2524e-02,  2.3304e-02]]],


        [[[-3.5636e-03, -1.2934e-02, -2.3888e-02],
          [ 1.4170e-02,  2.3284e-02, -1.5566e-02],
          [ 1.8602e-02,  2.7389e-02,  1.5756e-02]],

         [[-1.2817e-02, -6.2735e-03,  4.2991e-03],
          [ 3.2025e-03,  2.9356e-02, -9.0245e-03],
          [-2.0173e-02,  4.5353e-03, -2.4210e-02]],

         [[ 1.4677e-02, -9.4783e-04,  4.0573e-03],
          [-6.6413e-03,  1.7009e-02,  7.6570e-04],
          [-1.1370e-02, -2.0277e-02, -1.1386e-02]],

         ...,

         [[-2.9276e-02,  9.1124e-03,  3.9844e-03],
          [ 6.1416e-03, -8.6654e-03,  8.3142e-03],
          [-3.1780e-03, -3.1551e-03,  2.4916e-02]],

         [[ 2.8426e-02, -6.4266e-03, -1.5769e-02],
          [-1.9493e-02, -3.5080e-03,  2.5468e-02],
          [ 1.1843e-02, -2.3012e-02,  1.2617e-02]],

         [[-8.9353e-03, -1.3834e-02, -1.5740e-02],
          [ 3.0274e-03, -2.3203e-02, -2.9812e-03],
          [ 2.4825e-02,  2.4326e-02,  3.7773e-03]]]], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([ 1.2925e-02, -2.8340e-02, -2.2119e-02,  1.7973e-02, -2.5629e-02,
         1.6713e-03, -4.5494e-04,  7.3140e-03, -1.1474e-02, -2.4245e-02,
        -2.4731e-02, -1.7754e-02, -1.0132e-02, -1.4753e-02, -1.7116e-03,
        -2.1424e-02,  1.8921e-02,  2.5732e-03, -2.1065e-03,  1.8724e-02,
        -2.6229e-02, -1.2588e-02,  1.8256e-02, -2.1994e-02,  1.2928e-03,
        -1.3472e-02,  5.5339e-03, -6.3103e-03,  1.3384e-02,  2.4037e-02,
         5.8723e-03, -6.3647e-03, -2.0924e-02,  1.0217e-02,  2.8223e-02,
         2.0527e-03,  5.4846e-03, -1.2194e-02, -6.0574e-03,  2.6820e-02,
        -1.5106e-02, -2.4590e-02, -2.3627e-02, -1.6032e-02,  7.1653e-05,
         2.4337e-02,  8.6639e-04, -5.8384e-03,  7.9358e-03,  2.0289e-02,
        -1.3435e-02,  6.3464e-03,  1.3167e-02,  5.7539e-04,  1.1267e-02,
         2.5924e-02, -7.2255e-03,  5.1039e-04,  2.2475e-02,  1.4289e-03,
         2.5346e-02,  2.9852e-03,  7.2466e-03, -2.2359e-03], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[-1.0167e-03, -7.9711e-04, -6.1652e-04,  ..., -1.2207e-03,
          9.1585e-04, -1.3481e-04],
        [ 1.0409e-03, -4.7957e-04,  3.7023e-04,  ..., -4.1433e-04,
          5.4535e-04,  4.4666e-05],
        [-1.0489e-03, -5.6772e-04, -5.4059e-04,  ...,  4.6646e-04,
          4.5091e-04, -1.9330e-04],
        ...,
        [ 5.6396e-04, -4.5875e-04, -7.7641e-04,  ..., -1.0306e-03,
          9.4737e-05, -9.8452e-04],
        [-2.2380e-04,  3.8886e-04, -4.3662e-04,  ...,  4.9510e-04,
          8.0998e-04,  8.0477e-04],
        [-1.1275e-03, -8.5918e-04,  1.2136e-03,  ..., -1.0646e-04,
          3.6420e-04, -1.0462e-03]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 8.2490e-05,  7.9214e-04, -4.6564e-04, -1.0110e-03, -9.6571e-04,
         7.4078e-04,  1.1145e-03, -2.6957e-04,  1.1915e-03,  1.1747e-03,
        -5.8867e-04,  7.2217e-04,  3.8313e-05,  9.6535e-04, -1.1793e-03,
         7.1274e-04, -6.2603e-04,  6.9898e-04, -2.6961e-05, -1.1569e-03,
         2.9337e-04,  4.1618e-04,  9.8982e-04,  8.2820e-04,  3.5958e-04,
        -1.0010e-03,  1.6920e-04, -2.3556e-04,  1.1794e-03,  4.0641e-04,
         9.0323e-04,  1.6744e-04,  8.7198e-05,  9.4663e-04,  1.5950e-04,
        -5.4904e-05, -1.0279e-03, -1.8942e-04,  6.6067e-04, -1.4668e-04,
         1.1107e-03,  2.5380e-04,  1.1150e-03, -5.6788e-04, -1.1781e-03,
         7.3234e-04,  5.2115e-04, -9.4535e-04,  3.5736e-04,  1.0765e-03,
        -4.8418e-04, -8.8663e-04, -1.1302e-03,  1.0342e-03, -6.8624e-04,
        -9.3784e-04,  1.1971e-03, -2.8124e-04, -6.4876e-04,  7.3768e-04,
        -1.3691e-04, -5.2910e-05,  1.0802e-03,  7.2598e-05,  3.7359e-04,
        -7.4984e-04,  3.4124e-04, -4.4581e-04, -1.3135e-04, -1.1280e-03,
         8.2058e-04, -4.7856e-04,  2.4444e-04, -5.9814e-04,  5.0440e-04,
         2.3484e-04, -7.1410e-04, -6.1887e-04,  1.0223e-03, -2.6023e-05,
        -1.1177e-03, -9.9812e-04,  7.4757e-04,  4.1047e-04,  9.8998e-04,
        -1.5070e-04, -1.0127e-03, -5.5961e-04, -1.2132e-03,  1.1563e-03,
         6.1132e-04,  3.5548e-04,  8.2525e-05,  3.5655e-04,  7.9925e-04,
        -9.8057e-04,  6.4325e-04,  1.0989e-03,  8.7143e-04, -4.5986e-04,
         5.7024e-04,  1.0072e-03,  1.0436e-03, -1.1720e-03, -1.1004e-03,
        -1.0363e-03, -4.4857e-05,  5.5693e-04, -8.2361e-04, -2.8400e-04,
        -5.4471e-04, -5.1889e-04,  2.5192e-04,  7.3594e-05,  4.0026e-04,
        -1.0342e-03, -2.5211e-04,  1.3573e-05,  1.0586e-03,  6.9255e-04,
        -9.1473e-04,  9.8570e-04,  1.0302e-03,  1.1541e-03, -9.5821e-04,
        -7.9774e-04,  9.0594e-04, -1.0331e-03,  1.4645e-05,  8.2563e-04,
        -4.8806e-04, -9.2835e-04, -8.0500e-05,  1.1810e-03,  1.4080e-04,
        -1.3869e-04, -6.9341e-04, -9.9163e-04,  6.2961e-04, -3.3478e-04,
        -6.5256e-04, -7.6679e-04, -1.1920e-03,  9.4395e-04, -5.0802e-04,
         1.1457e-03,  7.0343e-04,  7.8325e-04, -6.4942e-04,  1.1788e-03,
        -7.2126e-04, -3.5105e-04,  3.8601e-04, -1.0603e-03,  7.4049e-04,
        -5.2252e-04,  9.5582e-04, -9.3071e-04,  1.9794e-04,  1.0190e-03,
        -4.7878e-04, -1.0513e-03, -4.5800e-05, -1.4807e-04, -1.1599e-03,
         1.0344e-03, -6.3925e-04, -1.0943e-03,  5.8245e-04,  1.0895e-03,
        -8.4961e-04,  5.5546e-05,  2.0741e-04, -2.2007e-04, -3.6700e-04,
        -9.7091e-04,  9.9772e-04, -8.0280e-04,  6.0113e-04, -6.1427e-05,
        -6.7603e-04,  7.2016e-04, -3.6544e-04, -1.2526e-05,  8.5646e-04,
         2.5470e-04, -9.9230e-04, -8.8535e-05,  7.1564e-04, -6.1584e-04,
         3.9028e-04, -8.2282e-04,  1.0631e-03,  1.0438e-04, -6.0402e-04,
         8.1669e-04,  1.2002e-03, -8.8434e-04, -8.1060e-04,  8.5121e-05,
        -5.9289e-04, -3.2750e-04,  2.7762e-04,  1.1664e-03,  3.1957e-04,
        -2.3027e-04,  3.9996e-04,  6.2040e-04,  7.2916e-04,  2.5134e-05,
         2.2891e-04, -2.0518e-04,  1.1346e-03,  4.1367e-04, -3.1525e-04,
        -1.0020e-04,  3.9422e-04, -4.0628e-04,  2.5092e-04, -3.0448e-04,
        -5.3575e-04, -3.7205e-05,  1.0253e-03, -4.6911e-04,  6.7080e-04,
         1.1481e-03, -5.4737e-04, -4.8293e-04,  8.5930e-04, -4.6021e-05,
         8.7356e-04, -8.2400e-04,  7.0621e-04,  4.0010e-04, -9.2210e-05,
        -3.0186e-04,  4.8250e-04, -1.7573e-04,  1.1657e-03,  1.1834e-03,
        -1.3861e-04, -7.4215e-04,  2.5374e-06,  1.0761e-03, -4.5970e-04,
         2.8531e-04, -1.0594e-03, -5.1552e-05,  5.2889e-04, -8.6710e-04,
         4.6757e-04,  3.0927e-04,  8.5147e-04, -9.1277e-04,  9.6686e-04,
         4.4460e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0174, -0.0114,  0.0484,  ...,  0.0023, -0.0041,  0.0069],
        [ 0.0006,  0.0028,  0.0379,  ...,  0.0272,  0.0568, -0.0385],
        [ 0.0090, -0.0161,  0.0416,  ..., -0.0535,  0.0581, -0.0574],
        ...,
        [-0.0110, -0.0366, -0.0179,  ..., -0.0119, -0.0015, -0.0489],
        [ 0.0097,  0.0624,  0.0618,  ...,  0.0016,  0.0272, -0.0114],
        [-0.0509,  0.0286, -0.0018,  ...,  0.0613, -0.0220, -0.0525]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0146, -0.0255, -0.0035,  0.0116,  0.0262,  0.0490, -0.0265, -0.0298,
         0.0304,  0.0131,  0.0304, -0.0583,  0.0556,  0.0331, -0.0496, -0.0300,
         0.0285,  0.0110, -0.0443, -0.0515, -0.0447,  0.0083, -0.0401, -0.0439,
         0.0560,  0.0112, -0.0206, -0.0049,  0.0125,  0.0295, -0.0109,  0.0379,
        -0.0457,  0.0523, -0.0167,  0.0120, -0.0301, -0.0025, -0.0617, -0.0137,
         0.0336,  0.0352,  0.0573, -0.0338,  0.0138,  0.0069,  0.0388,  0.0233,
        -0.0438, -0.0114,  0.0073,  0.0145, -0.0341, -0.0573,  0.0318, -0.0018,
        -0.0015, -0.0185,  0.0061, -0.0070, -0.0239, -0.0605, -0.0247, -0.0112,
        -0.0431, -0.0434,  0.0572,  0.0047,  0.0226, -0.0168,  0.0048, -0.0488,
        -0.0538, -0.0327,  0.0354, -0.0497, -0.0275,  0.0412, -0.0167, -0.0325,
        -0.0186, -0.0263, -0.0028,  0.0366, -0.0302,  0.0548, -0.0248,  0.0608,
         0.0355,  0.0157, -0.0331,  0.0613,  0.0537, -0.0169, -0.0456,  0.0502,
         0.0016,  0.0152, -0.0617,  0.0005,  0.0432,  0.0243,  0.0214,  0.0243,
        -0.0077, -0.0219, -0.0179, -0.0496, -0.0456,  0.0166,  0.0181, -0.0505,
        -0.0181,  0.0214, -0.0028,  0.0527, -0.0079,  0.0250,  0.0403, -0.0255,
        -0.0343, -0.0321,  0.0369, -0.0493, -0.0239, -0.0538, -0.0260,  0.0067],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0308, -0.0784, -0.0195,  ..., -0.0858,  0.0618,  0.0718],
        [-0.0188,  0.0541, -0.0324,  ..., -0.0372,  0.0684, -0.0490],
        [ 0.0392, -0.0595, -0.0700,  ...,  0.0688,  0.0409,  0.0560],
        ...,
        [-0.0331, -0.0172, -0.0060,  ...,  0.0520,  0.0295,  0.0678],
        [-0.0135,  0.0073,  0.0119,  ..., -0.0285,  0.0584, -0.0192],
        [ 0.0478,  0.0660,  0.0831,  ..., -0.0137, -0.0551, -0.0205]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0866, -0.0298,  0.0598, -0.0754, -0.0837,  0.0276,  0.0182, -0.0629,
         0.0237,  0.0291,  0.0177,  0.0620,  0.0639,  0.0761,  0.0273, -0.0169,
        -0.0571,  0.0191,  0.0694,  0.0624, -0.0009,  0.0840,  0.0391, -0.0394,
        -0.0169,  0.0391,  0.0152,  0.0530, -0.0176,  0.0094, -0.0695,  0.0481,
         0.0383, -0.0255, -0.0239, -0.0393,  0.0083,  0.0096,  0.0514,  0.0233,
        -0.0260,  0.0068,  0.0627, -0.0509, -0.0287, -0.0096,  0.0213,  0.0489,
        -0.0347,  0.0811,  0.0490, -0.0506,  0.0134,  0.0409,  0.0332,  0.0638,
        -0.0529, -0.0671,  0.0365,  0.0422, -0.0766, -0.0548,  0.0291, -0.0850],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-2.4949e-02, -1.0006e-01, -1.0102e-01,  ..., -1.0864e-01,
         -4.1625e-02,  1.1924e-01],
        [ 1.0515e-01,  4.4813e-02,  9.0565e-02,  ..., -7.4679e-02,
         -6.1702e-02,  5.3593e-02],
        [-1.0389e-02,  1.1763e-01, -3.0448e-02,  ...,  1.2344e-01,
         -4.3430e-02,  4.7424e-02],
        ...,
        [ 1.1695e-01, -9.3734e-02, -1.0180e-01,  ...,  8.0784e-02,
         -1.1053e-01,  3.4320e-02],
        [ 9.5114e-05, -6.9015e-02,  5.5913e-02,  ..., -1.6636e-02,
          7.2829e-02,  1.1890e-01],
        [ 6.5126e-02, -7.8668e-02, -1.1826e-01,  ...,  3.8232e-02,
          1.6224e-02,  4.5751e-02]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0931, -0.0141,  0.0605,  ...,  0.0113, -0.0671,  0.0225],
       device='cuda:0', requires_grad=True)], 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}]
epoch: 0 batch 0.0 event: 0 loss: tensor(184.4722, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 10.0 event: 300 loss: tensor(2016.7347, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 30.0 event: 900 loss: tensor(3446.2278, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 40.0 event: 1200 loss: tensor(1822.5006, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 50.0 event: 1500 loss: tensor(2037.3690, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 60.0 event: 1800 loss: tensor(1798.2770, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 70.0 event: 2100 loss: tensor(1840.6522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 80.0 event: 2400 loss: tensor(1575.3679, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 90.0 event: 2700 loss: tensor(2061.3755, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 100.0 event: 3000 loss: tensor(1791.4121, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 110.0 event: 3300 loss: tensor(1866.5078, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 120.0 event: 3600 loss: tensor(1914.5800, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 130.0 event: 3900 loss: tensor(1763.8265, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 140.0 event: 4200 loss: tensor(1974.4746, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 150.0 event: 4500 loss: tensor(2011.4941, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 160.0 event: 4800 loss: tensor(1769.5648, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 170.0 event: 5100 loss: tensor(1580.0081, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 190.0 event: 5700 loss: tensor(3836.5208, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 200.0 event: 6000 loss: tensor(2136.3340, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 210.0 event: 6300 loss: tensor(1745.2279, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 220.0 event: 6600 loss: tensor(2066.9080, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 230.0 event: 6900 loss: tensor(1824.3469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 240.0 event: 7200 loss: tensor(2096.1667, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 250.0 event: 7500 loss: tensor(2074.3250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 260.0 event: 7800 loss: tensor(2014.7406, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 270.0 event: 8100 loss: tensor(1985.6725, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 280.0 event: 8400 loss: tensor(1840.9528, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 290.0 event: 8700 loss: tensor(1762.7168, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 300.0 event: 9000 loss: tensor(2048.6030, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 310.0 event: 9300 loss: tensor(1980.2125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 320.0 event: 9600 loss: tensor(1930.8496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 0 batch 330.0 event: 9900 loss: tensor(1839.7460, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:00:22.083917
evaluation loss: 1985.3826904296875
epoch: 0 mean loss: 1899.428955078125
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 1 batch 0.0 event: 0 loss: tensor(182.2335, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 10.0 event: 300 loss: tensor(1981.3496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 30.0 event: 900 loss: tensor(3387.2297, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 40.0 event: 1200 loss: tensor(1786.5520, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 50.0 event: 1500 loss: tensor(1996.1659, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 60.0 event: 1800 loss: tensor(1758.8301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 70.0 event: 2100 loss: tensor(1801.6914, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 80.0 event: 2400 loss: tensor(1537.3574, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 90.0 event: 2700 loss: tensor(2011.0771, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 100.0 event: 3000 loss: tensor(1742.8499, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 110.0 event: 3300 loss: tensor(1814.6328, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 120.0 event: 3600 loss: tensor(1854.8906, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 130.0 event: 3900 loss: tensor(1707.9606, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 140.0 event: 4200 loss: tensor(1912.9545, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 150.0 event: 4500 loss: tensor(1949.7412, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 160.0 event: 4800 loss: tensor(1706.3138, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 170.0 event: 5100 loss: tensor(1525.9698, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 190.0 event: 5700 loss: tensor(3699.4712, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 200.0 event: 6000 loss: tensor(2060.3196, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 210.0 event: 6300 loss: tensor(1674.9742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 220.0 event: 6600 loss: tensor(1992.0887, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 230.0 event: 6900 loss: tensor(1757.3704, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 240.0 event: 7200 loss: tensor(2015.6484, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 250.0 event: 7500 loss: tensor(1993.2711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 260.0 event: 7800 loss: tensor(1933.3561, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 270.0 event: 8100 loss: tensor(1901.3773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 280.0 event: 8400 loss: tensor(1768.0052, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 290.0 event: 8700 loss: tensor(1692.8674, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 300.0 event: 9000 loss: tensor(1963.9882, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 310.0 event: 9300 loss: tensor(1895.8333, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 320.0 event: 9600 loss: tensor(1847.6741, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 1 batch 330.0 event: 9900 loss: tensor(1770.4778, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:01.640529
evaluation loss: 1930.5379638671875
epoch: 1 mean loss: 1838.2747802734375
epoch: 2 batch 0.0 event: 0 loss: tensor(173.6318, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 10.0 event: 300 loss: tensor(1905.6305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 30.0 event: 900 loss: tensor(3265.6921, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 40.0 event: 1200 loss: tensor(1727.6836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 50.0 event: 1500 loss: tensor(1935.2366, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 60.0 event: 1800 loss: tensor(1705.9231, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 70.0 event: 2100 loss: tensor(1752.0126, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 80.0 event: 2400 loss: tensor(1496.9615, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 90.0 event: 2700 loss: tensor(1962.9766, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 100.0 event: 3000 loss: tensor(1703.4198, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 110.0 event: 3300 loss: tensor(1774.8873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 120.0 event: 3600 loss: tensor(1813.1530, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 130.0 event: 3900 loss: tensor(1675.9346, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 140.0 event: 4200 loss: tensor(1875.2457, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 150.0 event: 4500 loss: tensor(1915.3873, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 160.0 event: 4800 loss: tensor(1675.7367, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 170.0 event: 5100 loss: tensor(1499.6727, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 190.0 event: 5700 loss: tensor(3637.8474, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 200.0 event: 6000 loss: tensor(2033.8490, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 210.0 event: 6300 loss: tensor(1650.3212, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 220.0 event: 6600 loss: tensor(1965.3137, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 230.0 event: 6900 loss: tensor(1733.1848, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 240.0 event: 7200 loss: tensor(1992.4657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 250.0 event: 7500 loss: tensor(1969.3373, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 260.0 event: 7800 loss: tensor(1908.8313, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 270.0 event: 8100 loss: tensor(1878.5756, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 280.0 event: 8400 loss: tensor(1748.2841, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 290.0 event: 8700 loss: tensor(1676.6592, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 300.0 event: 9000 loss: tensor(1945.0377, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 310.0 event: 9300 loss: tensor(1878.6010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 320.0 event: 9600 loss: tensor(1828.9000, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 2 batch 330.0 event: 9900 loss: tensor(1757.0547, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:01:36.621829
evaluation loss: 1888.6575927734375
epoch: 2 mean loss: 1803.2740478515625
epoch: 3 batch 0.0 event: 0 loss: tensor(172.3114, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 10.0 event: 300 loss: tensor(1890.0491, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 30.0 event: 900 loss: tensor(3240.1509, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 40.0 event: 1200 loss: tensor(1712.9867, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 50.0 event: 1500 loss: tensor(1920.2375, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 60.0 event: 1800 loss: tensor(1691.5547, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 70.0 event: 2100 loss: tensor(1738.3768, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 80.0 event: 2400 loss: tensor(1485.6324, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 90.0 event: 2700 loss: tensor(1948.4554, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 100.0 event: 3000 loss: tensor(1691.6019, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 110.0 event: 3300 loss: tensor(1763.1959, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 120.0 event: 3600 loss: tensor(1801.4619, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 130.0 event: 3900 loss: tensor(1664.0619, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 140.0 event: 4200 loss: tensor(1862.7698, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 150.0 event: 4500 loss: tensor(1903.0907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 160.0 event: 4800 loss: tensor(1666.9303, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 170.0 event: 5100 loss: tensor(1490.6100, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 190.0 event: 5700 loss: tensor(3617.9607, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 200.0 event: 6000 loss: tensor(2023.6669, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 210.0 event: 6300 loss: tensor(1640.5801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 220.0 event: 6600 loss: tensor(1955.5599, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 230.0 event: 6900 loss: tensor(1722.9496, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 240.0 event: 7200 loss: tensor(1982.5664, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 250.0 event: 7500 loss: tensor(1960.1182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 260.0 event: 7800 loss: tensor(1899.7203, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 270.0 event: 8100 loss: tensor(1869.5260, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 280.0 event: 8400 loss: tensor(1739.5657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 290.0 event: 8700 loss: tensor(1668.9696, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 300.0 event: 9000 loss: tensor(1935.3760, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 310.0 event: 9300 loss: tensor(1869.8955, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 320.0 event: 9600 loss: tensor(1820.4407, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 3 batch 330.0 event: 9900 loss: tensor(1749.4803, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:11.585162
evaluation loss: 1877.5240478515625
epoch: 3 mean loss: 1792.2735595703125
epoch: 4 batch 0.0 event: 0 loss: tensor(171.5041, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 10.0 event: 300 loss: tensor(1882.3469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 30.0 event: 900 loss: tensor(3225.1633, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 40.0 event: 1200 loss: tensor(1705.1387, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 50.0 event: 1500 loss: tensor(1911.0781, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 60.0 event: 1800 loss: tensor(1683.5006, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 70.0 event: 2100 loss: tensor(1730.9010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 80.0 event: 2400 loss: tensor(1480.2975, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 90.0 event: 2700 loss: tensor(1939.5834, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 100.0 event: 3000 loss: tensor(1685.2158, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 110.0 event: 3300 loss: tensor(1756.6445, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 120.0 event: 3600 loss: tensor(1793.2047, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 130.0 event: 3900 loss: tensor(1656.2870, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 140.0 event: 4200 loss: tensor(1854.9681, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 150.0 event: 4500 loss: tensor(1894.2021, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 160.0 event: 4800 loss: tensor(1659.7352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 170.0 event: 5100 loss: tensor(1484.0680, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 190.0 event: 5700 loss: tensor(3603.4192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 200.0 event: 6000 loss: tensor(2016.3088, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 210.0 event: 6300 loss: tensor(1635.6052, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 220.0 event: 6600 loss: tensor(1948.9730, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 230.0 event: 6900 loss: tensor(1717.2203, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 240.0 event: 7200 loss: tensor(1975.5374, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 250.0 event: 7500 loss: tensor(1952.2610, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 260.0 event: 7800 loss: tensor(1893.3008, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 270.0 event: 8100 loss: tensor(1864.1416, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 280.0 event: 8400 loss: tensor(1734.4130, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 290.0 event: 8700 loss: tensor(1663.3700, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 300.0 event: 9000 loss: tensor(1928.6815, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 310.0 event: 9300 loss: tensor(1862.7336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 320.0 event: 9600 loss: tensor(1814.3583, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 4 batch 330.0 event: 9900 loss: tensor(1744.3793, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:02:46.533818
evaluation loss: 1871.639892578125
epoch: 4 mean loss: 1785.2742919921875
epoch: 5 batch 0.0 event: 0 loss: tensor(171.0793, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 10.0 event: 300 loss: tensor(1876.8906, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 30.0 event: 900 loss: tensor(3217.1257, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 40.0 event: 1200 loss: tensor(1700.8866, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 50.0 event: 1500 loss: tensor(1905.2393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 60.0 event: 1800 loss: tensor(1677.9945, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 70.0 event: 2100 loss: tensor(1724.8164, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 80.0 event: 2400 loss: tensor(1476.1028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 90.0 event: 2700 loss: tensor(1934.3734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 100.0 event: 3000 loss: tensor(1680.7750, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 110.0 event: 3300 loss: tensor(1752.0907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 120.0 event: 3600 loss: tensor(1788.2305, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 130.0 event: 3900 loss: tensor(1651.3997, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 140.0 event: 4200 loss: tensor(1848.9940, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 150.0 event: 4500 loss: tensor(1889.1371, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 160.0 event: 4800 loss: tensor(1654.8895, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 170.0 event: 5100 loss: tensor(1479.7753, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 190.0 event: 5700 loss: tensor(3593.5105, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 200.0 event: 6000 loss: tensor(2010.0531, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 210.0 event: 6300 loss: tensor(1630.4130, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 220.0 event: 6600 loss: tensor(1944.0551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 230.0 event: 6900 loss: tensor(1713.1254, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 240.0 event: 7200 loss: tensor(1972.4788, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 250.0 event: 7500 loss: tensor(1949.1711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 260.0 event: 7800 loss: tensor(1889.1904, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 270.0 event: 8100 loss: tensor(1860.5872, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 280.0 event: 8400 loss: tensor(1732.1371, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 290.0 event: 8700 loss: tensor(1660.6959, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 300.0 event: 9000 loss: tensor(1926.6813, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 310.0 event: 9300 loss: tensor(1858.8336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 320.0 event: 9600 loss: tensor(1811.1149, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 5 batch 330.0 event: 9900 loss: tensor(1742.7178, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:03:21.460940
evaluation loss: 1869.0211181640625
epoch: 5 mean loss: 1780.9202880859375
=> saveing checkpoint at epoch 5
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 6 batch 0.0 event: 0 loss: tensor(170.5045, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 10.0 event: 300 loss: tensor(1873.4307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 30.0 event: 900 loss: tensor(3211.2156, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 40.0 event: 1200 loss: tensor(1697.6230, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 50.0 event: 1500 loss: tensor(1901.1422, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 60.0 event: 1800 loss: tensor(1675.4971, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 70.0 event: 2100 loss: tensor(1722.4264, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 80.0 event: 2400 loss: tensor(1474.0732, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 90.0 event: 2700 loss: tensor(1932.3733, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 100.0 event: 3000 loss: tensor(1679.4935, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 110.0 event: 3300 loss: tensor(1751.0430, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 120.0 event: 3600 loss: tensor(1786.3026, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 130.0 event: 3900 loss: tensor(1651.3879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 140.0 event: 4200 loss: tensor(1844.9056, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 150.0 event: 4500 loss: tensor(1886.1908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 160.0 event: 4800 loss: tensor(1653.4359, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 170.0 event: 5100 loss: tensor(1479.2040, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 190.0 event: 5700 loss: tensor(3591.7244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 200.0 event: 6000 loss: tensor(2009.0237, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 210.0 event: 6300 loss: tensor(1628.2968, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 220.0 event: 6600 loss: tensor(1941.5702, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 230.0 event: 6900 loss: tensor(1709.0094, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 240.0 event: 7200 loss: tensor(1967.3391, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 250.0 event: 7500 loss: tensor(1946.3109, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 260.0 event: 7800 loss: tensor(1885.5775, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 270.0 event: 8100 loss: tensor(1857.8495, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 280.0 event: 8400 loss: tensor(1729.8047, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 290.0 event: 8700 loss: tensor(1659.1263, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 300.0 event: 9000 loss: tensor(1923.8174, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 310.0 event: 9300 loss: tensor(1854.9720, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 320.0 event: 9600 loss: tensor(1806.6598, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 6 batch 330.0 event: 9900 loss: tensor(1740.2770, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:02.068457
evaluation loss: 1869.0653076171875
epoch: 6 mean loss: 1778.416748046875
epoch: 7 batch 0.0 event: 0 loss: tensor(170.3804, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 10.0 event: 300 loss: tensor(1870.4008, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 30.0 event: 900 loss: tensor(3206.9802, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 40.0 event: 1200 loss: tensor(1696.0321, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 50.0 event: 1500 loss: tensor(1898.3893, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 60.0 event: 1800 loss: tensor(1674.5907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 70.0 event: 2100 loss: tensor(1720.4668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 80.0 event: 2400 loss: tensor(1472.8802, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 90.0 event: 2700 loss: tensor(1930.4711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 100.0 event: 3000 loss: tensor(1676.8125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 110.0 event: 3300 loss: tensor(1747.3060, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 120.0 event: 3600 loss: tensor(1784.4004, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 130.0 event: 3900 loss: tensor(1646.9154, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 140.0 event: 4200 loss: tensor(1842.1625, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 150.0 event: 4500 loss: tensor(1882.8729, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 160.0 event: 4800 loss: tensor(1651.1125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 170.0 event: 5100 loss: tensor(1477.0839, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 190.0 event: 5700 loss: tensor(3583.5449, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 200.0 event: 6000 loss: tensor(2004.8011, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 210.0 event: 6300 loss: tensor(1625.3809, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 220.0 event: 6600 loss: tensor(1940.1295, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 230.0 event: 6900 loss: tensor(1706.5885, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 240.0 event: 7200 loss: tensor(1964.4047, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 250.0 event: 7500 loss: tensor(1945.0682, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 260.0 event: 7800 loss: tensor(1882.7186, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 270.0 event: 8100 loss: tensor(1855.3359, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 280.0 event: 8400 loss: tensor(1727.0381, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 290.0 event: 8700 loss: tensor(1655.0446, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 300.0 event: 9000 loss: tensor(1918.7092, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 310.0 event: 9300 loss: tensor(1852.8405, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 320.0 event: 9600 loss: tensor(1804.1250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 7 batch 330.0 event: 9900 loss: tensor(1736.0551, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:04:37.042183
evaluation loss: 1869.2430419921875
epoch: 7 mean loss: 1775.652587890625
epoch: 8 batch 0.0 event: 0 loss: tensor(170.2421, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 10.0 event: 300 loss: tensor(1867.7363, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 30.0 event: 900 loss: tensor(3202.8171, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 40.0 event: 1200 loss: tensor(1694.4661, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 50.0 event: 1500 loss: tensor(1896.3186, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 60.0 event: 1800 loss: tensor(1673.0618, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 70.0 event: 2100 loss: tensor(1717.3274, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 80.0 event: 2400 loss: tensor(1470.1248, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 90.0 event: 2700 loss: tensor(1927.2188, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 100.0 event: 3000 loss: tensor(1672.5078, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 110.0 event: 3300 loss: tensor(1742.5811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 120.0 event: 3600 loss: tensor(1780.4297, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 130.0 event: 3900 loss: tensor(1644.0735, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 140.0 event: 4200 loss: tensor(1840.0322, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 150.0 event: 4500 loss: tensor(1880.9641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 160.0 event: 4800 loss: tensor(1648.1322, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 170.0 event: 5100 loss: tensor(1471.5681, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 190.0 event: 5700 loss: tensor(3576.5671, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 200.0 event: 6000 loss: tensor(2003.6125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 210.0 event: 6300 loss: tensor(1624.0928, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 220.0 event: 6600 loss: tensor(1935.9213, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 230.0 event: 6900 loss: tensor(1701.3944, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 240.0 event: 7200 loss: tensor(1960.8707, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 250.0 event: 7500 loss: tensor(1939.9290, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 260.0 event: 7800 loss: tensor(1877.9691, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 270.0 event: 8100 loss: tensor(1852.2422, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 280.0 event: 8400 loss: tensor(1724.0557, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 290.0 event: 8700 loss: tensor(1651.3695, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 300.0 event: 9000 loss: tensor(1914.5208, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 310.0 event: 9300 loss: tensor(1848.5826, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 320.0 event: 9600 loss: tensor(1801.5208, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 8 batch 330.0 event: 9900 loss: tensor(1732.8479, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:12.020781
evaluation loss: 1867.801025390625
epoch: 8 mean loss: 1772.443115234375
epoch: 9 batch 0.0 event: 0 loss: tensor(169.9851, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 10.0 event: 300 loss: tensor(1863.5393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 30.0 event: 900 loss: tensor(3197.3455, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 40.0 event: 1200 loss: tensor(1689.9075, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 50.0 event: 1500 loss: tensor(1892.3643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 60.0 event: 1800 loss: tensor(1667.9537, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 70.0 event: 2100 loss: tensor(1713.5211, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 80.0 event: 2400 loss: tensor(1467.1145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 90.0 event: 2700 loss: tensor(1924.7031, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 100.0 event: 3000 loss: tensor(1671.9647, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 110.0 event: 3300 loss: tensor(1740.5121, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 120.0 event: 3600 loss: tensor(1778.4320, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 130.0 event: 3900 loss: tensor(1642.6725, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 140.0 event: 4200 loss: tensor(1837.9379, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 150.0 event: 4500 loss: tensor(1878.9436, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 160.0 event: 4800 loss: tensor(1645.8037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 170.0 event: 5100 loss: tensor(1471.6245, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 190.0 event: 5700 loss: tensor(3574.2656, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 200.0 event: 6000 loss: tensor(2001.5233, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 210.0 event: 6300 loss: tensor(1623.9801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 220.0 event: 6600 loss: tensor(1934.9833, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 230.0 event: 6900 loss: tensor(1698.6483, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 240.0 event: 7200 loss: tensor(1959.1686, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 250.0 event: 7500 loss: tensor(1938.9805, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 260.0 event: 7800 loss: tensor(1876.6924, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 270.0 event: 8100 loss: tensor(1850.3046, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 280.0 event: 8400 loss: tensor(1720.9258, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 290.0 event: 8700 loss: tensor(1648.9182, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 300.0 event: 9000 loss: tensor(1912.0844, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 310.0 event: 9300 loss: tensor(1846.4818, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 320.0 event: 9600 loss: tensor(1799.2102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 9 batch 330.0 event: 9900 loss: tensor(1730.8115, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:05:47.015461
evaluation loss: 1867.9554443359375
epoch: 9 mean loss: 1770.2021484375
epoch: 10 batch 0.0 event: 0 loss: tensor(169.8733, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 10.0 event: 300 loss: tensor(1861.7220, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 30.0 event: 900 loss: tensor(3195.9651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 40.0 event: 1200 loss: tensor(1689.9462, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 50.0 event: 1500 loss: tensor(1891.8754, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 60.0 event: 1800 loss: tensor(1667.3114, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 70.0 event: 2100 loss: tensor(1711.1178, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 80.0 event: 2400 loss: tensor(1462.5087, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 90.0 event: 2700 loss: tensor(1918.5609, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 100.0 event: 3000 loss: tensor(1667.8090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 110.0 event: 3300 loss: tensor(1737.3456, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 120.0 event: 3600 loss: tensor(1775.7061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 130.0 event: 3900 loss: tensor(1641.7799, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 140.0 event: 4200 loss: tensor(1837.0367, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 150.0 event: 4500 loss: tensor(1879.4891, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 160.0 event: 4800 loss: tensor(1645.6084, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 170.0 event: 5100 loss: tensor(1470.8879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 190.0 event: 5700 loss: tensor(3573.0310, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 200.0 event: 6000 loss: tensor(1998.0619, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 210.0 event: 6300 loss: tensor(1620.4642, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 220.0 event: 6600 loss: tensor(1934.9749, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 230.0 event: 6900 loss: tensor(1700.9672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 240.0 event: 7200 loss: tensor(1958.2826, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 250.0 event: 7500 loss: tensor(1936.3837, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 260.0 event: 7800 loss: tensor(1873.8899, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 270.0 event: 8100 loss: tensor(1846.5677, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 280.0 event: 8400 loss: tensor(1717.9940, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 290.0 event: 8700 loss: tensor(1645.7850, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 300.0 event: 9000 loss: tensor(1909.7030, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 310.0 event: 9300 loss: tensor(1844.2021, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 320.0 event: 9600 loss: tensor(1798.0023, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 10 batch 330.0 event: 9900 loss: tensor(1729.5234, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:06:22.013872
evaluation loss: 1867.0423583984375
epoch: 10 mean loss: 1768.4261474609375
=> saveing checkpoint at epoch 10
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 11 batch 0.0 event: 0 loss: tensor(169.7276, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 10.0 event: 300 loss: tensor(1859.2512, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 30.0 event: 900 loss: tensor(3188.1082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 40.0 event: 1200 loss: tensor(1683.9086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 50.0 event: 1500 loss: tensor(1888.6732, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 60.0 event: 1800 loss: tensor(1665.4690, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 70.0 event: 2100 loss: tensor(1709.7190, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 80.0 event: 2400 loss: tensor(1461.3749, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 90.0 event: 2700 loss: tensor(1916.7675, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 100.0 event: 3000 loss: tensor(1665.5814, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 110.0 event: 3300 loss: tensor(1735.2268, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 120.0 event: 3600 loss: tensor(1773.3770, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 130.0 event: 3900 loss: tensor(1640.6047, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 140.0 event: 4200 loss: tensor(1836.9349, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 150.0 event: 4500 loss: tensor(1877.4628, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 160.0 event: 4800 loss: tensor(1644.5602, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 170.0 event: 5100 loss: tensor(1471.4976, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 190.0 event: 5700 loss: tensor(3569.9255, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 200.0 event: 6000 loss: tensor(1994.6737, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 210.0 event: 6300 loss: tensor(1619.5601, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 220.0 event: 6600 loss: tensor(1929.6283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 230.0 event: 6900 loss: tensor(1695.7372, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 240.0 event: 7200 loss: tensor(1952.9742, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 250.0 event: 7500 loss: tensor(1931.9388, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 260.0 event: 7800 loss: tensor(1870.8301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 270.0 event: 8100 loss: tensor(1845.5078, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 280.0 event: 8400 loss: tensor(1717.2020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 290.0 event: 8700 loss: tensor(1643.7057, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 300.0 event: 9000 loss: tensor(1908.4984, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 310.0 event: 9300 loss: tensor(1844.5654, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 320.0 event: 9600 loss: tensor(1796.7047, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 11 batch 330.0 event: 9900 loss: tensor(1728.2811, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:01.661888
evaluation loss: 1866.9537353515625
epoch: 11 mean loss: 1766.18603515625
epoch: 12 batch 0.0 event: 0 loss: tensor(169.6335, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 10.0 event: 300 loss: tensor(1857.8418, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 30.0 event: 900 loss: tensor(3190.6440, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 40.0 event: 1200 loss: tensor(1683.7559, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 50.0 event: 1500 loss: tensor(1886.0907, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 60.0 event: 1800 loss: tensor(1664.9908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 70.0 event: 2100 loss: tensor(1709.5277, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 80.0 event: 2400 loss: tensor(1461.7611, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 90.0 event: 2700 loss: tensor(1917.8121, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 100.0 event: 3000 loss: tensor(1665.2015, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 110.0 event: 3300 loss: tensor(1735.1711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 120.0 event: 3600 loss: tensor(1772.1143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 130.0 event: 3900 loss: tensor(1638.2948, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 140.0 event: 4200 loss: tensor(1834.0020, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 150.0 event: 4500 loss: tensor(1876.8489, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 160.0 event: 4800 loss: tensor(1643.6185, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 170.0 event: 5100 loss: tensor(1468.1053, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 190.0 event: 5700 loss: tensor(3563.5227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 200.0 event: 6000 loss: tensor(1992.9385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 210.0 event: 6300 loss: tensor(1617.2949, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 220.0 event: 6600 loss: tensor(1928.5879, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 230.0 event: 6900 loss: tensor(1694.1390, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 240.0 event: 7200 loss: tensor(1951.6041, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 250.0 event: 7500 loss: tensor(1930.6029, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 260.0 event: 7800 loss: tensor(1869.4950, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 270.0 event: 8100 loss: tensor(1845.1981, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 280.0 event: 8400 loss: tensor(1715.6537, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 290.0 event: 8700 loss: tensor(1643.9053, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 300.0 event: 9000 loss: tensor(1907.8973, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 310.0 event: 9300 loss: tensor(1842.1979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 320.0 event: 9600 loss: tensor(1797.4574, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 12 batch 330.0 event: 9900 loss: tensor(1727.5374, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:07:36.696273
evaluation loss: 1866.7515869140625
epoch: 12 mean loss: 1765.1077880859375
epoch: 13 batch 0.0 event: 0 loss: tensor(169.0803, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 10.0 event: 300 loss: tensor(1856.6229, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 30.0 event: 900 loss: tensor(3184.6711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 40.0 event: 1200 loss: tensor(1682.2250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 50.0 event: 1500 loss: tensor(1887.7440, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 60.0 event: 1800 loss: tensor(1665.4094, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 70.0 event: 2100 loss: tensor(1708.1475, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 80.0 event: 2400 loss: tensor(1459.5083, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 90.0 event: 2700 loss: tensor(1915.4918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 100.0 event: 3000 loss: tensor(1663.0684, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 110.0 event: 3300 loss: tensor(1733.2668, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 120.0 event: 3600 loss: tensor(1768.8011, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 130.0 event: 3900 loss: tensor(1636.0863, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 140.0 event: 4200 loss: tensor(1831.7516, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 150.0 event: 4500 loss: tensor(1872.5692, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 160.0 event: 4800 loss: tensor(1638.6813, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 170.0 event: 5100 loss: tensor(1464.4127, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 190.0 event: 5700 loss: tensor(3556.1660, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 200.0 event: 6000 loss: tensor(1990.1317, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 210.0 event: 6300 loss: tensor(1616.0933, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 220.0 event: 6600 loss: tensor(1926.8260, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 230.0 event: 6900 loss: tensor(1694.1575, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 240.0 event: 7200 loss: tensor(1950.8422, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 250.0 event: 7500 loss: tensor(1927.6523, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 260.0 event: 7800 loss: tensor(1865.8467, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 270.0 event: 8100 loss: tensor(1841.8414, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 280.0 event: 8400 loss: tensor(1714.3102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 290.0 event: 8700 loss: tensor(1641.1810, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 300.0 event: 9000 loss: tensor(1904.3073, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 310.0 event: 9300 loss: tensor(1839.2952, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 320.0 event: 9600 loss: tensor(1794.2151, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 13 batch 330.0 event: 9900 loss: tensor(1723.1799, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:11.763692
evaluation loss: 1865.3743896484375
epoch: 13 mean loss: 1762.702880859375
epoch: 14 batch 0.0 event: 0 loss: tensor(169.0629, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 10.0 event: 300 loss: tensor(1853.2762, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 30.0 event: 900 loss: tensor(3179.8416, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 40.0 event: 1200 loss: tensor(1681.6039, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 50.0 event: 1500 loss: tensor(1886.0631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 60.0 event: 1800 loss: tensor(1663.6923, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 70.0 event: 2100 loss: tensor(1707.1191, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 80.0 event: 2400 loss: tensor(1456.3734, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 90.0 event: 2700 loss: tensor(1912.1243, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 100.0 event: 3000 loss: tensor(1659.1351, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 110.0 event: 3300 loss: tensor(1731.5336, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 120.0 event: 3600 loss: tensor(1765.2930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 130.0 event: 3900 loss: tensor(1632.4414, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 140.0 event: 4200 loss: tensor(1826.8932, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 150.0 event: 4500 loss: tensor(1868.0375, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 160.0 event: 4800 loss: tensor(1635.2726, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 170.0 event: 5100 loss: tensor(1463.9242, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 190.0 event: 5700 loss: tensor(3556.4348, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 200.0 event: 6000 loss: tensor(1989.8037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 210.0 event: 6300 loss: tensor(1614.9600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 220.0 event: 6600 loss: tensor(1925.7067, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 230.0 event: 6900 loss: tensor(1692.8752, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 240.0 event: 7200 loss: tensor(1950.5897, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 250.0 event: 7500 loss: tensor(1928.6908, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 260.0 event: 7800 loss: tensor(1865.2053, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 270.0 event: 8100 loss: tensor(1839.0751, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 280.0 event: 8400 loss: tensor(1712.1556, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 290.0 event: 8700 loss: tensor(1637.5256, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 300.0 event: 9000 loss: tensor(1901.6393, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 310.0 event: 9300 loss: tensor(1837.2848, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 320.0 event: 9600 loss: tensor(1790.0977, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 14 batch 330.0 event: 9900 loss: tensor(1721.2317, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:08:46.848164
evaluation loss: 1865.320556640625
epoch: 14 mean loss: 1760.6004638671875
epoch: 15 batch 0.0 event: 0 loss: tensor(168.8578, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 10.0 event: 300 loss: tensor(1850.8840, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 30.0 event: 900 loss: tensor(3176.7551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 40.0 event: 1200 loss: tensor(1682.3004, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 50.0 event: 1500 loss: tensor(1884.9775, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 60.0 event: 1800 loss: tensor(1660.3395, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 70.0 event: 2100 loss: tensor(1703.3352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 80.0 event: 2400 loss: tensor(1458.0520, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 90.0 event: 2700 loss: tensor(1912.8041, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 100.0 event: 3000 loss: tensor(1659.7750, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 110.0 event: 3300 loss: tensor(1731.5897, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 120.0 event: 3600 loss: tensor(1767.0696, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 130.0 event: 3900 loss: tensor(1632.0342, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 140.0 event: 4200 loss: tensor(1824.6504, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 150.0 event: 4500 loss: tensor(1867.3271, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 160.0 event: 4800 loss: tensor(1634.9071, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 170.0 event: 5100 loss: tensor(1459.6627, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 190.0 event: 5700 loss: tensor(3551.7700, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 200.0 event: 6000 loss: tensor(1990.3776, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 210.0 event: 6300 loss: tensor(1613.3250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 220.0 event: 6600 loss: tensor(1924.7031, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 230.0 event: 6900 loss: tensor(1691.6809, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 240.0 event: 7200 loss: tensor(1947.0826, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 250.0 event: 7500 loss: tensor(1926.6575, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 260.0 event: 7800 loss: tensor(1864.3905, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 270.0 event: 8100 loss: tensor(1839.8851, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 280.0 event: 8400 loss: tensor(1710.3221, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 290.0 event: 8700 loss: tensor(1635.8126, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 300.0 event: 9000 loss: tensor(1898.1830, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 310.0 event: 9300 loss: tensor(1834.2203, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 320.0 event: 9600 loss: tensor(1787.5227, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 15 batch 330.0 event: 9900 loss: tensor(1719.1895, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:09:21.950323
evaluation loss: 1865.582275390625
epoch: 15 mean loss: 1759.239013671875
=> saveing checkpoint at epoch 15
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 16 batch 0.0 event: 0 loss: tensor(168.4394, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 10.0 event: 300 loss: tensor(1848.9307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 30.0 event: 900 loss: tensor(3172.6497, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 40.0 event: 1200 loss: tensor(1679.9672, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 50.0 event: 1500 loss: tensor(1885.2360, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 60.0 event: 1800 loss: tensor(1661.0811, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 70.0 event: 2100 loss: tensor(1702.9030, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 80.0 event: 2400 loss: tensor(1455.1060, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 90.0 event: 2700 loss: tensor(1908.8563, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 100.0 event: 3000 loss: tensor(1658.1686, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 110.0 event: 3300 loss: tensor(1731.0682, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 120.0 event: 3600 loss: tensor(1766.2010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 130.0 event: 3900 loss: tensor(1631.4639, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 140.0 event: 4200 loss: tensor(1826.1428, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 150.0 event: 4500 loss: tensor(1866.9047, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 160.0 event: 4800 loss: tensor(1633.6250, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 170.0 event: 5100 loss: tensor(1459.0201, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 190.0 event: 5700 loss: tensor(3547.7766, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 200.0 event: 6000 loss: tensor(1986.2096, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 210.0 event: 6300 loss: tensor(1611.9817, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 220.0 event: 6600 loss: tensor(1921.8807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 230.0 event: 6900 loss: tensor(1689.9554, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 240.0 event: 7200 loss: tensor(1946.6096, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 250.0 event: 7500 loss: tensor(1925.1488, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 260.0 event: 7800 loss: tensor(1862.6090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 270.0 event: 8100 loss: tensor(1838.6897, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 280.0 event: 8400 loss: tensor(1707.9354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 290.0 event: 8700 loss: tensor(1633.4716, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 300.0 event: 9000 loss: tensor(1896.0354, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 310.0 event: 9300 loss: tensor(1831.6702, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 320.0 event: 9600 loss: tensor(1785.2688, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 16 batch 330.0 event: 9900 loss: tensor(1717.0497, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:10:02.364864
evaluation loss: 1865.0208740234375
epoch: 16 mean loss: 1757.6710205078125
epoch: 17 batch 0.0 event: 0 loss: tensor(168.5163, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 10.0 event: 300 loss: tensor(1847.3900, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 30.0 event: 900 loss: tensor(3172.9275, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 40.0 event: 1200 loss: tensor(1676.7623, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 50.0 event: 1500 loss: tensor(1881.2516, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 60.0 event: 1800 loss: tensor(1660.8190, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 70.0 event: 2100 loss: tensor(1702.8639, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 80.0 event: 2400 loss: tensor(1455.5302, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 90.0 event: 2700 loss: tensor(1909.2181, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 100.0 event: 3000 loss: tensor(1657.4559, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 110.0 event: 3300 loss: tensor(1730.7402, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 120.0 event: 3600 loss: tensor(1765.4309, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 130.0 event: 3900 loss: tensor(1630.7266, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 140.0 event: 4200 loss: tensor(1824.9244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 150.0 event: 4500 loss: tensor(1865.9075, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 160.0 event: 4800 loss: tensor(1633.8372, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 170.0 event: 5100 loss: tensor(1458.0331, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 190.0 event: 5700 loss: tensor(3545.9558, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 200.0 event: 6000 loss: tensor(1983.0090, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 210.0 event: 6300 loss: tensor(1608.0531, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 220.0 event: 6600 loss: tensor(1916.8459, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 230.0 event: 6900 loss: tensor(1684.1180, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 240.0 event: 7200 loss: tensor(1942.5911, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 250.0 event: 7500 loss: tensor(1923.3300, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 260.0 event: 7800 loss: tensor(1863.1903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 270.0 event: 8100 loss: tensor(1838.1102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 280.0 event: 8400 loss: tensor(1707.9808, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 290.0 event: 8700 loss: tensor(1632.9379, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 300.0 event: 9000 loss: tensor(1894.4215, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 310.0 event: 9300 loss: tensor(1831.8990, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 320.0 event: 9600 loss: tensor(1784.3016, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 17 batch 330.0 event: 9900 loss: tensor(1716.1342, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:10:37.515597
evaluation loss: 1865.3433837890625
epoch: 17 mean loss: 1756.365478515625
epoch: 18 batch 0.0 event: 0 loss: tensor(168.4595, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 10.0 event: 300 loss: tensor(1846.2139, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 30.0 event: 900 loss: tensor(3166.4119, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 40.0 event: 1200 loss: tensor(1673.6061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 50.0 event: 1500 loss: tensor(1875.9434, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 60.0 event: 1800 loss: tensor(1655.3740, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 70.0 event: 2100 loss: tensor(1697.8988, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 80.0 event: 2400 loss: tensor(1452.8661, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 90.0 event: 2700 loss: tensor(1906.0989, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 100.0 event: 3000 loss: tensor(1653.0094, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 110.0 event: 3300 loss: tensor(1725.1211, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 120.0 event: 3600 loss: tensor(1761.5061, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 130.0 event: 3900 loss: tensor(1628.1699, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 140.0 event: 4200 loss: tensor(1822.2743, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 150.0 event: 4500 loss: tensor(1865.0898, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 160.0 event: 4800 loss: tensor(1631.5426, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 170.0 event: 5100 loss: tensor(1458.0204, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 190.0 event: 5700 loss: tensor(3545.1301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 200.0 event: 6000 loss: tensor(1980.4447, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 210.0 event: 6300 loss: tensor(1608.8549, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 220.0 event: 6600 loss: tensor(1918.1594, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 230.0 event: 6900 loss: tensor(1682.7629, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 240.0 event: 7200 loss: tensor(1940.2748, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 250.0 event: 7500 loss: tensor(1922.5817, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 260.0 event: 7800 loss: tensor(1859.7773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 270.0 event: 8100 loss: tensor(1836.8854, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 280.0 event: 8400 loss: tensor(1706.2803, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 290.0 event: 8700 loss: tensor(1630.4192, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 300.0 event: 9000 loss: tensor(1890.8251, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 310.0 event: 9300 loss: tensor(1828.1283, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 320.0 event: 9600 loss: tensor(1783.9727, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 18 batch 330.0 event: 9900 loss: tensor(1715.3428, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:11:12.677394
evaluation loss: 1864.4940185546875
epoch: 18 mean loss: 1754.0281982421875
epoch: 19 batch 0.0 event: 0 loss: tensor(168.1428, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 10.0 event: 300 loss: tensor(1845.1112, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 30.0 event: 900 loss: tensor(3163.3518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 40.0 event: 1200 loss: tensor(1670.3344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 50.0 event: 1500 loss: tensor(1871.4779, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 60.0 event: 1800 loss: tensor(1653.9176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 70.0 event: 2100 loss: tensor(1696.4954, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 80.0 event: 2400 loss: tensor(1450.3887, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 90.0 event: 2700 loss: tensor(1906.5791, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 100.0 event: 3000 loss: tensor(1654.7988, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 110.0 event: 3300 loss: tensor(1725.2200, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 120.0 event: 3600 loss: tensor(1759.9485, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 130.0 event: 3900 loss: tensor(1627.2526, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 140.0 event: 4200 loss: tensor(1822.6012, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 150.0 event: 4500 loss: tensor(1863.7758, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 160.0 event: 4800 loss: tensor(1632.8245, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 170.0 event: 5100 loss: tensor(1455.8690, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 190.0 event: 5700 loss: tensor(3543.9238, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 200.0 event: 6000 loss: tensor(1980.5502, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 210.0 event: 6300 loss: tensor(1607.2749, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 220.0 event: 6600 loss: tensor(1915.4717, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 230.0 event: 6900 loss: tensor(1683.8293, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 240.0 event: 7200 loss: tensor(1940.6903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 250.0 event: 7500 loss: tensor(1919.1191, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 260.0 event: 7800 loss: tensor(1861.1107, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 270.0 event: 8100 loss: tensor(1832.2656, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 280.0 event: 8400 loss: tensor(1705.9603, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 290.0 event: 8700 loss: tensor(1633.6790, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 300.0 event: 9000 loss: tensor(1894.2460, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 310.0 event: 9300 loss: tensor(1829.4655, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 320.0 event: 9600 loss: tensor(1784.5758, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 19 batch 330.0 event: 9900 loss: tensor(1717.3119, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:11:47.883266
evaluation loss: 1864.271728515625
epoch: 19 mean loss: 1753.438720703125
epoch: 20 batch 0.0 event: 0 loss: tensor(168.3302, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 10.0 event: 300 loss: tensor(1847.1735, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 30.0 event: 900 loss: tensor(3169.6379, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 40.0 event: 1200 loss: tensor(1671.8301, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 50.0 event: 1500 loss: tensor(1871.0641, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 60.0 event: 1800 loss: tensor(1650.9930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 70.0 event: 2100 loss: tensor(1694.8109, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 80.0 event: 2400 loss: tensor(1449.7885, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 90.0 event: 2700 loss: tensor(1904.6464, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 100.0 event: 3000 loss: tensor(1651.9364, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 110.0 event: 3300 loss: tensor(1724.1395, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 120.0 event: 3600 loss: tensor(1759.4160, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 130.0 event: 3900 loss: tensor(1625.7615, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 140.0 event: 4200 loss: tensor(1818.8558, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 150.0 event: 4500 loss: tensor(1860.8180, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 160.0 event: 4800 loss: tensor(1629.8441, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 170.0 event: 5100 loss: tensor(1454.7875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 190.0 event: 5700 loss: tensor(3538.4309, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 200.0 event: 6000 loss: tensor(1976.2434, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 210.0 event: 6300 loss: tensor(1604.2706, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 220.0 event: 6600 loss: tensor(1914.6522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 230.0 event: 6900 loss: tensor(1684.3026, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 240.0 event: 7200 loss: tensor(1939.4407, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 250.0 event: 7500 loss: tensor(1920.5774, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 260.0 event: 7800 loss: tensor(1859.7711, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 270.0 event: 8100 loss: tensor(1833.2344, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 280.0 event: 8400 loss: tensor(1704.5778, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 290.0 event: 8700 loss: tensor(1629.9287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 300.0 event: 9000 loss: tensor(1893.7219, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 310.0 event: 9300 loss: tensor(1828.8363, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 320.0 event: 9600 loss: tensor(1785.6696, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 20 batch 330.0 event: 9900 loss: tensor(1716.6610, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:12:23.061944
evaluation loss: 1863.1578369140625
epoch: 20 mean loss: 1752.45458984375
=> saveing checkpoint at epoch 20
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 21 batch 0.0 event: 0 loss: tensor(168.4482, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 10.0 event: 300 loss: tensor(1847.6019, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 30.0 event: 900 loss: tensor(3167.3308, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 40.0 event: 1200 loss: tensor(1673.9388, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 50.0 event: 1500 loss: tensor(1871.9471, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 60.0 event: 1800 loss: tensor(1652.6904, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 70.0 event: 2100 loss: tensor(1694.5686, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 80.0 event: 2400 loss: tensor(1448.5538, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 90.0 event: 2700 loss: tensor(1901.7689, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 100.0 event: 3000 loss: tensor(1648.9637, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 110.0 event: 3300 loss: tensor(1719.7133, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 120.0 event: 3600 loss: tensor(1755.7754, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 130.0 event: 3900 loss: tensor(1625.2266, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 140.0 event: 4200 loss: tensor(1817.3274, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 150.0 event: 4500 loss: tensor(1857.6176, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 160.0 event: 4800 loss: tensor(1626.3602, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 170.0 event: 5100 loss: tensor(1451.3993, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 190.0 event: 5700 loss: tensor(3533.2551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 200.0 event: 6000 loss: tensor(1974.1848, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 210.0 event: 6300 loss: tensor(1601.3959, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 220.0 event: 6600 loss: tensor(1913.2360, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 230.0 event: 6900 loss: tensor(1681.2512, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 240.0 event: 7200 loss: tensor(1939.1777, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 250.0 event: 7500 loss: tensor(1919.0673, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 260.0 event: 7800 loss: tensor(1855.6605, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 270.0 event: 8100 loss: tensor(1831.3417, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 280.0 event: 8400 loss: tensor(1700.5387, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 290.0 event: 8700 loss: tensor(1627.6469, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 300.0 event: 9000 loss: tensor(1889.9365, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 310.0 event: 9300 loss: tensor(1827.3229, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 320.0 event: 9600 loss: tensor(1782.4808, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 21 batch 330.0 event: 9900 loss: tensor(1713.7480, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:13:03.409470
evaluation loss: 1863.8914794921875
epoch: 21 mean loss: 1750.501220703125
epoch: 22 batch 0.0 event: 0 loss: tensor(168.6787, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 10.0 event: 300 loss: tensor(1844.6112, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 30.0 event: 900 loss: tensor(3164.0764, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 40.0 event: 1200 loss: tensor(1672.4594, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 50.0 event: 1500 loss: tensor(1869.3593, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 60.0 event: 1800 loss: tensor(1647.2256, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 70.0 event: 2100 loss: tensor(1690.4202, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 80.0 event: 2400 loss: tensor(1445.4156, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 90.0 event: 2700 loss: tensor(1899.6086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 100.0 event: 3000 loss: tensor(1650.1385, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 110.0 event: 3300 loss: tensor(1722.9037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 120.0 event: 3600 loss: tensor(1755.2891, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 130.0 event: 3900 loss: tensor(1623.7010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 140.0 event: 4200 loss: tensor(1817.2256, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 150.0 event: 4500 loss: tensor(1860.5409, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 160.0 event: 4800 loss: tensor(1629.1796, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 170.0 event: 5100 loss: tensor(1452.8160, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 190.0 event: 5700 loss: tensor(3535.3230, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 200.0 event: 6000 loss: tensor(1975.7748, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 210.0 event: 6300 loss: tensor(1602.7872, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 220.0 event: 6600 loss: tensor(1911.9788, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 230.0 event: 6900 loss: tensor(1679.9967, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 240.0 event: 7200 loss: tensor(1935.7518, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 250.0 event: 7500 loss: tensor(1913.2197, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 260.0 event: 7800 loss: tensor(1852.9537, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 270.0 event: 8100 loss: tensor(1829.0332, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 280.0 event: 8400 loss: tensor(1698.3715, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 290.0 event: 8700 loss: tensor(1624.9642, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 300.0 event: 9000 loss: tensor(1890.0663, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 310.0 event: 9300 loss: tensor(1825.0784, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 320.0 event: 9600 loss: tensor(1780.3617, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 22 batch 330.0 event: 9900 loss: tensor(1712.4286, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:13:38.613686
evaluation loss: 1862.6068115234375
epoch: 22 mean loss: 1749.3194580078125
epoch: 23 batch 0.0 event: 0 loss: tensor(167.8571, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 10.0 event: 300 loss: tensor(1844.7362, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 30.0 event: 900 loss: tensor(3162.2732, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 40.0 event: 1200 loss: tensor(1672.2313, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 50.0 event: 1500 loss: tensor(1874.0540, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 60.0 event: 1800 loss: tensor(1652.2740, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 70.0 event: 2100 loss: tensor(1695.5840, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 80.0 event: 2400 loss: tensor(1447.1917, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 90.0 event: 2700 loss: tensor(1897.2682, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 100.0 event: 3000 loss: tensor(1645.7079, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 110.0 event: 3300 loss: tensor(1718.3444, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 120.0 event: 3600 loss: tensor(1753.4622, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 130.0 event: 3900 loss: tensor(1621.9315, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 140.0 event: 4200 loss: tensor(1814.9596, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 150.0 event: 4500 loss: tensor(1858.5120, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 160.0 event: 4800 loss: tensor(1627.4384, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 170.0 event: 5100 loss: tensor(1450.9545, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 190.0 event: 5700 loss: tensor(3531.7773, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 200.0 event: 6000 loss: tensor(1974.4801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 210.0 event: 6300 loss: tensor(1601.7760, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 220.0 event: 6600 loss: tensor(1910.3912, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 230.0 event: 6900 loss: tensor(1678.8555, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 240.0 event: 7200 loss: tensor(1932.5273, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 250.0 event: 7500 loss: tensor(1911.4293, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 260.0 event: 7800 loss: tensor(1851.2753, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 270.0 event: 8100 loss: tensor(1828.4987, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 280.0 event: 8400 loss: tensor(1696.3606, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 290.0 event: 8700 loss: tensor(1623.3307, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 300.0 event: 9000 loss: tensor(1887.5413, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 310.0 event: 9300 loss: tensor(1822.7288, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 320.0 event: 9600 loss: tensor(1778.6605, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 23 batch 330.0 event: 9900 loss: tensor(1709.4795, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:14:13.825800
evaluation loss: 1863.3232421875
epoch: 23 mean loss: 1748.136474609375
epoch: 24 batch 0.0 event: 0 loss: tensor(167.4135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 10.0 event: 300 loss: tensor(1839.7167, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 30.0 event: 900 loss: tensor(3154.5100, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 40.0 event: 1200 loss: tensor(1667.8783, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 50.0 event: 1500 loss: tensor(1868.4199, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 60.0 event: 1800 loss: tensor(1647.4059, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 70.0 event: 2100 loss: tensor(1693.1016, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 80.0 event: 2400 loss: tensor(1446.5262, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 90.0 event: 2700 loss: tensor(1902.4784, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 100.0 event: 3000 loss: tensor(1646.9592, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 110.0 event: 3300 loss: tensor(1719.2083, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 120.0 event: 3600 loss: tensor(1753.8604, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 130.0 event: 3900 loss: tensor(1621.6339, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 140.0 event: 4200 loss: tensor(1812.6025, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 150.0 event: 4500 loss: tensor(1856.9076, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 160.0 event: 4800 loss: tensor(1624.2244, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 170.0 event: 5100 loss: tensor(1452.0364, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 190.0 event: 5700 loss: tensor(3528.8430, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 200.0 event: 6000 loss: tensor(1973.3402, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 210.0 event: 6300 loss: tensor(1599.5842, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 220.0 event: 6600 loss: tensor(1908.5651, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 230.0 event: 6900 loss: tensor(1676.7245, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 240.0 event: 7200 loss: tensor(1932.0618, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 250.0 event: 7500 loss: tensor(1912.8625, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 260.0 event: 7800 loss: tensor(1850.7629, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 270.0 event: 8100 loss: tensor(1828.5458, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 280.0 event: 8400 loss: tensor(1697.7510, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 290.0 event: 8700 loss: tensor(1624.9801, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 300.0 event: 9000 loss: tensor(1887.3680, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 310.0 event: 9300 loss: tensor(1825.0990, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 320.0 event: 9600 loss: tensor(1778.6771, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 24 batch 330.0 event: 9900 loss: tensor(1711.6031, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:14:49.088565
evaluation loss: 1863.5555419921875
epoch: 24 mean loss: 1747.185302734375
epoch: 25 batch 0.0 event: 0 loss: tensor(167.4813, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 10.0 event: 300 loss: tensor(1838.1799, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 30.0 event: 900 loss: tensor(3155.6357, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 40.0 event: 1200 loss: tensor(1669.4723, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 50.0 event: 1500 loss: tensor(1870.1028, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 60.0 event: 1800 loss: tensor(1646.9600, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 70.0 event: 2100 loss: tensor(1691.4414, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 80.0 event: 2400 loss: tensor(1445.4769, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 90.0 event: 2700 loss: tensor(1902.0120, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 100.0 event: 3000 loss: tensor(1650.1006, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 110.0 event: 3300 loss: tensor(1719.8710, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 120.0 event: 3600 loss: tensor(1757.2979, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 130.0 event: 3900 loss: tensor(1622.7655, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 140.0 event: 4200 loss: tensor(1810.5482, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 150.0 event: 4500 loss: tensor(1852.6112, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 160.0 event: 4800 loss: tensor(1623.5258, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 170.0 event: 5100 loss: tensor(1447.8828, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 190.0 event: 5700 loss: tensor(3523.7922, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 200.0 event: 6000 loss: tensor(1970.7327, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 210.0 event: 6300 loss: tensor(1600.5386, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 220.0 event: 6600 loss: tensor(1909.1194, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 230.0 event: 6900 loss: tensor(1678.0836, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 240.0 event: 7200 loss: tensor(1931.0573, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 250.0 event: 7500 loss: tensor(1910.7533, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 260.0 event: 7800 loss: tensor(1850.3031, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 270.0 event: 8100 loss: tensor(1828.4082, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 280.0 event: 8400 loss: tensor(1698.4329, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 290.0 event: 8700 loss: tensor(1624.4657, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 300.0 event: 9000 loss: tensor(1887.9535, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 310.0 event: 9300 loss: tensor(1824.7145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 320.0 event: 9600 loss: tensor(1780.2767, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 25 batch 330.0 event: 9900 loss: tensor(1711.1064, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:15:24.356563
evaluation loss: 1861.8392333984375
epoch: 25 mean loss: 1746.8626708984375
=> saveing checkpoint at epoch 25
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2
epoch: 26 batch 0.0 event: 0 loss: tensor(167.6418, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 10.0 event: 300 loss: tensor(1836.1588, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 30.0 event: 900 loss: tensor(3150.4626, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 40.0 event: 1200 loss: tensor(1668.2621, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 50.0 event: 1500 loss: tensor(1865.8174, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 60.0 event: 1800 loss: tensor(1647.9037, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 70.0 event: 2100 loss: tensor(1689.8756, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 80.0 event: 2400 loss: tensor(1445.1631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 90.0 event: 2700 loss: tensor(1899.2594, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 100.0 event: 3000 loss: tensor(1645.8119, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 110.0 event: 3300 loss: tensor(1719.6014, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 120.0 event: 3600 loss: tensor(1757.1635, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 130.0 event: 3900 loss: tensor(1623.6389, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 140.0 event: 4200 loss: tensor(1815.5551, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 150.0 event: 4500 loss: tensor(1852.0135, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 160.0 event: 4800 loss: tensor(1623.3588, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 170.0 event: 5100 loss: tensor(1446.8326, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 190.0 event: 5700 loss: tensor(3526.2898, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 200.0 event: 6000 loss: tensor(1971.0149, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 210.0 event: 6300 loss: tensor(1600.4100, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 220.0 event: 6600 loss: tensor(1907.3730, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 230.0 event: 6900 loss: tensor(1677.3705, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 240.0 event: 7200 loss: tensor(1929.3665, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 250.0 event: 7500 loss: tensor(1907.9232, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 260.0 event: 7800 loss: tensor(1848.1969, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 270.0 event: 8100 loss: tensor(1827.9875, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 280.0 event: 8400 loss: tensor(1697.2191, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 290.0 event: 8700 loss: tensor(1624.9703, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 300.0 event: 9000 loss: tensor(1886.6781, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 310.0 event: 9300 loss: tensor(1823.0403, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 320.0 event: 9600 loss: tensor(1779.8304, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 26 batch 330.0 event: 9900 loss: tensor(1708.7653, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:16:04.477012
evaluation loss: 1860.4774169921875
epoch: 26 mean loss: 1745.948974609375
epoch: 27 batch 0.0 event: 0 loss: tensor(167.7890, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 10.0 event: 300 loss: tensor(1834.5165, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 30.0 event: 900 loss: tensor(3146.5918, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 40.0 event: 1200 loss: tensor(1665.3807, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 50.0 event: 1500 loss: tensor(1862.6869, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 60.0 event: 1800 loss: tensor(1644.5956, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 70.0 event: 2100 loss: tensor(1685.7275, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 80.0 event: 2400 loss: tensor(1440.8085, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 90.0 event: 2700 loss: tensor(1892.0930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 100.0 event: 3000 loss: tensor(1641.5582, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 110.0 event: 3300 loss: tensor(1715.8440, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 120.0 event: 3600 loss: tensor(1751.6332, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 130.0 event: 3900 loss: tensor(1621.1903, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 140.0 event: 4200 loss: tensor(1812.9631, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 150.0 event: 4500 loss: tensor(1850.2522, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 160.0 event: 4800 loss: tensor(1619.6270, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 170.0 event: 5100 loss: tensor(1444.0897, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 190.0 event: 5700 loss: tensor(3516.1521, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 200.0 event: 6000 loss: tensor(1968.2465, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 210.0 event: 6300 loss: tensor(1595.1405, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 220.0 event: 6600 loss: tensor(1903.7520, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 230.0 event: 6900 loss: tensor(1671.8944, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 240.0 event: 7200 loss: tensor(1927.7708, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 250.0 event: 7500 loss: tensor(1908.2418, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 260.0 event: 7800 loss: tensor(1846.3567, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 270.0 event: 8100 loss: tensor(1823.7643, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 280.0 event: 8400 loss: tensor(1694.6143, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 290.0 event: 8700 loss: tensor(1621.6744, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 300.0 event: 9000 loss: tensor(1883.1624, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 310.0 event: 9300 loss: tensor(1818.9554, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 320.0 event: 9600 loss: tensor(1773.8490, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 27 batch 330.0 event: 9900 loss: tensor(1703.8977, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:16:39.758353
evaluation loss: 1860.8203125
epoch: 27 mean loss: 1742.402099609375
epoch: 28 batch 0.0 event: 0 loss: tensor(167.0287, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 10.0 event: 300 loss: tensor(1830.1523, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 30.0 event: 900 loss: tensor(3141.2556, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 40.0 event: 1200 loss: tensor(1662.4125, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 50.0 event: 1500 loss: tensor(1861.9290, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 60.0 event: 1800 loss: tensor(1643.4352, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 70.0 event: 2100 loss: tensor(1687.6830, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 80.0 event: 2400 loss: tensor(1441.6322, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 90.0 event: 2700 loss: tensor(1890.9384, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 100.0 event: 3000 loss: tensor(1639.6327, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 110.0 event: 3300 loss: tensor(1713.4594, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 120.0 event: 3600 loss: tensor(1748.8252, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 130.0 event: 3900 loss: tensor(1618.5214, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 140.0 event: 4200 loss: tensor(1809.4537, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 150.0 event: 4500 loss: tensor(1849.7109, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 160.0 event: 4800 loss: tensor(1617.6331, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 170.0 event: 5100 loss: tensor(1443.6785, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 190.0 event: 5700 loss: tensor(3512.5923, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 200.0 event: 6000 loss: tensor(1967.7137, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 210.0 event: 6300 loss: tensor(1597.2756, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 220.0 event: 6600 loss: tensor(1903.9736, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 230.0 event: 6900 loss: tensor(1672.3010, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 240.0 event: 7200 loss: tensor(1925.3713, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 250.0 event: 7500 loss: tensor(1907.2848, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 260.0 event: 7800 loss: tensor(1846.1276, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 270.0 event: 8100 loss: tensor(1823.7792, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 280.0 event: 8400 loss: tensor(1694.5145, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 290.0 event: 8700 loss: tensor(1618.9381, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 300.0 event: 9000 loss: tensor(1880.8750, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 310.0 event: 9300 loss: tensor(1816.5787, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 320.0 event: 9600 loss: tensor(1772.6342, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 28 batch 330.0 event: 9900 loss: tensor(1703.6926, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:17:15.038414
evaluation loss: 1862.0018310546875
epoch: 28 mean loss: 1741.0728759765625
epoch: 29 batch 0.0 event: 0 loss: tensor(167.0191, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 10.0 event: 300 loss: tensor(1828.1102, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 30.0 event: 900 loss: tensor(3137.9724, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 40.0 event: 1200 loss: tensor(1659.2930, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 50.0 event: 1500 loss: tensor(1858.0238, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 60.0 event: 1800 loss: tensor(1640.0052, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 70.0 event: 2100 loss: tensor(1685.8779, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 80.0 event: 2400 loss: tensor(1439.8331, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 90.0 event: 2700 loss: tensor(1889.2689, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 100.0 event: 3000 loss: tensor(1638.2806, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 110.0 event: 3300 loss: tensor(1710.6737, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 120.0 event: 3600 loss: tensor(1747.9349, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 130.0 event: 3900 loss: tensor(1615.3016, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 140.0 event: 4200 loss: tensor(1807.8051, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 150.0 event: 4500 loss: tensor(1849.4655, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 160.0 event: 4800 loss: tensor(1617.3464, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 170.0 event: 5100 loss: tensor(1443.6776, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 190.0 event: 5700 loss: tensor(3510.9446, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 200.0 event: 6000 loss: tensor(1965.0081, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 210.0 event: 6300 loss: tensor(1596.1515, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 220.0 event: 6600 loss: tensor(1903.2207, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 230.0 event: 6900 loss: tensor(1672.0364, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 240.0 event: 7200 loss: tensor(1925.2188, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 250.0 event: 7500 loss: tensor(1907.3994, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 260.0 event: 7800 loss: tensor(1846.4703, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 270.0 event: 8100 loss: tensor(1825.6086, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 280.0 event: 8400 loss: tensor(1692.5416, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 290.0 event: 8700 loss: tensor(1618.9491, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 300.0 event: 9000 loss: tensor(1878.2611, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 310.0 event: 9300 loss: tensor(1814.4257, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 320.0 event: 9600 loss: tensor(1773.9645, device='cuda:0', grad_fn=<DivBackward0>)
epoch: 29 batch 330.0 event: 9900 loss: tensor(1703.1953, device='cuda:0', grad_fn=<DivBackward0>)
time passed so far:
 0:19:08.588886
evaluation loss: 1862.2069091796875
epoch: 29 mean loss: 1739.842041015625
=> saveing checkpoint at epoch 29
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/pyt_pppipi_cnn_2

outi tensor([[-0.9977, -0.9978, -0.9763,  ..., -1.0000, -1.0000, -1.0000],
        [-0.8464, -0.9974, -0.9976,  ..., -1.0000, -1.0000, -1.0000],
        [ 0.9956, -0.8967, -1.0000,  ..., -1.0000, -0.9999, -0.9996],
        ...,
        [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
        [-0.9995, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
        [-1.0000, -1.0000, -0.9999,  ..., -1.0000, -1.0000, -1.0000]],
       device='cuda:0', grad_fn=<TanhBackward0>) 
 torch.Size([30, 6796]) 
 tensor(-103431.2891, device='cuda:0', grad_fn=<SumBackward0>) 
 tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]], device='cuda:0') 
 tensor(203880, device='cuda:0')



training loss:
 [1899.42895508 1838.27478027 1803.27404785 1792.27355957 1785.27429199
 1780.92028809 1778.41674805 1775.65258789 1772.44311523 1770.20214844
 1768.42614746 1766.18603516 1765.10778809 1762.70288086 1760.60046387
 1759.23901367 1757.67102051 1756.36547852 1754.02819824 1753.4387207
 1752.45458984 1750.5012207  1749.31945801 1748.13647461 1747.18530273
 1746.8626709  1745.94897461 1742.40209961 1741.07287598 1739.84204102] 

\evaluation loss:
 [1985.38269043 1930.53796387 1888.65759277 1877.52404785 1871.63989258
 1869.02111816 1869.06530762 1869.24304199 1867.80102539 1867.95544434
 1867.0423584  1866.95373535 1866.75158691 1865.37438965 1865.32055664
 1865.58227539 1865.02087402 1865.34338379 1864.49401855 1864.27172852
 1863.15783691 1863.89147949 1862.60681152 1863.32324219 1863.55554199
 1861.8392334  1860.47741699 1860.8203125  1862.00183105 1862.20690918]



eval_efficiency:
 [0.73509311 0.73448384 0.73382521 0.7331443  0.73263695 0.73206128
 0.73133325 0.73072358 0.73002003 0.72927369 0.7286542  0.72798288
 0.72733946 0.72656779 0.72592034 0.72531196 0.7247103  0.72411421
 0.72346981 0.72276718 0.72209708 0.72132654 0.72064585 0.71993012
 0.71926905 0.7186051  0.71782726 0.71706026 0.71614378 0.71545841
 0.71474459 0.71407875 0.71336021 0.7126847  0.71169537 0.71095229
 0.71015627 0.70947452 0.70867305 0.70784329 0.70688196 0.70602852
 0.70512873 0.70419266 0.70334067 0.70249583 0.70161644 0.70061465
 0.69971071 0.69867803 0.69750173 0.69652686 0.69558339 0.69467448
 0.69365306 0.69251343 0.69142699 0.6902936  0.68916872 0.68794446
 0.68680466 0.68575035 0.6846007  0.68326401 0.6822053  0.6811057
 0.67989765 0.6786548  0.67733072 0.67599502 0.67448157 0.67312311
 0.67153004 0.66990859 0.66827086 0.66652921 0.66481967 0.6630098
 0.66105972 0.65911085 0.65690917 0.65477827 0.65234959 0.65010044
 0.64750363 0.64486229 0.64196671 0.63867586 0.63540878 0.63176944
 0.62767161 0.62330734 0.61864064 0.61302109 0.60631848 0.59875274
 0.58926697 0.57653866 0.55774699 0.52680682] 


eval_purity:
 [0.90965553 0.90965855 0.90973759 0.90975057 0.9098856  0.90995965
 0.90995914 0.90996968 0.91003406 0.91003291 0.91007182 0.91011839
 0.9101169  0.91012233 0.91017633 0.91025692 0.91029682 0.91036147
 0.91035841 0.91038127 0.91047042 0.91045599 0.91053396 0.91051825
 0.91052021 0.91052908 0.91062022 0.91070478 0.91070427 0.91076429
 0.91079498 0.91084635 0.9109245  0.9110092  0.91102688 0.9109948
 0.91105281 0.91113711 0.91117753 0.91127347 0.91128294 0.91126426
 0.91134756 0.91137286 0.91145495 0.9115889  0.91165507 0.91166174
 0.91167513 0.91175674 0.9118084  0.91181379 0.91179391 0.91182842
 0.91184354 0.91189964 0.91192544 0.91197263 0.91206494 0.91215929
 0.91219564 0.91226667 0.91239149 0.91244876 0.91253267 0.91254542
 0.91262013 0.91270625 0.91270064 0.91281222 0.9128675  0.9129837
 0.91306666 0.91318578 0.91329018 0.91342138 0.91356095 0.91360675
 0.91374925 0.91386042 0.91392637 0.9140304  0.91406648 0.91414456
 0.91422498 0.91439724 0.91453246 0.91455903 0.91471307 0.91494098
 0.9149485  0.91503834 0.91532761 0.91557419 0.91563151 0.91587425
 0.91621961 0.91659898 0.91685736 0.91725403]

Passing event 10003 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([-1., -1., -1.,  ..., -1., -1., -1.], device='cuda:0',
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10003 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([-0.0238,  0.0457, -0.0897,  ..., -0.0688,  0.1051, -0.0434],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network before training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([ 1.0000,  1.0000,  1.0000,  ..., -1.0000, -0.9989,  0.9910],
       device='cuda:0', grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10005 from the network after training input tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2551],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3225],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3613]]) 
result1: tensor([-0.0236,  0.0460, -0.0896,  ..., -0.0689,  0.1051, -0.0434],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network before training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([-0.1212,  0.8521,  0.9318,  ..., -0.9991, -0.9263,  0.0834],
       device='cuda:0', grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

Passing event 10007 from the network after training input tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]) 
result1: tensor([-0.0236,  0.0458, -0.0896,  ..., -0.0688,  0.1050, -0.0435],
       grad_fn=<SelectBackward0>) 
result1.shape: torch.Size([6796])

real	19m51.699s
user	21m49.182s
sys	10m28.014s
